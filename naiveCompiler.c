// Generated by Futhark 0.25.24.
// git: 0bb3d37e788daf859346a635efd215ab37aa72f6
// Compiled with GHC 9.6.6.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_f32_1d;
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0);
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data);
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
struct futhark_i32_1d;
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0);
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data);
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);

// Opaque values



// Entry points
int futhark_entry_main(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_f32_1d *in2);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h
#include <getopt.h>
#include <ctype.h>
#include <inttypes.h>
#include <unistd.h>
// Start of values.h.

//// Text I/O

typedef int (*writer)(FILE*, const void*);
typedef int (*bin_reader)(void*);
typedef int (*str_reader)(const char *, void*);

struct array_reader {
  char* elems;
  int64_t n_elems_space;
  int64_t elem_size;
  int64_t n_elems_used;
  int64_t *shape;
  str_reader elem_reader;
};

static void skipspaces(FILE *f) {
  int c;
  do {
    c = getc(f);
  } while (isspace(c));

  if (c != EOF) {
    ungetc(c, f);
  }
}

static int constituent(char c) {
  return isalnum(c) || c == '.' || c == '-' || c == '+' || c == '_';
}

// Produces an empty token only on EOF.
static void next_token(FILE *f, char *buf, int bufsize) {
 start:
  skipspaces(f);

  int i = 0;
  while (i < bufsize) {
    int c = getc(f);
    buf[i] = (char)c;

    if (c == EOF) {
      buf[i] = 0;
      return;
    } else if (c == '-' && i == 1 && buf[0] == '-') {
      // Line comment, so skip to end of line and start over.
      for (; c != '\n' && c != EOF; c = getc(f));
      goto start;
    } else if (!constituent((char)c)) {
      if (i == 0) {
        // We permit single-character tokens that are not
        // constituents; this lets things like ']' and ',' be
        // tokens.
        buf[i+1] = 0;
        return;
      } else {
        ungetc(c, f);
        buf[i] = 0;
        return;
      }
    }

    i++;
  }

  buf[bufsize-1] = 0;
}

static int next_token_is(FILE *f, char *buf, int bufsize, const char* expected) {
  next_token(f, buf, bufsize);
  return strcmp(buf, expected) == 0;
}

static void remove_underscores(char *buf) {
  char *w = buf;

  for (char *r = buf; *r; r++) {
    if (*r != '_') {
      *w++ = *r;
    }
  }

  *w++ = 0;
}

static int read_str_elem(char *buf, struct array_reader *reader) {
  int ret;
  if (reader->n_elems_used == reader->n_elems_space) {
    reader->n_elems_space *= 2;
    reader->elems = (char*) realloc(reader->elems,
                                    (size_t)(reader->n_elems_space * reader->elem_size));
  }

  ret = reader->elem_reader(buf, reader->elems + reader->n_elems_used * reader->elem_size);

  if (ret == 0) {
    reader->n_elems_used++;
  }

  return ret;
}

static int read_str_array_elems(FILE *f,
                                char *buf, int bufsize,
                                struct array_reader *reader, int64_t dims) {
  int ret = 1;
  int expect_elem = 1;
  char *knows_dimsize = (char*) calloc((size_t)dims, sizeof(char));
  int cur_dim = (int)dims-1;
  int64_t *elems_read_in_dim = (int64_t*) calloc((size_t)dims, sizeof(int64_t));

  while (1) {
    next_token(f, buf, bufsize);
    if (strcmp(buf, "]") == 0) {
      expect_elem = 0;
      if (knows_dimsize[cur_dim]) {
        if (reader->shape[cur_dim] != elems_read_in_dim[cur_dim]) {
          ret = 1;
          break;
        }
      } else {
        knows_dimsize[cur_dim] = 1;
        reader->shape[cur_dim] = elems_read_in_dim[cur_dim];
      }
      if (cur_dim == 0) {
        ret = 0;
        break;
      } else {
        cur_dim--;
        elems_read_in_dim[cur_dim]++;
      }
    } else if (!expect_elem && strcmp(buf, ",") == 0) {
      expect_elem = 1;
    } else if (expect_elem) {
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else if (cur_dim == dims - 1) {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        expect_elem = 0;
        elems_read_in_dim[cur_dim]++;
      } else {
        ret = 1;
        break;
      }
    } else {
      ret = 1;
      break;
    }
  }

  free(knows_dimsize);
  free(elems_read_in_dim);
  return ret;
}

static int read_str_empty_array(FILE *f, char *buf, int bufsize,
                                const char *type_name, int64_t *shape, int64_t dims) {
  if (strlen(buf) == 0) {
    // EOF
    return 1;
  }

  if (strcmp(buf, "empty") != 0) {
    return 1;
  }

  if (!next_token_is(f, buf, bufsize, "(")) {
    return 1;
  }

  for (int i = 0; i < dims; i++) {
    if (!next_token_is(f, buf, bufsize, "[")) {
      return 1;
    }

    next_token(f, buf, bufsize);

    if (sscanf(buf, "%"SCNu64, (uint64_t*)&shape[i]) != 1) {
      return 1;
    }

    if (!next_token_is(f, buf, bufsize, "]")) {
      return 1;
    }
  }

  if (!next_token_is(f, buf, bufsize, type_name)) {
    return 1;
  }


  if (!next_token_is(f, buf, bufsize, ")")) {
    return 1;
  }

  // Check whether the array really is empty.
  for (int i = 0; i < dims; i++) {
    if (shape[i] == 0) {
      return 0;
    }
  }

  // Not an empty array!
  return 1;
}

static int read_str_array(FILE *f,
                          int64_t elem_size, str_reader elem_reader,
                          const char *type_name,
                          void **data, int64_t *shape, int64_t dims) {
  int ret;
  struct array_reader reader;
  char buf[100];

  int dims_seen;
  for (dims_seen = 0; dims_seen < dims; dims_seen++) {
    if (!next_token_is(f, buf, sizeof(buf), "[")) {
      break;
    }
  }

  if (dims_seen == 0) {
    return read_str_empty_array(f, buf, sizeof(buf), type_name, shape, dims);
  }

  if (dims_seen != dims) {
    return 1;
  }

  reader.shape = shape;
  reader.n_elems_used = 0;
  reader.elem_size = elem_size;
  reader.n_elems_space = 16;
  reader.elems = (char*) realloc(*data, (size_t)(elem_size*reader.n_elems_space));
  reader.elem_reader = elem_reader;

  ret = read_str_array_elems(f, buf, sizeof(buf), &reader, dims);

  *data = reader.elems;

  return ret;
}

#define READ_STR(MACRO, PTR, SUFFIX)                                   \
  remove_underscores(buf);                                              \
  int j;                                                                \
  if (sscanf(buf, "%"MACRO"%n", (PTR*)dest, &j) == 1) {                 \
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, SUFFIX) == 0);     \
  } else {                                                              \
    return 1;                                                           \
  }

static int read_str_i8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNi8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(int8_t*)dest = (int8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "i8") == 0);
  } else {
    return 1;
  }
}

static int read_str_u8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNu8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(uint8_t*)dest = (uint8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "u8") == 0);
  } else {
    return 1;
  }
}

static int read_str_i16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "i16");
}

static int read_str_u16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "u16");
}

static int read_str_i32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "i32");
}

static int read_str_u32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "u32");
}

static int read_str_i64(char *buf, void* dest) {
  READ_STR(SCNi64, int64_t, "i64");
}

static int read_str_u64(char *buf, void* dest) {
  // FIXME: This is not correct, as SCNu64 only permits decimal
  // literals.  However, SCNi64 does not handle very large numbers
  // correctly (it's really for signed numbers, so that's fair).
  READ_STR(SCNu64, uint64_t, "u64");
}

static int read_str_f16(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f16.nan") == 0) {
    *(uint16_t*)dest = float2halfbits(NAN);
    return 0;
  } else if (strcmp(buf, "f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(INFINITY);
    return 0;
  } else if (strcmp(buf, "-f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(-INFINITY);
    return 0;
  } else {
    int j;
    float x;
    if (sscanf(buf, "%f%n", &x, &j) == 1) {
      if (strcmp(buf+j, "") == 0 || strcmp(buf+j, "f16") == 0) {
        *(uint16_t*)dest = float2halfbits(x);
        return 0;
      }
    }
    return 1;
  }
}

static int read_str_f32(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f32.nan") == 0) {
    *(float*)dest = (float)NAN;
    return 0;
  } else if (strcmp(buf, "f32.inf") == 0) {
    *(float*)dest = (float)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f32.inf") == 0) {
    *(float*)dest = (float)-INFINITY;
    return 0;
  } else {
    READ_STR("f", float, "f32");
  }
}

static int read_str_f64(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f64.nan") == 0) {
    *(double*)dest = (double)NAN;
    return 0;
  } else if (strcmp(buf, "f64.inf") == 0) {
    *(double*)dest = (double)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f64.inf") == 0) {
    *(double*)dest = (double)-INFINITY;
    return 0;
  } else {
    READ_STR("lf", double, "f64");
  }
}

static int read_str_bool(char *buf, void* dest) {
  if (strcmp(buf, "true") == 0) {
    *(char*)dest = 1;
    return 0;
  } else if (strcmp(buf, "false") == 0) {
    *(char*)dest = 0;
    return 0;
  } else {
    return 1;
  }
}

static int write_str_i8(FILE *out, int8_t *src) {
  return fprintf(out, "%hhdi8", *src);
}

static int write_str_u8(FILE *out, uint8_t *src) {
  return fprintf(out, "%hhuu8", *src);
}

static int write_str_i16(FILE *out, int16_t *src) {
  return fprintf(out, "%hdi16", *src);
}

static int write_str_u16(FILE *out, uint16_t *src) {
  return fprintf(out, "%huu16", *src);
}

static int write_str_i32(FILE *out, int32_t *src) {
  return fprintf(out, "%di32", *src);
}

static int write_str_u32(FILE *out, uint32_t *src) {
  return fprintf(out, "%uu32", *src);
}

static int write_str_i64(FILE *out, int64_t *src) {
  return fprintf(out, "%"PRIi64"i64", *src);
}

static int write_str_u64(FILE *out, uint64_t *src) {
  return fprintf(out, "%"PRIu64"u64", *src);
}

static int write_str_f16(FILE *out, uint16_t *src) {
  float x = halfbits2float(*src);
  if (isnan(x)) {
    return fprintf(out, "f16.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f16.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f16.inf");
  } else {
    return fprintf(out, "%.*ff16", FLT_DIG, x);
  }
}

static int write_str_f32(FILE *out, float *src) {
  float x = *src;
  if (isnan(x)) {
    return fprintf(out, "f32.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f32.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f32.inf");
  } else {
    return fprintf(out, "%.*ff32", FLT_DIG, x);
  }
}

static int write_str_f64(FILE *out, double *src) {
  double x = *src;
  if (isnan(x)) {
    return fprintf(out, "f64.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f64.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f64.inf");
  } else {
    return fprintf(out, "%.*ff64", DBL_DIG, x);
  }
}

static int write_str_bool(FILE *out, void *src) {
  return fprintf(out, *(char*)src ? "true" : "false");
}

//// Binary I/O

#define BINARY_FORMAT_VERSION 2
#define IS_BIG_ENDIAN (!*(unsigned char *)&(uint16_t){1})

static void flip_bytes(size_t elem_size, unsigned char *elem) {
  for (size_t j=0; j<elem_size/2; j++) {
    unsigned char head = elem[j];
    size_t tail_index = elem_size-1-j;
    elem[j] = elem[tail_index];
    elem[tail_index] = head;
  }
}

// On Windows we need to explicitly set the file mode to not mangle
// newline characters.  On *nix there is no difference.
#ifdef _WIN32
#include <io.h>
#include <fcntl.h>
static void set_binary_mode(FILE *f) {
  setmode(fileno(f), O_BINARY);
}
#else
static void set_binary_mode(FILE *f) {
  (void)f;
}
#endif

static int read_byte(FILE *f, void* dest) {
  size_t num_elems_read = fread(dest, 1, 1, f);
  return num_elems_read == 1 ? 0 : 1;
}

//// Types

struct primtype_info_t {
  const char binname[4]; // Used for parsing binary data.
  const char* type_name; // Same name as in Futhark.
  const int64_t size; // in bytes
  const writer write_str; // Write in text format.
  const str_reader read_str; // Read in text format.
};

static const struct primtype_info_t i8_info =
  {.binname = "  i8", .type_name = "i8",   .size = 1,
   .write_str = (writer)write_str_i8, .read_str = (str_reader)read_str_i8};
static const struct primtype_info_t i16_info =
  {.binname = " i16", .type_name = "i16",  .size = 2,
   .write_str = (writer)write_str_i16, .read_str = (str_reader)read_str_i16};
static const struct primtype_info_t i32_info =
  {.binname = " i32", .type_name = "i32",  .size = 4,
   .write_str = (writer)write_str_i32, .read_str = (str_reader)read_str_i32};
static const struct primtype_info_t i64_info =
  {.binname = " i64", .type_name = "i64",  .size = 8,
   .write_str = (writer)write_str_i64, .read_str = (str_reader)read_str_i64};
static const struct primtype_info_t u8_info =
  {.binname = "  u8", .type_name = "u8",   .size = 1,
   .write_str = (writer)write_str_u8, .read_str = (str_reader)read_str_u8};
static const struct primtype_info_t u16_info =
  {.binname = " u16", .type_name = "u16",  .size = 2,
   .write_str = (writer)write_str_u16, .read_str = (str_reader)read_str_u16};
static const struct primtype_info_t u32_info =
  {.binname = " u32", .type_name = "u32",  .size = 4,
   .write_str = (writer)write_str_u32, .read_str = (str_reader)read_str_u32};
static const struct primtype_info_t u64_info =
  {.binname = " u64", .type_name = "u64",  .size = 8,
   .write_str = (writer)write_str_u64, .read_str = (str_reader)read_str_u64};
static const struct primtype_info_t f16_info =
  {.binname = " f16", .type_name = "f16",  .size = 2,
   .write_str = (writer)write_str_f16, .read_str = (str_reader)read_str_f16};
static const struct primtype_info_t f32_info =
  {.binname = " f32", .type_name = "f32",  .size = 4,
   .write_str = (writer)write_str_f32, .read_str = (str_reader)read_str_f32};
static const struct primtype_info_t f64_info =
  {.binname = " f64", .type_name = "f64",  .size = 8,
   .write_str = (writer)write_str_f64, .read_str = (str_reader)read_str_f64};
static const struct primtype_info_t bool_info =
  {.binname = "bool", .type_name = "bool", .size = 1,
   .write_str = (writer)write_str_bool, .read_str = (str_reader)read_str_bool};

static const struct primtype_info_t* primtypes[] = {
  &i8_info, &i16_info, &i32_info, &i64_info,
  &u8_info, &u16_info, &u32_info, &u64_info,
  &f16_info, &f32_info, &f64_info,
  &bool_info,
  NULL // NULL-terminated
};

// General value interface.  All endian business taken care of at
// lower layers.

static int read_is_binary(FILE *f) {
  skipspaces(f);
  int c = getc(f);
  if (c == 'b') {
    int8_t bin_version;
    int ret = read_byte(f, &bin_version);

    if (ret != 0) { futhark_panic(1, "binary-input: could not read version.\n"); }

    if (bin_version != BINARY_FORMAT_VERSION) {
      futhark_panic(1, "binary-input: File uses version %i, but I only understand version %i.\n",
            bin_version, BINARY_FORMAT_VERSION);
    }

    return 1;
  }
  ungetc(c, f);
  return 0;
}

static const struct primtype_info_t* read_bin_read_type_enum(FILE *f) {
  char read_binname[4];

  int num_matched = fscanf(f, "%4c", read_binname);
  if (num_matched != 1) { futhark_panic(1, "binary-input: Couldn't read element type.\n"); }

  const struct primtype_info_t **type = primtypes;

  for (; *type != NULL; type++) {
    // I compare the 4 characters manually instead of using strncmp because
    // this allows any value to be used, also NULL bytes
    if (memcmp(read_binname, (*type)->binname, 4) == 0) {
      return *type;
    }
  }
  futhark_panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname);
  return NULL;
}

static void read_bin_ensure_scalar(FILE *f, const struct primtype_info_t *expected_type) {
  int8_t bin_dims;
  int ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != 0) {
    futhark_panic(1, "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
          bin_dims);
  }

  const struct primtype_info_t *bin_type = read_bin_read_type_enum(f);
  if (bin_type != expected_type) {
    futhark_panic(1, "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
          expected_type->type_name,
          bin_type->type_name);
  }
}

//// High-level interface

static int read_bin_array(FILE *f,
                          const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  int ret;

  int8_t bin_dims;
  ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != dims) {
    futhark_panic(1, "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
          dims, bin_dims);
  }

  const struct primtype_info_t *bin_primtype = read_bin_read_type_enum(f);
  if (expected_type != bin_primtype) {
    futhark_panic(1, "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
          dims, expected_type->type_name, dims, bin_primtype->type_name);
  }

  int64_t elem_count = 1;
  for (int i=0; i<dims; i++) {
    int64_t bin_shape;
    ret = (int)fread(&bin_shape, sizeof(bin_shape), 1, f);
    if (ret != 1) {
      futhark_panic(1, "binary-input: Couldn't read size for dimension %i of array.\n", i);
    }
    if (IS_BIG_ENDIAN) {
      flip_bytes(sizeof(bin_shape), (unsigned char*) &bin_shape);
    }
    elem_count *= bin_shape;
    shape[i] = bin_shape;
  }

  int64_t elem_size = expected_type->size;
  void* tmp = realloc(*data, (size_t)(elem_count * elem_size));
  if (tmp == NULL) {
    futhark_panic(1, "binary-input: Failed to allocate array of size %i.\n",
          elem_count * elem_size);
  }
  *data = tmp;

  int64_t num_elems_read = (int64_t)fread(*data, (size_t)elem_size, (size_t)elem_count, f);
  if (num_elems_read != elem_count) {
    futhark_panic(1, "binary-input: tried to read %i elements of an array, but only got %i elements.\n",
          elem_count, num_elems_read);
  }

  // If we're on big endian platform we must change all multibyte elements
  // from using little endian to big endian
  if (IS_BIG_ENDIAN && elem_size != 1) {
    flip_bytes((size_t)elem_size, (unsigned char*) *data);
  }

  return 0;
}

static int read_array(FILE *f, const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  if (!read_is_binary(f)) {
    return read_str_array(f, expected_type->size, (str_reader)expected_type->read_str, expected_type->type_name, data, shape, dims);
  } else {
    return read_bin_array(f, expected_type, data, shape, dims);
  }
}

static int end_of_input(FILE *f) {
  skipspaces(f);
  char token[2];
  next_token(f, token, sizeof(token));
  if (strcmp(token, "") == 0) {
    return 0;
  } else {
    return 1;
  }
}

static int write_str_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  if (rank==0) {
    elem_type->write_str(out, (const void*)data);
  } else {
    int64_t len = (int64_t)shape[0];
    int64_t slice_size = 1;

    int64_t elem_size = elem_type->size;
    for (int8_t i = 1; i < rank; i++) {
      slice_size *= shape[i];
    }

    if (len*slice_size == 0) {
      fprintf(out, "empty(");
      for (int64_t i = 0; i < rank; i++) {
        fprintf(out, "[%"PRIi64"]", shape[i]);
      }
      fprintf(out, "%s", elem_type->type_name);
      fprintf(out, ")");
    } else if (rank==1) {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        elem_type->write_str(out, (const void*) (data + i * elem_size));
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    } else {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        write_str_array(out, elem_type, data + i * slice_size * elem_size, shape+1, rank-1);
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    }
  }
  return 0;
}

static int write_bin_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  int64_t num_elems = 1;
  for (int64_t i = 0; i < rank; i++) {
    num_elems *= shape[i];
  }

  fputc('b', out);
  fputc((char)BINARY_FORMAT_VERSION, out);
  fwrite(&rank, sizeof(int8_t), 1, out);
  fwrite(elem_type->binname, 4, 1, out);
  if (shape != NULL) {
    fwrite(shape, sizeof(int64_t), (size_t)rank, out);
  }

  if (IS_BIG_ENDIAN) {
    for (int64_t i = 0; i < num_elems; i++) {
      const unsigned char *elem = data+i*elem_type->size;
      for (int64_t j = 0; j < elem_type->size; j++) {
        fwrite(&elem[elem_type->size-j], 1, 1, out);
      }
    }
  } else {
    fwrite(data, (size_t)elem_type->size, (size_t)num_elems, out);
  }

  return 0;
}

static int write_array(FILE *out, int write_binary,
                       const struct primtype_info_t *elem_type,
                       const void *data,
                       const int64_t *shape,
                       const int8_t rank) {
  if (write_binary) {
    return write_bin_array(out, elem_type, data, shape, rank);
  } else {
    return write_str_array(out, elem_type, data, shape, rank);
  }
}

static int read_scalar(FILE *f,
                       const struct primtype_info_t *expected_type, void *dest) {
  if (!read_is_binary(f)) {
    char buf[100];
    next_token(f, buf, sizeof(buf));
    return expected_type->read_str(buf, dest);
  } else {
    read_bin_ensure_scalar(f, expected_type);
    size_t elem_size = (size_t)expected_type->size;
    size_t num_elems_read = fread(dest, elem_size, 1, f);
    if (IS_BIG_ENDIAN) {
      flip_bytes(elem_size, (unsigned char*) dest);
    }
    return num_elems_read == 1 ? 0 : 1;
  }
}

static int write_scalar(FILE *out, int write_binary, const struct primtype_info_t *type, void *src) {
  if (write_binary) {
    return write_bin_array(out, type, src, NULL, 0);
  } else {
    return type->write_str(out, src);
  }
}

// End of values.h.

static int binary_output = 0;
static int print_result = 1;
static FILE *runtime_file;
static int perform_warmup = 0;
static int num_runs = 1;
static const char *entry_point = "main";
// Start of tuning.h.


int is_blank_line_or_comment(const char *s) {
  size_t i = strspn(s, " \t\n");
  return s[i] == '\0' || // Line is blank.
         strncmp(s + i, "--", 2) == 0; // Line is comment.
}

static char* load_tuning_file(const char *fname,
                              void *cfg,
                              int (*set_tuning_param)(void*, const char*, size_t)) {
  const int max_line_len = 1024;
  char* line = (char*) malloc(max_line_len);

  FILE *f = fopen(fname, "r");

  if (f == NULL) {
    snprintf(line, max_line_len, "Cannot open file: %s", strerror(errno));
    return line;
  }

  int lineno = 0;
  while (fgets(line, max_line_len, f) != NULL) {
    lineno++;
    if (is_blank_line_or_comment(line)) {
      continue;
    }
    char *eql = strstr(line, "=");
    if (eql) {
      *eql = 0;
      char *endptr;
      int value = strtol(eql+1, &endptr, 10);
      if (*endptr && *endptr != '\n') {
        snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
                 lineno);
        return line;
      }
      if (set_tuning_param(cfg, line, (size_t)value) != 0) {
        char* err = (char*) malloc(max_line_len + 50);
        snprintf(err, max_line_len + 50, "Unknown name '%s' on line %d.", line, lineno);
        free(line);
        return err;
      }
    } else {
      snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
               lineno);
      return line;
    }
  }

  free(line);

  return NULL;
}

// End of tuning.h.

int parse_options(struct futhark_context_config *cfg, int argc, char *const argv[])
{
    int ch;
    static struct option long_options[] = {{"write-runtime-to", required_argument, NULL, 1}, {"runs", required_argument, NULL, 2}, {"debugging", no_argument, NULL, 3}, {"log", no_argument, NULL, 4}, {"profile", no_argument, NULL, 5}, {"entry-point", required_argument, NULL, 6}, {"binary-output", no_argument, NULL, 7}, {"no-print-result", no_argument, NULL, 8}, {"help", no_argument, NULL, 9}, {"print-params", no_argument, NULL, 10}, {"param", required_argument, NULL, 11}, {"tuning", required_argument, NULL, 12}, {"cache-file", required_argument, NULL, 13}, {"device", required_argument, NULL, 14}, {"default-thread-block-size", required_argument, NULL, 15}, {"default-grid-size", required_argument, NULL, 16}, {"default-group-size", required_argument, NULL, 17}, {"default-num-groups", required_argument, NULL, 18}, {"default-tile-size", required_argument, NULL, 19}, {"default-reg-tile-size", required_argument, NULL, 20}, {"default-registers", required_argument, NULL, 21}, {"default-cache", required_argument, NULL, 22}, {"default-threshold", required_argument, NULL, 23}, {"unified-memory", required_argument, NULL, 24}, {"dump-cuda", required_argument, NULL, 25}, {"load-cuda", required_argument, NULL, 26}, {"dump-ptx", required_argument, NULL, 27}, {"load-ptx", required_argument, NULL, 28}, {"nvrtc-option", required_argument, NULL, 29}, {0, 0, 0, 0}};
    static char *option_descriptions = "  -t/--write-runtime-to FILE      Print the time taken to execute the program to the indicated file, an integral number of microseconds.\n  -r/--runs INT                   Perform NUM runs of the program.\n  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information to stderr while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -e/--entry-point NAME           The entry point to run. Defaults to main.\n  -b/--binary-output              Print the program result in the binary output format.\n  -n/--no-print-result            Do not print the program result.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n";
    
    while ((ch = getopt_long(argc, argv, ":t:r:DLPe:bnhd:", long_options, NULL)) != -1) {
        if (ch == 1 || ch == 't') {
            runtime_file = fopen(optarg, "w");
            if (runtime_file == NULL)
                futhark_panic(1, "Cannot open %s: %s\n", optarg, strerror(errno));
        }
        if (ch == 2 || ch == 'r') {
            num_runs = atoi(optarg);
            perform_warmup = 1;
            if (num_runs <= 0)
                futhark_panic(1, "Need a positive number of runs, not %s\n", optarg);
        }
        if (ch == 3 || ch == 'D')
            futhark_context_config_set_debugging(cfg, 1);
        if (ch == 4 || ch == 'L')
            futhark_context_config_set_logging(cfg, 1);
        if (ch == 5 || ch == 'P')
            futhark_context_config_set_profiling(cfg, 1);
        if (ch == 6 || ch == 'e') {
            if (entry_point != NULL)
                entry_point = optarg;
        }
        if (ch == 7 || ch == 'b')
            binary_output = 1;
        if (ch == 8 || ch == 'n')
            print_result = 0;
        if (ch == 9 || ch == 'h') {
            printf("Usage: %s [OPTION]...\nOptions:\n\n%s\nFor more information, consult the Futhark User's Guide or the man pages.\n", fut_progname, option_descriptions);
            exit(0);
        }
        if (ch == 10) {
            int n = futhark_get_tuning_param_count();
            
            for (int i = 0; i < n; i++)
                printf("%s (%s)\n", futhark_get_tuning_param_name(i), futhark_get_tuning_param_class(i));
            exit(0);
        }
        if (ch == 11) {
            char *name = optarg;
            char *equals = strstr(optarg, "=");
            char *value_str = equals != NULL ? equals + 1 : optarg;
            int value = atoi(value_str);
            
            if (equals != NULL) {
                *equals = 0;
                if (futhark_context_config_set_tuning_param(cfg, name, (size_t) value) != 0)
                    futhark_panic(1, "Unknown size: %s\n", name);
            } else
                futhark_panic(1, "Invalid argument for size option: %s\n", optarg);
        }
        if (ch == 12) {
            char *ret = load_tuning_file(optarg, cfg, (int (*)(void *, const char *, size_t)) futhark_context_config_set_tuning_param);
            
            if (ret != NULL)
                futhark_panic(1, "When loading tuning file '%s': %s\n", optarg, ret);
        }
        if (ch == 13)
            futhark_context_config_set_cache_file(cfg, optarg);
        if (ch == 14 || ch == 'd')
            futhark_context_config_set_device(cfg, optarg);
        if (ch == 15)
            futhark_context_config_set_default_thread_block_size(cfg, atoi(optarg));
        if (ch == 16)
            futhark_context_config_set_default_grid_size(cfg, atoi(optarg));
        if (ch == 17)
            futhark_context_config_set_default_group_size(cfg, atoi(optarg));
        if (ch == 18)
            futhark_context_config_set_default_num_groups(cfg, atoi(optarg));
        if (ch == 19)
            futhark_context_config_set_default_tile_size(cfg, atoi(optarg));
        if (ch == 20)
            futhark_context_config_set_default_reg_tile_size(cfg, atoi(optarg));
        if (ch == 21)
            futhark_context_config_set_default_registers(cfg, atoi(optarg));
        if (ch == 22)
            futhark_context_config_set_default_cache(cfg, atoi(optarg));
        if (ch == 23)
            futhark_context_config_set_default_threshold(cfg, atoi(optarg));
        if (ch == 24)
            futhark_context_config_set_unified_memory(cfg, atoi(optarg));
        if (ch == 25) {
            const char *prog = futhark_context_config_get_program(cfg);
            
            if (dump_file(optarg, prog, strlen(prog)) != 0) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            exit(0);
        }
        if (ch == 26) {
            size_t n;
            const char *s = slurp_file(optarg, &n);
            
            if (s == NULL) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            futhark_context_config_set_program(cfg, s);
        }
        if (ch == 27) {
            futhark_context_config_dump_ptx_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 28)
            futhark_context_config_load_ptx_from(cfg, optarg);
        if (ch == 29)
            futhark_context_config_add_nvrtc_option(cfg, optarg);
        if (ch == ':')
            futhark_panic(-1, "Missing argument for option %s\n", argv[optind - 1]);
        if (ch == '?') {
            fprintf(stderr, "Usage: %s [OPTIONS]...\nOptions:\n\n%s\n", fut_progname, "  -t/--write-runtime-to FILE      Print the time taken to execute the program to the indicated file, an integral number of microseconds.\n  -r/--runs INT                   Perform NUM runs of the program.\n  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information to stderr while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -e/--entry-point NAME           The entry point to run. Defaults to main.\n  -b/--binary-output              Print the program result in the binary output format.\n  -n/--no-print-result            Do not print the program result.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n");
            futhark_panic(1, "Unknown option: %s\n", argv[optind - 1]);
        }
    }
    return optind;
}
static int futrts_cli_entry_main(struct futhark_context *ctx)
{
    int64_t t_start, t_end;
    int time_runs = 0, profile_run = 0;
    int retval = 0;
    
    // We do not want to profile all the initialisation.
    futhark_context_pause_profiling(ctx);
    // Declare and read input.
    set_binary_mode(stdin);
    
    struct futhark_i32_1d * read_value_0;
    int64_t read_shape_0[1];
    int32_t *read_arr_0 = NULL;
    
    errno = 0;
    if (read_array(stdin, &i32_info, (void **) &read_arr_0, read_shape_0, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 0, "[]i32", strerror(errno));
    
    struct futhark_i32_1d * read_value_1;
    int64_t read_shape_1[1];
    int32_t *read_arr_1 = NULL;
    
    errno = 0;
    if (read_array(stdin, &i32_info, (void **) &read_arr_1, read_shape_1, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 1, "[]i32", strerror(errno));
    
    struct futhark_f32_1d * read_value_2;
    int64_t read_shape_2[1];
    float *read_arr_2 = NULL;
    
    errno = 0;
    if (read_array(stdin, &f32_info, (void **) &read_arr_2, read_shape_2, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 2, "[]f32", strerror(errno));
    if (end_of_input(stdin) != 0)
        futhark_panic(1, "Expected EOF on stdin after reading input for \"%s\".\n", "main");
    
    struct futhark_f32_1d * result_0;
    
    if (perform_warmup) {
        int r;
        
        assert((read_value_0 = futhark_new_i32_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_i32_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_f32_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_main(ctx, &result_0, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_i32_1d(ctx, read_value_0) == 0);
        assert(futhark_free_i32_1d(ctx, read_value_1) == 0);
        assert(futhark_free_f32_1d(ctx, read_value_2) == 0);
        assert(futhark_free_f32_1d(ctx, result_0) == 0);
    }
    time_runs = 1;
    // Proper run.
    for (int run = 0; run < num_runs; run++) {
        // Only profile last run.
        profile_run = run == num_runs - 1;
        
        int r;
        
        assert((read_value_0 = futhark_new_i32_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_i32_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_f32_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_main(ctx, &result_0, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_i32_1d(ctx, read_value_0) == 0);
        assert(futhark_free_i32_1d(ctx, read_value_1) == 0);
        assert(futhark_free_f32_1d(ctx, read_value_2) == 0);
        if (run < num_runs - 1) {
            assert(futhark_free_f32_1d(ctx, result_0) == 0);
        }
    }
    free(read_arr_0);
    free(read_arr_1);
    free(read_arr_2);
    if (print_result) {
        // Print the final result.
        if (binary_output)
            set_binary_mode(stdout);
        {
            float *arr = calloc(futhark_shape_f32_1d(ctx, result_0)[0], f32_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_f32_1d(ctx, result_0, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &f32_info, arr, futhark_shape_f32_1d(ctx, result_0), 1);
            free(arr);
        }
        printf("\n");
    }
    
  print_end:
    { }
    assert(futhark_free_f32_1d(ctx, result_0) == 0);
    return retval;
}
typedef int entry_point_fun(struct futhark_context *);
struct entry_point_entry {
    const char *name;
    entry_point_fun *fun;
};
int main(int argc, char **argv)
{
    int retval = 0;
    
    fut_progname = argv[0];
    
    struct futhark_context_config *cfg = futhark_context_config_new();
    
    assert(cfg != NULL);
    
    int parsed_options = parse_options(cfg, argc, argv);
    
    argc -= parsed_options;
    argv += parsed_options;
    if (argc != 0)
        futhark_panic(1, "Excess non-option: %s\n", argv[0]);
    
    struct futhark_context *ctx = futhark_context_new(cfg);
    
    assert(ctx != NULL);
    
    char *error = futhark_context_get_error(ctx);
    
    if (error != NULL)
        futhark_panic(1, "%s", error);
    
    struct entry_point_entry entry_points[] = {{.name ="main", .fun =futrts_cli_entry_main}};
    
    if (entry_point != NULL) {
        int num_entry_points = sizeof(entry_points) / sizeof(entry_points[0]);
        entry_point_fun *entry_point_fun = NULL;
        
        for (int i = 0; i < num_entry_points; i++) {
            if (strcmp(entry_points[i].name, entry_point) == 0) {
                entry_point_fun = entry_points[i].fun;
                break;
            }
        }
        if (entry_point_fun == NULL) {
            fprintf(stderr, "No entry point '%s'.  Select another with --entry-point.  Options are:\n", entry_point);
            for (int i = 0; i < num_entry_points; i++)
                fprintf(stderr, "%s\n", entry_points[i].name);
            return 1;
        }
        if (isatty(fileno(stdin))) {
            fprintf(stderr, "Reading input from TTY.\n");
            fprintf(stderr, "Send EOF (CTRL-d) after typing all input values.\n");
        }
        retval = entry_point_fun(ctx);
        if (runtime_file != NULL)
            fclose(runtime_file);
    }
    futhark_context_free(ctx);
    futhark_context_config_free(cfg);
    return retval;
}

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_17243;
    struct memblock_device counters_mem_17420;
    struct memblock_device global_dynid_mem_17132;
    struct memblock_device global_dynid_mem_17135;
    struct memblock_device global_dynid_mem_17338;
    struct memblock_device global_dynid_mem_17475;
    struct memblock_device global_dynid_mem_17508;
    struct memblock_device global_dynid_mem_17738;
    struct memblock_device global_dynid_mem_18233;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhreplicate_boolzitblock_sizze_17299;
    int64_t *builtinzhreplicate_i32zitblock_sizze_17146;
    int64_t *builtinzhreplicate_i64zitblock_sizze_17449;
    int64_t *builtinzhreplicate_i8zitblock_sizze_17116;
    int64_t *mainzisegmap_num_tblocks_16605;
    int64_t *mainzisegmap_num_tblocks_16814;
    int64_t *mainzisegmap_num_tblocks_16822;
    int64_t *mainzisegmap_num_tblocks_16864;
    int64_t *mainzisegmap_num_tblocks_16872;
    int64_t *mainzisegmap_tblock_sizze_16603;
    int64_t *mainzisegmap_tblock_sizze_16619;
    int64_t *mainzisegmap_tblock_sizze_16639;
    int64_t *mainzisegmap_tblock_sizze_16674;
    int64_t *mainzisegmap_tblock_sizze_16812;
    int64_t *mainzisegmap_tblock_sizze_16820;
    int64_t *mainzisegmap_tblock_sizze_16862;
    int64_t *mainzisegmap_tblock_sizze_16870;
    int64_t *mainzisegmap_tblock_sizze_16878;
    int64_t *mainzisegscan_num_tblocks_16595;
    int64_t *mainzisegscan_num_tblocks_16611;
    int64_t *mainzisegscan_num_tblocks_16713;
    int64_t *mainzisegscan_num_tblocks_16721;
    int64_t *mainzisegscan_num_tblocks_16854;
    int64_t *mainzisegscan_tblock_sizze_16593;
    int64_t *mainzisegscan_tblock_sizze_16609;
    int64_t *mainzisegscan_tblock_sizze_16711;
    int64_t *mainzisegscan_tblock_sizze_16719;
    int64_t *mainzisegscan_tblock_sizze_16852;
    int64_t *replicated_iota_6108zihist_L2_17359;
    int64_t *replicated_iota_6108zihist_L_17306;
    int64_t *replicated_iota_6108ziseghist_num_tblocks_16568;
    int64_t *replicated_iota_6108ziseghist_tblock_sizze_16566;
    int64_t *replicated_iota_6108zisegred_num_tblocks_16558;
    int64_t *replicated_iota_6108zisegred_tblock_sizze_16556;
    int64_t *replicated_iota_6108zisegscan_num_tblocks_16550;
    int64_t *replicated_iota_6108zisegscan_num_tblocks_16587;
    int64_t *replicated_iota_6108zisegscan_tblock_sizze_16548;
    int64_t *replicated_iota_6108zisegscan_tblock_sizze_16585;
};
static const int num_tuning_params = 38;
static const char *tuning_param_names[] = {"builtin#replicate_bool.tblock_size_17299", "builtin#replicate_i32.tblock_size_17146", "builtin#replicate_i64.tblock_size_17449", "builtin#replicate_i8.tblock_size_17116", "main.segmap_num_tblocks_16605", "main.segmap_num_tblocks_16814", "main.segmap_num_tblocks_16822", "main.segmap_num_tblocks_16864", "main.segmap_num_tblocks_16872", "main.segmap_tblock_size_16603", "main.segmap_tblock_size_16619", "main.segmap_tblock_size_16639", "main.segmap_tblock_size_16674", "main.segmap_tblock_size_16812", "main.segmap_tblock_size_16820", "main.segmap_tblock_size_16862", "main.segmap_tblock_size_16870", "main.segmap_tblock_size_16878", "main.segscan_num_tblocks_16595", "main.segscan_num_tblocks_16611", "main.segscan_num_tblocks_16713", "main.segscan_num_tblocks_16721", "main.segscan_num_tblocks_16854", "main.segscan_tblock_size_16593", "main.segscan_tblock_size_16609", "main.segscan_tblock_size_16711", "main.segscan_tblock_size_16719", "main.segscan_tblock_size_16852", "replicated_iota_6108.hist_L2_17359", "replicated_iota_6108.hist_L_17306", "replicated_iota_6108.seghist_num_tblocks_16568", "replicated_iota_6108.seghist_tblock_size_16566", "replicated_iota_6108.segred_num_tblocks_16558", "replicated_iota_6108.segred_tblock_size_16556", "replicated_iota_6108.segscan_num_tblocks_16550", "replicated_iota_6108.segscan_num_tblocks_16587", "replicated_iota_6108.segscan_tblock_size_16548", "replicated_iota_6108.segscan_tblock_size_16585", NULL};
static const char *tuning_param_vars[] = {"builtinzhreplicate_boolzitblock_sizze_17299", "builtinzhreplicate_i32zitblock_sizze_17146", "builtinzhreplicate_i64zitblock_sizze_17449", "builtinzhreplicate_i8zitblock_sizze_17116", "mainzisegmap_num_tblocks_16605", "mainzisegmap_num_tblocks_16814", "mainzisegmap_num_tblocks_16822", "mainzisegmap_num_tblocks_16864", "mainzisegmap_num_tblocks_16872", "mainzisegmap_tblock_sizze_16603", "mainzisegmap_tblock_sizze_16619", "mainzisegmap_tblock_sizze_16639", "mainzisegmap_tblock_sizze_16674", "mainzisegmap_tblock_sizze_16812", "mainzisegmap_tblock_sizze_16820", "mainzisegmap_tblock_sizze_16862", "mainzisegmap_tblock_sizze_16870", "mainzisegmap_tblock_sizze_16878", "mainzisegscan_num_tblocks_16595", "mainzisegscan_num_tblocks_16611", "mainzisegscan_num_tblocks_16713", "mainzisegscan_num_tblocks_16721", "mainzisegscan_num_tblocks_16854", "mainzisegscan_tblock_sizze_16593", "mainzisegscan_tblock_sizze_16609", "mainzisegscan_tblock_sizze_16711", "mainzisegscan_tblock_sizze_16719", "mainzisegscan_tblock_sizze_16852", "replicated_iota_6108zihist_L2_17359", "replicated_iota_6108zihist_L_17306", "replicated_iota_6108ziseghist_num_tblocks_16568", "replicated_iota_6108ziseghist_tblock_sizze_16566", "replicated_iota_6108zisegred_num_tblocks_16558", "replicated_iota_6108zisegred_tblock_sizze_16556", "replicated_iota_6108zisegscan_num_tblocks_16550", "replicated_iota_6108zisegscan_num_tblocks_16587", "replicated_iota_6108zisegscan_tblock_sizze_16548", "replicated_iota_6108zisegscan_tblock_sizze_16585", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "cache", "shared_memory", "grid_size", "thread_block_size", "grid_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 0;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\nFUTHARK_FUN_ATTR void futrts_cmp_5210(bool *out_prim_out_0, float a_10315, int32_t aii_10316, float b_10317, int32_t bii_10318);\n\nFUTHARK_FUN_ATTR void futrts_cmp_5210(bool *out_prim_out_0, float a_10315, int32_t aii_10316, float b_10317, int32_t bii_10318)\n{\n    bool prim_out_17096;\n    bool cond_10319 = aii_10316 == bii_10318;\n    bool cmp_res_t_res_10321 = a_10315 <= b_10317;\n    bool cmp_res_f_res_10322 = sle32(aii_10316, bii_10318);\n    bool x_12442 = cond_10319 && cmp_res_t_res_10321;\n    bool x_12443 = !cond_10319;\n    bool y_12444 = cmp_res_f_res_10322 && x_12443;\n    bool cmp_res_10320 = x_12442 || y_12444;\n    \n    prim_out_17096 = cmp_res_10320;\n    *out_prim_out_0 = prim_out_17096;\n}\n\nFUTHARK_KERNEL\nvoid builtinzhreplicate_boolzireplicate_17295(int64_t num_elems_17291, unsigned char val_17292_bits, int64_t replicate_n_17294, int64_t virt_num_tblocks_17300, int64_t num_tblocks_17301, __global unsigned char *mem_17290)\n{\n    bool val_17292 = val_17292_bits;\n    int32_t replicate_ltid_17296;\n    int32_t tblock_sizze_17298;\n    int32_t replicate_gid_17297;\n    int32_t replicate_gtid_17295;\n    int32_t phys_tblock_id_17302;\n    int32_t iterations_17303;\n    \n    replicate_ltid_17296 = get_local_id(0);\n    tblock_sizze_17298 = get_local_size(0);\n    replicate_gid_17297 = get_tblock_id(0);\n    replicate_gtid_17295 = replicate_gid_17297 * tblock_sizze_17298 + replicate_ltid_17296;\n    phys_tblock_id_17302 = get_tblock_id(0);\n    iterations_17303 = sdiv_up32(sext_i64_i32(virt_num_tblocks_17300) - phys_tblock_id_17302, sext_i64_i32(num_tblocks_17301));\n    for (int32_t i_17304 = 0; i_17304 < iterations_17303; i_17304++) {\n        int32_t virt_tblock_id_17305;\n        int64_t global_tid_17306;\n        int64_t slice_17308;\n        int64_t rep_i_17307;\n        int64_t remnant_17309;\n        \n        vir", "t_tblock_id_17305 = phys_tblock_id_17302 + i_17304 * sext_i64_i32(num_tblocks_17301);\n        global_tid_17306 = sext_i32_i64(virt_tblock_id_17305) * sext_i32_i64(tblock_sizze_17298) + sext_i32_i64(replicate_ltid_17296);\n        slice_17308 = num_elems_17291;\n        rep_i_17307 = global_tid_17306;\n        remnant_17309 = global_tid_17306 - rep_i_17307;\n        if (slt64(global_tid_17306, replicate_n_17294)) {\n            ((__global bool *) mem_17290)[rep_i_17307] = val_17292;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_17142(int64_t num_elems_17138, int32_t val_17139, int64_t replicate_n_17141, int64_t virt_num_tblocks_17147, int64_t num_tblocks_17148, __global unsigned char *mem_17137)\n{\n    int32_t replicate_ltid_17143;\n    int32_t tblock_sizze_17145;\n    int32_t replicate_gid_17144;\n    int32_t replicate_gtid_17142;\n    int32_t phys_tblock_id_17149;\n    int32_t iterations_17150;\n    \n    replicate_ltid_17143 = get_local_id(0);\n    tblock_sizze_17145 = get_local_size(0);\n    replicate_gid_17144 = get_tblock_id(0);\n    replicate_gtid_17142 = replicate_gid_17144 * tblock_sizze_17145 + replicate_ltid_17143;\n    phys_tblock_id_17149 = get_tblock_id(0);\n    iterations_17150 = sdiv_up32(sext_i64_i32(virt_num_tblocks_17147) - phys_tblock_id_17149, sext_i64_i32(num_tblocks_17148));\n    for (int32_t i_17151 = 0; i_17151 < iterations_17150; i_17151++) {\n        int32_t virt_tblock_id_17152;\n        int64_t global_tid_17153;\n        int64_t slice_17155;\n        int64_t rep_i_17154;\n        int64_t remnant_17156;\n        \n        virt_tblock_id_17152 = phys_tblock_id_17149 + i_17151 * sext_i64_i32(num_tblocks_17148);\n        global_tid_17153 = sext_i32_i64(virt_tblock_id_17152) * sext_i32_i64(tblock_sizze_17145) + sext_i32_i64(replicate_ltid_17143);\n        slice_17155 = num_elems_17138;\n        rep_i_17154 = global_tid_17153;\n        remnant_17156 = global_ti",
                                    "d_17153 - rep_i_17154;\n        if (slt64(global_tid_17153, replicate_n_17141)) {\n            ((__global int32_t *) mem_17137)[rep_i_17154] = val_17139;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i64zireplicate_17445(int64_t num_elems_17441, int64_t val_17442, int64_t replicate_n_17444, int64_t virt_num_tblocks_17450, int64_t num_tblocks_17451, __global unsigned char *mem_17440)\n{\n    int32_t replicate_ltid_17446;\n    int32_t tblock_sizze_17448;\n    int32_t replicate_gid_17447;\n    int32_t replicate_gtid_17445;\n    int32_t phys_tblock_id_17452;\n    int32_t iterations_17453;\n    \n    replicate_ltid_17446 = get_local_id(0);\n    tblock_sizze_17448 = get_local_size(0);\n    replicate_gid_17447 = get_tblock_id(0);\n    replicate_gtid_17445 = replicate_gid_17447 * tblock_sizze_17448 + replicate_ltid_17446;\n    phys_tblock_id_17452 = get_tblock_id(0);\n    iterations_17453 = sdiv_up32(sext_i64_i32(virt_num_tblocks_17450) - phys_tblock_id_17452, sext_i64_i32(num_tblocks_17451));\n    for (int32_t i_17454 = 0; i_17454 < iterations_17453; i_17454++) {\n        int32_t virt_tblock_id_17455;\n        int64_t global_tid_17456;\n        int64_t slice_17458;\n        int64_t rep_i_17457;\n        int64_t remnant_17459;\n        \n        virt_tblock_id_17455 = phys_tblock_id_17452 + i_17454 * sext_i64_i32(num_tblocks_17451);\n        global_tid_17456 = sext_i32_i64(virt_tblock_id_17455) * sext_i32_i64(tblock_sizze_17448) + sext_i32_i64(replicate_ltid_17446);\n        slice_17458 = num_elems_17441;\n        rep_i_17457 = global_tid_17456;\n        remnant_17459 = global_tid_17456 - rep_i_17457;\n        if (slt64(global_tid_17456, replicate_n_17444)) {\n            ((__global int64_t *) mem_17440)[rep_i_17457] = val_17442;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_17112(int64_t num_", "elems_17108, int8_t val_17109, int64_t replicate_n_17111, int64_t virt_num_tblocks_17117, int64_t num_tblocks_17118, __global unsigned char *mem_17107)\n{\n    int32_t replicate_ltid_17113;\n    int32_t tblock_sizze_17115;\n    int32_t replicate_gid_17114;\n    int32_t replicate_gtid_17112;\n    int32_t phys_tblock_id_17119;\n    int32_t iterations_17120;\n    \n    replicate_ltid_17113 = get_local_id(0);\n    tblock_sizze_17115 = get_local_size(0);\n    replicate_gid_17114 = get_tblock_id(0);\n    replicate_gtid_17112 = replicate_gid_17114 * tblock_sizze_17115 + replicate_ltid_17113;\n    phys_tblock_id_17119 = get_tblock_id(0);\n    iterations_17120 = sdiv_up32(sext_i64_i32(virt_num_tblocks_17117) - phys_tblock_id_17119, sext_i64_i32(num_tblocks_17118));\n    for (int32_t i_17121 = 0; i_17121 < iterations_17120; i_17121++) {\n        int32_t virt_tblock_id_17122;\n        int64_t global_tid_17123;\n        int64_t slice_17125;\n        int64_t rep_i_17124;\n        int64_t remnant_17126;\n        \n        virt_tblock_id_17122 = phys_tblock_id_17119 + i_17121 * sext_i64_i32(num_tblocks_17118);\n        global_tid_17123 = sext_i32_i64(virt_tblock_id_17122) * sext_i32_i64(tblock_sizze_17115) + sext_i32_i64(replicate_ltid_17113);\n        slice_17125 = num_elems_17108;\n        rep_i_17124 = global_tid_17123;\n        remnant_17126 = global_tid_17123 - rep_i_17124;\n        if (slt64(global_tid_17123, replicate_n_17111)) {\n            ((__global int8_t *) mem_17107)[rep_i_17124] = val_17109;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16601_dim1, 1, 1)\nvoid mainzisegmap_16601(__global int *global_failure, int64_t m_12436, int64_t n_12437, int64_t num_tblocks_16606, int32_t virt_num_tblocks_17311, __global unsigned char *mem_16951, __global unsigned char *mem_16954)\n{\n    #define segmap_tblock_sizze_16604 (mainzisegmap_16601zisegmap_tblock_sizze_16604)\n    if (*global_failure >= 0)\n        return;\n ", "   \n    int32_t local_tid_17313;\n    int32_t tblock_sizze_17316;\n    int32_t wave_sizze_17315;\n    int32_t block_id_17314;\n    int32_t global_tid_17312;\n    int64_t phys_tid_16601;\n    int32_t phys_tblock_id_17317;\n    int32_t iterations_17318;\n    \n    local_tid_17313 = get_local_id(0);\n    tblock_sizze_17316 = get_local_size(0);\n    wave_sizze_17315 = LOCKSTEP_WIDTH;\n    block_id_17314 = get_tblock_id(0);\n    global_tid_17312 = block_id_17314 * tblock_sizze_17316 + local_tid_17313;\n    phys_tid_16601 = sext_i32_i64(global_tid_17312);\n    phys_tblock_id_17317 = get_tblock_id(0);\n    iterations_17318 = sdiv_up32(virt_num_tblocks_17311 - phys_tblock_id_17317, sext_i64_i32(num_tblocks_16606));\n    for (int32_t i_17319 = 0; i_17319 < iterations_17318; i_17319++) {\n        int32_t virt_tblock_id_17320;\n        int64_t global_tid_17321;\n        int64_t slice_17322;\n        int64_t write_i_16600;\n        int64_t remnant_17323;\n        \n        virt_tblock_id_17320 = phys_tblock_id_17317 + i_17319 * sext_i64_i32(num_tblocks_16606);\n        global_tid_17321 = sext_i32_i64(virt_tblock_id_17320) * segmap_tblock_sizze_16604 + sext_i32_i64(local_tid_17313);\n        slice_17322 = m_12436;\n        write_i_16600 = global_tid_17321;\n        remnant_17323 = global_tid_17321 - write_i_16600;\n        if (slt64(write_i_16600, m_12436)) {\n            int64_t zv_lhs_14577;\n            int64_t tmp_14578;\n            bool cond_14581;\n            int64_t lifted_lambda_res_14582;\n            \n            zv_lhs_14577 = add64((int64_t) -1, write_i_16600);\n            tmp_14578 = smod64(zv_lhs_14577, m_12436);\n            cond_14581 = write_i_16600 == (int64_t) 0;\n            if (cond_14581) {\n                lifted_lambda_res_14582 = (int64_t) 0;\n            } else {\n                int64_t lifted_lambda_res_14579 = ((__global int64_t *) mem_16951)[tmp_14578];\n                \n                lifted_lambda_res_14582 = lifted_lambda_res_14579;\n            }\n            if (sle64((int64_t) 0, l",
                                    "ifted_lambda_res_14582) && slt64(lifted_lambda_res_14582, n_12437)) {\n                ((__global bool *) mem_16954)[lifted_lambda_res_14582] = 1;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_16604\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16632_dim1, 1, 1)\nvoid mainzisegmap_16632(__global int *global_failure, int64_t n_12437, __global unsigned char *mem_16961)\n{\n    #define segmap_tblock_sizze_16628 (mainzisegmap_16632zisegmap_tblock_sizze_16628)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17429;\n    int32_t tblock_sizze_17432;\n    int32_t wave_sizze_17431;\n    int32_t block_id_17430;\n    int32_t global_tid_17428;\n    int64_t phys_tid_16632;\n    int64_t global_tid_17433;\n    int64_t slice_17434;\n    int64_t gtid_16631;\n    int64_t remnant_17435;\n    \n    local_tid_17429 = get_local_id(0);\n    tblock_sizze_17432 = get_local_size(0);\n    wave_sizze_17431 = LOCKSTEP_WIDTH;\n    block_id_17430 = get_tblock_id(0);\n    global_tid_17428 = block_id_17430 * tblock_sizze_17432 + local_tid_17429;\n    phys_tid_16632 = sext_i32_i64(global_tid_17428);\n    global_tid_17433 = sext_i32_i64(block_id_17430) * segmap_tblock_sizze_16628 + sext_i32_i64(local_tid_17429);\n    slice_17434 = n_12437;\n    gtid_16631 = global_tid_17433;\n    remnant_17435 = global_tid_17433 - gtid_16631;\n    if (slt64(gtid_16631, n_12437)) {\n        int32_t eta_p_16633;\n        int32_t lifted_lambda_res_16635;\n        \n        eta_p_16633 = ((__global int32_t *) mem_16961)[gtid_16631];\n        lifted_lambda_res_16635 = sub32(eta_p_16633, 1);\n        ((__global int32_t *) mem_16961)[gtid_16631] = lifted_lambda_res_16635;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16628\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16660_dim1, 1, 1)\nvoid mainzisegmap_16660(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_12437, int64_t lo", "op_dz2085U_14130, __global unsigned char *mem_16963, __global unsigned char *mem_16965, __global unsigned char *mem_param_16976, __global unsigned char *mem_param_16979, __global unsigned char *mem_16982, __global unsigned char *mem_16984)\n{\n    #define segmap_tblock_sizze_16655 (mainzisegmap_16660zisegmap_tblock_sizze_16655)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17470;\n    int32_t tblock_sizze_17473;\n    int32_t wave_sizze_17472;\n    int32_t block_id_17471;\n    int32_t global_tid_17469;\n    int64_t phys_tid_16660;\n    int64_t global_tid_17474;\n    int64_t slice_17475;\n    int64_t gtid_16659;\n    int64_t remnant_17476;\n    \n    local_tid_17470 = get_local_id(0);\n    tblock_sizze_17473 = get_local_size(0);\n    wave_sizze_17472 = LOCKSTEP_WIDTH;\n    block_id_17471 = get_tblock_id(0);\n    global_tid_17469 = block_id_17471 * tblock_sizze_17473 + local_tid_17470;\n    phys_tid_16660 = sext_i32_i64(global_tid_17469);\n    global_tid_17474 = sext_i32_i64(block_id_17471) * segmap_tblock_sizze_16655 + sext_i32_i64(local_tid_17470);\n    slice_17475 = loop_dz2085U_14130;\n    gtid_16659 = global_tid_17474;\n    remnant_17476 = global_tid_17474 - gtid_16659;\n    if (slt64(gtid_16659, loop_dz2085U_14130)) {\n        int64_t eta_p_16661;\n        int64_t eta_p_16662;\n        int64_t zp_rhs_16663;\n        int64_t tmp_16664;\n        bool x_16665;\n        bool y_16666;\n        bool bounds_check_16667;\n        bool index_certs_16668;\n        float lifted_lambda_res_16669;\n        int32_t lifted_lambda_res_16670;\n        \n        eta_p_16661 = ((__global int64_t *) mem_param_16976)[gtid_16659];\n        eta_p_16662 = ((__global int64_t *) mem_param_16979)[gtid_16659];\n        zp_rhs_16663 = sdiv64(eta_p_16662, (int64_t) 2);\n        tmp_16664 = add64(eta_p_16661, zp_rhs_16663);\n        x_16665 = sle64((int64_t) 0, tmp_16664);\n        y_16666 = slt64(tmp_16664, n_12437);\n        bounds_check_16667 = x_16665 && y_16666;\n        if (!bounds_check_16667) {\n     ", "       {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_16664;\n                    global_failure_args[1] = (int64_t) n_12437;\n                    ;\n                }\n                return;\n            }\n        }\n        lifted_lambda_res_16669 = ((__global float *) mem_16963)[tmp_16664];\n        lifted_lambda_res_16670 = ((__global int32_t *) mem_16965)[tmp_16664];\n        ((__global float *) mem_16982)[gtid_16659] = lifted_lambda_res_16669;\n        ((__global int32_t *) mem_16984)[gtid_16659] = lifted_lambda_res_16670;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16655\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16697_dim1, 1, 1)\nvoid mainzisegmap_16697(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t loop_dz2085U_14130, int64_t idxs_14149, __global unsigned char *mem_param_16976, __global unsigned char *ext_mem_16988, __global unsigned char *mem_16990, __global unsigned char *mem_16992)\n{\n    #define segmap_tblock_sizze_16692 (mainzisegmap_16697zisegmap_tblock_sizze_16692)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17479;\n    int32_t tblock_sizze_17482;\n    int32_t wave_sizze_17481;\n    int32_t block_id_17480;\n    int32_t global_tid_17478;\n    int64_t phys_tid_16697;\n    int64_t global_tid_17483;\n    int64_t slice_17484;\n    int64_t gtid_16696;\n    int64_t remnant_17485;\n    \n    local_tid_17479 = get_local_id(0);\n    tblock_sizze_17482 = get_local_size(0);\n    wave_sizze_17481 = LOCKSTEP_WIDTH;\n    block_id_17480 = get_tblock_id(0);\n    global_tid_17478 = block_id_17480 * tblock_sizze_17482 + local_tid_17479;\n    phys_tid_16697 = sext_i32_i64(global_tid_17478);\n    global_tid_17483 = sext_i32_i64(block_id_17480) * segmap_tblock_sizze_16692 + sext_i32_i64(local_tid_17479);\n    slice_17484 = idxs_14149;\n    gtid_16696 = global_tid_17483;\n    remnant_17485 = global_tid_17483 - gti",
                                    "d_16696;\n    if (slt64(gtid_16696, idxs_14149)) {\n        int64_t eta_p_16698;\n        bool x_16700;\n        bool y_16701;\n        bool bounds_check_16702;\n        bool index_certs_16703;\n        int64_t lifted_lambda_res_16704;\n        int64_t zv_lhs_16705;\n        int64_t tmp_16706;\n        int64_t lifted_lambda_res_16707;\n        bool defunc_0_f_res_16708;\n        bool defunc_0_f_res_16709;\n        \n        eta_p_16698 = ((__global int64_t *) ext_mem_16988)[gtid_16696];\n        x_16700 = sle64((int64_t) 0, eta_p_16698);\n        y_16701 = slt64(eta_p_16698, loop_dz2085U_14130);\n        bounds_check_16702 = x_16700 && y_16701;\n        if (!bounds_check_16702) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                    global_failure_args[0] = (int64_t) eta_p_16698;\n                    global_failure_args[1] = (int64_t) loop_dz2085U_14130;\n                    ;\n                }\n                return;\n            }\n        }\n        lifted_lambda_res_16704 = ((__global int64_t *) mem_param_16976)[eta_p_16698];\n        zv_lhs_16705 = add64((int64_t) -1, gtid_16696);\n        tmp_16706 = smod64(zv_lhs_16705, idxs_14149);\n        lifted_lambda_res_16707 = ((__global int64_t *) ext_mem_16988)[tmp_16706];\n        defunc_0_f_res_16708 = eta_p_16698 == lifted_lambda_res_16707;\n        defunc_0_f_res_16709 = !defunc_0_f_res_16708;\n        ((__global bool *) mem_16990)[gtid_16696] = defunc_0_f_res_16709;\n        ((__global int64_t *) mem_16992)[gtid_16696] = lifted_lambda_res_16704;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16692\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16810_dim1, 1, 1)\nvoid mainzisegmap_16810(__global int *global_failure, int64_t idxs_14149, int64_t num_segments_14275, int64_t num_tblocks_16815, int32_t virt_num_tblocks_18192, __global unsigned char *mem_16998, __global unsigned char *mem_16999, __global unsigned char *mem_17010, __global unsigned char *mem_17012, __global unsigned cha", "r *mem_17014, __global unsigned char *mem_17022, __global unsigned char *mem_17024, __global unsigned char *mem_17026)\n{\n    #define segmap_tblock_sizze_16813 (mainzisegmap_16810zisegmap_tblock_sizze_16813)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18194;\n    int32_t tblock_sizze_18197;\n    int32_t wave_sizze_18196;\n    int32_t block_id_18195;\n    int32_t global_tid_18193;\n    int64_t phys_tid_16810;\n    int32_t phys_tblock_id_18198;\n    int32_t iterations_18199;\n    \n    local_tid_18194 = get_local_id(0);\n    tblock_sizze_18197 = get_local_size(0);\n    wave_sizze_18196 = LOCKSTEP_WIDTH;\n    block_id_18195 = get_tblock_id(0);\n    global_tid_18193 = block_id_18195 * tblock_sizze_18197 + local_tid_18194;\n    phys_tid_16810 = sext_i32_i64(global_tid_18193);\n    phys_tblock_id_18198 = get_tblock_id(0);\n    iterations_18199 = sdiv_up32(virt_num_tblocks_18192 - phys_tblock_id_18198, sext_i64_i32(num_tblocks_16815));\n    for (int32_t i_18200 = 0; i_18200 < iterations_18199; i_18200++) {\n        int32_t virt_tblock_id_18201;\n        int64_t global_tid_18202;\n        int64_t slice_18203;\n        int64_t write_i_16809;\n        int64_t remnant_18204;\n        \n        virt_tblock_id_18201 = phys_tblock_id_18198 + i_18200 * sext_i64_i32(num_tblocks_16815);\n        global_tid_18202 = sext_i32_i64(virt_tblock_id_18201) * segmap_tblock_sizze_16813 + sext_i32_i64(local_tid_18194);\n        slice_18203 = idxs_14149;\n        write_i_16809 = global_tid_18202;\n        remnant_18204 = global_tid_18202 - write_i_16809;\n        if (slt64(write_i_16809, idxs_14149)) {\n            bool eta_p_14649;\n            int64_t write_value_14650;\n            int64_t write_value_14651;\n            int64_t write_value_14652;\n            int64_t lifted_index_res_14653;\n            \n            eta_p_14649 = ((__global bool *) mem_16999)[write_i_16809];\n            write_value_14650 = ((__global int64_t *) mem_17010)[write_i_16809];\n            write_value_14651 = ((__global ", "int64_t *) mem_17012)[write_i_16809];\n            write_value_14652 = ((__global int64_t *) mem_17014)[write_i_16809];\n            if (eta_p_14649) {\n                int64_t eta_p_14648;\n                int64_t lifted_index_res_t_res_16488;\n                \n                eta_p_14648 = ((__global int64_t *) mem_16998)[write_i_16809];\n                lifted_index_res_t_res_16488 = sub64(eta_p_14648, (int64_t) 1);\n                lifted_index_res_14653 = lifted_index_res_t_res_16488;\n            } else {\n                lifted_index_res_14653 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_index_res_14653) && slt64(lifted_index_res_14653, num_segments_14275)) {\n                ((__global int64_t *) mem_17022)[lifted_index_res_14653] = write_value_14650;\n            }\n            if (sle64((int64_t) 0, lifted_index_res_14653) && slt64(lifted_index_res_14653, num_segments_14275)) {\n                ((__global int64_t *) mem_17024)[lifted_index_res_14653] = write_value_14651;\n            }\n            if (sle64((int64_t) 0, lifted_index_res_14653) && slt64(lifted_index_res_14653, num_segments_14275)) {\n                ((__global int64_t *) mem_17026)[lifted_index_res_14653] = write_value_14652;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_16813\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16842_dim1, 1, 1)\nvoid mainzisegmap_16842(__global int *global_failure, int64_t loop_dz2085U_14130, int64_t num_tblocks_16837, int32_t virt_num_tblocks_18206, __global unsigned char *mem_param_16976, __global unsigned char *mem_17022, __global unsigned char *mem_17024, __global unsigned char *mem_17026, __global unsigned char *mem_17048, __global unsigned char *mem_17058)\n{\n    #define segmap_tblock_sizze_16836 (mainzisegmap_16842zisegmap_tblock_sizze_16836)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18208;\n    int32_t tblock_sizze_18211;\n",
                                    "    int32_t wave_sizze_18210;\n    int32_t block_id_18209;\n    int32_t global_tid_18207;\n    int64_t phys_tid_16842;\n    int32_t phys_tblock_id_18212;\n    int32_t iterations_18213;\n    \n    local_tid_18208 = get_local_id(0);\n    tblock_sizze_18211 = get_local_size(0);\n    wave_sizze_18210 = LOCKSTEP_WIDTH;\n    block_id_18209 = get_tblock_id(0);\n    global_tid_18207 = block_id_18209 * tblock_sizze_18211 + local_tid_18208;\n    phys_tid_16842 = sext_i32_i64(global_tid_18207);\n    phys_tblock_id_18212 = get_tblock_id(0);\n    iterations_18213 = sdiv_up32(virt_num_tblocks_18206 - phys_tblock_id_18212, sext_i64_i32(num_tblocks_16837));\n    for (int32_t i_18214 = 0; i_18214 < iterations_18213; i_18214++) {\n        int32_t virt_tblock_id_18215;\n        int64_t global_tid_18216;\n        int64_t slice_18217;\n        int64_t gtid_16841;\n        int64_t remnant_18218;\n        \n        virt_tblock_id_18215 = phys_tblock_id_18212 + i_18214 * sext_i64_i32(num_tblocks_16837);\n        global_tid_18216 = sext_i32_i64(virt_tblock_id_18215) * segmap_tblock_sizze_16836 + sext_i32_i64(local_tid_18208);\n        slice_18217 = loop_dz2085U_14130;\n        gtid_16841 = global_tid_18216;\n        remnant_18218 = global_tid_18216 - gtid_16841;\n        if (slt64(gtid_16841, loop_dz2085U_14130)) {\n            int64_t eta_p_16843;\n            int64_t eta_p_16844;\n            int64_t eta_p_16845;\n            int64_t eta_p_16846;\n            int64_t zp_lhs_16847;\n            int64_t tmp_16848;\n            int64_t mem_17033[(int64_t) 2];\n            int64_t mem_17038[(int64_t) 2];\n            \n            eta_p_16843 = ((__global int64_t *) mem_param_16976)[gtid_16841];\n            eta_p_16844 = ((__global int64_t *) mem_17022)[gtid_16841];\n            eta_p_16845 = ((__global int64_t *) mem_17024)[gtid_16841];\n            eta_p_16846 = ((__global int64_t *) mem_17026)[gtid_16841];\n            zp_lhs_16847 = add64(eta_p_16843, eta_p_16844);\n            tmp_16848 = add64(eta_p_16845, zp_lhs_16847);\n     ", "       mem_17033[(int64_t) 0] = eta_p_16843;\n            mem_17033[(int64_t) 1] = tmp_16848;\n            mem_17038[(int64_t) 0] = eta_p_16844;\n            mem_17038[(int64_t) 1] = eta_p_16846;\n            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                ((__global int64_t *) mem_17048)[gtid_16841 + i_0 * loop_dz2085U_14130] = mem_17033[i_0];\n            }\n            for (int64_t i_0 = 0; i_0 < (int64_t) 2; i_0++) {\n                ((__global int64_t *) mem_17058)[gtid_16841 + i_0 * loop_dz2085U_14130] = mem_17038[i_0];\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_16836\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16860_dim1, 1, 1)\nvoid mainzisegmap_16860(__global int *global_failure, int64_t loop_dz2085U_14130, int64_t dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, int64_t m_14332, int64_t num_tblocks_16865, int32_t virt_num_tblocks_18323, __global unsigned char *mem_17048, __global unsigned char *mem_17058, __global unsigned char *mem_17069, __global unsigned char *mem_17071, __global unsigned char *mem_17073, __global unsigned char *mem_17075)\n{\n    #define segmap_tblock_sizze_16863 (mainzisegmap_16860zisegmap_tblock_sizze_16863)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18325;\n    int32_t tblock_sizze_18328;\n    int32_t wave_sizze_18327;\n    int32_t block_id_18326;\n    int32_t global_tid_18324;\n    int64_t phys_tid_16860;\n    int32_t phys_tblock_id_18329;\n    int32_t iterations_18330;\n    \n    local_tid_18325 = get_local_id(0);\n    tblock_sizze_18328 = get_local_size(0);\n    wave_sizze_18327 = LOCKSTEP_WIDTH;\n    block_id_18326 = get_tblock_id(0);\n    global_tid_18324 = block_id_18326 * tblock_sizze_18328 + local_tid_18325;\n    phys_tid_16860 = sext_i32_i64(global_tid_18324);\n    phys_tblock_id_18329 = get_tblock_id(0);\n    iterations_18330 = sdiv_up32(virt_num_tblocks_18323 - phys_tblock_id_18329, sext_i64_i32(num_tblocks_16865))", ";\n    for (int32_t i_18331 = 0; i_18331 < iterations_18330; i_18331++) {\n        int32_t virt_tblock_id_18332;\n        int64_t global_tid_18333;\n        int64_t slice_18334;\n        int64_t write_i_16859;\n        int64_t remnant_18335;\n        \n        virt_tblock_id_18332 = phys_tblock_id_18329 + i_18331 * sext_i64_i32(num_tblocks_16865);\n        global_tid_18333 = sext_i32_i64(virt_tblock_id_18332) * segmap_tblock_sizze_16863 + sext_i32_i64(local_tid_18325);\n        slice_18334 = dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136;\n        write_i_16859 = global_tid_18333;\n        remnant_18335 = global_tid_18333 - write_i_16859;\n        if (slt64(write_i_16859, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136)) {\n            int64_t eta_p_14634;\n            int64_t new_index_16921;\n            int64_t binop_y_16923;\n            int64_t new_index_16924;\n            int64_t write_value_14636;\n            int64_t write_value_14637;\n            bool cond_14638;\n            int64_t lifted_lambda_res_14639;\n            \n            eta_p_14634 = ((__global int64_t *) mem_17071)[write_i_16859];\n            new_index_16921 = squot64(write_i_16859, (int64_t) 2);\n            binop_y_16923 = (int64_t) 2 * new_index_16921;\n            new_index_16924 = write_i_16859 - binop_y_16923;\n            write_value_14636 = ((__global int64_t *) mem_17048)[new_index_16921 + new_index_16924 * loop_dz2085U_14130];\n            write_value_14637 = ((__global int64_t *) mem_17058)[new_index_16921 + new_index_16924 * loop_dz2085U_14130];\n            cond_14638 = eta_p_14634 == (int64_t) 1;\n            if (cond_14638) {\n                int64_t eta_p_14635;\n                int64_t lifted_lambda_res_t_res_16490;\n                \n                eta_p_14635 = ((__global int64_t *) mem_17069)[write_i_16859];\n                lifted_lambda_res_t_res_16490 = sub64(eta_p_14635, (int64_t) 1);\n                lifted_lambda_res_14639 = lifted_lambda_res_t_res_16490;\n            } else {\n                lifted_lambda_res_14639 = (i",
                                    "nt64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_14639) && slt64(lifted_lambda_res_14639, m_14332)) {\n                ((__global int64_t *) mem_17075)[lifted_lambda_res_14639] = write_value_14636;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_14639) && slt64(lifted_lambda_res_14639, m_14332)) {\n                ((__global int64_t *) mem_17073)[lifted_lambda_res_14639] = write_value_14637;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_16863\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16868_dim1, 1, 1)\nvoid mainzisegmap_16868(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_12437, int64_t loop_dz2085U_14130, int64_t idxs_14149, int64_t num_tblocks_16873, int32_t virt_num_tblocks_18337, __global unsigned char *mem_16963, __global unsigned char *mem_16965, __global unsigned char *mem_param_16976, __global unsigned char *ext_mem_16988, __global unsigned char *mem_17003, __global unsigned char *mem_17005, __global unsigned char *mem_17007, __global unsigned char *mem_17016, __global unsigned char *mem_17018, __global unsigned char *mem_17020, __global unsigned char *mem_17022, __global unsigned char *mem_17024)\n{\n    #define segmap_tblock_sizze_16871 (mainzisegmap_16868zisegmap_tblock_sizze_16871)\n    \n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_18339;\n    int32_t tblock_sizze_18342;\n    int32_t wave_sizze_18341;\n    int32_t block_id_18340;\n    int32_t global_tid_18338;\n    int64_t phys_tid_16868;\n    int32_t phys_tblock_id_18343;\n    int32_t iterations_18344;\n    \n    local_tid_18339 = get_local_id(0);\n    tblock_sizze_18342 = get_local_size(0);\n    wave_sizze_1", "8341 = LOCKSTEP_WIDTH;\n    block_id_18340 = get_tblock_id(0);\n    global_tid_18338 = block_id_18340 * tblock_sizze_18342 + local_tid_18339;\n    phys_tid_16868 = sext_i32_i64(global_tid_18338);\n    phys_tblock_id_18343 = get_tblock_id(0);\n    iterations_18344 = sdiv_up32(virt_num_tblocks_18337 - phys_tblock_id_18343, sext_i64_i32(num_tblocks_16873));\n    for (int32_t i_18345 = 0; i_18345 < iterations_18344; i_18345++) {\n        int32_t virt_tblock_id_18346;\n        int64_t global_tid_18347;\n        int64_t slice_18348;\n        int64_t write_i_16867;\n        int64_t remnant_18349;\n        \n        virt_tblock_id_18346 = phys_tblock_id_18343 + i_18345 * sext_i64_i32(num_tblocks_16873);\n        global_tid_18347 = sext_i32_i64(virt_tblock_id_18346) * segmap_tblock_sizze_16871 + sext_i32_i64(local_tid_18339);\n        slice_18348 = idxs_14149;\n        write_i_16867 = global_tid_18347;\n        remnant_18349 = global_tid_18347 - write_i_16867;\n        if (slt64(write_i_16867, idxs_14149)) {\n            int64_t eta_p_14605;\n            bool x_14612;\n            bool y_14613;\n            bool bounds_check_14614;\n            bool index_certs_14615;\n            int64_t eta_p_14609;\n            float write_value_14610;\n            int32_t write_value_14611;\n            int64_t lifted_lambda_res_14618;\n            bool cond_14619;\n            int64_t lifted_lambda_res_14620;\n            \n            eta_p_14605 = ((__global int64_t *) ext_mem_16988)[write_i_16867];\n            x_14612 = sle64((int64_t) 0, eta_p_14605);\n            y_14613 = slt64(eta_p_14605, loop_dz2085U_14130);\n            bounds_check_14614 = x_14612 && y_14613;\n            if (!bounds_check_14614) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                        global_failure_args[0] = (int64_t) eta_p_14605;\n                        global_failure_args[1] = (int64_t) loop_dz2085U_14130;\n                        ;\n                    }\n                 ", "   local_failure = 1;\n                    goto error_0;\n                }\n            }\n            eta_p_14609 = ((__global int64_t *) mem_17020)[write_i_16867];\n            write_value_14610 = ((__global float *) mem_17016)[write_i_16867];\n            write_value_14611 = ((__global int32_t *) mem_17018)[write_i_16867];\n            lifted_lambda_res_14618 = ((__global int64_t *) mem_param_16976)[eta_p_14605];\n            cond_14619 = slt64(eta_p_14609, (int64_t) 0);\n            if (cond_14619) {\n                int64_t eta_p_14606;\n                int64_t zm_lhs_16491;\n                int64_t lifted_lambda_res_t_res_16492;\n                \n                eta_p_14606 = ((__global int64_t *) mem_17003)[write_i_16867];\n                zm_lhs_16491 = add64(eta_p_14606, lifted_lambda_res_14618);\n                lifted_lambda_res_t_res_16492 = sub64(zm_lhs_16491, (int64_t) 1);\n                lifted_lambda_res_14620 = lifted_lambda_res_t_res_16492;\n            } else {\n                int64_t lifted_lambda_res_14616;\n                bool cond_14623;\n                int64_t lifted_lambda_res_f_res_14624;\n                \n                lifted_lambda_res_14616 = ((__global int64_t *) mem_17022)[eta_p_14605];\n                cond_14623 = slt64((int64_t) 0, eta_p_14609);\n                if (cond_14623) {\n                    int64_t eta_p_14608;\n                    int64_t lifted_lambda_res_14617;\n                    int64_t zm_lhs_16493;\n                    int64_t zp_lhs_16494;\n                    int64_t zp_lhs_16495;\n                    int64_t lifted_lambda_res_f_res_t_res_16496;\n                    \n                    eta_p_14608 = ((__global int64_t *) mem_17007)[write_i_16867];\n                    lifted_lambda_res_14617 = ((__global int64_t *) mem_17024)[eta_p_14605];\n                    zm_lhs_16493 = add64(eta_p_14608, lifted_lambda_res_14618);\n                    zp_lhs_16494 = sub64(zm_lhs_16493, (int64_t) 1);\n                    zp_lhs_16495 = add64(lifted_la",
                                    "mbda_res_14616, zp_lhs_16494);\n                    lifted_lambda_res_f_res_t_res_16496 = add64(lifted_lambda_res_14617, zp_lhs_16495);\n                    lifted_lambda_res_f_res_14624 = lifted_lambda_res_f_res_t_res_16496;\n                } else {\n                    int64_t eta_p_14607;\n                    int64_t zm_lhs_14629;\n                    int64_t zp_lhs_14630;\n                    int64_t lifted_lambda_res_f_res_f_res_14631;\n                    \n                    eta_p_14607 = ((__global int64_t *) mem_17005)[write_i_16867];\n                    zm_lhs_14629 = add64(eta_p_14607, lifted_lambda_res_14618);\n                    zp_lhs_14630 = sub64(zm_lhs_14629, (int64_t) 1);\n                    lifted_lambda_res_f_res_f_res_14631 = add64(lifted_lambda_res_14616, zp_lhs_14630);\n                    lifted_lambda_res_f_res_14624 = lifted_lambda_res_f_res_f_res_14631;\n                }\n                lifted_lambda_res_14620 = lifted_lambda_res_f_res_14624;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_14620) && slt64(lifted_lambda_res_14620, n_12437)) {\n                ((__global float *) mem_16963)[lifted_lambda_res_14620] = write_value_14610;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_14620) && slt64(lifted_lambda_res_14620, n_12437)) {\n                ((__global int32_t *) mem_16965)[lifted_lambda_res_14620] = write_value_14611;\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_16871\n}\nFUTHARK_KERNEL_SIZED(mainzisegmap_16903_dim1, 1, 1)\nvoid mainzisegmap_16903(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t m_12436, int64_t n_12437, __global unsigned char *ks_mem_16946, __global unsigned char *mem_16953, __global unsigned char *ext_", "mem_17092, __global unsigned char *mem_17095)\n{\n    #define segmap_tblock_sizze_16899 (mainzisegmap_16903zisegmap_tblock_sizze_16899)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18354;\n    int32_t tblock_sizze_18357;\n    int32_t wave_sizze_18356;\n    int32_t block_id_18355;\n    int32_t global_tid_18353;\n    int64_t phys_tid_16903;\n    int64_t global_tid_18358;\n    int64_t slice_18359;\n    int64_t gtid_16902;\n    int64_t remnant_18360;\n    \n    local_tid_18354 = get_local_id(0);\n    tblock_sizze_18357 = get_local_size(0);\n    wave_sizze_18356 = LOCKSTEP_WIDTH;\n    block_id_18355 = get_tblock_id(0);\n    global_tid_18353 = block_id_18355 * tblock_sizze_18357 + local_tid_18354;\n    phys_tid_16903 = sext_i32_i64(global_tid_18353);\n    global_tid_18358 = sext_i32_i64(block_id_18355) * segmap_tblock_sizze_16899 + sext_i32_i64(local_tid_18354);\n    slice_18359 = m_12436;\n    gtid_16902 = global_tid_18358;\n    remnant_18360 = global_tid_18358 - gtid_16902;\n    if (slt64(gtid_16902, m_12436)) {\n        int32_t eta_p_16905;\n        int64_t zv_lhs_16906;\n        int64_t tmp_16907;\n        bool cond_16909;\n        int32_t lifted_lambda_res_16910;\n        int32_t zm_lhs_16911;\n        int32_t tmp_16912;\n        int64_t tmp_16913;\n        bool x_16914;\n        bool y_16915;\n        bool bounds_check_16916;\n        bool index_certs_16917;\n        float lifted_lambda_res_16918;\n        \n        eta_p_16905 = ((__global int32_t *) ks_mem_16946)[gtid_16902];\n        zv_lhs_16906 = add64((int64_t) -1, gtid_16902);\n        tmp_16907 = smod64(zv_lhs_16906, m_12436);\n        cond_16909 = gtid_16902 == (int64_t) 0;\n        if (cond_16909) {\n            lifted_lambda_res_16910 = 0;\n        } else {\n            int32_t lifted_lambda_res_16908 = ((__global int32_t *) mem_16953)[tmp_16907];\n            \n            lifted_lambda_res_16910 = lifted_lambda_res_16908;\n        }\n        zm_lhs_16911 = add32(eta_p_16905, lifted_lambda_res_16910);\n        tmp_16912 = sub", "32(zm_lhs_16911, 1);\n        tmp_16913 = sext_i32_i64(tmp_16912);\n        x_16914 = sle64((int64_t) 0, tmp_16913);\n        y_16915 = slt64(tmp_16913, n_12437);\n        bounds_check_16916 = x_16914 && y_16915;\n        if (!bounds_check_16916) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_16913;\n                    global_failure_args[1] = (int64_t) n_12437;\n                    ;\n                }\n                return;\n            }\n        }\n        lifted_lambda_res_16918 = ((__global float *) ext_mem_17092)[tmp_16913];\n        ((__global float *) mem_17095)[gtid_16902] = lifted_lambda_res_16918;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_16899\n}\nFUTHARK_KERNEL_SIZED(mainzisegscan_16599_dim1, 1, 1)\nvoid mainzisegscan_16599(__global int *global_failure, int64_t m_12436, int64_t num_tblocks_16596, int64_t num_virt_blocks_17103, int64_t num_virt_threads_17104, __global unsigned char *shp_mem_16947, __global unsigned char *mem_16951, __global unsigned char *mem_16953, __global unsigned char *status_flags_mem_17105, __global unsigned char *aggregates_mem_17127, __global unsigned char *incprefixes_mem_17129, __global unsigned char *aggregates_mem_17131, __global unsigned char *incprefixes_mem_17133, __global unsigned char *global_dynid_mem_17135)\n{\n    #define segscan_tblock_sizze_16594 (mainzisegscan_16599zisegscan_tblock_sizze_16594)\n    #define chunk_sizze_17102 (mainzisegscan_16599zichunk_sizze_17102)\n    \n    volatile __local unsigned char *local_mem_17167_backing_0 = &shared_mem[0];\n    const int64_t local_mem_17167_backing_0_offset = 0 + (smax64(smax64((int64_t) 416, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_16594, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_16594), smax64(chunk_sizze_17102 * segscan_tblock_sizze_16594 * (int64_t) 8, chunk_sizze_17102 * segscan_tblock_sizze_16594 * (int64_t) 4)) + srem64((int64_t)",
                                    " 8 - srem64(smax64(smax64((int64_t) 416, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_16594, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_16594), smax64(chunk_sizze_17102 * segscan_tblock_sizze_16594 * (int64_t) 8, chunk_sizze_17102 * segscan_tblock_sizze_16594 * (int64_t) 4)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17158;\n    int32_t tblock_sizze_17161;\n    int32_t wave_sizze_17160;\n    int32_t block_id_17159;\n    int32_t global_tid_17157;\n    int64_t phys_tid_16599;\n    int32_t chunk_sizze_32b_17162;\n    int64_t byte_offsets_17163;\n    int64_t byte_offsets_17164;\n    int64_t warp_byte_offset_17165;\n    int64_t warp_byte_offset_17166;\n    __local unsigned char *local_mem_17167;\n    int64_t trans_arr_len_17168;\n    int64_t phys_block_id_17177;\n    int64_t virtloop_bound_17178;\n    \n    local_tid_17158 = get_local_id(0);\n    tblock_sizze_17161 = get_local_size(0);\n    wave_sizze_17160 = LOCKSTEP_WIDTH;\n    block_id_17159 = get_tblock_id(0);\n    global_tid_17157 = block_id_17159 * tblock_sizze_17161 + local_tid_17158;\n    phys_tid_16599 = sext_i32_i64(global_tid_17157);\n    chunk_sizze_32b_17162 = sext_i64_i32(chunk_sizze_17102);\n    byte_offsets_17163 = segscan_tblock_sizze_16594 * (int64_t) 8;\n    byte_offsets_17164 = sdiv_up64(byte_offsets_17163, (int64_t) 4) * (int64_t) 4 + segscan_tblock_sizze_16594 * (int64_t) 4;\n    warp_byte_offset_17165 = (int64_t) 288;\n    warp_byte_offset_17166 = sdiv_up64(warp_byte_offset_17165, (int64_t) 4) * (int64_t) 4 + (int64_t) 128;\n    // Allocate reusable shared memory\n    { }\n    local_mem_17167 = (__local unsigned char *) local_mem_17167_backing_0;\n    trans_arr_len_17168 = chunk_sizze_17102 * segscan_tblock_sizze_16594;\n    phys_block_id_17177 = get_tblock_id(0);\n    virtloop_bound_17178 = sdiv_up64(num_virt_blocks_17103 - phys_block_id_17177, num_tblocks_16596);\n    for (int64_t virtloop_i_17179 = 0; virtloop_i_17179 < virtloop_bound_17178; v", "irtloop_i_17179++) {\n        int64_t dynamic_id_17180;\n        int64_t block_offset_17181;\n        int64_t sgm_idx_17182;\n        int32_t boundary_17183;\n        int32_t segsizze_compact_17184;\n        int64_t private_mem_17185[chunk_sizze_17102];\n        int32_t private_mem_17187[chunk_sizze_17102];\n        int64_t thd_offset_17189;\n        int64_t acc_17215;\n        int32_t acc_17216;\n        int64_t prefix_17229;\n        int32_t prefix_17230;\n        bool block_new_sgm_17231;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_17158 == 0) {\n                dynamic_id_17180 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_17135)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_17167)[(int64_t) 0] = dynamic_id_17180;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_17180 == num_virt_blocks_17103 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_17135)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_17180 = ((__local int32_t *) local_mem_17167)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_17181 = dynamic_id_17180 * chunk_sizze_17102 * segscan_tblock_sizze_16594;\n        sgm_idx_17182 = smod64(block_offset_17181, m_12436);\n        boundary_17183 = sext_i64_i32(smin64(chunk_sizze_17102 * segscan_tblock_sizze_16594, m_12436 - sgm_idx_17182));\n        segsizze_compact_17184 = sext_i64_i32(smin64(chunk_sizze_17102 * segscan_tblock_sizze_16594, m_12436));\n        thd_offset_17189 = block_offset_17181 + sext_i32_i64(local_tid_17158);\n        // Load and map\n        {\n            for (int64_t i_17190 = 0; i_17190 < chunk_sizze_17102; i_17190++) {\n            ", "    int64_t virt_tid_17191 = thd_offset_17189 + i_17190 * segscan_tblock_sizze_16594;\n                int64_t slice_17192 = m_12436;\n                int64_t gtid_16598 = virt_tid_17191;\n                int64_t remnant_17193 = virt_tid_17191 - gtid_16598;\n                \n                if (slt64(virt_tid_17191, m_12436)) {\n                    int32_t x_14589 = ((__global int32_t *) shp_mem_16947)[gtid_16598];\n                    int64_t i32_res_14591 = sext_i32_i64(x_14589);\n                    \n                    private_mem_17185[i_17190] = i32_res_14591;\n                    private_mem_17187[i_17190] = x_14589;\n                } else {\n                    private_mem_17185[i_17190] = (int64_t) 0;\n                    private_mem_17187[i_17190] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_17194 = 0; i_17194 < chunk_sizze_17102; i_17194++) {\n                int64_t sharedIdx_17195 = sext_i32_i64(local_tid_17158) + i_17194 * segscan_tblock_sizze_16594;\n                int64_t tmp_17196 = private_mem_17185[i_17194];\n                \n                ((__local int64_t *) local_mem_17167)[sharedIdx_17195] = tmp_17196;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17197 = 0; i_17197 < chunk_sizze_17102; i_17197++) {\n                int64_t sharedIdx_17198 = sext_i32_i64(local_tid_17158) * chunk_sizze_17102 + i_17197;\n                int64_t tmp_17199 = ((__local int64_t *) local_mem_17167)[sharedIdx_17198];\n                \n                private_mem_17185[i_17197] = tmp_17199;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17200 = 0; i_17200 < chunk_sizze_17102; i_17200++) {\n                int64_t sharedIdx_17201 = sext_i32_i64(local_tid_17158) + i_17200 * segscan_tblock_sizze_16594;\n                int32_t tmp_17202 = private_mem_17187[i_17200];\n                \n                ((__loca",
                                    "l int32_t *) local_mem_17167)[sharedIdx_17201] = tmp_17202;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17203 = 0; i_17203 < chunk_sizze_17102; i_17203++) {\n                int64_t sharedIdx_17204 = sext_i32_i64(local_tid_17158) * chunk_sizze_17102 + i_17203;\n                int32_t tmp_17205 = ((__local int32_t *) local_mem_17167)[sharedIdx_17204];\n                \n                private_mem_17187[i_17203] = tmp_17205;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_17206 = 0; i_17206 < chunk_sizze_17102 - (int64_t) 1; i_17206++) {\n                int64_t eta_p_14082;\n                int64_t eta_p_14083;\n                \n                eta_p_14082 = private_mem_17185[i_17206];\n                eta_p_14083 = private_mem_17185[i_17206 + (int64_t) 1];\n                \n                int32_t eta_p_14425;\n                int32_t eta_p_14426;\n                \n                eta_p_14425 = private_mem_17187[i_17206];\n                eta_p_14426 = private_mem_17187[i_17206 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_14084 = add64(eta_p_14082, eta_p_14083);\n                int32_t defunc_0_op_res_14427 = add32(eta_p_14425, eta_p_14426);\n                \n                private_mem_17185[i_17206 + (int64_t) 1] = defunc_0_op_res_14084;\n                private_mem_17187[i_17206 + (int64_t) 1] = defunc_0_op_res_14427;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_17207 = private_mem_17185[chunk_sizze_17102 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)] = tmp_17207;\n            \n            int32_t tmp_17208 = private_mem_17187[chunk_sizze_17102 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + sext_i32_i64(local_tid_17158)] = tmp_17208;\n    ", "        barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_17209;\n            int32_t eta_p_17210;\n            int64_t eta_p_17211;\n            int32_t eta_p_17212;\n            int64_t eta_p_17217;\n            int32_t eta_p_17218;\n            int64_t eta_p_17219;\n            int32_t eta_p_17220;\n            bool ltid_in_bounds_17223 = slt64(sext_i32_i64(local_tid_17158), num_virt_threads_17104);\n            int32_t skip_threads_17224;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_17223) {\n                    eta_p_17211 = ((volatile __local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)];\n                    eta_p_17212 = ((volatile __local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + sext_i32_i64(local_tid_17158)];\n                    if ((local_tid_17158 - squot32(local_tid_17158, 32) * 32) == 0) {\n                        eta_p_17209 = eta_p_17211;\n                        eta_p_17210 = eta_p_17212;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_17224 = 1;\n                while (slt32(skip_threads_17224, 32)) {\n                    bool thread_active_17225 = sle32(skip_threads_17224, local_tid_17158 - squot32(local_tid_17158, 32) * 32) && ltid_in_bounds_17223;\n                    \n                    if (thread_active_17225) {\n                        // read operands\n                        {\n                            eta_p_17209 = ((volatile __local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158) - sext_i32_i64(skip_threads_17224)];\n                            eta_p_17210 = ((volatile __local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + (sext_i32_i64(local_tid_17158) - sext_i32_i64(skip_threads_17224))];\n                        }\n                    }\n        ", "            // perform operation\n                    {\n                        if (thread_active_17225) {\n                            int64_t defunc_0_op_res_17213 = add64(eta_p_17209, eta_p_17211);\n                            int32_t defunc_0_op_res_17214 = add32(eta_p_17210, eta_p_17212);\n                            \n                            eta_p_17209 = defunc_0_op_res_17213;\n                            eta_p_17210 = defunc_0_op_res_17214;\n                        }\n                    }\n                    if (sle32(wave_sizze_17160, skip_threads_17224)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_17225) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)] = eta_p_17209;\n                            eta_p_17211 = eta_p_17209;\n                            ((volatile __local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + sext_i32_i64(local_tid_17158)] = eta_p_17210;\n                            eta_p_17212 = eta_p_17210;\n                        }\n                    }\n                    if (sle32(wave_sizze_17160, skip_threads_17224)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_17224 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_17158 - squot32(local_tid_17158, 32) * 32) == 31 && ltid_in_bounds_17223) {\n                    ((volatile __local int64_t *) local_mem_17167)[sext_i32_i64(squot32(local_tid_17158, 32))] = eta_p_17209;\n                    ((volatile __local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + sext_i32_i64(squot32(local_tid_17158, 32))] = eta_p_17210;\n                }\n            }\n            ",
                                    "barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_17226;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_17158, 32) == 0 && ltid_in_bounds_17223) {\n                        eta_p_17219 = ((volatile __local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)];\n                        eta_p_17220 = ((volatile __local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + sext_i32_i64(local_tid_17158)];\n                        if ((local_tid_17158 - squot32(local_tid_17158, 32) * 32) == 0) {\n                            eta_p_17217 = eta_p_17219;\n                            eta_p_17218 = eta_p_17220;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_17226 = 1;\n                    while (slt32(skip_threads_17226, 32)) {\n                        bool thread_active_17227 = sle32(skip_threads_17226, local_tid_17158 - squot32(local_tid_17158, 32) * 32) && (squot32(local_tid_17158, 32) == 0 && ltid_in_bounds_17223);\n                        \n                        if (thread_active_17227) {\n                            // read operands\n                            {\n                                eta_p_17217 = ((volatile __local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158) - sext_i32_i64(skip_threads_17226)];\n                                eta_p_17218 = ((volatile __local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + (sext_i32_i64(local_tid_17158) - sext_i32_i64(skip_threads_17226))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_17227) {\n                             ", "   int64_t defunc_0_op_res_17221 = add64(eta_p_17217, eta_p_17219);\n                                int32_t defunc_0_op_res_17222 = add32(eta_p_17218, eta_p_17220);\n                                \n                                eta_p_17217 = defunc_0_op_res_17221;\n                                eta_p_17218 = defunc_0_op_res_17222;\n                            }\n                        }\n                        if (sle32(wave_sizze_17160, skip_threads_17226)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_17227) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)] = eta_p_17217;\n                                eta_p_17219 = eta_p_17217;\n                                ((volatile __local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + sext_i32_i64(local_tid_17158)] = eta_p_17218;\n                                eta_p_17220 = eta_p_17218;\n                            }\n                        }\n                        if (sle32(wave_sizze_17160, skip_threads_17226)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_17226 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_17228 = squot32(local_tid_17158, 32) == 0 || !ltid_in_bounds_17223;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_17228) {\n                        eta_p_17211 = eta_p_17209;\n                        eta_p_17212 = eta_p_17210;\n                        eta_p_17209 = ((__local int64_t *) local_mem_17167)[sext_i32_i64(squot32(local_tid_17158, 32)) - (int64_t) 1];\n                        e", "ta_p_17210 = ((__local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + (sext_i32_i64(squot32(local_tid_17158, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_17228) {\n                        int64_t defunc_0_op_res_17213 = add64(eta_p_17209, eta_p_17211);\n                        int32_t defunc_0_op_res_17214 = add32(eta_p_17210, eta_p_17212);\n                        \n                        eta_p_17209 = defunc_0_op_res_17213;\n                        eta_p_17210 = defunc_0_op_res_17214;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_17228) {\n                        ((__local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)] = eta_p_17209;\n                        ((__local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + sext_i32_i64(local_tid_17158)] = eta_p_17210;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_17158, 32) == 0 && ltid_in_bounds_17223) {\n                    ((__local int64_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)] = eta_p_17211;\n                    ((__local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + sext_i32_i64(local_tid_17158)] = eta_p_17212;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_17158 == 0) {\n                acc_17215 = ((__local int64_t *) local_mem_17167)[segscan_tblock_sizze_16594 - (int64_t) 1];\n                acc_17216 = ((__local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + (segscan_tblock_sizze_16594 - (int64_t) 1)];\n            } else {\n                acc_17215 = ((__local int6",
                                    "4_t *) local_mem_17167)[sext_i32_i64(local_tid_17158) - (int64_t) 1];\n                acc_17216 = ((__local int32_t *) local_mem_17167)[squot64(byte_offsets_17163, (int64_t) 4) + (sext_i32_i64(local_tid_17158) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_17229 = (int64_t) 0;\n        prefix_17230 = 0;\n        block_new_sgm_17231 = sgm_idx_17182 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_17231 && local_tid_17158 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_17129)[dynamic_id_17180] = acc_17215;\n                ((volatile __global int32_t *) incprefixes_mem_17133)[dynamic_id_17180] = acc_17216;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_17105)[dynamic_id_17180] = (int8_t) 2;\n                acc_17215 = (int64_t) 0;\n                acc_17216 = 0;\n            }\n            if (!block_new_sgm_17231 && slt32(local_tid_17158, wave_sizze_17160)) {\n                if (local_tid_17158 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_17127)[dynamic_id_17180] = acc_17215;\n                    ((volatile __global int32_t *) aggregates_mem_17131)[dynamic_id_17180] = acc_17216;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_17105)[dynamic_id_17180] = (int8_t) 1;\n                    \n                    int8_t tmp_17232 = ((volatile __global int8_t *) status_flags_mem_17105)[dynamic_id_17180 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_17167)[(int64_t) 0] = tmp_17232;\n                }\n                mem_fence_local();\n                \n                int8_t status_17233 = ((__local int8_t *) local_mem_17167)[(int64_t) 0];\n                \n                if (status_17233 == (int8_t) 2) {\n                    if (local_tid_17158 == 0) {\n                        prefix_17229 = ((v", "olatile __global int64_t *) incprefixes_mem_17129)[dynamic_id_17180 - (int64_t) 1];\n                        prefix_17230 = ((volatile __global int32_t *) incprefixes_mem_17133)[dynamic_id_17180 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_17234 = sext_i64_i32(dynamic_id_17180 - sext_i32_i64(wave_sizze_17160));\n                    \n                    while (slt32(wave_sizze_17160 * -1, readOffset_17234)) {\n                        int32_t read_i_17235 = readOffset_17234 + local_tid_17158;\n                        int64_t aggr_17236 = (int64_t) 0;\n                        int32_t aggr_17237 = 0;\n                        int8_t flag_17238 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_17235)) {\n                            flag_17238 = ((volatile __global int8_t *) status_flags_mem_17105)[sext_i32_i64(read_i_17235)];\n                            if (flag_17238 == (int8_t) 2) {\n                                aggr_17236 = ((volatile __global int64_t *) incprefixes_mem_17129)[sext_i32_i64(read_i_17235)];\n                                aggr_17237 = ((volatile __global int32_t *) incprefixes_mem_17133)[sext_i32_i64(read_i_17235)];\n                            } else if (flag_17238 == (int8_t) 1) {\n                                aggr_17236 = ((volatile __global int64_t *) aggregates_mem_17127)[sext_i32_i64(read_i_17235)];\n                                aggr_17237 = ((volatile __global int32_t *) aggregates_mem_17131)[sext_i32_i64(read_i_17235)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_17167)[(int64_t) 4 + sext_i32_i64(local_tid_17158)] = aggr_17236;\n                        ((__local int32_t *) local_mem_17167)[squot64(warp_byte_offset_17165, (int64_t) 4) + sext_i32_i64(local_tid_17158)] = aggr_17237;\n                        ((__local int8_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)] = flag_17238;\n           ", "             flag_17238 = ((__local int8_t *) local_mem_17167)[sext_i32_i64(wave_sizze_17160) - (int64_t) 1];\n                        if (slt8(flag_17238, (int8_t) 2)) {\n                            int8_t flg_x_17245;\n                            int8_t flg_y_17246;\n                            int64_t eta_p_17239;\n                            int32_t eta_p_17240;\n                            int64_t eta_p_17241;\n                            int32_t eta_p_17242;\n                            int32_t skip_threads_17247;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_17246 = ((volatile __local int8_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)];\n                                eta_p_17241 = ((volatile __local int64_t *) local_mem_17167)[(int64_t) 4 + sext_i32_i64(local_tid_17158)];\n                                eta_p_17242 = ((volatile __local int32_t *) local_mem_17167)[squot64(warp_byte_offset_17165, (int64_t) 4) + sext_i32_i64(local_tid_17158)];\n                                if ((local_tid_17158 - squot32(local_tid_17158, 32) * 32) == 0) {\n                                    eta_p_17239 = eta_p_17241;\n                                    eta_p_17240 = eta_p_17242;\n                                    flg_x_17245 = flg_y_17246;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_17247 = 1;\n                                while (slt32(skip_threads_17247, 32)) {\n                                    if (sle32(skip_threads_17247, local_tid_17158 - squot32(local_tid_17158, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_17245 = ((volatile __local int8_t *) local_mem_17167)[sext_i32_i64(local",
                                    "_tid_17158) - sext_i32_i64(skip_threads_17247)];\n                                            eta_p_17239 = ((volatile __local int64_t *) local_mem_17167)[(int64_t) 4 + (sext_i32_i64(local_tid_17158) - sext_i32_i64(skip_threads_17247))];\n                                            eta_p_17240 = ((volatile __local int32_t *) local_mem_17167)[squot64(warp_byte_offset_17165, (int64_t) 4) + (sext_i32_i64(local_tid_17158) - sext_i32_i64(skip_threads_17247))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_17246 == (int8_t) 2 || flg_y_17246 == (int8_t) 0) {\n                                                flg_x_17245 = flg_y_17246;\n                                                eta_p_17239 = eta_p_17241;\n                                                eta_p_17240 = eta_p_17242;\n                                            } else {\n                                                int64_t defunc_0_op_res_17243 = add64(eta_p_17239, eta_p_17241);\n                                                int32_t defunc_0_op_res_17244 = add32(eta_p_17240, eta_p_17242);\n                                                \n                                                eta_p_17239 = defunc_0_op_res_17243;\n                                                eta_p_17240 = defunc_0_op_res_17244;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_17167)[sext_i32_i64(local_tid_17158)] = flg_x_17245;\n                                            flg_y_17246 = flg_x_17245;\n                                            ((volatile __local int64_t *) local_mem_17167)[(int64_t) 4 + sext_i32_i64(local_tid_17158)] = eta_p_17239;\n                        ", "                    eta_p_17241 = eta_p_17239;\n                                            ((volatile __local int32_t *) local_mem_17167)[squot64(warp_byte_offset_17165, (int64_t) 4) + sext_i32_i64(local_tid_17158)] = eta_p_17240;\n                                            eta_p_17242 = eta_p_17240;\n                                        }\n                                    }\n                                    skip_threads_17247 *= 2;\n                                }\n                            }\n                        }\n                        flag_17238 = ((__local int8_t *) local_mem_17167)[sext_i32_i64(wave_sizze_17160) - (int64_t) 1];\n                        aggr_17236 = ((__local int64_t *) local_mem_17167)[(int64_t) 4 + (sext_i32_i64(wave_sizze_17160) - (int64_t) 1)];\n                        aggr_17237 = ((__local int32_t *) local_mem_17167)[squot64(warp_byte_offset_17165, (int64_t) 4) + (sext_i32_i64(wave_sizze_17160) - (int64_t) 1)];\n                        if (flag_17238 == (int8_t) 2) {\n                            readOffset_17234 = wave_sizze_17160 * -1;\n                        } else if (flag_17238 == (int8_t) 1) {\n                            readOffset_17234 -= wave_sizze_17160;\n                        }\n                        if (slt8((int8_t) 0, flag_17238)) {\n                            int64_t eta_p_17248 = aggr_17236;\n                            int32_t eta_p_17249 = aggr_17237;\n                            int64_t eta_p_17250 = prefix_17229;\n                            int32_t eta_p_17251 = prefix_17230;\n                            int64_t defunc_0_op_res_17252 = add64(eta_p_17248, eta_p_17250);\n                            int32_t defunc_0_op_res_17253 = add32(eta_p_17249, eta_p_17251);\n                            \n                            prefix_17229 = defunc_0_op_res_17252;\n                            prefix_17230 = defunc_0_op_res_17253;\n                        }\n                        mem_fence_local();\n                    }\n      ", "          }\n                if (local_tid_17158 == 0) {\n                    if (boundary_17183 == sext_i64_i32(segscan_tblock_sizze_16594 * chunk_sizze_17102)) {\n                        int64_t eta_p_17254 = prefix_17229;\n                        int32_t eta_p_17255 = prefix_17230;\n                        int64_t eta_p_17256 = acc_17215;\n                        int32_t eta_p_17257 = acc_17216;\n                        int64_t defunc_0_op_res_17258 = add64(eta_p_17254, eta_p_17256);\n                        int32_t defunc_0_op_res_17259 = add32(eta_p_17255, eta_p_17257);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_17129)[dynamic_id_17180] = defunc_0_op_res_17258;\n                        ((volatile __global int32_t *) incprefixes_mem_17133)[dynamic_id_17180] = defunc_0_op_res_17259;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_17105)[dynamic_id_17180] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_17167)[(int64_t) 4] = prefix_17229;\n                    ((__local int32_t *) local_mem_17167)[squot64(warp_byte_offset_17165, (int64_t) 4)] = prefix_17230;\n                    acc_17215 = (int64_t) 0;\n                    acc_17216 = 0;\n                }\n            }\n            if (!(dynamic_id_17180 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_17229 = ((__local int64_t *) local_mem_17167)[(int64_t) 4];\n                prefix_17230 = ((__local int32_t *) local_mem_17167)[squot64(warp_byte_offset_17165, (int64_t) 4)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_17260;\n            int64_t eta_p_17262;\n            int64_t eta_p_17266 = prefix_17229;\n            int64_t eta_p_17268 = acc_17215;\n            int32_t eta_p_17261;\n            int32_t eta_p_17263;\n            int32_t eta_p_1726",
                                    "7 = prefix_17230;\n            int32_t eta_p_17269 = acc_17216;\n            \n            if (slt32(local_tid_17158 * chunk_sizze_32b_17162, boundary_17183) && !block_new_sgm_17231) {\n                int64_t defunc_0_op_res_17270 = add64(eta_p_17266, eta_p_17268);\n                int32_t defunc_0_op_res_17271 = add32(eta_p_17267, eta_p_17269);\n                \n                eta_p_17260 = defunc_0_op_res_17270;\n                eta_p_17261 = defunc_0_op_res_17271;\n            } else {\n                eta_p_17260 = acc_17215;\n                eta_p_17261 = acc_17216;\n            }\n            \n            int32_t stopping_point_17272 = segsizze_compact_17184 - srem32(local_tid_17158 * chunk_sizze_32b_17162 - 1 + segsizze_compact_17184 - boundary_17183, segsizze_compact_17184);\n            \n            for (int64_t i_17273 = 0; i_17273 < chunk_sizze_17102; i_17273++) {\n                if (slt32(sext_i64_i32(i_17273), stopping_point_17272 - 1)) {\n                    eta_p_17262 = private_mem_17185[i_17273];\n                    eta_p_17263 = private_mem_17187[i_17273];\n                    \n                    int64_t defunc_0_op_res_17264 = add64(eta_p_17260, eta_p_17262);\n                    int32_t defunc_0_op_res_17265 = add32(eta_p_17261, eta_p_17263);\n                    \n                    private_mem_17185[i_17273] = defunc_0_op_res_17264;\n                    private_mem_17187[i_17273] = defunc_0_op_res_17265;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_17274 = 0; i_17274 < chunk_sizze_17102; i_17274++) {\n                int64_t sharedIdx_17275 = sext_i32_i64(local_tid_17158) * chunk_sizze_17102 + i_17274;\n                int64_t tmp_17276 = private_mem_17185[i_17274];\n                \n                ((__local int64_t *) local_mem_17167)[sharedIdx_17275] = tmp_17276;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t ", "i_17277 = 0; i_17277 < chunk_sizze_17102; i_17277++) {\n                int64_t flat_idx_17278 = thd_offset_17189 + i_17277 * segscan_tblock_sizze_16594;\n                int64_t slice_17279 = m_12436;\n                int64_t gtid_16598 = flat_idx_17278;\n                int64_t remnant_17280 = flat_idx_17278 - gtid_16598;\n                \n                if (slt64(flat_idx_17278, m_12436)) {\n                    int64_t tmp_17281 = ((__local int64_t *) local_mem_17167)[flat_idx_17278 - block_offset_17181];\n                    \n                    ((__global int64_t *) mem_16951)[gtid_16598] = tmp_17281;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17282 = 0; i_17282 < chunk_sizze_17102; i_17282++) {\n                int64_t sharedIdx_17283 = sext_i32_i64(local_tid_17158) * chunk_sizze_17102 + i_17282;\n                int32_t tmp_17284 = private_mem_17187[i_17282];\n                \n                ((__local int32_t *) local_mem_17167)[sharedIdx_17283] = tmp_17284;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17285 = 0; i_17285 < chunk_sizze_17102; i_17285++) {\n                int64_t flat_idx_17286 = thd_offset_17189 + i_17285 * segscan_tblock_sizze_16594;\n                int64_t slice_17287 = m_12436;\n                int64_t gtid_16598 = flat_idx_17286;\n                int64_t remnant_17288 = flat_idx_17286 - gtid_16598;\n                \n                if (slt64(flat_idx_17286, m_12436)) {\n                    int32_t tmp_17289 = ((__local int32_t *) local_mem_17167)[flat_idx_17286 - block_offset_17181];\n                    \n                    ((__global int32_t *) mem_16953)[gtid_16598] = tmp_17289;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16594\n    #undef chunk_sizze_17102\n}\nFUTHARK_KERNEL_SIZED(mainzisegscan_16615_dim1, 1, 1)\nvoid mainzisegscan_16615(__global int *gl", "obal_failure, int64_t n_12437, int64_t num_tblocks_16612, int64_t num_virt_blocks_17330, int64_t num_virt_threads_17331, __global unsigned char *mem_16954, __global unsigned char *mem_16961, __global unsigned char *status_flags_mem_17332, __global unsigned char *aggregates_mem_17334, __global unsigned char *incprefixes_mem_17336, __global unsigned char *global_dynid_mem_17338)\n{\n    #define segscan_tblock_sizze_16610 (mainzisegscan_16615zisegscan_tblock_sizze_16610)\n    #define chunk_sizze_17329 (mainzisegscan_16615zichunk_sizze_17329)\n    \n    volatile __local unsigned char *local_mem_17348_backing_0 = &shared_mem[0];\n    const int64_t local_mem_17348_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_16610), chunk_sizze_17329 * segscan_tblock_sizze_16610 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_16610), chunk_sizze_17329 * segscan_tblock_sizze_16610 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17341;\n    int32_t tblock_sizze_17344;\n    int32_t wave_sizze_17343;\n    int32_t block_id_17342;\n    int32_t global_tid_17340;\n    int64_t phys_tid_16615;\n    int32_t chunk_sizze_32b_17345;\n    int64_t byte_offsets_17346;\n    int64_t warp_byte_offset_17347;\n    __local unsigned char *local_mem_17348;\n    int64_t trans_arr_len_17349;\n    int64_t phys_block_id_17355;\n    int64_t virtloop_bound_17356;\n    \n    local_tid_17341 = get_local_id(0);\n    tblock_sizze_17344 = get_local_size(0);\n    wave_sizze_17343 = LOCKSTEP_WIDTH;\n    block_id_17342 = get_tblock_id(0);\n    global_tid_17340 = block_id_17342 * tblock_sizze_17344 + local_tid_17341;\n    phys_tid_16615 = sext_i32_i64(global_tid_17340);\n    chunk_sizze_32b_17345 = sext_i64_i32(chunk_sizze_17329);\n    byte_offsets_17346 = segscan_tblock_sizze_16610 * (int64_t) 4;\n    warp_byte_offset_17347 = (int64_t) 160;\n    // Allocate reusable shared memory",
                                    "\n    { }\n    local_mem_17348 = (__local unsigned char *) local_mem_17348_backing_0;\n    trans_arr_len_17349 = chunk_sizze_17329 * segscan_tblock_sizze_16610;\n    phys_block_id_17355 = get_tblock_id(0);\n    virtloop_bound_17356 = sdiv_up64(num_virt_blocks_17330 - phys_block_id_17355, num_tblocks_16612);\n    for (int64_t virtloop_i_17357 = 0; virtloop_i_17357 < virtloop_bound_17356; virtloop_i_17357++) {\n        int64_t dynamic_id_17358;\n        int64_t block_offset_17359;\n        int64_t sgm_idx_17360;\n        int32_t boundary_17361;\n        int32_t segsizze_compact_17362;\n        int32_t private_mem_17363[chunk_sizze_17329];\n        int64_t thd_offset_17365;\n        int32_t acc_17381;\n        int32_t prefix_17391;\n        bool block_new_sgm_17392;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_17341 == 0) {\n                dynamic_id_17358 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_17338)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_17348)[(int64_t) 0] = dynamic_id_17358;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_17358 == num_virt_blocks_17330 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_17338)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_17358 = ((__local int32_t *) local_mem_17348)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_17359 = dynamic_id_17358 * chunk_sizze_17329 * segscan_tblock_sizze_16610;\n        sgm_idx_17360 = smod64(block_offset_17359, n_12437);\n        boundary_17361 = sext_i64_i32(smin64(chunk_sizze_17329 * segscan_tblock_sizze_16610, n_12437 - sgm_idx_17360));\n        segsizze_compact_17362 = sext_i64_i", "32(smin64(chunk_sizze_17329 * segscan_tblock_sizze_16610, n_12437));\n        thd_offset_17365 = block_offset_17359 + sext_i32_i64(local_tid_17341);\n        // Load and map\n        {\n            for (int64_t i_17366 = 0; i_17366 < chunk_sizze_17329; i_17366++) {\n                int64_t virt_tid_17367 = thd_offset_17365 + i_17366 * segscan_tblock_sizze_16610;\n                int64_t slice_17368 = n_12437;\n                int64_t gtid_16614 = virt_tid_17367;\n                int64_t remnant_17369 = virt_tid_17367 - gtid_16614;\n                \n                if (slt64(virt_tid_17367, n_12437)) {\n                    bool eta_p_14599 = ((__global bool *) mem_16954)[gtid_16614];\n                    int32_t bool_res_14600 = btoi_bool_i32(eta_p_14599);\n                    \n                    private_mem_17363[i_17366] = bool_res_14600;\n                } else {\n                    private_mem_17363[i_17366] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_17370 = 0; i_17370 < chunk_sizze_17329; i_17370++) {\n                int64_t sharedIdx_17371 = sext_i32_i64(local_tid_17341) + i_17370 * segscan_tblock_sizze_16610;\n                int32_t tmp_17372 = private_mem_17363[i_17370];\n                \n                ((__local int32_t *) local_mem_17348)[sharedIdx_17371] = tmp_17372;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17373 = 0; i_17373 < chunk_sizze_17329; i_17373++) {\n                int64_t sharedIdx_17374 = sext_i32_i64(local_tid_17341) * chunk_sizze_17329 + i_17373;\n                int32_t tmp_17375 = ((__local int32_t *) local_mem_17348)[sharedIdx_17374];\n                \n                private_mem_17363[i_17373] = tmp_17375;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_17376 = 0; i_17376 < chunk_sizze_17329 - (int64_t) 1; i_17376++) {\n ", "               int32_t eta_p_14549;\n                int32_t eta_p_14550;\n                \n                eta_p_14549 = private_mem_17363[i_17376];\n                eta_p_14550 = private_mem_17363[i_17376 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_14551 = add32(eta_p_14549, eta_p_14550);\n                \n                private_mem_17363[i_17376 + (int64_t) 1] = defunc_0_op_res_14551;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_17377 = private_mem_17363[chunk_sizze_17329 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)] = tmp_17377;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_17378;\n            int32_t eta_p_17379;\n            int32_t eta_p_17382;\n            int32_t eta_p_17383;\n            bool ltid_in_bounds_17385 = slt64(sext_i32_i64(local_tid_17341), num_virt_threads_17331);\n            int32_t skip_threads_17386;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_17385) {\n                    eta_p_17379 = ((volatile __local int32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)];\n                    if ((local_tid_17341 - squot32(local_tid_17341, 32) * 32) == 0) {\n                        eta_p_17378 = eta_p_17379;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_17386 = 1;\n                while (slt32(skip_threads_17386, 32)) {\n                    bool thread_active_17387 = sle32(skip_threads_17386, local_tid_17341 - squot32(local_tid_17341, 32) * 32) && ltid_in_bounds_17385;\n                    \n                    if (thread_active_17387) {\n                        // read operands\n                        {\n                            eta_p_17378 = ((volatile __local i",
                                    "nt32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341) - sext_i32_i64(skip_threads_17386)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_17387) {\n                            int32_t defunc_0_op_res_17380 = add32(eta_p_17378, eta_p_17379);\n                            \n                            eta_p_17378 = defunc_0_op_res_17380;\n                        }\n                    }\n                    if (sle32(wave_sizze_17343, skip_threads_17386)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_17387) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)] = eta_p_17378;\n                            eta_p_17379 = eta_p_17378;\n                        }\n                    }\n                    if (sle32(wave_sizze_17343, skip_threads_17386)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_17386 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_17341 - squot32(local_tid_17341, 32) * 32) == 31 && ltid_in_bounds_17385) {\n                    ((volatile __local int32_t *) local_mem_17348)[sext_i32_i64(squot32(local_tid_17341, 32))] = eta_p_17378;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_17388;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_17341, 32) == 0 && ltid_in_bounds_17385) {\n                        eta_p_17383 = ((volati", "le __local int32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)];\n                        if ((local_tid_17341 - squot32(local_tid_17341, 32) * 32) == 0) {\n                            eta_p_17382 = eta_p_17383;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_17388 = 1;\n                    while (slt32(skip_threads_17388, 32)) {\n                        bool thread_active_17389 = sle32(skip_threads_17388, local_tid_17341 - squot32(local_tid_17341, 32) * 32) && (squot32(local_tid_17341, 32) == 0 && ltid_in_bounds_17385);\n                        \n                        if (thread_active_17389) {\n                            // read operands\n                            {\n                                eta_p_17382 = ((volatile __local int32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341) - sext_i32_i64(skip_threads_17388)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_17389) {\n                                int32_t defunc_0_op_res_17384 = add32(eta_p_17382, eta_p_17383);\n                                \n                                eta_p_17382 = defunc_0_op_res_17384;\n                            }\n                        }\n                        if (sle32(wave_sizze_17343, skip_threads_17388)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_17389) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)] = eta_p_17382;\n                                eta_p_17383 = eta_p_17382;\n                            }\n                        }\n                        if (sle32(wave_sizze_17343, skip_threads_1", "7388)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_17388 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_17390 = squot32(local_tid_17341, 32) == 0 || !ltid_in_bounds_17385;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_17390) {\n                        eta_p_17379 = eta_p_17378;\n                        eta_p_17378 = ((__local int32_t *) local_mem_17348)[sext_i32_i64(squot32(local_tid_17341, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_17390) {\n                        int32_t defunc_0_op_res_17380 = add32(eta_p_17378, eta_p_17379);\n                        \n                        eta_p_17378 = defunc_0_op_res_17380;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_17390) {\n                        ((__local int32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)] = eta_p_17378;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_17341, 32) == 0 && ltid_in_bounds_17385) {\n                    ((__local int32_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)] = eta_p_17379;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_17341 == 0) {\n                acc_17381 = ((__local int32_t *) local_mem_17348)[segscan_tblock_sizze_16610 - (int64_t) 1];\n            } else {\n                acc_17381 = ((__local int32_t *) local_mem_17348)[sext_i32_i64(local",
                                    "_tid_17341) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_17391 = 0;\n        block_new_sgm_17392 = sgm_idx_17360 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_17392 && local_tid_17341 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_17336)[dynamic_id_17358] = acc_17381;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_17332)[dynamic_id_17358] = (int8_t) 2;\n                acc_17381 = 0;\n            }\n            if (!block_new_sgm_17392 && slt32(local_tid_17341, wave_sizze_17343)) {\n                if (local_tid_17341 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_17334)[dynamic_id_17358] = acc_17381;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_17332)[dynamic_id_17358] = (int8_t) 1;\n                    \n                    int8_t tmp_17393 = ((volatile __global int8_t *) status_flags_mem_17332)[dynamic_id_17358 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_17348)[(int64_t) 0] = tmp_17393;\n                }\n                mem_fence_local();\n                \n                int8_t status_17394 = ((__local int8_t *) local_mem_17348)[(int64_t) 0];\n                \n                if (status_17394 == (int8_t) 2) {\n                    if (local_tid_17341 == 0) {\n                        prefix_17391 = ((volatile __global int32_t *) incprefixes_mem_17336)[dynamic_id_17358 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_17395 = sext_i64_i32(dynamic_id_17358 - sext_i32_i64(wave_sizze_17343));\n                    \n                    while (slt32(wave_sizze_17343 * -1, readOffset_17395)) {\n                        int32_t read_i_17396 = readOffset_17395 + local_tid_17341;\n                        int32_t aggr_17397 = 0;\n         ", "               int8_t flag_17398 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_17396)) {\n                            flag_17398 = ((volatile __global int8_t *) status_flags_mem_17332)[sext_i32_i64(read_i_17396)];\n                            if (flag_17398 == (int8_t) 2) {\n                                aggr_17397 = ((volatile __global int32_t *) incprefixes_mem_17336)[sext_i32_i64(read_i_17396)];\n                            } else if (flag_17398 == (int8_t) 1) {\n                                aggr_17397 = ((volatile __global int32_t *) aggregates_mem_17334)[sext_i32_i64(read_i_17396)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_17348)[(int64_t) 8 + sext_i32_i64(local_tid_17341)] = aggr_17397;\n                        ((__local int8_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)] = flag_17398;\n                        flag_17398 = ((__local int8_t *) local_mem_17348)[sext_i32_i64(wave_sizze_17343) - (int64_t) 1];\n                        if (slt8(flag_17398, (int8_t) 2)) {\n                            int8_t flg_x_17402;\n                            int8_t flg_y_17403;\n                            int32_t eta_p_17399;\n                            int32_t eta_p_17400;\n                            int32_t skip_threads_17404;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_17403 = ((volatile __local int8_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)];\n                                eta_p_17400 = ((volatile __local int32_t *) local_mem_17348)[(int64_t) 8 + sext_i32_i64(local_tid_17341)];\n                                if ((local_tid_17341 - squot32(local_tid_17341, 32) * 32) == 0) {\n                                    eta_p_17399 = eta_p_17400;\n                                    flg_x_17402 = flg_y_17403;\n                                }\n              ", "              }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_17404 = 1;\n                                while (slt32(skip_threads_17404, 32)) {\n                                    if (sle32(skip_threads_17404, local_tid_17341 - squot32(local_tid_17341, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_17402 = ((volatile __local int8_t *) local_mem_17348)[sext_i32_i64(local_tid_17341) - sext_i32_i64(skip_threads_17404)];\n                                            eta_p_17399 = ((volatile __local int32_t *) local_mem_17348)[(int64_t) 8 + (sext_i32_i64(local_tid_17341) - sext_i32_i64(skip_threads_17404))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_17403 == (int8_t) 2 || flg_y_17403 == (int8_t) 0) {\n                                                flg_x_17402 = flg_y_17403;\n                                                eta_p_17399 = eta_p_17400;\n                                            } else {\n                                                int32_t defunc_0_op_res_17401 = add32(eta_p_17399, eta_p_17400);\n                                                \n                                                eta_p_17399 = defunc_0_op_res_17401;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_17348)[sext_i32_i64(local_tid_17341)] = flg_x_17402;\n                                            flg_y_17403 = flg_x_17402;\n                                            ((volatile __local int32_t *) lo",
                                    "cal_mem_17348)[(int64_t) 8 + sext_i32_i64(local_tid_17341)] = eta_p_17399;\n                                            eta_p_17400 = eta_p_17399;\n                                        }\n                                    }\n                                    skip_threads_17404 *= 2;\n                                }\n                            }\n                        }\n                        flag_17398 = ((__local int8_t *) local_mem_17348)[sext_i32_i64(wave_sizze_17343) - (int64_t) 1];\n                        aggr_17397 = ((__local int32_t *) local_mem_17348)[(int64_t) 8 + (sext_i32_i64(wave_sizze_17343) - (int64_t) 1)];\n                        if (flag_17398 == (int8_t) 2) {\n                            readOffset_17395 = wave_sizze_17343 * -1;\n                        } else if (flag_17398 == (int8_t) 1) {\n                            readOffset_17395 -= wave_sizze_17343;\n                        }\n                        if (slt8((int8_t) 0, flag_17398)) {\n                            int32_t eta_p_17405 = aggr_17397;\n                            int32_t eta_p_17406 = prefix_17391;\n                            int32_t defunc_0_op_res_17407 = add32(eta_p_17405, eta_p_17406);\n                            \n                            prefix_17391 = defunc_0_op_res_17407;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_17341 == 0) {\n                    if (boundary_17361 == sext_i64_i32(segscan_tblock_sizze_16610 * chunk_sizze_17329)) {\n                        int32_t eta_p_17408 = prefix_17391;\n                        int32_t eta_p_17409 = acc_17381;\n                        int32_t defunc_0_op_res_17410 = add32(eta_p_17408, eta_p_17409);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_17336)[dynamic_id_17358] = defunc_0_op_res_17410;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) ", "status_flags_mem_17332)[dynamic_id_17358] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_17348)[(int64_t) 8] = prefix_17391;\n                    acc_17381 = 0;\n                }\n            }\n            if (!(dynamic_id_17358 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_17391 = ((__local int32_t *) local_mem_17348)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_17411;\n            int32_t eta_p_17412;\n            int32_t eta_p_17414 = prefix_17391;\n            int32_t eta_p_17415 = acc_17381;\n            \n            if (slt32(local_tid_17341 * chunk_sizze_32b_17345, boundary_17361) && !block_new_sgm_17392) {\n                int32_t defunc_0_op_res_17416 = add32(eta_p_17414, eta_p_17415);\n                \n                eta_p_17411 = defunc_0_op_res_17416;\n            } else {\n                eta_p_17411 = acc_17381;\n            }\n            \n            int32_t stopping_point_17417 = segsizze_compact_17362 - srem32(local_tid_17341 * chunk_sizze_32b_17345 - 1 + segsizze_compact_17362 - boundary_17361, segsizze_compact_17362);\n            \n            for (int64_t i_17418 = 0; i_17418 < chunk_sizze_17329; i_17418++) {\n                if (slt32(sext_i64_i32(i_17418), stopping_point_17417 - 1)) {\n                    eta_p_17412 = private_mem_17363[i_17418];\n                    \n                    int32_t defunc_0_op_res_17413 = add32(eta_p_17411, eta_p_17412);\n                    \n                    private_mem_17363[i_17418] = defunc_0_op_res_17413;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_17419 = 0; i_17419 < chunk_sizze_17329; i_17419++) {\n                int64_t sharedIdx_17420 = sext_i32_i64(local_tid_17341) * chunk_sizze_17329 + i_17419;\n                int", "32_t tmp_17421 = private_mem_17363[i_17419];\n                \n                ((__local int32_t *) local_mem_17348)[sharedIdx_17420] = tmp_17421;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17422 = 0; i_17422 < chunk_sizze_17329; i_17422++) {\n                int64_t flat_idx_17423 = thd_offset_17365 + i_17422 * segscan_tblock_sizze_16610;\n                int64_t slice_17424 = n_12437;\n                int64_t gtid_16614 = flat_idx_17423;\n                int64_t remnant_17425 = flat_idx_17423 - gtid_16614;\n                \n                if (slt64(flat_idx_17423, n_12437)) {\n                    int32_t tmp_17426 = ((__local int32_t *) local_mem_17348)[flat_idx_17423 - block_offset_17359];\n                    \n                    ((__global int32_t *) mem_16961)[gtid_16614] = tmp_17426;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16610\n    #undef chunk_sizze_17329\n}\nFUTHARK_KERNEL_SIZED(mainzisegscan_16717_dim1, 1, 1)\nvoid mainzisegscan_16717(__global int *global_failure, int64_t idxs_14149, int64_t num_tblocks_16714, int64_t num_virt_blocks_17492, int64_t num_virt_threads_17493, __global unsigned char *mem_16990, __global unsigned char *mem_16992, __global unsigned char *mem_16994, __global unsigned char *mem_16996, __global unsigned char *mem_16998, __global unsigned char *mem_16999, __global unsigned char *status_flags_mem_17494, __global unsigned char *aggregates_mem_17496, __global unsigned char *incprefixes_mem_17498, __global unsigned char *aggregates_mem_17500, __global unsigned char *incprefixes_mem_17502, __global unsigned char *aggregates_mem_17504, __global unsigned char *incprefixes_mem_17506, __global unsigned char *global_dynid_mem_17508)\n{\n    #define segscan_tblock_sizze_16712 (mainzisegscan_16717zisegscan_tblock_sizze_16712)\n    #define chunk_sizze_17491 (mainzisegscan_16717zichunk_sizze_17491)\n    \n    vola",
                                    "tile __local unsigned char *local_mem_17522_backing_0 = &shared_mem[0];\n    const int64_t local_mem_17522_backing_0_offset = 0 + (smax64(smax64((int64_t) 576, sdiv_up64(sdiv_up64(segscan_tblock_sizze_16712, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16712, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16712), smax64(smax64(chunk_sizze_17491 * segscan_tblock_sizze_16712, chunk_sizze_17491 * segscan_tblock_sizze_16712 * (int64_t) 8), chunk_sizze_17491 * segscan_tblock_sizze_16712 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 576, sdiv_up64(sdiv_up64(segscan_tblock_sizze_16712, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16712, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16712), smax64(smax64(chunk_sizze_17491 * segscan_tblock_sizze_16712, chunk_sizze_17491 * segscan_tblock_sizze_16712 * (int64_t) 8), chunk_sizze_17491 * segscan_tblock_sizze_16712 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17511;\n    int32_t tblock_sizze_17514;\n    int32_t wave_sizze_17513;\n    int32_t block_id_17512;\n    int32_t global_tid_17510;\n    int64_t phys_tid_16717;\n    int32_t chunk_sizze_32b_17515;\n    int64_t byte_offsets_17516;\n    int64_t byte_offsets_17517;\n    int64_t byte_offsets_17518;\n    int64_t warp_byte_offset_17519;\n    int64_t warp_byte_offset_17520;\n    int64_t warp_byte_offset_17521;\n    __local unsigned char *local_mem_17522;\n    int64_t trans_arr_len_17523;\n    int64_t phys_block_id_17535;\n    int64_t virtloop_bound_17536;\n    \n    local_tid_17511 = get_local_id(0);\n    tblock_sizze_17514 = get_local_size(0);\n    wave_sizze_17513 = LOCKSTEP_WIDTH;\n    block_id_17512 = get_tblock_id(0);\n    global_tid_17510 = block_id_17512 * tblock_sizze_17514 + local_tid_17511;\n    phys_tid_16717 = sext_i32_i64(global_tid_17510);\n    chunk_sizze_32b_17515 = sext_i64_i32(chunk_sizze_17491);\n    byte_offsets_175", "16 = segscan_tblock_sizze_16712;\n    byte_offsets_17517 = sdiv_up64(byte_offsets_17516, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16712 * (int64_t) 8;\n    byte_offsets_17518 = sdiv_up64(byte_offsets_17517, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16712 * (int64_t) 8;\n    warp_byte_offset_17519 = (int64_t) 64;\n    warp_byte_offset_17520 = sdiv_up64(warp_byte_offset_17519, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    warp_byte_offset_17521 = sdiv_up64(warp_byte_offset_17520, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_17522 = (__local unsigned char *) local_mem_17522_backing_0;\n    trans_arr_len_17523 = chunk_sizze_17491 * segscan_tblock_sizze_16712;\n    phys_block_id_17535 = get_tblock_id(0);\n    virtloop_bound_17536 = sdiv_up64(num_virt_blocks_17492 - phys_block_id_17535, num_tblocks_16714);\n    for (int64_t virtloop_i_17537 = 0; virtloop_i_17537 < virtloop_bound_17536; virtloop_i_17537++) {\n        int64_t dynamic_id_17538;\n        int64_t block_offset_17539;\n        int64_t sgm_idx_17540;\n        int32_t boundary_17541;\n        int32_t segsizze_compact_17542;\n        bool private_mem_17543[chunk_sizze_17491];\n        int64_t private_mem_17545[chunk_sizze_17491];\n        int64_t private_mem_17547[chunk_sizze_17491];\n        int64_t thd_offset_17549;\n        bool acc_17586;\n        int64_t acc_17587;\n        int64_t acc_17588;\n        bool prefix_17605;\n        int64_t prefix_17606;\n        int64_t prefix_17607;\n        bool block_new_sgm_17608;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_17511 == 0) {\n                dynamic_id_17538 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_17508)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_17522)[(int64_t) 0] = dynamic_id_17538;\n                }\n                ", "// First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_17538 == num_virt_blocks_17492 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_17508)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_17538 = ((__local int32_t *) local_mem_17522)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_17539 = dynamic_id_17538 * chunk_sizze_17491 * segscan_tblock_sizze_16712;\n        sgm_idx_17540 = smod64(block_offset_17539, idxs_14149);\n        boundary_17541 = sext_i64_i32(smin64(chunk_sizze_17491 * segscan_tblock_sizze_16712, idxs_14149 - sgm_idx_17540));\n        segsizze_compact_17542 = sext_i64_i32(smin64(chunk_sizze_17491 * segscan_tblock_sizze_16712, idxs_14149));\n        thd_offset_17549 = block_offset_17539 + sext_i32_i64(local_tid_17511);\n        // Load and map\n        {\n            for (int64_t i_17550 = 0; i_17550 < chunk_sizze_17491; i_17550++) {\n                int64_t virt_tid_17551 = thd_offset_17549 + i_17550 * segscan_tblock_sizze_16712;\n                int64_t slice_17552 = idxs_14149;\n                int64_t gtid_16716 = virt_tid_17551;\n                int64_t remnant_17553 = virt_tid_17551 - gtid_16716;\n                \n                if (slt64(virt_tid_17551, idxs_14149)) {\n                    int64_t eta_p_16231 = ((__global int64_t *) mem_16992)[gtid_16716];\n                    int64_t zv_lhs_16234 = add64((int64_t) -1, gtid_16716);\n                    int64_t tmp_16235 = smod64(zv_lhs_16234, idxs_14149);\n                    int64_t lifted_lambda_res_16236 = ((__global int64_t *) mem_16992)[tmp_16235];\n                    bool defunc_0_f_res_16238 = eta_p_16231 == lifted_lambda_res_16236;\n                    bool defunc_0_f_res_16239 = !defunc_0_f_res_16238;\n                    int64_t zv_lhs_16241 = add64((int64_t) 1, gtid_16716);\n                    i",
                                    "nt64_t tmp_16242 = smod64(zv_lhs_16241, idxs_14149);\n                    bool lifted_lambda_res_16243 = ((__global bool *) mem_16990)[tmp_16242];\n                    int64_t bool_res_16244 = btoi_bool_i64(lifted_lambda_res_16243);\n                    \n                    ((__global bool *) mem_16999)[gtid_16716] = lifted_lambda_res_16243;\n                    private_mem_17543[i_17550] = defunc_0_f_res_16239;\n                    private_mem_17545[i_17550] = (int64_t) 1;\n                    private_mem_17547[i_17550] = bool_res_16244;\n                } else {\n                    private_mem_17543[i_17550] = 0;\n                    private_mem_17545[i_17550] = (int64_t) 0;\n                    private_mem_17547[i_17550] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_17554 = 0; i_17554 < chunk_sizze_17491; i_17554++) {\n                int64_t sharedIdx_17555 = sext_i32_i64(local_tid_17511) + i_17554 * segscan_tblock_sizze_16712;\n                bool tmp_17556 = private_mem_17543[i_17554];\n                \n                ((__local bool *) local_mem_17522)[sharedIdx_17555] = tmp_17556;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17557 = 0; i_17557 < chunk_sizze_17491; i_17557++) {\n                int64_t sharedIdx_17558 = sext_i32_i64(local_tid_17511) * chunk_sizze_17491 + i_17557;\n                bool tmp_17559 = ((__local bool *) local_mem_17522)[sharedIdx_17558];\n                \n                private_mem_17543[i_17557] = tmp_17559;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17560 = 0; i_17560 < chunk_sizze_17491; i_17560++) {\n                int64_t sharedIdx_17561 = sext_i32_i64(local_tid_17511) + i_17560 * segscan_tblock_sizze_16712;\n                int64_t tmp_17562 = private_mem_17545[i_17560];\n                \n                ((__local int64_t *) local_mem_17522)[share", "dIdx_17561] = tmp_17562;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17563 = 0; i_17563 < chunk_sizze_17491; i_17563++) {\n                int64_t sharedIdx_17564 = sext_i32_i64(local_tid_17511) * chunk_sizze_17491 + i_17563;\n                int64_t tmp_17565 = ((__local int64_t *) local_mem_17522)[sharedIdx_17564];\n                \n                private_mem_17545[i_17563] = tmp_17565;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17566 = 0; i_17566 < chunk_sizze_17491; i_17566++) {\n                int64_t sharedIdx_17567 = sext_i32_i64(local_tid_17511) + i_17566 * segscan_tblock_sizze_16712;\n                int64_t tmp_17568 = private_mem_17547[i_17566];\n                \n                ((__local int64_t *) local_mem_17522)[sharedIdx_17567] = tmp_17568;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17569 = 0; i_17569 < chunk_sizze_17491; i_17569++) {\n                int64_t sharedIdx_17570 = sext_i32_i64(local_tid_17511) * chunk_sizze_17491 + i_17569;\n                int64_t tmp_17571 = ((__local int64_t *) local_mem_17522)[sharedIdx_17570];\n                \n                private_mem_17547[i_17569] = tmp_17571;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_17572 = 0; i_17572 < chunk_sizze_17491 - (int64_t) 1; i_17572++) {\n                bool eta_p_15927;\n                bool eta_p_15929;\n                \n                eta_p_15927 = private_mem_17543[i_17572];\n                eta_p_15929 = private_mem_17543[i_17572 + (int64_t) 1];\n                \n                int64_t eta_p_15928;\n                int64_t eta_p_15930;\n                \n                eta_p_15928 = private_mem_17545[i_17572];\n                eta_p_15930 = private_mem_17545[i_17572 + (int64_t) 1];\n                \n                int64_t eta_p_16148;\n                int64_t eta_p_16149;\n             ", "   \n                eta_p_16148 = private_mem_17547[i_17572];\n                eta_p_16149 = private_mem_17547[i_17572 + (int64_t) 1];\n                \n                bool tmp_15931 = eta_p_15927 || eta_p_15929;\n                int64_t tmp_15932;\n                \n                if (eta_p_15929) {\n                    tmp_15932 = eta_p_15930;\n                } else {\n                    int64_t defunc_0_op_res_15933 = add64(eta_p_15928, eta_p_15930);\n                    \n                    tmp_15932 = defunc_0_op_res_15933;\n                }\n                \n                int64_t defunc_0_op_res_16150 = add64(eta_p_16148, eta_p_16149);\n                \n                private_mem_17543[i_17572 + (int64_t) 1] = tmp_15931;\n                private_mem_17545[i_17572 + (int64_t) 1] = tmp_15932;\n                private_mem_17547[i_17572 + (int64_t) 1] = defunc_0_op_res_16150;\n            }\n        }\n        // Publish results in shared memory\n        {\n            bool tmp_17573 = private_mem_17543[chunk_sizze_17491 - (int64_t) 1];\n            \n            ((__local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511)] = tmp_17573;\n            \n            int64_t tmp_17574 = private_mem_17545[chunk_sizze_17491 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = tmp_17574;\n            \n            int64_t tmp_17575 = private_mem_17547[chunk_sizze_17491 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = tmp_17575;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            bool eta_p_17576;\n            int64_t eta_p_17577;\n            int64_t eta_p_17578;\n            bool eta_p_17579;\n            int64_t eta_p_17580;\n            int64_t eta_p_17581;\n            bool eta_p_17589;\n            int64_t eta_p_17590;\n",
                                    "            int64_t eta_p_17591;\n            bool eta_p_17592;\n            int64_t eta_p_17593;\n            int64_t eta_p_17594;\n            bool ltid_in_bounds_17599 = slt64(sext_i32_i64(local_tid_17511), num_virt_threads_17493);\n            int32_t skip_threads_17600;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_17599) {\n                    eta_p_17579 = ((volatile __local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511)];\n                    eta_p_17580 = ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + sext_i32_i64(local_tid_17511)];\n                    eta_p_17581 = ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + sext_i32_i64(local_tid_17511)];\n                    if ((local_tid_17511 - squot32(local_tid_17511, 32) * 32) == 0) {\n                        eta_p_17576 = eta_p_17579;\n                        eta_p_17577 = eta_p_17580;\n                        eta_p_17578 = eta_p_17581;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_17600 = 1;\n                while (slt32(skip_threads_17600, 32)) {\n                    bool thread_active_17601 = sle32(skip_threads_17600, local_tid_17511 - squot32(local_tid_17511, 32) * 32) && ltid_in_bounds_17599;\n                    \n                    if (thread_active_17601) {\n                        // read operands\n                        {\n                            eta_p_17576 = ((volatile __local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17600)];\n                            eta_p_17577 = ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + (sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17600))];\n                            eta_p_17578 = ((volatile __local int64_t *) local_mem_17522)[", "squot64(byte_offsets_17517, (int64_t) 8) + (sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17600))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_17601) {\n                            bool tmp_17582 = eta_p_17576 || eta_p_17579;\n                            int64_t tmp_17583;\n                            \n                            if (eta_p_17579) {\n                                tmp_17583 = eta_p_17580;\n                            } else {\n                                int64_t defunc_0_op_res_17584 = add64(eta_p_17577, eta_p_17580);\n                                \n                                tmp_17583 = defunc_0_op_res_17584;\n                            }\n                            \n                            int64_t defunc_0_op_res_17585 = add64(eta_p_17578, eta_p_17581);\n                            \n                            eta_p_17576 = tmp_17582;\n                            eta_p_17577 = tmp_17583;\n                            eta_p_17578 = defunc_0_op_res_17585;\n                        }\n                    }\n                    if (sle32(wave_sizze_17513, skip_threads_17600)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_17601) {\n                        // write result\n                        {\n                            ((volatile __local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511)] = eta_p_17576;\n                            eta_p_17579 = eta_p_17576;\n                            ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17577;\n                            eta_p_17580 = eta_p_17577;\n                            ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17578;\n                       ", "     eta_p_17581 = eta_p_17578;\n                        }\n                    }\n                    if (sle32(wave_sizze_17513, skip_threads_17600)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_17600 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_17511 - squot32(local_tid_17511, 32) * 32) == 31 && ltid_in_bounds_17599) {\n                    ((volatile __local bool *) local_mem_17522)[sext_i32_i64(squot32(local_tid_17511, 32))] = eta_p_17576;\n                    ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17511, 32))] = eta_p_17577;\n                    ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17511, 32))] = eta_p_17578;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_17602;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_17511, 32) == 0 && ltid_in_bounds_17599) {\n                        eta_p_17592 = ((volatile __local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511)];\n                        eta_p_17593 = ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + sext_i32_i64(local_tid_17511)];\n                        eta_p_17594 = ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + sext_i32_i64(local_tid_17511)];\n                        if ((local_tid_17511 - squot32(local_tid_17511, 32) * 32) == 0) {\n                            eta_p_17589 = eta_p_17592;\n                           ",
                                    " eta_p_17590 = eta_p_17593;\n                            eta_p_17591 = eta_p_17594;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_17602 = 1;\n                    while (slt32(skip_threads_17602, 32)) {\n                        bool thread_active_17603 = sle32(skip_threads_17602, local_tid_17511 - squot32(local_tid_17511, 32) * 32) && (squot32(local_tid_17511, 32) == 0 && ltid_in_bounds_17599);\n                        \n                        if (thread_active_17603) {\n                            // read operands\n                            {\n                                eta_p_17589 = ((volatile __local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17602)];\n                                eta_p_17590 = ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + (sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17602))];\n                                eta_p_17591 = ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + (sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17602))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_17603) {\n                                bool tmp_17595 = eta_p_17589 || eta_p_17592;\n                                int64_t tmp_17596;\n                                \n                                if (eta_p_17592) {\n                                    tmp_17596 = eta_p_17593;\n                                } else {\n                                    int64_t defunc_0_op_res_17597 = add64(eta_p_17590, eta_p_17593);\n                                    \n                                    tmp_17596 = defunc_0_op_res_17597;\n                                }\n              ", "                  \n                                int64_t defunc_0_op_res_17598 = add64(eta_p_17591, eta_p_17594);\n                                \n                                eta_p_17589 = tmp_17595;\n                                eta_p_17590 = tmp_17596;\n                                eta_p_17591 = defunc_0_op_res_17598;\n                            }\n                        }\n                        if (sle32(wave_sizze_17513, skip_threads_17602)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_17603) {\n                            // write result\n                            {\n                                ((volatile __local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511)] = eta_p_17589;\n                                eta_p_17592 = eta_p_17589;\n                                ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17590;\n                                eta_p_17593 = eta_p_17590;\n                                ((volatile __local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17591;\n                                eta_p_17594 = eta_p_17591;\n                            }\n                        }\n                        if (sle32(wave_sizze_17513, skip_threads_17602)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_17602 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_17604 = squot32(local_tid_17511, 32) == 0 || !ltid_in_bounds_17599;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_17604) {\n                        eta_p_17579 = eta_", "p_17576;\n                        eta_p_17580 = eta_p_17577;\n                        eta_p_17581 = eta_p_17578;\n                        eta_p_17576 = ((__local bool *) local_mem_17522)[sext_i32_i64(squot32(local_tid_17511, 32)) - (int64_t) 1];\n                        eta_p_17577 = ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17511, 32)) - (int64_t) 1)];\n                        eta_p_17578 = ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17511, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_17604) {\n                        bool tmp_17582 = eta_p_17576 || eta_p_17579;\n                        int64_t tmp_17583;\n                        \n                        if (eta_p_17579) {\n                            tmp_17583 = eta_p_17580;\n                        } else {\n                            int64_t defunc_0_op_res_17584 = add64(eta_p_17577, eta_p_17580);\n                            \n                            tmp_17583 = defunc_0_op_res_17584;\n                        }\n                        \n                        int64_t defunc_0_op_res_17585 = add64(eta_p_17578, eta_p_17581);\n                        \n                        eta_p_17576 = tmp_17582;\n                        eta_p_17577 = tmp_17583;\n                        eta_p_17578 = defunc_0_op_res_17585;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_17604) {\n                        ((__local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511)] = eta_p_17576;\n                        ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17577;\n                        ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_",
                                    "17517, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17578;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_17511, 32) == 0 && ltid_in_bounds_17599) {\n                    ((__local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511)] = eta_p_17579;\n                    ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17580;\n                    ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17581;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_17511 == 0) {\n                acc_17586 = ((__local bool *) local_mem_17522)[segscan_tblock_sizze_16712 - (int64_t) 1];\n                acc_17587 = ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + (segscan_tblock_sizze_16712 - (int64_t) 1)];\n                acc_17588 = ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + (segscan_tblock_sizze_16712 - (int64_t) 1)];\n            } else {\n                acc_17586 = ((__local bool *) local_mem_17522)[sext_i32_i64(local_tid_17511) - (int64_t) 1];\n                acc_17587 = ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17516, (int64_t) 8) + (sext_i32_i64(local_tid_17511) - (int64_t) 1)];\n                acc_17588 = ((__local int64_t *) local_mem_17522)[squot64(byte_offsets_17517, (int64_t) 8) + (sext_i32_i64(local_tid_17511) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_17605 = 0;\n        prefix_17606 = (int64_t) 0;\n        prefix_17607 = (int64_t) 0;\n        block_new_sgm_17608 = sgm_idx_17540 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (", "block_new_sgm_17608 && local_tid_17511 == 0) {\n                ((volatile __global bool *) incprefixes_mem_17498)[dynamic_id_17538] = acc_17586;\n                ((volatile __global int64_t *) incprefixes_mem_17502)[dynamic_id_17538] = acc_17587;\n                ((volatile __global int64_t *) incprefixes_mem_17506)[dynamic_id_17538] = acc_17588;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_17494)[dynamic_id_17538] = (int8_t) 2;\n                acc_17586 = 0;\n                acc_17587 = (int64_t) 0;\n                acc_17588 = (int64_t) 0;\n            }\n            if (!block_new_sgm_17608 && slt32(local_tid_17511, wave_sizze_17513)) {\n                if (local_tid_17511 == 0) {\n                    ((volatile __global bool *) aggregates_mem_17496)[dynamic_id_17538] = acc_17586;\n                    ((volatile __global int64_t *) aggregates_mem_17500)[dynamic_id_17538] = acc_17587;\n                    ((volatile __global int64_t *) aggregates_mem_17504)[dynamic_id_17538] = acc_17588;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_17494)[dynamic_id_17538] = (int8_t) 1;\n                    \n                    int8_t tmp_17609 = ((volatile __global int8_t *) status_flags_mem_17494)[dynamic_id_17538 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_17522)[(int64_t) 0] = tmp_17609;\n                }\n                mem_fence_local();\n                \n                int8_t status_17610 = ((__local int8_t *) local_mem_17522)[(int64_t) 0];\n                \n                if (status_17610 == (int8_t) 2) {\n                    if (local_tid_17511 == 0) {\n                        prefix_17605 = ((volatile __global bool *) incprefixes_mem_17498)[dynamic_id_17538 - (int64_t) 1];\n                        prefix_17606 = ((volatile __global int64_t *) incprefixes_mem_17502)[dynamic_id_17538 - (int64_t) 1];\n                      ", "  prefix_17607 = ((volatile __global int64_t *) incprefixes_mem_17506)[dynamic_id_17538 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_17611 = sext_i64_i32(dynamic_id_17538 - sext_i32_i64(wave_sizze_17513));\n                    \n                    while (slt32(wave_sizze_17513 * -1, readOffset_17611)) {\n                        int32_t read_i_17612 = readOffset_17611 + local_tid_17511;\n                        bool aggr_17613 = 0;\n                        int64_t aggr_17614 = (int64_t) 0;\n                        int64_t aggr_17615 = (int64_t) 0;\n                        int8_t flag_17616 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_17612)) {\n                            flag_17616 = ((volatile __global int8_t *) status_flags_mem_17494)[sext_i32_i64(read_i_17612)];\n                            if (flag_17616 == (int8_t) 2) {\n                                aggr_17613 = ((volatile __global bool *) incprefixes_mem_17498)[sext_i32_i64(read_i_17612)];\n                                aggr_17614 = ((volatile __global int64_t *) incprefixes_mem_17502)[sext_i32_i64(read_i_17612)];\n                                aggr_17615 = ((volatile __global int64_t *) incprefixes_mem_17506)[sext_i32_i64(read_i_17612)];\n                            } else if (flag_17616 == (int8_t) 1) {\n                                aggr_17613 = ((volatile __global bool *) aggregates_mem_17496)[sext_i32_i64(read_i_17612)];\n                                aggr_17614 = ((volatile __global int64_t *) aggregates_mem_17500)[sext_i32_i64(read_i_17612)];\n                                aggr_17615 = ((volatile __global int64_t *) aggregates_mem_17504)[sext_i32_i64(read_i_17612)];\n                            }\n                        }\n                        ((__local bool *) local_mem_17522)[(int64_t) 32 + sext_i32_i64(local_tid_17511)] = aggr_17613;\n                        ((__local int64_t *) local_mem_17522)[squot64(warp_",
                                    "byte_offset_17519, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = aggr_17614;\n                        ((__local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17520, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = aggr_17615;\n                        ((__local int8_t *) local_mem_17522)[sext_i32_i64(local_tid_17511)] = flag_17616;\n                        flag_17616 = ((__local int8_t *) local_mem_17522)[sext_i32_i64(wave_sizze_17513) - (int64_t) 1];\n                        if (slt8(flag_17616, (int8_t) 2)) {\n                            int8_t flg_x_17627;\n                            int8_t flg_y_17628;\n                            bool eta_p_17617;\n                            int64_t eta_p_17618;\n                            int64_t eta_p_17619;\n                            bool eta_p_17620;\n                            int64_t eta_p_17621;\n                            int64_t eta_p_17622;\n                            int32_t skip_threads_17629;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_17628 = ((volatile __local int8_t *) local_mem_17522)[sext_i32_i64(local_tid_17511)];\n                                eta_p_17620 = ((volatile __local bool *) local_mem_17522)[(int64_t) 32 + sext_i32_i64(local_tid_17511)];\n                                eta_p_17621 = ((volatile __local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17519, (int64_t) 8) + sext_i32_i64(local_tid_17511)];\n                                eta_p_17622 = ((volatile __local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17520, (int64_t) 8) + sext_i32_i64(local_tid_17511)];\n                                if ((local_tid_17511 - squot32(local_tid_17511, 32) * 32) == 0) {\n                                    eta_p_17617 = eta_p_17620;\n                                    eta_p_17618 = eta_p_17621;\n                                    eta_p_17619 = eta_p_17622;\n                             ", "       flg_x_17627 = flg_y_17628;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_17629 = 1;\n                                while (slt32(skip_threads_17629, 32)) {\n                                    if (sle32(skip_threads_17629, local_tid_17511 - squot32(local_tid_17511, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_17627 = ((volatile __local int8_t *) local_mem_17522)[sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17629)];\n                                            eta_p_17617 = ((volatile __local bool *) local_mem_17522)[(int64_t) 32 + (sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17629))];\n                                            eta_p_17618 = ((volatile __local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17519, (int64_t) 8) + (sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17629))];\n                                            eta_p_17619 = ((volatile __local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17520, (int64_t) 8) + (sext_i32_i64(local_tid_17511) - sext_i32_i64(skip_threads_17629))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_17628 == (int8_t) 2 || flg_y_17628 == (int8_t) 0) {\n                                                flg_x_17627 = flg_y_17628;\n                                                eta_p_17617 = eta_p_17620;\n                                                eta_p_17618 = eta_p_17621;\n                                                eta_p_17619 = eta_p_17622;\n                                            } else {\n                                            ", "    bool tmp_17623 = eta_p_17617 || eta_p_17620;\n                                                int64_t tmp_17624;\n                                                \n                                                if (eta_p_17620) {\n                                                    tmp_17624 = eta_p_17621;\n                                                } else {\n                                                    int64_t defunc_0_op_res_17625 = add64(eta_p_17618, eta_p_17621);\n                                                    \n                                                    tmp_17624 = defunc_0_op_res_17625;\n                                                }\n                                                \n                                                int64_t defunc_0_op_res_17626 = add64(eta_p_17619, eta_p_17622);\n                                                \n                                                eta_p_17617 = tmp_17623;\n                                                eta_p_17618 = tmp_17624;\n                                                eta_p_17619 = defunc_0_op_res_17626;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_17522)[sext_i32_i64(local_tid_17511)] = flg_x_17627;\n                                            flg_y_17628 = flg_x_17627;\n                                            ((volatile __local bool *) local_mem_17522)[(int64_t) 32 + sext_i32_i64(local_tid_17511)] = eta_p_17617;\n                                            eta_p_17620 = eta_p_17617;\n                                            ((volatile __local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17519, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17618;\n                                            eta_p_17621 = eta_p_17618;\n                 ",
                                    "                           ((volatile __local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17520, (int64_t) 8) + sext_i32_i64(local_tid_17511)] = eta_p_17619;\n                                            eta_p_17622 = eta_p_17619;\n                                        }\n                                    }\n                                    skip_threads_17629 *= 2;\n                                }\n                            }\n                        }\n                        flag_17616 = ((__local int8_t *) local_mem_17522)[sext_i32_i64(wave_sizze_17513) - (int64_t) 1];\n                        aggr_17613 = ((__local bool *) local_mem_17522)[(int64_t) 32 + (sext_i32_i64(wave_sizze_17513) - (int64_t) 1)];\n                        aggr_17614 = ((__local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17519, (int64_t) 8) + (sext_i32_i64(wave_sizze_17513) - (int64_t) 1)];\n                        aggr_17615 = ((__local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17520, (int64_t) 8) + (sext_i32_i64(wave_sizze_17513) - (int64_t) 1)];\n                        if (flag_17616 == (int8_t) 2) {\n                            readOffset_17611 = wave_sizze_17513 * -1;\n                        } else if (flag_17616 == (int8_t) 1) {\n                            readOffset_17611 -= wave_sizze_17513;\n                        }\n                        if (slt8((int8_t) 0, flag_17616)) {\n                            bool eta_p_17630 = aggr_17613;\n                            int64_t eta_p_17631 = aggr_17614;\n                            int64_t eta_p_17632 = aggr_17615;\n                            bool eta_p_17633 = prefix_17605;\n                            int64_t eta_p_17634 = prefix_17606;\n                            int64_t eta_p_17635 = prefix_17607;\n                            bool tmp_17636 = eta_p_17630 || eta_p_17633;\n                            int64_t tmp_17637;\n                            \n                            if (eta_p_17633) {\n                       ", "         tmp_17637 = eta_p_17634;\n                            } else {\n                                int64_t defunc_0_op_res_17638 = add64(eta_p_17631, eta_p_17634);\n                                \n                                tmp_17637 = defunc_0_op_res_17638;\n                            }\n                            \n                            int64_t defunc_0_op_res_17639 = add64(eta_p_17632, eta_p_17635);\n                            \n                            prefix_17605 = tmp_17636;\n                            prefix_17606 = tmp_17637;\n                            prefix_17607 = defunc_0_op_res_17639;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_17511 == 0) {\n                    if (boundary_17541 == sext_i64_i32(segscan_tblock_sizze_16712 * chunk_sizze_17491)) {\n                        bool eta_p_17640 = prefix_17605;\n                        int64_t eta_p_17641 = prefix_17606;\n                        int64_t eta_p_17642 = prefix_17607;\n                        bool eta_p_17643 = acc_17586;\n                        int64_t eta_p_17644 = acc_17587;\n                        int64_t eta_p_17645 = acc_17588;\n                        bool tmp_17646 = eta_p_17640 || eta_p_17643;\n                        int64_t tmp_17647;\n                        \n                        if (eta_p_17643) {\n                            tmp_17647 = eta_p_17644;\n                        } else {\n                            int64_t defunc_0_op_res_17648 = add64(eta_p_17641, eta_p_17644);\n                            \n                            tmp_17647 = defunc_0_op_res_17648;\n                        }\n                        \n                        int64_t defunc_0_op_res_17649 = add64(eta_p_17642, eta_p_17645);\n                        \n                        ((volatile __global bool *) incprefixes_mem_17498)[dynamic_id_17538] = tmp_17646;\n                        ((volatile __global int64_t", " *) incprefixes_mem_17502)[dynamic_id_17538] = tmp_17647;\n                        ((volatile __global int64_t *) incprefixes_mem_17506)[dynamic_id_17538] = defunc_0_op_res_17649;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_17494)[dynamic_id_17538] = (int8_t) 2;\n                    }\n                    ((__local bool *) local_mem_17522)[(int64_t) 32] = prefix_17605;\n                    ((__local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17519, (int64_t) 8)] = prefix_17606;\n                    ((__local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17520, (int64_t) 8)] = prefix_17607;\n                    acc_17586 = 0;\n                    acc_17587 = (int64_t) 0;\n                    acc_17588 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_17538 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_17605 = ((__local bool *) local_mem_17522)[(int64_t) 32];\n                prefix_17606 = ((__local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17519, (int64_t) 8)];\n                prefix_17607 = ((__local int64_t *) local_mem_17522)[squot64(warp_byte_offset_17520, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            bool eta_p_17650;\n            bool eta_p_17653;\n            bool eta_p_17660 = prefix_17605;\n            bool eta_p_17663 = acc_17586;\n            int64_t eta_p_17651;\n            int64_t eta_p_17654;\n            int64_t eta_p_17661 = prefix_17606;\n            int64_t eta_p_17664 = acc_17587;\n            int64_t eta_p_17652;\n            int64_t eta_p_17655;\n            int64_t eta_p_17662 = prefix_17607;\n            int64_t eta_p_17665 = acc_17588;\n            \n            if (slt32(local_tid_17511 * chunk_sizze_32b_17515, boundary_17541) && !block_new_sgm_17608) {\n                bool tmp_17666 = eta_p_17660 || eta_p_17",
                                    "663;\n                int64_t tmp_17667;\n                \n                if (eta_p_17663) {\n                    tmp_17667 = eta_p_17664;\n                } else {\n                    int64_t defunc_0_op_res_17668 = add64(eta_p_17661, eta_p_17664);\n                    \n                    tmp_17667 = defunc_0_op_res_17668;\n                }\n                \n                int64_t defunc_0_op_res_17669 = add64(eta_p_17662, eta_p_17665);\n                \n                eta_p_17650 = tmp_17666;\n                eta_p_17651 = tmp_17667;\n                eta_p_17652 = defunc_0_op_res_17669;\n            } else {\n                eta_p_17650 = acc_17586;\n                eta_p_17651 = acc_17587;\n                eta_p_17652 = acc_17588;\n            }\n            \n            int32_t stopping_point_17670 = segsizze_compact_17542 - srem32(local_tid_17511 * chunk_sizze_32b_17515 - 1 + segsizze_compact_17542 - boundary_17541, segsizze_compact_17542);\n            \n            for (int64_t i_17671 = 0; i_17671 < chunk_sizze_17491; i_17671++) {\n                if (slt32(sext_i64_i32(i_17671), stopping_point_17670 - 1)) {\n                    eta_p_17653 = private_mem_17543[i_17671];\n                    eta_p_17654 = private_mem_17545[i_17671];\n                    eta_p_17655 = private_mem_17547[i_17671];\n                    \n                    bool tmp_17656 = eta_p_17650 || eta_p_17653;\n                    int64_t tmp_17657;\n                    \n                    if (eta_p_17653) {\n                        tmp_17657 = eta_p_17654;\n                    } else {\n                        int64_t defunc_0_op_res_17658 = add64(eta_p_17651, eta_p_17654);\n                        \n                        tmp_17657 = defunc_0_op_res_17658;\n                    }\n                    \n                    int64_t defunc_0_op_res_17659 = add64(eta_p_17652, eta_p_17655);\n                    \n                    private_mem_17543[i_17671] = tmp_17656;\n                    private_mem_17545[i_17671] = ", "tmp_17657;\n                    private_mem_17547[i_17671] = defunc_0_op_res_17659;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_17672 = 0; i_17672 < chunk_sizze_17491; i_17672++) {\n                int64_t sharedIdx_17673 = sext_i32_i64(local_tid_17511) * chunk_sizze_17491 + i_17672;\n                bool tmp_17674 = private_mem_17543[i_17672];\n                \n                ((__local bool *) local_mem_17522)[sharedIdx_17673] = tmp_17674;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17675 = 0; i_17675 < chunk_sizze_17491; i_17675++) {\n                int64_t flat_idx_17676 = thd_offset_17549 + i_17675 * segscan_tblock_sizze_16712;\n                int64_t slice_17677 = idxs_14149;\n                int64_t gtid_16716 = flat_idx_17676;\n                int64_t remnant_17678 = flat_idx_17676 - gtid_16716;\n                \n                if (slt64(flat_idx_17676, idxs_14149)) {\n                    bool tmp_17679 = ((__local bool *) local_mem_17522)[flat_idx_17676 - block_offset_17539];\n                    \n                    ((__global bool *) mem_16994)[gtid_16716] = tmp_17679;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17680 = 0; i_17680 < chunk_sizze_17491; i_17680++) {\n                int64_t sharedIdx_17681 = sext_i32_i64(local_tid_17511) * chunk_sizze_17491 + i_17680;\n                int64_t tmp_17682 = private_mem_17545[i_17680];\n                \n                ((__local int64_t *) local_mem_17522)[sharedIdx_17681] = tmp_17682;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17683 = 0; i_17683 < chunk_sizze_17491; i_17683++) {\n                int64_t flat_idx_17684 = thd_offset_17549 + i_17683 * segscan_tblock_sizze_16712;\n                int64_t slice_17685 = idxs_14149;\n                int64_t gtid_16716 = flat_idx_1", "7684;\n                int64_t remnant_17686 = flat_idx_17684 - gtid_16716;\n                \n                if (slt64(flat_idx_17684, idxs_14149)) {\n                    int64_t tmp_17687 = ((__local int64_t *) local_mem_17522)[flat_idx_17684 - block_offset_17539];\n                    \n                    ((__global int64_t *) mem_16996)[gtid_16716] = tmp_17687;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17688 = 0; i_17688 < chunk_sizze_17491; i_17688++) {\n                int64_t sharedIdx_17689 = sext_i32_i64(local_tid_17511) * chunk_sizze_17491 + i_17688;\n                int64_t tmp_17690 = private_mem_17547[i_17688];\n                \n                ((__local int64_t *) local_mem_17522)[sharedIdx_17689] = tmp_17690;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17691 = 0; i_17691 < chunk_sizze_17491; i_17691++) {\n                int64_t flat_idx_17692 = thd_offset_17549 + i_17691 * segscan_tblock_sizze_16712;\n                int64_t slice_17693 = idxs_14149;\n                int64_t gtid_16716 = flat_idx_17692;\n                int64_t remnant_17694 = flat_idx_17692 - gtid_16716;\n                \n                if (slt64(flat_idx_17692, idxs_14149)) {\n                    int64_t tmp_17695 = ((__local int64_t *) local_mem_17522)[flat_idx_17692 - block_offset_17539];\n                    \n                    ((__global int64_t *) mem_16998)[gtid_16716] = tmp_17695;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16712\n    #undef chunk_sizze_17491\n}\nFUTHARK_KERNEL_SIZED(mainzisegscan_16725_dim1, 1, 1)\nvoid mainzisegscan_16725(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_12437, int64_t loop_dz2085U_14130, int64_t idxs_14149, int64_t num_tblocks_16722, int64_t num_virt_blocks_17702, int64_t num_virt_threads_17703, __gl",
                                    "obal unsigned char *mem_16963, __global unsigned char *mem_16965, __global unsigned char *mem_16982, __global unsigned char *mem_16984, __global unsigned char *ext_mem_16988, __global unsigned char *mem_16990, __global unsigned char *mem_16992, __global unsigned char *mem_16996, __global unsigned char *mem_17001, __global unsigned char *mem_17003, __global unsigned char *mem_17005, __global unsigned char *mem_17007, __global unsigned char *mem_17008, __global unsigned char *mem_17010, __global unsigned char *mem_17012, __global unsigned char *mem_17014, __global unsigned char *mem_17016, __global unsigned char *mem_17018, __global unsigned char *mem_17020, __global unsigned char *status_flags_mem_17704, __global unsigned char *aggregates_mem_17706, __global unsigned char *incprefixes_mem_17708, __global unsigned char *aggregates_mem_17710, __global unsigned char *incprefixes_mem_17712, __global unsigned char *aggregates_mem_17714, __global unsigned char *incprefixes_mem_17716, __global unsigned char *aggregates_mem_17718, __global unsigned char *incprefixes_mem_17720, __global unsigned char *aggregates_mem_17722, __global unsigned char *incprefixes_mem_17724, __global unsigned char *aggregates_mem_17726, __global unsigned char *incprefixes_mem_17728, __global unsigned char *aggregates_mem_17730, __global unsigned char *incprefixes_mem_17732, __global unsigned char *aggregates_mem_17734, __global unsigned char *incprefixes_mem_17736, __global unsigned char *global_dynid_mem_17738)\n{\n    #define segscan_tblock_sizze_16720 (mainzisegscan_16725zisegscan_tblock_sizze_16720)\n    #define chunk_sizze_17701 (mainzisegscan_16725zichunk_sizze_17701)\n    \n    volatile __local unsigned char *local_mem_17762_backing_0 = &shared_mem[0];\n    const int64_t local_mem_17762_backing_0_offset = 0 + (smax64(smax64((int64_t) 1632, sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizz", "e_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 1) + segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720), smax64(smax64(smax64(smax64(smax64(smax64(smax64(chunk_sizze_17701 * segscan_tblock_sizze_16720, chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 1632, sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 1) + segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720), smax64(smax64(smax64(smax64(smax64(smax64(smax64(chunk_sizze_17701 * segscan_tblock_sizze_16720, chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_1", "6720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    // Harmless for all threads to write this.\n    local_failure = 0;\n    \n    int32_t local_tid_17741;\n    int32_t tblock_sizze_17744;\n    int32_t wave_sizze_17743;\n    int32_t block_id_17742;\n    int32_t global_tid_17740;\n    int64_t phys_tid_16725;\n    int32_t chunk_sizze_32b_17745;\n    int64_t byte_offsets_17746;\n    int64_t byte_offsets_17747;\n    int64_t byte_offsets_17748;\n    int64_t byte_offsets_17749;\n    int64_t byte_offsets_17750;\n    int64_t byte_offsets_17751;\n    int64_t byte_offsets_17752;\n    int64_t byte_offsets_17753;\n    int64_t warp_byte_offset_17754;\n    int64_t warp_byte_offset_17755;\n    int64_t warp_byte_offset_17756;\n    int64_t warp_byte_offset_17757;\n    int64_t warp_byte_offset_17758;\n    int64_t warp_byte_offset_17759;\n    int64_t warp_byte_offset_17760;\n    int64_t warp_byte_offset_17761;\n    __local unsigned char *local_mem_17762;\n    int64_t trans_arr_len_17763;\n    int64_t phys_block_id_17790;\n    int64_t virtloop_bound_17791;\n    \n    local_tid_17741 = get_local_id(0);\n    tblock_sizze_17744 = get_local_size(0);\n    wave_sizze_17743 = LOCKSTEP_WIDTH;\n    block_id_17742 = get_tblock_id(0);\n    global_tid_17740 = block_id_17742 * tblock_sizze_17744 + local_tid_17741;\n    phys_tid_16725 = sext_i32_i64(global_tid_17740);\n    chunk_sizze_32b_17745 = sext_i64_i32(chunk_sizze_17701);\n    byte_offsets_17746 = segscan_tblock_sizze_16720;\n    byte_offsets_17747 = sdiv_up64(byte_offsets_17746, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16720 * (int64_t) 8;\n    byte_offsets_17748 = sdiv_up64(byte_offsets_17747, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16720 * (int64_t) 8;\n    byte_offsets_17749 = sdiv_up64(byte_offsets_17748, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16720 * (int64_t) 8;\n    byte_offsets_17750 = sdiv_up64(byte_offsets_17749, (int64_t) 1) + segscan",
                                    "_tblock_sizze_16720;\n    byte_offsets_17751 = sdiv_up64(byte_offsets_17750, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16720 * (int64_t) 8;\n    byte_offsets_17752 = sdiv_up64(byte_offsets_17751, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16720 * (int64_t) 8;\n    byte_offsets_17753 = sdiv_up64(byte_offsets_17752, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16720 * (int64_t) 8;\n    warp_byte_offset_17754 = (int64_t) 64;\n    warp_byte_offset_17755 = sdiv_up64(warp_byte_offset_17754, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    warp_byte_offset_17756 = sdiv_up64(warp_byte_offset_17755, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    warp_byte_offset_17757 = sdiv_up64(warp_byte_offset_17756, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    warp_byte_offset_17758 = sdiv_up64(warp_byte_offset_17757, (int64_t) 1) + (int64_t) 32;\n    warp_byte_offset_17759 = sdiv_up64(warp_byte_offset_17758, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    warp_byte_offset_17760 = sdiv_up64(warp_byte_offset_17759, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    warp_byte_offset_17761 = sdiv_up64(warp_byte_offset_17760, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_17762 = (__local unsigned char *) local_mem_17762_backing_0;\n    trans_arr_len_17763 = chunk_sizze_17701 * segscan_tblock_sizze_16720;\n    phys_block_id_17790 = get_tblock_id(0);\n    virtloop_bound_17791 = sdiv_up64(num_virt_blocks_17702 - phys_block_id_17790, num_tblocks_16722);\n    for (int64_t virtloop_i_17792 = 0; virtloop_i_17792 < virtloop_bound_17791; virtloop_i_17792++) {\n        int64_t dynamic_id_17793;\n        int64_t block_offset_17794;\n        int64_t sgm_idx_17795;\n        int32_t boundary_17796;\n        int32_t segsizze_compact_17797;\n        bool private_mem_17798[chunk_sizze_17701];\n        int64_t private_mem_17800[chunk_sizze_17701];\n        int64_t private_mem_17802[chunk_sizze_17701];\n        int64_t private_mem_17804[chunk_sizze_17", "701];\n        bool private_mem_17806[chunk_sizze_17701];\n        int64_t private_mem_17808[chunk_sizze_17701];\n        int64_t private_mem_17810[chunk_sizze_17701];\n        int64_t private_mem_17812[chunk_sizze_17701];\n        int64_t thd_offset_17814;\n        bool acc_17906;\n        int64_t acc_17907;\n        int64_t acc_17908;\n        int64_t acc_17909;\n        bool acc_17910;\n        int64_t acc_17911;\n        int64_t acc_17912;\n        int64_t acc_17913;\n        bool prefix_17950;\n        int64_t prefix_17951;\n        int64_t prefix_17952;\n        int64_t prefix_17953;\n        bool prefix_17954;\n        int64_t prefix_17955;\n        int64_t prefix_17956;\n        int64_t prefix_17957;\n        bool block_new_sgm_17958;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_17741 == 0) {\n                dynamic_id_17793 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_17738)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_17762)[(int64_t) 0] = dynamic_id_17793;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_17793 == num_virt_blocks_17702 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_17738)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_17793 = ((__local int32_t *) local_mem_17762)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_17794 = dynamic_id_17793 * chunk_sizze_17701 * segscan_tblock_sizze_16720;\n        sgm_idx_17795 = smod64(block_offset_17794, idxs_14149);\n        boundary_17796 = sext_i64_i32(smin64(chunk_sizze_17701 * segscan_tblock_sizze_16720, idxs_14149 - sgm_idx_17795));\n        segsizze_compact_17797 = sext_i64_i32(smin64(chunk_sizze", "_17701 * segscan_tblock_sizze_16720, idxs_14149));\n        thd_offset_17814 = block_offset_17794 + sext_i32_i64(local_tid_17741);\n        // Load and map\n        {\n            for (int64_t i_17815 = 0; i_17815 < chunk_sizze_17701; i_17815++) {\n                int64_t virt_tid_17816 = thd_offset_17814 + i_17815 * segscan_tblock_sizze_16720;\n                int64_t slice_17817 = idxs_14149;\n                int64_t gtid_16724 = virt_tid_17816;\n                int64_t remnant_17818 = virt_tid_17816 - gtid_16724;\n                \n                if (slt64(virt_tid_17816, idxs_14149)) {\n                    int64_t eta_p_16171 = ((__global int64_t *) mem_16996)[gtid_16724];\n                    int64_t eta_p_16172 = ((__global int64_t *) mem_16992)[gtid_16724];\n                    int64_t eta_p_16173 = ((__global int64_t *) ext_mem_16988)[gtid_16724];\n                    int64_t lifted_lambda_res_16178 = sub64(eta_p_16171, (int64_t) 1);\n                    int64_t defunc_0_f_res_16179 = add64(eta_p_16172, lifted_lambda_res_16178);\n                    bool x_16180 = sle64((int64_t) 0, eta_p_16173);\n                    bool y_16181 = slt64(eta_p_16173, loop_dz2085U_14130);\n                    bool bounds_check_16182 = x_16180 && y_16181;\n                    bool index_certs_16183;\n                    \n                    if (!bounds_check_16182) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                                global_failure_args[0] = (int64_t) eta_p_16173;\n                                global_failure_args[1] = (int64_t) loop_dz2085U_14130;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    bool x_16186 = sle64((int64_t) 0, defunc_0_f_res_16179);\n                    bool y_16187 = slt64(defunc_0_f_res_16",
                                    "179, n_12437);\n                    bool bounds_check_16188 = x_16186 && y_16187;\n                    bool index_certs_16189;\n                    \n                    if (!bounds_check_16188) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                                global_failure_args[0] = (int64_t) defunc_0_f_res_16179;\n                                global_failure_args[1] = (int64_t) n_12437;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    bool index_certs_16207;\n                    \n                    if (!bounds_check_16188) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                                global_failure_args[0] = (int64_t) defunc_0_f_res_16179;\n                                global_failure_args[1] = (int64_t) n_12437;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    bool x_16174 = ((__global bool *) mem_16990)[gtid_16724];\n                    float info_arg2_16184 = ((__global float *) mem_16982)[eta_p_16173];\n                    int32_t info_arg2_16185 = ((__global int32_t *) mem_16984)[eta_p_16173];\n                    float info_arg1_16190 = ((__global float *) mem_16963)[defunc_0_f_res_16179];\n                    int32_t info_arg1_16191 = ((__global int32_t *) mem_16965)[defunc_0_f_res_16179];\n                    bool defunc_0_zlze_res_16192;\n                    \n                    futrts_cmp_5210(&defunc_0_zlze_res_16192, info_arg1_16190, info_arg1_16191, info_arg2_16184, info_arg2_16185);\n                    \n      ", "              int64_t defunc_0_info_res_16193;\n                    \n                    if (defunc_0_zlze_res_16192) {\n                        bool defunc_0_zlze_res_16456;\n                        \n                        futrts_cmp_5210(&defunc_0_zlze_res_16456, info_arg2_16184, info_arg2_16185, info_arg1_16190, info_arg1_16191);\n                        \n                        int64_t defunc_0_info_res_t_res_16457;\n                        \n                        if (defunc_0_zlze_res_16456) {\n                            defunc_0_info_res_t_res_16457 = (int64_t) 0;\n                        } else {\n                            defunc_0_info_res_t_res_16457 = (int64_t) -1;\n                        }\n                        defunc_0_info_res_16193 = defunc_0_info_res_t_res_16457;\n                    } else {\n                        defunc_0_info_res_16193 = (int64_t) 1;\n                    }\n                    \n                    bool cond_16196 = slt64(defunc_0_info_res_16193, (int64_t) 0);\n                    int64_t tripit_res_16197 = btoi_bool_i64(cond_16196);\n                    int64_t tripit_res_16198;\n                    int64_t tripit_res_16199;\n                    \n                    if (cond_16196) {\n                        tripit_res_16198 = (int64_t) 0;\n                        tripit_res_16199 = (int64_t) 0;\n                    } else {\n                        bool cond_16200 = slt64((int64_t) 0, defunc_0_info_res_16193);\n                        bool cond_neg_16201 = !cond_16200;\n                        int64_t tripit_res_f_res_16202 = btoi_bool_i64(cond_neg_16201);\n                        int64_t tripit_res_f_res_16203 = btoi_bool_i64(cond_16200);\n                        \n                        tripit_res_16198 = tripit_res_f_res_16202;\n                        tripit_res_16199 = tripit_res_f_res_16203;\n                    }\n                    ((__global float *) mem_17016)[gtid_16724] = info_arg1_16190;\n                    ((__global int32_t *) mem_1", "7018)[gtid_16724] = info_arg1_16191;\n                    ((__global int64_t *) mem_17020)[gtid_16724] = defunc_0_info_res_16193;\n                    private_mem_17798[i_17815] = x_16174;\n                    private_mem_17800[i_17815] = tripit_res_16197;\n                    private_mem_17802[i_17815] = tripit_res_16198;\n                    private_mem_17804[i_17815] = tripit_res_16199;\n                    private_mem_17806[i_17815] = x_16174;\n                    private_mem_17808[i_17815] = tripit_res_16197;\n                    private_mem_17810[i_17815] = tripit_res_16198;\n                    private_mem_17812[i_17815] = tripit_res_16199;\n                } else {\n                    private_mem_17798[i_17815] = 0;\n                    private_mem_17800[i_17815] = (int64_t) 0;\n                    private_mem_17802[i_17815] = (int64_t) 0;\n                    private_mem_17804[i_17815] = (int64_t) 0;\n                    private_mem_17806[i_17815] = 0;\n                    private_mem_17808[i_17815] = (int64_t) 0;\n                    private_mem_17810[i_17815] = (int64_t) 0;\n                    private_mem_17812[i_17815] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_17819 = 0; i_17819 < chunk_sizze_17701; i_17819++) {\n                int64_t sharedIdx_17820 = sext_i32_i64(local_tid_17741) + i_17819 * segscan_tblock_sizze_16720;\n                bool tmp_17821 = private_mem_17798[i_17819];\n                \n                ((__local bool *) local_mem_17762)[sharedIdx_17820] = tmp_17821;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17822 = 0; i_17822 < chunk_sizze_17701; i_17822++) {\n                int64_t sharedIdx_17823 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_17822;\n                bool tmp_17824",
                                    " = ((__local bool *) local_mem_17762)[sharedIdx_17823];\n                \n                private_mem_17798[i_17822] = tmp_17824;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17825 = 0; i_17825 < chunk_sizze_17701; i_17825++) {\n                int64_t sharedIdx_17826 = sext_i32_i64(local_tid_17741) + i_17825 * segscan_tblock_sizze_16720;\n                int64_t tmp_17827 = private_mem_17800[i_17825];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_17826] = tmp_17827;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17828 = 0; i_17828 < chunk_sizze_17701; i_17828++) {\n                int64_t sharedIdx_17829 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_17828;\n                int64_t tmp_17830 = ((__local int64_t *) local_mem_17762)[sharedIdx_17829];\n                \n                private_mem_17800[i_17828] = tmp_17830;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17831 = 0; i_17831 < chunk_sizze_17701; i_17831++) {\n                int64_t sharedIdx_17832 = sext_i32_i64(local_tid_17741) + i_17831 * segscan_tblock_sizze_16720;\n                int64_t tmp_17833 = private_mem_17802[i_17831];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_17832] = tmp_17833;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17834 = 0; i_17834 < chunk_sizze_17701; i_17834++) {\n                int64_t sharedIdx_17835 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_17834;\n                int64_t tmp_17836 = ((__local int64_t *) local_mem_17762)[sharedIdx_17835];\n                \n                private_mem_17802[i_17834] = tmp_17836;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17837 = 0; i_17837 < chunk_sizze_17701; i_17837++) {\n                int64_t sharedIdx_17838 = sext_i32_i64(local_tid_17741) + i_17837 * segscan_tblock_si", "zze_16720;\n                int64_t tmp_17839 = private_mem_17804[i_17837];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_17838] = tmp_17839;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17840 = 0; i_17840 < chunk_sizze_17701; i_17840++) {\n                int64_t sharedIdx_17841 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_17840;\n                int64_t tmp_17842 = ((__local int64_t *) local_mem_17762)[sharedIdx_17841];\n                \n                private_mem_17804[i_17840] = tmp_17842;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17843 = 0; i_17843 < chunk_sizze_17701; i_17843++) {\n                int64_t sharedIdx_17844 = sext_i32_i64(local_tid_17741) + i_17843 * segscan_tblock_sizze_16720;\n                bool tmp_17845 = private_mem_17806[i_17843];\n                \n                ((__local bool *) local_mem_17762)[sharedIdx_17844] = tmp_17845;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17846 = 0; i_17846 < chunk_sizze_17701; i_17846++) {\n                int64_t sharedIdx_17847 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_17846;\n                bool tmp_17848 = ((__local bool *) local_mem_17762)[sharedIdx_17847];\n                \n                private_mem_17806[i_17846] = tmp_17848;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17849 = 0; i_17849 < chunk_sizze_17701; i_17849++) {\n                int64_t sharedIdx_17850 = sext_i32_i64(local_tid_17741) + i_17849 * segscan_tblock_sizze_16720;\n                int64_t tmp_17851 = private_mem_17808[i_17849];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_17850] = tmp_17851;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17852 = 0; i_17852 < chunk_sizze_17701; i_17852++) {\n                int64_t sharedIdx_17853 = sext_i32_i64(local_tid_1", "7741) * chunk_sizze_17701 + i_17852;\n                int64_t tmp_17854 = ((__local int64_t *) local_mem_17762)[sharedIdx_17853];\n                \n                private_mem_17808[i_17852] = tmp_17854;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17855 = 0; i_17855 < chunk_sizze_17701; i_17855++) {\n                int64_t sharedIdx_17856 = sext_i32_i64(local_tid_17741) + i_17855 * segscan_tblock_sizze_16720;\n                int64_t tmp_17857 = private_mem_17810[i_17855];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_17856] = tmp_17857;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17858 = 0; i_17858 < chunk_sizze_17701; i_17858++) {\n                int64_t sharedIdx_17859 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_17858;\n                int64_t tmp_17860 = ((__local int64_t *) local_mem_17762)[sharedIdx_17859];\n                \n                private_mem_17810[i_17858] = tmp_17860;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17861 = 0; i_17861 < chunk_sizze_17701; i_17861++) {\n                int64_t sharedIdx_17862 = sext_i32_i64(local_tid_17741) + i_17861 * segscan_tblock_sizze_16720;\n                int64_t tmp_17863 = private_mem_17812[i_17861];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_17862] = tmp_17863;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17864 = 0; i_17864 < chunk_sizze_17701; i_17864++) {\n                int64_t sharedIdx_17865 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_17864;\n                int64_t tmp_17866 = ((__local int64_t *) local_mem_17762)[sharedIdx_17865];\n                \n                private_mem_17812[i_17864] = tmp_17866;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_17867 = 0; i_17867 < chunk_sizze_1",
                                    "7701 - (int64_t) 1; i_17867++) {\n                bool eta_p_15971;\n                bool eta_p_15979;\n                \n                eta_p_15971 = private_mem_17798[i_17867];\n                eta_p_15979 = private_mem_17798[i_17867 + (int64_t) 1];\n                \n                int64_t eta_p_15972;\n                int64_t eta_p_15980;\n                \n                eta_p_15972 = private_mem_17800[i_17867];\n                eta_p_15980 = private_mem_17800[i_17867 + (int64_t) 1];\n                \n                int64_t eta_p_15973;\n                int64_t eta_p_15981;\n                \n                eta_p_15973 = private_mem_17802[i_17867];\n                eta_p_15981 = private_mem_17802[i_17867 + (int64_t) 1];\n                \n                int64_t eta_p_15974;\n                int64_t eta_p_15982;\n                \n                eta_p_15974 = private_mem_17804[i_17867];\n                eta_p_15982 = private_mem_17804[i_17867 + (int64_t) 1];\n                \n                bool eta_p_15975;\n                bool eta_p_15983;\n                \n                eta_p_15975 = private_mem_17806[i_17867];\n                eta_p_15983 = private_mem_17806[i_17867 + (int64_t) 1];\n                \n                int64_t eta_p_15976;\n                int64_t eta_p_15984;\n                \n                eta_p_15976 = private_mem_17808[i_17867];\n                eta_p_15984 = private_mem_17808[i_17867 + (int64_t) 1];\n                \n                int64_t eta_p_15977;\n                int64_t eta_p_15985;\n                \n                eta_p_15977 = private_mem_17810[i_17867];\n                eta_p_15985 = private_mem_17810[i_17867 + (int64_t) 1];\n                \n                int64_t eta_p_15978;\n                int64_t eta_p_15986;\n                \n                eta_p_15978 = private_mem_17812[i_17867];\n                eta_p_15986 = private_mem_17812[i_17867 + (int64_t) 1];\n                \n                bool tmp_15987 = eta_p_15971 || eta_p_15979;\n              ", "  int64_t tmp_15988;\n                int64_t tmp_15989;\n                int64_t tmp_15990;\n                \n                if (eta_p_15979) {\n                    tmp_15988 = eta_p_15980;\n                    tmp_15989 = eta_p_15981;\n                    tmp_15990 = eta_p_15982;\n                } else {\n                    int64_t tmp_15991 = add64(eta_p_15972, eta_p_15980);\n                    int64_t tmp_15992 = add64(eta_p_15973, eta_p_15981);\n                    int64_t tmp_15993 = add64(eta_p_15974, eta_p_15982);\n                    \n                    tmp_15988 = tmp_15991;\n                    tmp_15989 = tmp_15992;\n                    tmp_15990 = tmp_15993;\n                }\n                \n                bool tmp_15994 = eta_p_15975 || eta_p_15983;\n                int64_t tmp_15995;\n                int64_t tmp_15996;\n                int64_t tmp_15997;\n                \n                if (eta_p_15983) {\n                    tmp_15995 = eta_p_15984;\n                    tmp_15996 = eta_p_15985;\n                    tmp_15997 = eta_p_15986;\n                } else {\n                    int64_t tmp_15998 = add64(eta_p_15976, eta_p_15984);\n                    int64_t tmp_15999 = add64(eta_p_15977, eta_p_15985);\n                    int64_t tmp_16000 = add64(eta_p_15978, eta_p_15986);\n                    \n                    tmp_15995 = tmp_15998;\n                    tmp_15996 = tmp_15999;\n                    tmp_15997 = tmp_16000;\n                }\n                private_mem_17798[i_17867 + (int64_t) 1] = tmp_15987;\n                private_mem_17800[i_17867 + (int64_t) 1] = tmp_15988;\n                private_mem_17802[i_17867 + (int64_t) 1] = tmp_15989;\n                private_mem_17804[i_17867 + (int64_t) 1] = tmp_15990;\n                private_mem_17806[i_17867 + (int64_t) 1] = tmp_15994;\n                private_mem_17808[i_17867 + (int64_t) 1] = tmp_15995;\n                private_mem_17810[i_17867 + (int64_t) 1] = tmp_15996;\n                private_mem_17812[i_17", "867 + (int64_t) 1] = tmp_15997;\n            }\n        }\n        // Publish results in shared memory\n        {\n            bool tmp_17868 = private_mem_17798[chunk_sizze_17701 - (int64_t) 1];\n            \n            ((__local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741)] = tmp_17868;\n            \n            int64_t tmp_17869 = private_mem_17800[chunk_sizze_17701 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = tmp_17869;\n            \n            int64_t tmp_17870 = private_mem_17802[chunk_sizze_17701 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = tmp_17870;\n            \n            int64_t tmp_17871 = private_mem_17804[chunk_sizze_17701 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = tmp_17871;\n            \n            bool tmp_17872 = private_mem_17806[chunk_sizze_17701 - (int64_t) 1];\n            \n            ((__local bool *) local_mem_17762)[byte_offsets_17749 + sext_i32_i64(local_tid_17741)] = tmp_17872;\n            \n            int64_t tmp_17873 = private_mem_17808[chunk_sizze_17701 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = tmp_17873;\n            \n            int64_t tmp_17874 = private_mem_17810[chunk_sizze_17701 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = tmp_17874;\n            \n            int64_t tmp_17875 = private_mem_17812[chunk_sizze_17701 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = tmp_17875;\n    ",
                                    "        barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            bool eta_p_17876;\n            int64_t eta_p_17877;\n            int64_t eta_p_17878;\n            int64_t eta_p_17879;\n            bool eta_p_17880;\n            int64_t eta_p_17881;\n            int64_t eta_p_17882;\n            int64_t eta_p_17883;\n            bool eta_p_17884;\n            int64_t eta_p_17885;\n            int64_t eta_p_17886;\n            int64_t eta_p_17887;\n            bool eta_p_17888;\n            int64_t eta_p_17889;\n            int64_t eta_p_17890;\n            int64_t eta_p_17891;\n            bool eta_p_17914;\n            int64_t eta_p_17915;\n            int64_t eta_p_17916;\n            int64_t eta_p_17917;\n            bool eta_p_17918;\n            int64_t eta_p_17919;\n            int64_t eta_p_17920;\n            int64_t eta_p_17921;\n            bool eta_p_17922;\n            int64_t eta_p_17923;\n            int64_t eta_p_17924;\n            int64_t eta_p_17925;\n            bool eta_p_17926;\n            int64_t eta_p_17927;\n            int64_t eta_p_17928;\n            int64_t eta_p_17929;\n            bool ltid_in_bounds_17944 = slt64(sext_i32_i64(local_tid_17741), num_virt_threads_17703);\n            int32_t skip_threads_17945;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_17944) {\n                    eta_p_17884 = ((volatile __local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741)];\n                    eta_p_17885 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                    eta_p_17886 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                    eta_p_17887 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                    eta_p_17888 = ", "((volatile __local bool *) local_mem_17762)[byte_offsets_17749 + sext_i32_i64(local_tid_17741)];\n                    eta_p_17889 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                    eta_p_17890 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                    eta_p_17891 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                    if ((local_tid_17741 - squot32(local_tid_17741, 32) * 32) == 0) {\n                        eta_p_17876 = eta_p_17884;\n                        eta_p_17877 = eta_p_17885;\n                        eta_p_17878 = eta_p_17886;\n                        eta_p_17879 = eta_p_17887;\n                        eta_p_17880 = eta_p_17888;\n                        eta_p_17881 = eta_p_17889;\n                        eta_p_17882 = eta_p_17890;\n                        eta_p_17883 = eta_p_17891;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_17945 = 1;\n                while (slt32(skip_threads_17945, 32)) {\n                    bool thread_active_17946 = sle32(skip_threads_17945, local_tid_17741 - squot32(local_tid_17741, 32) * 32) && ltid_in_bounds_17944;\n                    \n                    if (thread_active_17946) {\n                        // read operands\n                        {\n                            eta_p_17876 = ((volatile __local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17945)];\n                            eta_p_17877 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17945))];\n                            eta_p_17878 = ((volatile __local int64_t *) local", "_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17945))];\n                            eta_p_17879 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17945))];\n                            eta_p_17880 = ((volatile __local bool *) local_mem_17762)[byte_offsets_17749 + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17945))];\n                            eta_p_17881 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17945))];\n                            eta_p_17882 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17945))];\n                            eta_p_17883 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17945))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_17946) {\n                            bool tmp_17892 = eta_p_17876 || eta_p_17884;\n                            int64_t tmp_17893;\n                            int64_t tmp_17894;\n                            int64_t tmp_17895;\n                            \n                            if (eta_p_17884) {\n                                tmp_17893 = eta_p_17885;\n                                tmp_17894 = eta_p_17886;\n                                tmp_17895 = eta_p_17887;\n                            } else {\n                                int64_t tmp_17896 = add64(eta_p_17877, eta_p_17885);\n                                int64_t tmp_17897 = add64(eta_p_17878, eta_p_17886);\n                                int64_t tmp_17898 = add64(eta_p_17",
                                    "879, eta_p_17887);\n                                \n                                tmp_17893 = tmp_17896;\n                                tmp_17894 = tmp_17897;\n                                tmp_17895 = tmp_17898;\n                            }\n                            \n                            bool tmp_17899 = eta_p_17880 || eta_p_17888;\n                            int64_t tmp_17900;\n                            int64_t tmp_17901;\n                            int64_t tmp_17902;\n                            \n                            if (eta_p_17888) {\n                                tmp_17900 = eta_p_17889;\n                                tmp_17901 = eta_p_17890;\n                                tmp_17902 = eta_p_17891;\n                            } else {\n                                int64_t tmp_17903 = add64(eta_p_17881, eta_p_17889);\n                                int64_t tmp_17904 = add64(eta_p_17882, eta_p_17890);\n                                int64_t tmp_17905 = add64(eta_p_17883, eta_p_17891);\n                                \n                                tmp_17900 = tmp_17903;\n                                tmp_17901 = tmp_17904;\n                                tmp_17902 = tmp_17905;\n                            }\n                            eta_p_17876 = tmp_17892;\n                            eta_p_17877 = tmp_17893;\n                            eta_p_17878 = tmp_17894;\n                            eta_p_17879 = tmp_17895;\n                            eta_p_17880 = tmp_17899;\n                            eta_p_17881 = tmp_17900;\n                            eta_p_17882 = tmp_17901;\n                            eta_p_17883 = tmp_17902;\n                        }\n                    }\n                    if (sle32(wave_sizze_17743, skip_threads_17945)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_17946) {\n                        // write result\n                        {\n           ", "                 ((volatile __local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741)] = eta_p_17876;\n                            eta_p_17884 = eta_p_17876;\n                            ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17877;\n                            eta_p_17885 = eta_p_17877;\n                            ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17878;\n                            eta_p_17886 = eta_p_17878;\n                            ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17879;\n                            eta_p_17887 = eta_p_17879;\n                            ((volatile __local bool *) local_mem_17762)[byte_offsets_17749 + sext_i32_i64(local_tid_17741)] = eta_p_17880;\n                            eta_p_17888 = eta_p_17880;\n                            ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17881;\n                            eta_p_17889 = eta_p_17881;\n                            ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17882;\n                            eta_p_17890 = eta_p_17882;\n                            ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17883;\n                            eta_p_17891 = eta_p_17883;\n                        }\n                    }\n                    if (sle32(wave_sizze_17743, skip_threads_17945)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_17945 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // l", "ast thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_17741 - squot32(local_tid_17741, 32) * 32) == 31 && ltid_in_bounds_17944) {\n                    ((volatile __local bool *) local_mem_17762)[sext_i32_i64(squot32(local_tid_17741, 32))] = eta_p_17876;\n                    ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17741, 32))] = eta_p_17877;\n                    ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17741, 32))] = eta_p_17878;\n                    ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17741, 32))] = eta_p_17879;\n                    ((volatile __local bool *) local_mem_17762)[byte_offsets_17749 + sext_i32_i64(squot32(local_tid_17741, 32))] = eta_p_17880;\n                    ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17741, 32))] = eta_p_17881;\n                    ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17741, 32))] = eta_p_17882;\n                    ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17741, 32))] = eta_p_17883;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_17947;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_17741, 32) == 0 && ltid_in_bounds_17944) {\n                        eta_p_17922 = ((volatile __local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741)];\n                        eta_p_1792",
                                    "3 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                        eta_p_17924 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                        eta_p_17925 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                        eta_p_17926 = ((volatile __local bool *) local_mem_17762)[byte_offsets_17749 + sext_i32_i64(local_tid_17741)];\n                        eta_p_17927 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                        eta_p_17928 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                        eta_p_17929 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                        if ((local_tid_17741 - squot32(local_tid_17741, 32) * 32) == 0) {\n                            eta_p_17914 = eta_p_17922;\n                            eta_p_17915 = eta_p_17923;\n                            eta_p_17916 = eta_p_17924;\n                            eta_p_17917 = eta_p_17925;\n                            eta_p_17918 = eta_p_17926;\n                            eta_p_17919 = eta_p_17927;\n                            eta_p_17920 = eta_p_17928;\n                            eta_p_17921 = eta_p_17929;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_17947 = 1;\n                    while (slt32(skip_threads_17947, 32)) {\n                        bool thread_active_17948 = sle32(skip_threads_17947, local_tid_17741 - squot32(local_tid_17741, 32) * 32) && (squot32(local_tid_17741", ", 32) == 0 && ltid_in_bounds_17944);\n                        \n                        if (thread_active_17948) {\n                            // read operands\n                            {\n                                eta_p_17914 = ((volatile __local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17947)];\n                                eta_p_17915 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17947))];\n                                eta_p_17916 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17947))];\n                                eta_p_17917 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17947))];\n                                eta_p_17918 = ((volatile __local bool *) local_mem_17762)[byte_offsets_17749 + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17947))];\n                                eta_p_17919 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17947))];\n                                eta_p_17920 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17947))];\n                                eta_p_17921 = ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_17947))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_17948) {\n                                bool tmp_17930 = eta_p_17914 ||", " eta_p_17922;\n                                int64_t tmp_17931;\n                                int64_t tmp_17932;\n                                int64_t tmp_17933;\n                                \n                                if (eta_p_17922) {\n                                    tmp_17931 = eta_p_17923;\n                                    tmp_17932 = eta_p_17924;\n                                    tmp_17933 = eta_p_17925;\n                                } else {\n                                    int64_t tmp_17934 = add64(eta_p_17915, eta_p_17923);\n                                    int64_t tmp_17935 = add64(eta_p_17916, eta_p_17924);\n                                    int64_t tmp_17936 = add64(eta_p_17917, eta_p_17925);\n                                    \n                                    tmp_17931 = tmp_17934;\n                                    tmp_17932 = tmp_17935;\n                                    tmp_17933 = tmp_17936;\n                                }\n                                \n                                bool tmp_17937 = eta_p_17918 || eta_p_17926;\n                                int64_t tmp_17938;\n                                int64_t tmp_17939;\n                                int64_t tmp_17940;\n                                \n                                if (eta_p_17926) {\n                                    tmp_17938 = eta_p_17927;\n                                    tmp_17939 = eta_p_17928;\n                                    tmp_17940 = eta_p_17929;\n                                } else {\n                                    int64_t tmp_17941 = add64(eta_p_17919, eta_p_17927);\n                                    int64_t tmp_17942 = add64(eta_p_17920, eta_p_17928);\n                                    int64_t tmp_17943 = add64(eta_p_17921, eta_p_17929);\n                                    \n                                    tmp_17938 = tmp_17941;\n                                    tmp_17939 = tmp_17942;\n                 ",
                                    "                   tmp_17940 = tmp_17943;\n                                }\n                                eta_p_17914 = tmp_17930;\n                                eta_p_17915 = tmp_17931;\n                                eta_p_17916 = tmp_17932;\n                                eta_p_17917 = tmp_17933;\n                                eta_p_17918 = tmp_17937;\n                                eta_p_17919 = tmp_17938;\n                                eta_p_17920 = tmp_17939;\n                                eta_p_17921 = tmp_17940;\n                            }\n                        }\n                        if (sle32(wave_sizze_17743, skip_threads_17947)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_17948) {\n                            // write result\n                            {\n                                ((volatile __local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741)] = eta_p_17914;\n                                eta_p_17922 = eta_p_17914;\n                                ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17915;\n                                eta_p_17923 = eta_p_17915;\n                                ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17916;\n                                eta_p_17924 = eta_p_17916;\n                                ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17917;\n                                eta_p_17925 = eta_p_17917;\n                                ((volatile __local bool *) local_mem_17762)[byte_offsets_17749 + sext_i32_i64(local_tid_17741)] = eta_p_17918;\n                                eta_p_17926 = eta_p_17918;\n                                ((volatile __local int64_t *) lo", "cal_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17919;\n                                eta_p_17927 = eta_p_17919;\n                                ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17920;\n                                eta_p_17928 = eta_p_17920;\n                                ((volatile __local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17921;\n                                eta_p_17929 = eta_p_17921;\n                            }\n                        }\n                        if (sle32(wave_sizze_17743, skip_threads_17947)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_17947 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_17949 = squot32(local_tid_17741, 32) == 0 || !ltid_in_bounds_17944;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_17949) {\n                        eta_p_17884 = eta_p_17876;\n                        eta_p_17885 = eta_p_17877;\n                        eta_p_17886 = eta_p_17878;\n                        eta_p_17887 = eta_p_17879;\n                        eta_p_17888 = eta_p_17880;\n                        eta_p_17889 = eta_p_17881;\n                        eta_p_17890 = eta_p_17882;\n                        eta_p_17891 = eta_p_17883;\n                        eta_p_17876 = ((__local bool *) local_mem_17762)[sext_i32_i64(squot32(local_tid_17741, 32)) - (int64_t) 1];\n                        eta_p_17877 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17741, 32)) - (int64_t) 1)];\n            ", "            eta_p_17878 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17741, 32)) - (int64_t) 1)];\n                        eta_p_17879 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17741, 32)) - (int64_t) 1)];\n                        eta_p_17880 = ((__local bool *) local_mem_17762)[byte_offsets_17749 + (sext_i32_i64(squot32(local_tid_17741, 32)) - (int64_t) 1)];\n                        eta_p_17881 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17741, 32)) - (int64_t) 1)];\n                        eta_p_17882 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17741, 32)) - (int64_t) 1)];\n                        eta_p_17883 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17741, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_17949) {\n                        bool tmp_17892 = eta_p_17876 || eta_p_17884;\n                        int64_t tmp_17893;\n                        int64_t tmp_17894;\n                        int64_t tmp_17895;\n                        \n                        if (eta_p_17884) {\n                            tmp_17893 = eta_p_17885;\n                            tmp_17894 = eta_p_17886;\n                            tmp_17895 = eta_p_17887;\n                        } else {\n                            int64_t tmp_17896 = add64(eta_p_17877, eta_p_17885);\n                            int64_t tmp_17897 = add64(eta_p_17878, eta_p_17886);\n                            int64_t tmp_17898 = add64(eta_p_17879, eta_p_17887);\n                            \n                            tmp_17893 = tmp_17896;\n                            tmp_178",
                                    "94 = tmp_17897;\n                            tmp_17895 = tmp_17898;\n                        }\n                        \n                        bool tmp_17899 = eta_p_17880 || eta_p_17888;\n                        int64_t tmp_17900;\n                        int64_t tmp_17901;\n                        int64_t tmp_17902;\n                        \n                        if (eta_p_17888) {\n                            tmp_17900 = eta_p_17889;\n                            tmp_17901 = eta_p_17890;\n                            tmp_17902 = eta_p_17891;\n                        } else {\n                            int64_t tmp_17903 = add64(eta_p_17881, eta_p_17889);\n                            int64_t tmp_17904 = add64(eta_p_17882, eta_p_17890);\n                            int64_t tmp_17905 = add64(eta_p_17883, eta_p_17891);\n                            \n                            tmp_17900 = tmp_17903;\n                            tmp_17901 = tmp_17904;\n                            tmp_17902 = tmp_17905;\n                        }\n                        eta_p_17876 = tmp_17892;\n                        eta_p_17877 = tmp_17893;\n                        eta_p_17878 = tmp_17894;\n                        eta_p_17879 = tmp_17895;\n                        eta_p_17880 = tmp_17899;\n                        eta_p_17881 = tmp_17900;\n                        eta_p_17882 = tmp_17901;\n                        eta_p_17883 = tmp_17902;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_17949) {\n                        ((__local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741)] = eta_p_17876;\n                        ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17877;\n                        ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17878;\n                        ((__loca", "l int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17879;\n                        ((__local bool *) local_mem_17762)[byte_offsets_17749 + sext_i32_i64(local_tid_17741)] = eta_p_17880;\n                        ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17881;\n                        ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17882;\n                        ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17883;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_17741, 32) == 0 && ltid_in_bounds_17944) {\n                    ((__local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741)] = eta_p_17884;\n                    ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17885;\n                    ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17886;\n                    ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17887;\n                    ((__local bool *) local_mem_17762)[byte_offsets_17749 + sext_i32_i64(local_tid_17741)] = eta_p_17888;\n                    ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17889;\n                    ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17890;\n                    ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) ", "+ sext_i32_i64(local_tid_17741)] = eta_p_17891;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_17741 == 0) {\n                acc_17906 = ((__local bool *) local_mem_17762)[segscan_tblock_sizze_16720 - (int64_t) 1];\n                acc_17907 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + (segscan_tblock_sizze_16720 - (int64_t) 1)];\n                acc_17908 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + (segscan_tblock_sizze_16720 - (int64_t) 1)];\n                acc_17909 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + (segscan_tblock_sizze_16720 - (int64_t) 1)];\n                acc_17910 = ((__local bool *) local_mem_17762)[byte_offsets_17749 + (segscan_tblock_sizze_16720 - (int64_t) 1)];\n                acc_17911 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + (segscan_tblock_sizze_16720 - (int64_t) 1)];\n                acc_17912 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + (segscan_tblock_sizze_16720 - (int64_t) 1)];\n                acc_17913 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + (segscan_tblock_sizze_16720 - (int64_t) 1)];\n            } else {\n                acc_17906 = ((__local bool *) local_mem_17762)[sext_i32_i64(local_tid_17741) - (int64_t) 1];\n                acc_17907 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17746, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - (int64_t) 1)];\n                acc_17908 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17747, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - (int64_t) 1)];\n                acc_17909 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17748, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - (int64_t) 1)];\n                acc_17910 = ((__loca",
                                    "l bool *) local_mem_17762)[byte_offsets_17749 + (sext_i32_i64(local_tid_17741) - (int64_t) 1)];\n                acc_17911 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17750, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - (int64_t) 1)];\n                acc_17912 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17751, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - (int64_t) 1)];\n                acc_17913 = ((__local int64_t *) local_mem_17762)[squot64(byte_offsets_17752, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_17950 = 0;\n        prefix_17951 = (int64_t) 0;\n        prefix_17952 = (int64_t) 0;\n        prefix_17953 = (int64_t) 0;\n        prefix_17954 = 0;\n        prefix_17955 = (int64_t) 0;\n        prefix_17956 = (int64_t) 0;\n        prefix_17957 = (int64_t) 0;\n        block_new_sgm_17958 = sgm_idx_17795 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_17958 && local_tid_17741 == 0) {\n                ((volatile __global bool *) incprefixes_mem_17708)[dynamic_id_17793] = acc_17906;\n                ((volatile __global int64_t *) incprefixes_mem_17712)[dynamic_id_17793] = acc_17907;\n                ((volatile __global int64_t *) incprefixes_mem_17716)[dynamic_id_17793] = acc_17908;\n                ((volatile __global int64_t *) incprefixes_mem_17720)[dynamic_id_17793] = acc_17909;\n                ((volatile __global bool *) incprefixes_mem_17724)[dynamic_id_17793] = acc_17910;\n                ((volatile __global int64_t *) incprefixes_mem_17728)[dynamic_id_17793] = acc_17911;\n                ((volatile __global int64_t *) incprefixes_mem_17732)[dynamic_id_17793] = acc_17912;\n                ((volatile __global int64_t *) incprefixes_mem_17736)[dynamic_id_17793] = acc_17913;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_17704)[dynamic_id_17793] = (int8_t) 2", ";\n                acc_17906 = 0;\n                acc_17907 = (int64_t) 0;\n                acc_17908 = (int64_t) 0;\n                acc_17909 = (int64_t) 0;\n                acc_17910 = 0;\n                acc_17911 = (int64_t) 0;\n                acc_17912 = (int64_t) 0;\n                acc_17913 = (int64_t) 0;\n            }\n            if (!block_new_sgm_17958 && slt32(local_tid_17741, wave_sizze_17743)) {\n                if (local_tid_17741 == 0) {\n                    ((volatile __global bool *) aggregates_mem_17706)[dynamic_id_17793] = acc_17906;\n                    ((volatile __global int64_t *) aggregates_mem_17710)[dynamic_id_17793] = acc_17907;\n                    ((volatile __global int64_t *) aggregates_mem_17714)[dynamic_id_17793] = acc_17908;\n                    ((volatile __global int64_t *) aggregates_mem_17718)[dynamic_id_17793] = acc_17909;\n                    ((volatile __global bool *) aggregates_mem_17722)[dynamic_id_17793] = acc_17910;\n                    ((volatile __global int64_t *) aggregates_mem_17726)[dynamic_id_17793] = acc_17911;\n                    ((volatile __global int64_t *) aggregates_mem_17730)[dynamic_id_17793] = acc_17912;\n                    ((volatile __global int64_t *) aggregates_mem_17734)[dynamic_id_17793] = acc_17913;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_17704)[dynamic_id_17793] = (int8_t) 1;\n                    \n                    int8_t tmp_17959 = ((volatile __global int8_t *) status_flags_mem_17704)[dynamic_id_17793 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_17762)[(int64_t) 0] = tmp_17959;\n                }\n                mem_fence_local();\n                \n                int8_t status_17960 = ((__local int8_t *) local_mem_17762)[(int64_t) 0];\n                \n                if (status_17960 == (int8_t) 2) {\n                    if (local_tid_17741 == 0) {\n                        prefix_17950 = ((v", "olatile __global bool *) incprefixes_mem_17708)[dynamic_id_17793 - (int64_t) 1];\n                        prefix_17951 = ((volatile __global int64_t *) incprefixes_mem_17712)[dynamic_id_17793 - (int64_t) 1];\n                        prefix_17952 = ((volatile __global int64_t *) incprefixes_mem_17716)[dynamic_id_17793 - (int64_t) 1];\n                        prefix_17953 = ((volatile __global int64_t *) incprefixes_mem_17720)[dynamic_id_17793 - (int64_t) 1];\n                        prefix_17954 = ((volatile __global bool *) incprefixes_mem_17724)[dynamic_id_17793 - (int64_t) 1];\n                        prefix_17955 = ((volatile __global int64_t *) incprefixes_mem_17728)[dynamic_id_17793 - (int64_t) 1];\n                        prefix_17956 = ((volatile __global int64_t *) incprefixes_mem_17732)[dynamic_id_17793 - (int64_t) 1];\n                        prefix_17957 = ((volatile __global int64_t *) incprefixes_mem_17736)[dynamic_id_17793 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_17961 = sext_i64_i32(dynamic_id_17793 - sext_i32_i64(wave_sizze_17743));\n                    \n                    while (slt32(wave_sizze_17743 * -1, readOffset_17961)) {\n                        int32_t read_i_17962 = readOffset_17961 + local_tid_17741;\n                        bool aggr_17963 = 0;\n                        int64_t aggr_17964 = (int64_t) 0;\n                        int64_t aggr_17965 = (int64_t) 0;\n                        int64_t aggr_17966 = (int64_t) 0;\n                        bool aggr_17967 = 0;\n                        int64_t aggr_17968 = (int64_t) 0;\n                        int64_t aggr_17969 = (int64_t) 0;\n                        int64_t aggr_17970 = (int64_t) 0;\n                        int8_t flag_17971 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_17962)) {\n                            flag_17971 = ((volatile __global int8_t *) status_flags_mem_17704)[sext_i32_i64(read_i_17962)];\n   ",
                                    "                         if (flag_17971 == (int8_t) 2) {\n                                aggr_17963 = ((volatile __global bool *) incprefixes_mem_17708)[sext_i32_i64(read_i_17962)];\n                                aggr_17964 = ((volatile __global int64_t *) incprefixes_mem_17712)[sext_i32_i64(read_i_17962)];\n                                aggr_17965 = ((volatile __global int64_t *) incprefixes_mem_17716)[sext_i32_i64(read_i_17962)];\n                                aggr_17966 = ((volatile __global int64_t *) incprefixes_mem_17720)[sext_i32_i64(read_i_17962)];\n                                aggr_17967 = ((volatile __global bool *) incprefixes_mem_17724)[sext_i32_i64(read_i_17962)];\n                                aggr_17968 = ((volatile __global int64_t *) incprefixes_mem_17728)[sext_i32_i64(read_i_17962)];\n                                aggr_17969 = ((volatile __global int64_t *) incprefixes_mem_17732)[sext_i32_i64(read_i_17962)];\n                                aggr_17970 = ((volatile __global int64_t *) incprefixes_mem_17736)[sext_i32_i64(read_i_17962)];\n                            } else if (flag_17971 == (int8_t) 1) {\n                                aggr_17963 = ((volatile __global bool *) aggregates_mem_17706)[sext_i32_i64(read_i_17962)];\n                                aggr_17964 = ((volatile __global int64_t *) aggregates_mem_17710)[sext_i32_i64(read_i_17962)];\n                                aggr_17965 = ((volatile __global int64_t *) aggregates_mem_17714)[sext_i32_i64(read_i_17962)];\n                                aggr_17966 = ((volatile __global int64_t *) aggregates_mem_17718)[sext_i32_i64(read_i_17962)];\n                                aggr_17967 = ((volatile __global bool *) aggregates_mem_17722)[sext_i32_i64(read_i_17962)];\n                                aggr_17968 = ((volatile __global int64_t *) aggregates_mem_17726)[sext_i32_i64(read_i_17962)];\n                                aggr_17969 = ((volatile __global int64_t *) aggregates_mem_17730)[sext", "_i32_i64(read_i_17962)];\n                                aggr_17970 = ((volatile __global int64_t *) aggregates_mem_17734)[sext_i32_i64(read_i_17962)];\n                            }\n                        }\n                        ((__local bool *) local_mem_17762)[(int64_t) 32 + sext_i32_i64(local_tid_17741)] = aggr_17963;\n                        ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17754, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = aggr_17964;\n                        ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17755, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = aggr_17965;\n                        ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17756, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = aggr_17966;\n                        ((__local bool *) local_mem_17762)[warp_byte_offset_17757 + sext_i32_i64(local_tid_17741)] = aggr_17967;\n                        ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17758, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = aggr_17968;\n                        ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17759, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = aggr_17969;\n                        ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17760, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = aggr_17970;\n                        ((__local int8_t *) local_mem_17762)[sext_i32_i64(local_tid_17741)] = flag_17971;\n                        flag_17971 = ((__local int8_t *) local_mem_17762)[sext_i32_i64(wave_sizze_17743) - (int64_t) 1];\n                        if (slt8(flag_17971, (int8_t) 2)) {\n                            int8_t flg_x_18002;\n                            int8_t flg_y_18003;\n                            bool eta_p_17972;\n                            int64_t eta_p_17973;\n                            int64_t eta_p_17974;\n                            int64_t eta_p_17975;\n                            bool eta_p_17976", ";\n                            int64_t eta_p_17977;\n                            int64_t eta_p_17978;\n                            int64_t eta_p_17979;\n                            bool eta_p_17980;\n                            int64_t eta_p_17981;\n                            int64_t eta_p_17982;\n                            int64_t eta_p_17983;\n                            bool eta_p_17984;\n                            int64_t eta_p_17985;\n                            int64_t eta_p_17986;\n                            int64_t eta_p_17987;\n                            int32_t skip_threads_18004;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_18003 = ((volatile __local int8_t *) local_mem_17762)[sext_i32_i64(local_tid_17741)];\n                                eta_p_17980 = ((volatile __local bool *) local_mem_17762)[(int64_t) 32 + sext_i32_i64(local_tid_17741)];\n                                eta_p_17981 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17754, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                                eta_p_17982 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17755, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                                eta_p_17983 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17756, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                                eta_p_17984 = ((volatile __local bool *) local_mem_17762)[warp_byte_offset_17757 + sext_i32_i64(local_tid_17741)];\n                                eta_p_17985 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17758, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                                eta_p_17986 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17759, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                      ",
                                    "          eta_p_17987 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17760, (int64_t) 8) + sext_i32_i64(local_tid_17741)];\n                                if ((local_tid_17741 - squot32(local_tid_17741, 32) * 32) == 0) {\n                                    eta_p_17972 = eta_p_17980;\n                                    eta_p_17973 = eta_p_17981;\n                                    eta_p_17974 = eta_p_17982;\n                                    eta_p_17975 = eta_p_17983;\n                                    eta_p_17976 = eta_p_17984;\n                                    eta_p_17977 = eta_p_17985;\n                                    eta_p_17978 = eta_p_17986;\n                                    eta_p_17979 = eta_p_17987;\n                                    flg_x_18002 = flg_y_18003;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_18004 = 1;\n                                while (slt32(skip_threads_18004, 32)) {\n                                    if (sle32(skip_threads_18004, local_tid_17741 - squot32(local_tid_17741, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_18002 = ((volatile __local int8_t *) local_mem_17762)[sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004)];\n                                            eta_p_17972 = ((volatile __local bool *) local_mem_17762)[(int64_t) 32 + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004))];\n                                            eta_p_17973 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17754, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004))];\n                                            eta_p_17974 = ((volatile __local int64_t *) ", "local_mem_17762)[squot64(warp_byte_offset_17755, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004))];\n                                            eta_p_17975 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17756, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004))];\n                                            eta_p_17976 = ((volatile __local bool *) local_mem_17762)[warp_byte_offset_17757 + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004))];\n                                            eta_p_17977 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17758, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004))];\n                                            eta_p_17978 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17759, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004))];\n                                            eta_p_17979 = ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17760, (int64_t) 8) + (sext_i32_i64(local_tid_17741) - sext_i32_i64(skip_threads_18004))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_18003 == (int8_t) 2 || flg_y_18003 == (int8_t) 0) {\n                                                flg_x_18002 = flg_y_18003;\n                                                eta_p_17972 = eta_p_17980;\n                                                eta_p_17973 = eta_p_17981;\n                                                eta_p_17974 = eta_p_17982;\n                                                eta_p_17975 = eta_p_17983;\n                                                eta_p_17976 = eta_p_17984;\n                                                eta_p_17977 = eta_p_17985;\n           ", "                                     eta_p_17978 = eta_p_17986;\n                                                eta_p_17979 = eta_p_17987;\n                                            } else {\n                                                bool tmp_17988 = eta_p_17972 || eta_p_17980;\n                                                int64_t tmp_17989;\n                                                int64_t tmp_17990;\n                                                int64_t tmp_17991;\n                                                \n                                                if (eta_p_17980) {\n                                                    tmp_17989 = eta_p_17981;\n                                                    tmp_17990 = eta_p_17982;\n                                                    tmp_17991 = eta_p_17983;\n                                                } else {\n                                                    int64_t tmp_17992 = add64(eta_p_17973, eta_p_17981);\n                                                    int64_t tmp_17993 = add64(eta_p_17974, eta_p_17982);\n                                                    int64_t tmp_17994 = add64(eta_p_17975, eta_p_17983);\n                                                    \n                                                    tmp_17989 = tmp_17992;\n                                                    tmp_17990 = tmp_17993;\n                                                    tmp_17991 = tmp_17994;\n                                                }\n                                                \n                                                bool tmp_17995 = eta_p_17976 || eta_p_17984;\n                                                int64_t tmp_17996;\n                                                int64_t tmp_17997;\n                                                int64_t tmp_17998;\n                                                \n                                                if (eta_p_17984) {\n        ",
                                    "                                            tmp_17996 = eta_p_17985;\n                                                    tmp_17997 = eta_p_17986;\n                                                    tmp_17998 = eta_p_17987;\n                                                } else {\n                                                    int64_t tmp_17999 = add64(eta_p_17977, eta_p_17985);\n                                                    int64_t tmp_18000 = add64(eta_p_17978, eta_p_17986);\n                                                    int64_t tmp_18001 = add64(eta_p_17979, eta_p_17987);\n                                                    \n                                                    tmp_17996 = tmp_17999;\n                                                    tmp_17997 = tmp_18000;\n                                                    tmp_17998 = tmp_18001;\n                                                }\n                                                eta_p_17972 = tmp_17988;\n                                                eta_p_17973 = tmp_17989;\n                                                eta_p_17974 = tmp_17990;\n                                                eta_p_17975 = tmp_17991;\n                                                eta_p_17976 = tmp_17995;\n                                                eta_p_17977 = tmp_17996;\n                                                eta_p_17978 = tmp_17997;\n                                                eta_p_17979 = tmp_17998;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_17762)[sext_i32_i64(local_tid_17741)] = flg_x_18002;\n                                            flg_y_18003 = flg_x_18002;\n                                            ((volatile __local bool *) local_mem_17762)[(int64_t) 32", " + sext_i32_i64(local_tid_17741)] = eta_p_17972;\n                                            eta_p_17980 = eta_p_17972;\n                                            ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17754, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17973;\n                                            eta_p_17981 = eta_p_17973;\n                                            ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17755, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17974;\n                                            eta_p_17982 = eta_p_17974;\n                                            ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17756, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17975;\n                                            eta_p_17983 = eta_p_17975;\n                                            ((volatile __local bool *) local_mem_17762)[warp_byte_offset_17757 + sext_i32_i64(local_tid_17741)] = eta_p_17976;\n                                            eta_p_17984 = eta_p_17976;\n                                            ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17758, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17977;\n                                            eta_p_17985 = eta_p_17977;\n                                            ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17759, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17978;\n                                            eta_p_17986 = eta_p_17978;\n                                            ((volatile __local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17760, (int64_t) 8) + sext_i32_i64(local_tid_17741)] = eta_p_17979;\n                                            eta_p_17987 = eta_p_17979;\n                                        }\n                                    }\n                                    skip", "_threads_18004 *= 2;\n                                }\n                            }\n                        }\n                        flag_17971 = ((__local int8_t *) local_mem_17762)[sext_i32_i64(wave_sizze_17743) - (int64_t) 1];\n                        aggr_17963 = ((__local bool *) local_mem_17762)[(int64_t) 32 + (sext_i32_i64(wave_sizze_17743) - (int64_t) 1)];\n                        aggr_17964 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17754, (int64_t) 8) + (sext_i32_i64(wave_sizze_17743) - (int64_t) 1)];\n                        aggr_17965 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17755, (int64_t) 8) + (sext_i32_i64(wave_sizze_17743) - (int64_t) 1)];\n                        aggr_17966 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17756, (int64_t) 8) + (sext_i32_i64(wave_sizze_17743) - (int64_t) 1)];\n                        aggr_17967 = ((__local bool *) local_mem_17762)[warp_byte_offset_17757 + (sext_i32_i64(wave_sizze_17743) - (int64_t) 1)];\n                        aggr_17968 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17758, (int64_t) 8) + (sext_i32_i64(wave_sizze_17743) - (int64_t) 1)];\n                        aggr_17969 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17759, (int64_t) 8) + (sext_i32_i64(wave_sizze_17743) - (int64_t) 1)];\n                        aggr_17970 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17760, (int64_t) 8) + (sext_i32_i64(wave_sizze_17743) - (int64_t) 1)];\n                        if (flag_17971 == (int8_t) 2) {\n                            readOffset_17961 = wave_sizze_17743 * -1;\n                        } else if (flag_17971 == (int8_t) 1) {\n                            readOffset_17961 -= wave_sizze_17743;\n                        }\n                        if (slt8((int8_t) 0, flag_17971)) {\n                            bool eta_p_18005 = aggr_17963;\n                            int64_t eta_p_18006 = aggr_17964",
                                    ";\n                            int64_t eta_p_18007 = aggr_17965;\n                            int64_t eta_p_18008 = aggr_17966;\n                            bool eta_p_18009 = aggr_17967;\n                            int64_t eta_p_18010 = aggr_17968;\n                            int64_t eta_p_18011 = aggr_17969;\n                            int64_t eta_p_18012 = aggr_17970;\n                            bool eta_p_18013 = prefix_17950;\n                            int64_t eta_p_18014 = prefix_17951;\n                            int64_t eta_p_18015 = prefix_17952;\n                            int64_t eta_p_18016 = prefix_17953;\n                            bool eta_p_18017 = prefix_17954;\n                            int64_t eta_p_18018 = prefix_17955;\n                            int64_t eta_p_18019 = prefix_17956;\n                            int64_t eta_p_18020 = prefix_17957;\n                            bool tmp_18021 = eta_p_18005 || eta_p_18013;\n                            int64_t tmp_18022;\n                            int64_t tmp_18023;\n                            int64_t tmp_18024;\n                            \n                            if (eta_p_18013) {\n                                tmp_18022 = eta_p_18014;\n                                tmp_18023 = eta_p_18015;\n                                tmp_18024 = eta_p_18016;\n                            } else {\n                                int64_t tmp_18025 = add64(eta_p_18006, eta_p_18014);\n                                int64_t tmp_18026 = add64(eta_p_18007, eta_p_18015);\n                                int64_t tmp_18027 = add64(eta_p_18008, eta_p_18016);\n                                \n                                tmp_18022 = tmp_18025;\n                                tmp_18023 = tmp_18026;\n                                tmp_18024 = tmp_18027;\n                            }\n                            \n                            bool tmp_18028 = eta_p_18009 || eta_p_18017;\n                            int64_t tmp_", "18029;\n                            int64_t tmp_18030;\n                            int64_t tmp_18031;\n                            \n                            if (eta_p_18017) {\n                                tmp_18029 = eta_p_18018;\n                                tmp_18030 = eta_p_18019;\n                                tmp_18031 = eta_p_18020;\n                            } else {\n                                int64_t tmp_18032 = add64(eta_p_18010, eta_p_18018);\n                                int64_t tmp_18033 = add64(eta_p_18011, eta_p_18019);\n                                int64_t tmp_18034 = add64(eta_p_18012, eta_p_18020);\n                                \n                                tmp_18029 = tmp_18032;\n                                tmp_18030 = tmp_18033;\n                                tmp_18031 = tmp_18034;\n                            }\n                            prefix_17950 = tmp_18021;\n                            prefix_17951 = tmp_18022;\n                            prefix_17952 = tmp_18023;\n                            prefix_17953 = tmp_18024;\n                            prefix_17954 = tmp_18028;\n                            prefix_17955 = tmp_18029;\n                            prefix_17956 = tmp_18030;\n                            prefix_17957 = tmp_18031;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_17741 == 0) {\n                    if (boundary_17796 == sext_i64_i32(segscan_tblock_sizze_16720 * chunk_sizze_17701)) {\n                        bool eta_p_18035 = prefix_17950;\n                        int64_t eta_p_18036 = prefix_17951;\n                        int64_t eta_p_18037 = prefix_17952;\n                        int64_t eta_p_18038 = prefix_17953;\n                        bool eta_p_18039 = prefix_17954;\n                        int64_t eta_p_18040 = prefix_17955;\n                        int64_t eta_p_18041 = prefix_17956;\n                        int", "64_t eta_p_18042 = prefix_17957;\n                        bool eta_p_18043 = acc_17906;\n                        int64_t eta_p_18044 = acc_17907;\n                        int64_t eta_p_18045 = acc_17908;\n                        int64_t eta_p_18046 = acc_17909;\n                        bool eta_p_18047 = acc_17910;\n                        int64_t eta_p_18048 = acc_17911;\n                        int64_t eta_p_18049 = acc_17912;\n                        int64_t eta_p_18050 = acc_17913;\n                        bool tmp_18051 = eta_p_18035 || eta_p_18043;\n                        int64_t tmp_18052;\n                        int64_t tmp_18053;\n                        int64_t tmp_18054;\n                        \n                        if (eta_p_18043) {\n                            tmp_18052 = eta_p_18044;\n                            tmp_18053 = eta_p_18045;\n                            tmp_18054 = eta_p_18046;\n                        } else {\n                            int64_t tmp_18055 = add64(eta_p_18036, eta_p_18044);\n                            int64_t tmp_18056 = add64(eta_p_18037, eta_p_18045);\n                            int64_t tmp_18057 = add64(eta_p_18038, eta_p_18046);\n                            \n                            tmp_18052 = tmp_18055;\n                            tmp_18053 = tmp_18056;\n                            tmp_18054 = tmp_18057;\n                        }\n                        \n                        bool tmp_18058 = eta_p_18039 || eta_p_18047;\n                        int64_t tmp_18059;\n                        int64_t tmp_18060;\n                        int64_t tmp_18061;\n                        \n                        if (eta_p_18047) {\n                            tmp_18059 = eta_p_18048;\n                            tmp_18060 = eta_p_18049;\n                            tmp_18061 = eta_p_18050;\n                        } else {\n                            int64_t tmp_18062 = add64(eta_p_18040, eta_p_18048);\n                            int64_t tmp_1806",
                                    "3 = add64(eta_p_18041, eta_p_18049);\n                            int64_t tmp_18064 = add64(eta_p_18042, eta_p_18050);\n                            \n                            tmp_18059 = tmp_18062;\n                            tmp_18060 = tmp_18063;\n                            tmp_18061 = tmp_18064;\n                        }\n                        ((volatile __global bool *) incprefixes_mem_17708)[dynamic_id_17793] = tmp_18051;\n                        ((volatile __global int64_t *) incprefixes_mem_17712)[dynamic_id_17793] = tmp_18052;\n                        ((volatile __global int64_t *) incprefixes_mem_17716)[dynamic_id_17793] = tmp_18053;\n                        ((volatile __global int64_t *) incprefixes_mem_17720)[dynamic_id_17793] = tmp_18054;\n                        ((volatile __global bool *) incprefixes_mem_17724)[dynamic_id_17793] = tmp_18058;\n                        ((volatile __global int64_t *) incprefixes_mem_17728)[dynamic_id_17793] = tmp_18059;\n                        ((volatile __global int64_t *) incprefixes_mem_17732)[dynamic_id_17793] = tmp_18060;\n                        ((volatile __global int64_t *) incprefixes_mem_17736)[dynamic_id_17793] = tmp_18061;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_17704)[dynamic_id_17793] = (int8_t) 2;\n                    }\n                    ((__local bool *) local_mem_17762)[(int64_t) 32] = prefix_17950;\n                    ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17754, (int64_t) 8)] = prefix_17951;\n                    ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17755, (int64_t) 8)] = prefix_17952;\n                    ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17756, (int64_t) 8)] = prefix_17953;\n                    ((__local bool *) local_mem_17762)[warp_byte_offset_17757] = prefix_17954;\n                    ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17758, (i", "nt64_t) 8)] = prefix_17955;\n                    ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17759, (int64_t) 8)] = prefix_17956;\n                    ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17760, (int64_t) 8)] = prefix_17957;\n                    acc_17906 = 0;\n                    acc_17907 = (int64_t) 0;\n                    acc_17908 = (int64_t) 0;\n                    acc_17909 = (int64_t) 0;\n                    acc_17910 = 0;\n                    acc_17911 = (int64_t) 0;\n                    acc_17912 = (int64_t) 0;\n                    acc_17913 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_17793 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_17950 = ((__local bool *) local_mem_17762)[(int64_t) 32];\n                prefix_17951 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17754, (int64_t) 8)];\n                prefix_17952 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17755, (int64_t) 8)];\n                prefix_17953 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17756, (int64_t) 8)];\n                prefix_17954 = ((__local bool *) local_mem_17762)[warp_byte_offset_17757];\n                prefix_17955 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17758, (int64_t) 8)];\n                prefix_17956 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17759, (int64_t) 8)];\n                prefix_17957 = ((__local int64_t *) local_mem_17762)[squot64(warp_byte_offset_17760, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            bool eta_p_18065;\n            bool eta_p_18073;\n            bool eta_p_18095 = prefix_17950;\n            bool eta_p_18103 = acc_17906;\n            int64_t eta_p_18066;\n            int64_t eta_p_18074;\n            int64_t eta_p_18096 = prefix_17951;\n            int64_t e", "ta_p_18104 = acc_17907;\n            int64_t eta_p_18067;\n            int64_t eta_p_18075;\n            int64_t eta_p_18097 = prefix_17952;\n            int64_t eta_p_18105 = acc_17908;\n            int64_t eta_p_18068;\n            int64_t eta_p_18076;\n            int64_t eta_p_18098 = prefix_17953;\n            int64_t eta_p_18106 = acc_17909;\n            bool eta_p_18069;\n            bool eta_p_18077;\n            bool eta_p_18099 = prefix_17954;\n            bool eta_p_18107 = acc_17910;\n            int64_t eta_p_18070;\n            int64_t eta_p_18078;\n            int64_t eta_p_18100 = prefix_17955;\n            int64_t eta_p_18108 = acc_17911;\n            int64_t eta_p_18071;\n            int64_t eta_p_18079;\n            int64_t eta_p_18101 = prefix_17956;\n            int64_t eta_p_18109 = acc_17912;\n            int64_t eta_p_18072;\n            int64_t eta_p_18080;\n            int64_t eta_p_18102 = prefix_17957;\n            int64_t eta_p_18110 = acc_17913;\n            \n            if (slt32(local_tid_17741 * chunk_sizze_32b_17745, boundary_17796) && !block_new_sgm_17958) {\n                bool tmp_18111 = eta_p_18095 || eta_p_18103;\n                int64_t tmp_18112;\n                int64_t tmp_18113;\n                int64_t tmp_18114;\n                \n                if (eta_p_18103) {\n                    tmp_18112 = eta_p_18104;\n                    tmp_18113 = eta_p_18105;\n                    tmp_18114 = eta_p_18106;\n                } else {\n                    int64_t tmp_18115 = add64(eta_p_18096, eta_p_18104);\n                    int64_t tmp_18116 = add64(eta_p_18097, eta_p_18105);\n                    int64_t tmp_18117 = add64(eta_p_18098, eta_p_18106);\n                    \n                    tmp_18112 = tmp_18115;\n                    tmp_18113 = tmp_18116;\n                    tmp_18114 = tmp_18117;\n                }\n                \n                bool tmp_18118 = eta_p_18099 || eta_p_18107;\n                int64_t tmp_18119;\n                int64_t tmp_18120;\n  ",
                                    "              int64_t tmp_18121;\n                \n                if (eta_p_18107) {\n                    tmp_18119 = eta_p_18108;\n                    tmp_18120 = eta_p_18109;\n                    tmp_18121 = eta_p_18110;\n                } else {\n                    int64_t tmp_18122 = add64(eta_p_18100, eta_p_18108);\n                    int64_t tmp_18123 = add64(eta_p_18101, eta_p_18109);\n                    int64_t tmp_18124 = add64(eta_p_18102, eta_p_18110);\n                    \n                    tmp_18119 = tmp_18122;\n                    tmp_18120 = tmp_18123;\n                    tmp_18121 = tmp_18124;\n                }\n                eta_p_18065 = tmp_18111;\n                eta_p_18066 = tmp_18112;\n                eta_p_18067 = tmp_18113;\n                eta_p_18068 = tmp_18114;\n                eta_p_18069 = tmp_18118;\n                eta_p_18070 = tmp_18119;\n                eta_p_18071 = tmp_18120;\n                eta_p_18072 = tmp_18121;\n            } else {\n                eta_p_18065 = acc_17906;\n                eta_p_18066 = acc_17907;\n                eta_p_18067 = acc_17908;\n                eta_p_18068 = acc_17909;\n                eta_p_18069 = acc_17910;\n                eta_p_18070 = acc_17911;\n                eta_p_18071 = acc_17912;\n                eta_p_18072 = acc_17913;\n            }\n            \n            int32_t stopping_point_18125 = segsizze_compact_17797 - srem32(local_tid_17741 * chunk_sizze_32b_17745 - 1 + segsizze_compact_17797 - boundary_17796, segsizze_compact_17797);\n            \n            for (int64_t i_18126 = 0; i_18126 < chunk_sizze_17701; i_18126++) {\n                if (slt32(sext_i64_i32(i_18126), stopping_point_18125 - 1)) {\n                    eta_p_18073 = private_mem_17798[i_18126];\n                    eta_p_18074 = private_mem_17800[i_18126];\n                    eta_p_18075 = private_mem_17802[i_18126];\n                    eta_p_18076 = private_mem_17804[i_18126];\n                    eta_p_18077 = private_mem_17806[i_1812", "6];\n                    eta_p_18078 = private_mem_17808[i_18126];\n                    eta_p_18079 = private_mem_17810[i_18126];\n                    eta_p_18080 = private_mem_17812[i_18126];\n                    \n                    bool tmp_18081 = eta_p_18065 || eta_p_18073;\n                    int64_t tmp_18082;\n                    int64_t tmp_18083;\n                    int64_t tmp_18084;\n                    \n                    if (eta_p_18073) {\n                        tmp_18082 = eta_p_18074;\n                        tmp_18083 = eta_p_18075;\n                        tmp_18084 = eta_p_18076;\n                    } else {\n                        int64_t tmp_18085 = add64(eta_p_18066, eta_p_18074);\n                        int64_t tmp_18086 = add64(eta_p_18067, eta_p_18075);\n                        int64_t tmp_18087 = add64(eta_p_18068, eta_p_18076);\n                        \n                        tmp_18082 = tmp_18085;\n                        tmp_18083 = tmp_18086;\n                        tmp_18084 = tmp_18087;\n                    }\n                    \n                    bool tmp_18088 = eta_p_18069 || eta_p_18077;\n                    int64_t tmp_18089;\n                    int64_t tmp_18090;\n                    int64_t tmp_18091;\n                    \n                    if (eta_p_18077) {\n                        tmp_18089 = eta_p_18078;\n                        tmp_18090 = eta_p_18079;\n                        tmp_18091 = eta_p_18080;\n                    } else {\n                        int64_t tmp_18092 = add64(eta_p_18070, eta_p_18078);\n                        int64_t tmp_18093 = add64(eta_p_18071, eta_p_18079);\n                        int64_t tmp_18094 = add64(eta_p_18072, eta_p_18080);\n                        \n                        tmp_18089 = tmp_18092;\n                        tmp_18090 = tmp_18093;\n                        tmp_18091 = tmp_18094;\n                    }\n                    private_mem_17798[i_18126] = tmp_18081;\n                    private_mem_17", "800[i_18126] = tmp_18082;\n                    private_mem_17802[i_18126] = tmp_18083;\n                    private_mem_17804[i_18126] = tmp_18084;\n                    private_mem_17806[i_18126] = tmp_18088;\n                    private_mem_17808[i_18126] = tmp_18089;\n                    private_mem_17810[i_18126] = tmp_18090;\n                    private_mem_17812[i_18126] = tmp_18091;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_18127 = 0; i_18127 < chunk_sizze_17701; i_18127++) {\n                int64_t sharedIdx_18128 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_18127;\n                bool tmp_18129 = private_mem_17798[i_18127];\n                \n                ((__local bool *) local_mem_17762)[sharedIdx_18128] = tmp_18129;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18130 = 0; i_18130 < chunk_sizze_17701; i_18130++) {\n                int64_t flat_idx_18131 = thd_offset_17814 + i_18130 * segscan_tblock_sizze_16720;\n                int64_t slice_18132 = idxs_14149;\n                int64_t gtid_16724 = flat_idx_18131;\n                int64_t remnant_18133 = flat_idx_18131 - gtid_16724;\n                \n                if (slt64(flat_idx_18131, idxs_14149)) {\n                    bool tmp_18134 = ((__local bool *) local_mem_17762)[flat_idx_18131 - block_offset_17794];\n                    \n                    ((__global bool *) mem_17001)[gtid_16724] = tmp_18134;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18135 = 0; i_18135 < chunk_sizze_17701; i_18135++) {\n                int64_t sharedIdx_18136 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_18135;\n                int64_t tmp_18137 = private_mem_17800[i_18135];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_18136] = tmp_18137;\n            }\n            ba",
                                    "rrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18138 = 0; i_18138 < chunk_sizze_17701; i_18138++) {\n                int64_t flat_idx_18139 = thd_offset_17814 + i_18138 * segscan_tblock_sizze_16720;\n                int64_t slice_18140 = idxs_14149;\n                int64_t gtid_16724 = flat_idx_18139;\n                int64_t remnant_18141 = flat_idx_18139 - gtid_16724;\n                \n                if (slt64(flat_idx_18139, idxs_14149)) {\n                    int64_t tmp_18142 = ((__local int64_t *) local_mem_17762)[flat_idx_18139 - block_offset_17794];\n                    \n                    ((__global int64_t *) mem_17003)[gtid_16724] = tmp_18142;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18143 = 0; i_18143 < chunk_sizze_17701; i_18143++) {\n                int64_t sharedIdx_18144 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_18143;\n                int64_t tmp_18145 = private_mem_17802[i_18143];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_18144] = tmp_18145;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18146 = 0; i_18146 < chunk_sizze_17701; i_18146++) {\n                int64_t flat_idx_18147 = thd_offset_17814 + i_18146 * segscan_tblock_sizze_16720;\n                int64_t slice_18148 = idxs_14149;\n                int64_t gtid_16724 = flat_idx_18147;\n                int64_t remnant_18149 = flat_idx_18147 - gtid_16724;\n                \n                if (slt64(flat_idx_18147, idxs_14149)) {\n                    int64_t tmp_18150 = ((__local int64_t *) local_mem_17762)[flat_idx_18147 - block_offset_17794];\n                    \n                    ((__global int64_t *) mem_17005)[gtid_16724] = tmp_18150;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18151 = 0; i_18151 < chunk_sizze_17701; i_18151++) {\n                int64_t sharedIdx_18152 = sext_i32_i64(local_t", "id_17741) * chunk_sizze_17701 + i_18151;\n                int64_t tmp_18153 = private_mem_17804[i_18151];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_18152] = tmp_18153;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18154 = 0; i_18154 < chunk_sizze_17701; i_18154++) {\n                int64_t flat_idx_18155 = thd_offset_17814 + i_18154 * segscan_tblock_sizze_16720;\n                int64_t slice_18156 = idxs_14149;\n                int64_t gtid_16724 = flat_idx_18155;\n                int64_t remnant_18157 = flat_idx_18155 - gtid_16724;\n                \n                if (slt64(flat_idx_18155, idxs_14149)) {\n                    int64_t tmp_18158 = ((__local int64_t *) local_mem_17762)[flat_idx_18155 - block_offset_17794];\n                    \n                    ((__global int64_t *) mem_17007)[gtid_16724] = tmp_18158;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18159 = 0; i_18159 < chunk_sizze_17701; i_18159++) {\n                int64_t sharedIdx_18160 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_18159;\n                bool tmp_18161 = private_mem_17806[i_18159];\n                \n                ((__local bool *) local_mem_17762)[sharedIdx_18160] = tmp_18161;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18162 = 0; i_18162 < chunk_sizze_17701; i_18162++) {\n                int64_t flat_idx_18163 = thd_offset_17814 + i_18162 * segscan_tblock_sizze_16720;\n                int64_t slice_18164 = idxs_14149;\n                int64_t gtid_16724 = flat_idx_18163;\n                int64_t remnant_18165 = flat_idx_18163 - gtid_16724;\n                \n                if (slt64(flat_idx_18163, idxs_14149)) {\n                    bool tmp_18166 = ((__local bool *) local_mem_17762)[flat_idx_18163 - block_offset_17794];\n                    \n                    ((__global bool *) mem_17008)[gtid_16724] = tmp_1816", "6;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18167 = 0; i_18167 < chunk_sizze_17701; i_18167++) {\n                int64_t sharedIdx_18168 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_18167;\n                int64_t tmp_18169 = private_mem_17808[i_18167];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_18168] = tmp_18169;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18170 = 0; i_18170 < chunk_sizze_17701; i_18170++) {\n                int64_t flat_idx_18171 = thd_offset_17814 + i_18170 * segscan_tblock_sizze_16720;\n                int64_t slice_18172 = idxs_14149;\n                int64_t gtid_16724 = flat_idx_18171;\n                int64_t remnant_18173 = flat_idx_18171 - gtid_16724;\n                \n                if (slt64(flat_idx_18171, idxs_14149)) {\n                    int64_t tmp_18174 = ((__local int64_t *) local_mem_17762)[flat_idx_18171 - block_offset_17794];\n                    \n                    ((__global int64_t *) mem_17010)[gtid_16724] = tmp_18174;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18175 = 0; i_18175 < chunk_sizze_17701; i_18175++) {\n                int64_t sharedIdx_18176 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_18175;\n                int64_t tmp_18177 = private_mem_17810[i_18175];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_18176] = tmp_18177;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18178 = 0; i_18178 < chunk_sizze_17701; i_18178++) {\n                int64_t flat_idx_18179 = thd_offset_17814 + i_18178 * segscan_tblock_sizze_16720;\n                int64_t slice_18180 = idxs_14149;\n                int64_t gtid_16724 = flat_idx_18179;\n                int64_t remnant_18181 = flat_idx_18179 - gtid_16724;\n                \n                if (slt64(flat_idx_",
                                    "18179, idxs_14149)) {\n                    int64_t tmp_18182 = ((__local int64_t *) local_mem_17762)[flat_idx_18179 - block_offset_17794];\n                    \n                    ((__global int64_t *) mem_17012)[gtid_16724] = tmp_18182;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18183 = 0; i_18183 < chunk_sizze_17701; i_18183++) {\n                int64_t sharedIdx_18184 = sext_i32_i64(local_tid_17741) * chunk_sizze_17701 + i_18183;\n                int64_t tmp_18185 = private_mem_17812[i_18183];\n                \n                ((__local int64_t *) local_mem_17762)[sharedIdx_18184] = tmp_18185;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18186 = 0; i_18186 < chunk_sizze_17701; i_18186++) {\n                int64_t flat_idx_18187 = thd_offset_17814 + i_18186 * segscan_tblock_sizze_16720;\n                int64_t slice_18188 = idxs_14149;\n                int64_t gtid_16724 = flat_idx_18187;\n                int64_t remnant_18189 = flat_idx_18187 - gtid_16724;\n                \n                if (slt64(flat_idx_18187, idxs_14149)) {\n                    int64_t tmp_18190 = ((__local int64_t *) local_mem_17762)[flat_idx_18187 - block_offset_17794];\n                    \n                    ((__global int64_t *) mem_17014)[gtid_16724] = tmp_18190;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16720\n    #undef chunk_sizze_17701\n}\nFUTHARK_KERNEL_SIZED(mainzisegscan_16858_dim1, 1, 1)\nvoid mainzisegscan_16858(__global int *global_failure, int64_t loop_dz2085U_14130, int64_t dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, int64_t num_tblocks_16855, int64_t num_virt_blocks_18225, int64_t num_virt_threads_18226, __global unsigned char *mem_17058, __global unsigned char *mem_17069, __global unsigned char *mem_17071, __global unsigned char *status_flags_mem_18227, __global unsigned char *aggregates_", "mem_18229, __global unsigned char *incprefixes_mem_18231, __global unsigned char *global_dynid_mem_18233)\n{\n    #define segscan_tblock_sizze_16853 (mainzisegscan_16858zisegscan_tblock_sizze_16853)\n    #define chunk_sizze_18224 (mainzisegscan_16858zichunk_sizze_18224)\n    \n    volatile __local unsigned char *local_mem_18243_backing_0 = &shared_mem[0];\n    const int64_t local_mem_18243_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16853), chunk_sizze_18224 * segscan_tblock_sizze_16853 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16853), chunk_sizze_18224 * segscan_tblock_sizze_16853 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18236;\n    int32_t tblock_sizze_18239;\n    int32_t wave_sizze_18238;\n    int32_t block_id_18237;\n    int32_t global_tid_18235;\n    int64_t phys_tid_16858;\n    int32_t chunk_sizze_32b_18240;\n    int64_t byte_offsets_18241;\n    int64_t warp_byte_offset_18242;\n    __local unsigned char *local_mem_18243;\n    int64_t trans_arr_len_18244;\n    int64_t phys_block_id_18250;\n    int64_t virtloop_bound_18251;\n    \n    local_tid_18236 = get_local_id(0);\n    tblock_sizze_18239 = get_local_size(0);\n    wave_sizze_18238 = LOCKSTEP_WIDTH;\n    block_id_18237 = get_tblock_id(0);\n    global_tid_18235 = block_id_18237 * tblock_sizze_18239 + local_tid_18236;\n    phys_tid_16858 = sext_i32_i64(global_tid_18235);\n    chunk_sizze_32b_18240 = sext_i64_i32(chunk_sizze_18224);\n    byte_offsets_18241 = segscan_tblock_sizze_16853 * (int64_t) 8;\n    warp_byte_offset_18242 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_18243 = (__local unsigned char *) local_mem_18243_backing_0;\n    trans_arr_len_18244 = chunk_sizze_18224 * segscan_tblock_sizze_16853;\n    phys_block_id_18250 = get_tblock_id(0);\n    virtloop_bound_18251 = sdiv_up64(num_virt_blocks_18225 - phys_block_", "id_18250, num_tblocks_16855);\n    for (int64_t virtloop_i_18252 = 0; virtloop_i_18252 < virtloop_bound_18251; virtloop_i_18252++) {\n        int64_t dynamic_id_18253;\n        int64_t block_offset_18254;\n        int64_t sgm_idx_18255;\n        int32_t boundary_18256;\n        int32_t segsizze_compact_18257;\n        int64_t private_mem_18258[chunk_sizze_18224];\n        int64_t thd_offset_18260;\n        int64_t acc_18276;\n        int64_t prefix_18286;\n        bool block_new_sgm_18287;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_18236 == 0) {\n                dynamic_id_18253 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_18233)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_18243)[(int64_t) 0] = dynamic_id_18253;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_18253 == num_virt_blocks_18225 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_18233)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_18253 = ((__local int32_t *) local_mem_18243)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_18254 = dynamic_id_18253 * chunk_sizze_18224 * segscan_tblock_sizze_16853;\n        sgm_idx_18255 = smod64(block_offset_18254, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136);\n        boundary_18256 = sext_i64_i32(smin64(chunk_sizze_18224 * segscan_tblock_sizze_16853, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136 - sgm_idx_18255));\n        segsizze_compact_18257 = sext_i64_i32(smin64(chunk_sizze_18224 * segscan_tblock_sizze_16853, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136));\n        thd_offset_18260 = block_offset_18254 + sext_i32_i64(local_tid_18236);\n        // Load and map\n        {\n        ",
                                    "    for (int64_t i_18261 = 0; i_18261 < chunk_sizze_18224; i_18261++) {\n                int64_t virt_tid_18262 = thd_offset_18260 + i_18261 * segscan_tblock_sizze_16853;\n                int64_t slice_18263 = dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136;\n                int64_t gtid_16857 = virt_tid_18262;\n                int64_t remnant_18264 = virt_tid_18262 - gtid_16857;\n                \n                if (slt64(virt_tid_18262, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136)) {\n                    int64_t new_index_16929 = squot64(gtid_16857, (int64_t) 2);\n                    int64_t binop_y_16931 = (int64_t) 2 * new_index_16929;\n                    int64_t new_index_16932 = gtid_16857 - binop_y_16931;\n                    int64_t eta_p_14643 = ((__global int64_t *) mem_17058)[new_index_16929 + new_index_16932 * loop_dz2085U_14130];\n                    bool lifted_lambda_res_14644 = slt64((int64_t) 1, eta_p_14643);\n                    int64_t defunc_0_f_res_14645 = btoi_bool_i64(lifted_lambda_res_14644);\n                    \n                    ((__global int64_t *) mem_17071)[gtid_16857] = defunc_0_f_res_14645;\n                    private_mem_18258[i_18261] = defunc_0_f_res_14645;\n                } else {\n                    private_mem_18258[i_18261] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_18265 = 0; i_18265 < chunk_sizze_18224; i_18265++) {\n                int64_t sharedIdx_18266 = sext_i32_i64(local_tid_18236) + i_18265 * segscan_tblock_sizze_16853;\n                int64_t tmp_18267 = private_mem_18258[i_18265];\n                \n                ((__local int64_t *) local_mem_18243)[sharedIdx_18266] = tmp_18267;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18268 = 0; i_18268 < chunk_sizze_18224; i_18268++) {\n                int64_t sharedIdx_18269 = sext_i32_i64(local_tid_18236) * chunk_sizze_18224 + i_18268;\n           ", "     int64_t tmp_18270 = ((__local int64_t *) local_mem_18243)[sharedIdx_18269];\n                \n                private_mem_18258[i_18268] = tmp_18270;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_18271 = 0; i_18271 < chunk_sizze_18224 - (int64_t) 1; i_18271++) {\n                int64_t eta_p_14318;\n                int64_t eta_p_14319;\n                \n                eta_p_14318 = private_mem_18258[i_18271];\n                eta_p_14319 = private_mem_18258[i_18271 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_14320 = add64(eta_p_14318, eta_p_14319);\n                \n                private_mem_18258[i_18271 + (int64_t) 1] = defunc_0_op_res_14320;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_18272 = private_mem_18258[chunk_sizze_18224 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)] = tmp_18272;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_18273;\n            int64_t eta_p_18274;\n            int64_t eta_p_18277;\n            int64_t eta_p_18278;\n            bool ltid_in_bounds_18280 = slt64(sext_i32_i64(local_tid_18236), num_virt_threads_18226);\n            int32_t skip_threads_18281;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_18280) {\n                    eta_p_18274 = ((volatile __local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)];\n                    if ((local_tid_18236 - squot32(local_tid_18236, 32) * 32) == 0) {\n                        eta_p_18273 = eta_p_18274;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_18281 = 1;\n                while (slt32(skip_threads_18281, 32)", ") {\n                    bool thread_active_18282 = sle32(skip_threads_18281, local_tid_18236 - squot32(local_tid_18236, 32) * 32) && ltid_in_bounds_18280;\n                    \n                    if (thread_active_18282) {\n                        // read operands\n                        {\n                            eta_p_18273 = ((volatile __local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236) - sext_i32_i64(skip_threads_18281)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_18282) {\n                            int64_t defunc_0_op_res_18275 = add64(eta_p_18273, eta_p_18274);\n                            \n                            eta_p_18273 = defunc_0_op_res_18275;\n                        }\n                    }\n                    if (sle32(wave_sizze_18238, skip_threads_18281)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_18282) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)] = eta_p_18273;\n                            eta_p_18274 = eta_p_18273;\n                        }\n                    }\n                    if (sle32(wave_sizze_18238, skip_threads_18281)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_18281 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_18236 - squot32(local_tid_18236, 32) * 32) == 31 && ltid_in_bounds_18280) {\n                    ((volatile __local int64_t *) local_mem_18243)[sext_i32_i64(squot32(local_tid_18236, 32))] = eta_p_18273;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            //",
                                    " scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_18283;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_18236, 32) == 0 && ltid_in_bounds_18280) {\n                        eta_p_18278 = ((volatile __local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)];\n                        if ((local_tid_18236 - squot32(local_tid_18236, 32) * 32) == 0) {\n                            eta_p_18277 = eta_p_18278;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_18283 = 1;\n                    while (slt32(skip_threads_18283, 32)) {\n                        bool thread_active_18284 = sle32(skip_threads_18283, local_tid_18236 - squot32(local_tid_18236, 32) * 32) && (squot32(local_tid_18236, 32) == 0 && ltid_in_bounds_18280);\n                        \n                        if (thread_active_18284) {\n                            // read operands\n                            {\n                                eta_p_18277 = ((volatile __local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236) - sext_i32_i64(skip_threads_18283)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_18284) {\n                                int64_t defunc_0_op_res_18279 = add64(eta_p_18277, eta_p_18278);\n                                \n                                eta_p_18277 = defunc_0_op_res_18279;\n                            }\n                        }\n                        if (sle32(wave_sizze_18238, skip_threads_18283)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_18284) {\n                            ", "// write result\n                            {\n                                ((volatile __local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)] = eta_p_18277;\n                                eta_p_18278 = eta_p_18277;\n                            }\n                        }\n                        if (sle32(wave_sizze_18238, skip_threads_18283)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_18283 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_18285 = squot32(local_tid_18236, 32) == 0 || !ltid_in_bounds_18280;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_18285) {\n                        eta_p_18274 = eta_p_18273;\n                        eta_p_18273 = ((__local int64_t *) local_mem_18243)[sext_i32_i64(squot32(local_tid_18236, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_18285) {\n                        int64_t defunc_0_op_res_18275 = add64(eta_p_18273, eta_p_18274);\n                        \n                        eta_p_18273 = defunc_0_op_res_18275;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_18285) {\n                        ((__local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)] = eta_p_18273;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_18236, 32) == 0 && ltid_in_bounds_18280) {\n                    ((__local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)] = eta_p_18274;\n                }\n", "            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_18236 == 0) {\n                acc_18276 = ((__local int64_t *) local_mem_18243)[segscan_tblock_sizze_16853 - (int64_t) 1];\n            } else {\n                acc_18276 = ((__local int64_t *) local_mem_18243)[sext_i32_i64(local_tid_18236) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_18286 = (int64_t) 0;\n        block_new_sgm_18287 = sgm_idx_18255 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_18287 && local_tid_18236 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_18231)[dynamic_id_18253] = acc_18276;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_18227)[dynamic_id_18253] = (int8_t) 2;\n                acc_18276 = (int64_t) 0;\n            }\n            if (!block_new_sgm_18287 && slt32(local_tid_18236, wave_sizze_18238)) {\n                if (local_tid_18236 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_18229)[dynamic_id_18253] = acc_18276;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_18227)[dynamic_id_18253] = (int8_t) 1;\n                    \n                    int8_t tmp_18288 = ((volatile __global int8_t *) status_flags_mem_18227)[dynamic_id_18253 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_18243)[(int64_t) 0] = tmp_18288;\n                }\n                mem_fence_local();\n                \n                int8_t status_18289 = ((__local int8_t *) local_mem_18243)[(int64_t) 0];\n                \n                if (status_18289 == (int8_t) 2) {\n                    if (local_tid_18236 == 0) {\n                        prefix_18286 = ((volatile __global int64_t *) incprefixes_mem_18231)[dynamic_id_18253 - (int64_t) 1];\n                    }\n   ",
                                    "             } else {\n                    int32_t readOffset_18290 = sext_i64_i32(dynamic_id_18253 - sext_i32_i64(wave_sizze_18238));\n                    \n                    while (slt32(wave_sizze_18238 * -1, readOffset_18290)) {\n                        int32_t read_i_18291 = readOffset_18290 + local_tid_18236;\n                        int64_t aggr_18292 = (int64_t) 0;\n                        int8_t flag_18293 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_18291)) {\n                            flag_18293 = ((volatile __global int8_t *) status_flags_mem_18227)[sext_i32_i64(read_i_18291)];\n                            if (flag_18293 == (int8_t) 2) {\n                                aggr_18292 = ((volatile __global int64_t *) incprefixes_mem_18231)[sext_i32_i64(read_i_18291)];\n                            } else if (flag_18293 == (int8_t) 1) {\n                                aggr_18292 = ((volatile __global int64_t *) aggregates_mem_18229)[sext_i32_i64(read_i_18291)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_18243)[(int64_t) 4 + sext_i32_i64(local_tid_18236)] = aggr_18292;\n                        ((__local int8_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)] = flag_18293;\n                        flag_18293 = ((__local int8_t *) local_mem_18243)[sext_i32_i64(wave_sizze_18238) - (int64_t) 1];\n                        if (slt8(flag_18293, (int8_t) 2)) {\n                            int8_t flg_x_18297;\n                            int8_t flg_y_18298;\n                            int64_t eta_p_18294;\n                            int64_t eta_p_18295;\n                            int32_t skip_threads_18299;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_18298 = ((volatile __local int8_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)];\n                             ", "   eta_p_18295 = ((volatile __local int64_t *) local_mem_18243)[(int64_t) 4 + sext_i32_i64(local_tid_18236)];\n                                if ((local_tid_18236 - squot32(local_tid_18236, 32) * 32) == 0) {\n                                    eta_p_18294 = eta_p_18295;\n                                    flg_x_18297 = flg_y_18298;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_18299 = 1;\n                                while (slt32(skip_threads_18299, 32)) {\n                                    if (sle32(skip_threads_18299, local_tid_18236 - squot32(local_tid_18236, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_18297 = ((volatile __local int8_t *) local_mem_18243)[sext_i32_i64(local_tid_18236) - sext_i32_i64(skip_threads_18299)];\n                                            eta_p_18294 = ((volatile __local int64_t *) local_mem_18243)[(int64_t) 4 + (sext_i32_i64(local_tid_18236) - sext_i32_i64(skip_threads_18299))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_18298 == (int8_t) 2 || flg_y_18298 == (int8_t) 0) {\n                                                flg_x_18297 = flg_y_18298;\n                                                eta_p_18294 = eta_p_18295;\n                                            } else {\n                                                int64_t defunc_0_op_res_18296 = add64(eta_p_18294, eta_p_18295);\n                                                \n                                                eta_p_18294 = defunc_0_op_res_18296;\n                                            }\n                                        }", "\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_18243)[sext_i32_i64(local_tid_18236)] = flg_x_18297;\n                                            flg_y_18298 = flg_x_18297;\n                                            ((volatile __local int64_t *) local_mem_18243)[(int64_t) 4 + sext_i32_i64(local_tid_18236)] = eta_p_18294;\n                                            eta_p_18295 = eta_p_18294;\n                                        }\n                                    }\n                                    skip_threads_18299 *= 2;\n                                }\n                            }\n                        }\n                        flag_18293 = ((__local int8_t *) local_mem_18243)[sext_i32_i64(wave_sizze_18238) - (int64_t) 1];\n                        aggr_18292 = ((__local int64_t *) local_mem_18243)[(int64_t) 4 + (sext_i32_i64(wave_sizze_18238) - (int64_t) 1)];\n                        if (flag_18293 == (int8_t) 2) {\n                            readOffset_18290 = wave_sizze_18238 * -1;\n                        } else if (flag_18293 == (int8_t) 1) {\n                            readOffset_18290 -= wave_sizze_18238;\n                        }\n                        if (slt8((int8_t) 0, flag_18293)) {\n                            int64_t eta_p_18300 = aggr_18292;\n                            int64_t eta_p_18301 = prefix_18286;\n                            int64_t defunc_0_op_res_18302 = add64(eta_p_18300, eta_p_18301);\n                            \n                            prefix_18286 = defunc_0_op_res_18302;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_18236 == 0) {\n                    if (boundary_18256 == sext_i64_i32(segscan_tblock_sizze_16853 * chunk_sizze_18224)) {\n                        int64_t eta_p_18303 = prefix_18286;\n        ",
                                    "                int64_t eta_p_18304 = acc_18276;\n                        int64_t defunc_0_op_res_18305 = add64(eta_p_18303, eta_p_18304);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_18231)[dynamic_id_18253] = defunc_0_op_res_18305;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_18227)[dynamic_id_18253] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_18243)[(int64_t) 4] = prefix_18286;\n                    acc_18276 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_18253 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_18286 = ((__local int64_t *) local_mem_18243)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_18306;\n            int64_t eta_p_18307;\n            int64_t eta_p_18309 = prefix_18286;\n            int64_t eta_p_18310 = acc_18276;\n            \n            if (slt32(local_tid_18236 * chunk_sizze_32b_18240, boundary_18256) && !block_new_sgm_18287) {\n                int64_t defunc_0_op_res_18311 = add64(eta_p_18309, eta_p_18310);\n                \n                eta_p_18306 = defunc_0_op_res_18311;\n            } else {\n                eta_p_18306 = acc_18276;\n            }\n            \n            int32_t stopping_point_18312 = segsizze_compact_18257 - srem32(local_tid_18236 * chunk_sizze_32b_18240 - 1 + segsizze_compact_18257 - boundary_18256, segsizze_compact_18257);\n            \n            for (int64_t i_18313 = 0; i_18313 < chunk_sizze_18224; i_18313++) {\n                if (slt32(sext_i64_i32(i_18313), stopping_point_18312 - 1)) {\n                    eta_p_18307 = private_mem_18258[i_18313];\n                    \n                    int64_t defunc_0_op_res_18308 = add64(eta_p_18306, eta_p_18307);\n                    \n                  ", "  private_mem_18258[i_18313] = defunc_0_op_res_18308;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_18314 = 0; i_18314 < chunk_sizze_18224; i_18314++) {\n                int64_t sharedIdx_18315 = sext_i32_i64(local_tid_18236) * chunk_sizze_18224 + i_18314;\n                int64_t tmp_18316 = private_mem_18258[i_18314];\n                \n                ((__local int64_t *) local_mem_18243)[sharedIdx_18315] = tmp_18316;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_18317 = 0; i_18317 < chunk_sizze_18224; i_18317++) {\n                int64_t flat_idx_18318 = thd_offset_18260 + i_18317 * segscan_tblock_sizze_16853;\n                int64_t slice_18319 = dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136;\n                int64_t gtid_16857 = flat_idx_18318;\n                int64_t remnant_18320 = flat_idx_18318 - gtid_16857;\n                \n                if (slt64(flat_idx_18318, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136)) {\n                    int64_t tmp_18321 = ((__local int64_t *) local_mem_18243)[flat_idx_18318 - block_offset_18254];\n                    \n                    ((__global int64_t *) mem_17069)[gtid_16857] = tmp_18321;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16853\n    #undef chunk_sizze_18224\n}\nFUTHARK_KERNEL_SIZED(replicated_iota_6108ziseghist_global_16574_dim1, 1, 1)\nvoid replicated_iota_6108ziseghist_global_16574(__global int *global_failure, int64_t n_9632, int64_t defunc_0_reduce_res_14478, int64_t num_tblocks_16569, int64_t num_subhistos_17297, int32_t chk_i_17367, int64_t hist_H_chk_17368, __global unsigned char *mem_16949, __global unsigned char *defunc_0_map_res_subhistos_mem_17298)\n{\n    #define seghist_tblock_sizze_16567 (replicated_iota_6108ziseghist_global_16574ziseghist_tblock_sizze_16567)\n    if (*gl", "obal_failure >= 0)\n        return;\n    \n    int32_t local_tid_17370;\n    int32_t tblock_sizze_17373;\n    int32_t wave_sizze_17372;\n    int32_t block_id_17371;\n    int32_t global_tid_17369;\n    int64_t phys_tid_16574;\n    int32_t subhisto_ind_17374;\n    int64_t num_chunks_17375;\n    \n    local_tid_17370 = get_local_id(0);\n    tblock_sizze_17373 = get_local_size(0);\n    wave_sizze_17372 = LOCKSTEP_WIDTH;\n    block_id_17371 = get_tblock_id(0);\n    global_tid_17369 = block_id_17371 * tblock_sizze_17373 + local_tid_17370;\n    phys_tid_16574 = sext_i32_i64(global_tid_17369);\n    subhisto_ind_17374 = squot32(global_tid_17369, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_16567 * num_tblocks_16569), sext_i64_i32(num_subhistos_17297)));\n    num_chunks_17375 = sdiv_up64(n_9632, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_16567 * num_tblocks_16569)));\n    for (int64_t chunk_i_17376 = 0; chunk_i_17376 < num_chunks_17375; chunk_i_17376++) {\n        int64_t i_17377 = chunk_i_17376 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_16567 * num_tblocks_16569)) + sext_i32_i64(global_tid_17369);\n        \n        if (slt64(i_17377, n_9632)) {\n            int64_t slice_17378;\n            int64_t gtid_16573;\n            int64_t remnant_17379;\n            \n            slice_17378 = n_9632;\n            gtid_16573 = i_17377;\n            remnant_17379 = i_17377 - gtid_16573;\n            if (slt64(i_17377, n_9632)) {\n                int64_t zv_lhs_16579;\n                int64_t tmp_16580;\n                bool cond_16582;\n                int64_t lifted_lambda_res_16583;\n                \n                zv_lhs_16579 = add64((int64_t) -1, gtid_16573);\n                tmp_16580 = smod64(zv_lhs_16579, n_9632);\n                cond_16582 = gtid_16573 == (int64_t) 0;\n                if (cond_16582) {\n                    lifted_lambda_res_16583 = (int64_t) 0;\n                } else {\n                    int64_t lifted_lambda_res_16581 = ((__global int64_t *) mem_16949)[tmp_16580];\n                   ",
                                    " \n                    lifted_lambda_res_16583 = lifted_lambda_res_16581;\n                }\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_17367) * hist_H_chk_17368, lifted_lambda_res_16583) && (slt64(lifted_lambda_res_16583, sext_i32_i64(chk_i_17367) * hist_H_chk_17368 + hist_H_chk_17368) && (sle64((int64_t) 0, lifted_lambda_res_16583) && slt64(lifted_lambda_res_16583, defunc_0_reduce_res_14478)))) {\n                        int64_t eta_p_16575;\n                        int64_t eta_p_16576 = gtid_16573;\n                        int64_t old_17380;\n                        \n                        old_17380 = atomic_smax_i64_global(&((volatile __global int64_t *) defunc_0_map_res_subhistos_mem_17298)[sext_i32_i64(subhisto_ind_17374) * defunc_0_reduce_res_14478 + lifted_lambda_res_16583], (int64_t) eta_p_16576);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_16567\n}\nFUTHARK_KERNEL_SIZED(replicated_iota_6108ziseghist_local_16574_dim1, 1, 1)\nvoid replicated_iota_6108ziseghist_local_16574(__global int *global_failure, int64_t n_9632, int64_t defunc_0_reduce_res_14478, int64_t num_subhistos_17297, int64_t num_tblocks_17308, int32_t hist_M_17314, int32_t chk_i_17318, int64_t num_segments_17319, int64_t hist_H_chk_17320, int64_t histo_sizze_17321, int32_t init_per_thread_17322, __global unsigned char *mem_16949, __global unsigned char *defunc_0_map_res_subhistos_mem_17298)\n{\n    #define max_tblock_sizze_17307 (replicated_iota_6108ziseghist_local_16574zimax_tblock_sizze_17307)\n    \n    volatile __local unsigned char *subhistogram_local_mem_17336_backing_0 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_17336_backing_0_offset = 0 + ((int64_t) 8 * (hist_M_17314 * hist_H_chk_17320) + srem64((int64_t) 8 - srem64((int64_t) 8 * (hist_M_17314 * hist_H_chk_17320), (int64_t) 8", "), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17324;\n    int32_t tblock_sizze_17327;\n    int32_t wave_sizze_17326;\n    int32_t block_id_17325;\n    int32_t global_tid_17323;\n    int64_t phys_tid_16574;\n    int32_t phys_tblock_id_17328;\n    int32_t iterations_17329;\n    \n    local_tid_17324 = get_local_id(0);\n    tblock_sizze_17327 = get_local_size(0);\n    wave_sizze_17326 = LOCKSTEP_WIDTH;\n    block_id_17325 = get_tblock_id(0);\n    global_tid_17323 = block_id_17325 * tblock_sizze_17327 + local_tid_17324;\n    phys_tid_16574 = sext_i32_i64(global_tid_17323);\n    phys_tblock_id_17328 = get_tblock_id(0);\n    iterations_17329 = sdiv_up32(sext_i64_i32(num_tblocks_17308 * num_segments_17319) - phys_tblock_id_17328, sext_i64_i32(num_tblocks_17308));\n    for (int32_t i_17330 = 0; i_17330 < iterations_17329; i_17330++) {\n        int32_t virt_tblock_id_17331;\n        int32_t flat_segment_id_17332;\n        int32_t gid_in_segment_17333;\n        int32_t pgtid_in_segment_17334;\n        int32_t threads_per_segment_17335;\n        __local unsigned char *subhistogram_local_mem_17336;\n        int32_t thread_local_subhisto_i_17338;\n        int64_t num_chunks_17345;\n        \n        virt_tblock_id_17331 = phys_tblock_id_17328 + i_17330 * sext_i64_i32(num_tblocks_17308);\n        flat_segment_id_17332 = squot32(virt_tblock_id_17331, sext_i64_i32(num_tblocks_17308));\n        gid_in_segment_17333 = srem32(virt_tblock_id_17331, sext_i64_i32(num_tblocks_17308));\n        pgtid_in_segment_17334 = gid_in_segment_17333 * sext_i64_i32(max_tblock_sizze_17307) + local_tid_17324;\n        threads_per_segment_17335 = sext_i64_i32(num_tblocks_17308 * max_tblock_sizze_17307);\n        subhistogram_local_mem_17336 = (__local unsigned char *) subhistogram_local_mem_17336_backing_0;\n        thread_local_subhisto_i_17338 = srem32(local_tid_17324, hist_M_17314);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_17339 = 0", "; local_i_17339 < init_per_thread_17322; local_i_17339++) {\n                int32_t j_17340 = local_i_17339 * sext_i64_i32(max_tblock_sizze_17307) + local_tid_17324;\n                int32_t j_offset_17341 = hist_M_17314 * sext_i64_i32(histo_sizze_17321) * gid_in_segment_17333 + j_17340;\n                int32_t local_subhisto_i_17342 = squot32(j_17340, sext_i64_i32(histo_sizze_17321));\n                int32_t global_subhisto_i_17343 = squot32(j_offset_17341, sext_i64_i32(histo_sizze_17321));\n                \n                if (slt32(j_17340, hist_M_17314 * sext_i64_i32(histo_sizze_17321))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_17343 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_17297)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_17340, sext_i64_i32(histo_sizze_17321))) + sext_i32_i64(chk_i_17318) * hist_H_chk_17320) && slt64(sext_i32_i64(srem32(j_17340, sext_i64_i32(histo_sizze_17321))) + sext_i32_i64(chk_i_17318) * hist_H_chk_17320, defunc_0_reduce_res_14478)))) {\n                            int64_t tmp_17344 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_17298)[sext_i32_i64(srem32(j_17340, sext_i64_i32(histo_sizze_17321))) + sext_i32_i64(chk_i_17318) * hist_H_chk_17320];\n                            \n                            ((__local int64_t *) subhistogram_local_mem_17336)[sext_i32_i64(local_subhisto_i_17342) * hist_H_chk_17320 + sext_i32_i64(srem32(j_17340, sext_i64_i32(histo_sizze_17321)))] = tmp_17344;\n                        } else {\n                            ((__local int64_t *) subhistogram_local_mem_17336)[sext_i32_i64(local_subhisto_i_17342) * hist_H_chk_17320 + sext_i32_i64(srem32(j_17340, sext_i64_i32(histo_sizze_17321)))] = (int64_t) 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        n",
                                    "um_chunks_17345 = sdiv_up64(n_9632, sext_i32_i64(threads_per_segment_17335));\n        for (int64_t chunk_i_17346 = 0; chunk_i_17346 < num_chunks_17345; chunk_i_17346++) {\n            int64_t i_17347 = chunk_i_17346 * sext_i32_i64(threads_per_segment_17335) + sext_i32_i64(pgtid_in_segment_17334);\n            \n            if (slt64(i_17347, n_9632)) {\n                int64_t gtid_16573;\n                int64_t zv_lhs_16579;\n                int64_t tmp_16580;\n                bool cond_16582;\n                int64_t lifted_lambda_res_16583;\n                \n                gtid_16573 = i_17347;\n                zv_lhs_16579 = add64((int64_t) -1, gtid_16573);\n                tmp_16580 = smod64(zv_lhs_16579, n_9632);\n                cond_16582 = gtid_16573 == (int64_t) 0;\n                if (cond_16582) {\n                    lifted_lambda_res_16583 = (int64_t) 0;\n                } else {\n                    int64_t lifted_lambda_res_16581 = ((__global int64_t *) mem_16949)[tmp_16580];\n                    \n                    lifted_lambda_res_16583 = lifted_lambda_res_16581;\n                }\n                if (chk_i_17318 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, lifted_lambda_res_16583) && slt64(lifted_lambda_res_16583, defunc_0_reduce_res_14478)) && (sle64(sext_i32_i64(chk_i_17318) * hist_H_chk_17320, lifted_lambda_res_16583) && slt64(lifted_lambda_res_16583, sext_i32_i64(chk_i_17318) * hist_H_chk_17320 + hist_H_chk_17320))) {\n                        int64_t eta_p_16575;\n                        int64_t eta_p_16576 = gtid_16573;\n                        int64_t old_17348;\n                        \n                        old_17348 = atomic_smax_i64_shared(&((volatile __local int64_t *) subhistogram_local_mem_17336)[sext_i32_i64(thread_local_subhisto_i_17338) * hist_H_chk_17320 + (lifted_lambda_res_16583 - sext_i32_i64(", "chk_i_17318) * hist_H_chk_17320)], (int64_t) eta_p_16576);\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_17349 = smin64(hist_H_chk_17320, defunc_0_reduce_res_14478 - sext_i32_i64(chk_i_17318) * hist_H_chk_17320);\n            int32_t histo_sizze_17350 = sext_i64_i32(trunc_H_17349);\n            \n            for (int32_t local_i_17351 = 0; local_i_17351 < init_per_thread_17322; local_i_17351++) {\n                int32_t j_17352 = local_i_17351 * sext_i64_i32(max_tblock_sizze_17307) + local_tid_17324;\n                \n                if (slt32(j_17352, histo_sizze_17350)) {\n                    int64_t eta_p_16575;\n                    int64_t eta_p_16576;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_16575 = ((__local int64_t *) subhistogram_local_mem_17336)[sext_i32_i64(j_17352)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_17353 = 0; subhisto_id_17353 < hist_M_17314 - 1; subhisto_id_17353++) {\n                            eta_p_16576 = ((__local int64_t *) subhistogram_local_mem_17336)[(sext_i32_i64(subhisto_id_17353) + (int64_t) 1) * hist_H_chk_17320 + sext_i32_i64(j_17352)];\n                            \n                            int64_t max_res_16577 = smax64(eta_p_16575, eta_p_16576);\n                            \n                            eta_p_16575 = max_res_16577;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int64_t *) defunc_0_map_res_subhistos_mem_17298)[srem64(sext_i32_i64(virt_tblock_id_17331), num_tblocks_17308) * defunc_0_reduce_r", "es_14478 + (sext_i32_i64(j_17352) + sext_i32_i64(chk_i_17318) * hist_H_chk_17320)] = eta_p_16575;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_17307\n}\nFUTHARK_KERNEL_SIZED(replicated_iota_6108zisegred_large_17383_dim1, 1, 1)\nvoid replicated_iota_6108zisegred_large_17383(__global int *global_failure, int64_t defunc_0_reduce_res_14478, int64_t num_tblocks_16569, int64_t num_subhistos_17297, int64_t blocks_per_segment_17414, int64_t q_17415, int64_t num_virtblocks_17416, int64_t threads_per_segment_17417, __global unsigned char *mem_16955, __global unsigned char *defunc_0_map_res_subhistos_mem_17298, __global unsigned char *segred_tmp_mem_17418, __global unsigned char *counters_mem_17420)\n{\n    #define seghist_tblock_sizze_16567 (replicated_iota_6108zisegred_large_17383ziseghist_tblock_sizze_16567)\n    #define chunk_sizze_17384 (replicated_iota_6108zisegred_large_17383zichunk_sizze_17384)\n    \n    volatile __local unsigned char *sync_arr_mem_17429_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_17429_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_17427_backing_0 = &shared_mem[sync_arr_mem_17429_backing_1_offset];\n    const int64_t red_arr_i64_mem_17427_backing_0_offset = sync_arr_mem_17429_backing_1_offset + ((int64_t) 8 * seghist_tblock_sizze_16567 + srem64((int64_t) 8 - srem64((int64_t) 8 * seghist_tblock_sizze_16567, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17423;\n    int32_t tblock_sizze_17426;\n    int32_t wave_sizze_17425;\n    int32_t block_id_17424;\n    int32_t global_tid_17422;\n    int64_t flat_gtid_17383;\n    __local unsigned char *red_arr_i64_mem_17427;\n    __local unsigned char *sync_arr_mem_17429;\n    int32_t phys_tblock_id_17431;\n    int32_t iterations_17432;\n    \n    local_tid_17423 = get_local_id(0);\n    tbloc",
                                    "k_sizze_17426 = get_local_size(0);\n    wave_sizze_17425 = LOCKSTEP_WIDTH;\n    block_id_17424 = get_tblock_id(0);\n    global_tid_17422 = block_id_17424 * tblock_sizze_17426 + local_tid_17423;\n    flat_gtid_17383 = sext_i32_i64(global_tid_17422);\n    red_arr_i64_mem_17427 = (__local unsigned char *) red_arr_i64_mem_17427_backing_0;\n    sync_arr_mem_17429 = (__local unsigned char *) sync_arr_mem_17429_backing_1;\n    phys_tblock_id_17431 = get_tblock_id(0);\n    iterations_17432 = sdiv_up32(sext_i64_i32(num_virtblocks_17416) - phys_tblock_id_17431, sext_i64_i32(num_tblocks_16569));\n    for (int32_t i_17433 = 0; i_17433 < iterations_17432; i_17433++) {\n        int32_t virt_tblock_id_17434;\n        int64_t flat_segment_id_17435;\n        int64_t global_tid_17436;\n        int64_t slice_17437;\n        int64_t bucket_id_17381;\n        int64_t remnant_17438;\n        int64_t subhistogram_id_17382;\n        int64_t eta_p_block_res_acc_17439;\n        int64_t eta_p_16575;\n        int64_t eta_p_16576;\n        int64_t tblock_id_in_segment_17443;\n        int64_t block_base_offset_17444;\n        int32_t offset_17447;\n        int32_t skip_waves_17448;\n        int64_t eta_p_17440;\n        int64_t eta_p_17441;\n        \n        virt_tblock_id_17434 = phys_tblock_id_17431 + i_17433 * sext_i64_i32(num_tblocks_16569);\n        flat_segment_id_17435 = squot64(sext_i32_i64(virt_tblock_id_17434), blocks_per_segment_17414);\n        global_tid_17436 = srem64(sext_i32_i64(virt_tblock_id_17434) * seghist_tblock_sizze_16567 + sext_i32_i64(local_tid_17423), threads_per_segment_17417);\n        slice_17437 = defunc_0_reduce_res_14478;\n        bucket_id_17381 = flat_segment_id_17435;\n        remnant_17438 = flat_segment_id_17435 - bucket_id_17381;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_17439 = (int64_t) 0;\n        }\n        tblock_id_in_segment_17443 = squot64(global_tid_17436, seghist_tblock_sizze_16567);\n        block_base_offset_17444 = tb", "lock_id_in_segment_17443 * q_17415 * seghist_tblock_sizze_16567;\n        for (int64_t i_17445 = 0; i_17445 < q_17415; i_17445++) {\n            int64_t block_offset_17446 = block_base_offset_17444 + i_17445 * seghist_tblock_sizze_16567;\n            \n            subhistogram_id_17382 = global_tid_17436 + threads_per_segment_17417 * i_17445;\n            if (slt64(subhistogram_id_17382, num_subhistos_17297)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_16575 = eta_p_block_res_acc_17439;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_16576 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_17298)[subhistogram_id_17382 * defunc_0_reduce_res_14478 + bucket_id_17381];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t max_res_16577 = smax64(eta_p_16575, eta_p_16576);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_17439 = max_res_16577;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423)] = eta_p_block_res_acc_17439;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_17448 = 1;\n        offset_17447 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_17423, sext_i64_i32(seghist_tblock_sizze_16567))) {\n                eta_p_17440 = ((__local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423 + offset_17447)];\n            }\n        }\n        offset_17447 = 1;\n        while (slt32(offset_17447, wave", "_sizze_17425)) {\n            if (slt32(local_tid_17423 + offset_17447, sext_i64_i32(seghist_tblock_sizze_16567)) && ((local_tid_17423 - squot32(local_tid_17423, wave_sizze_17425) * wave_sizze_17425) & (2 * offset_17447 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_17441 = ((volatile __local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423 + offset_17447)];\n                }\n                // apply reduction operation\n                {\n                    int64_t max_res_17442 = smax64(eta_p_17440, eta_p_17441);\n                    \n                    eta_p_17440 = max_res_17442;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423)] = eta_p_17440;\n                }\n            }\n            offset_17447 *= 2;\n        }\n        while (slt32(skip_waves_17448, squot32(sext_i64_i32(seghist_tblock_sizze_16567) + wave_sizze_17425 - 1, wave_sizze_17425))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_17447 = skip_waves_17448 * wave_sizze_17425;\n            if (slt32(local_tid_17423 + offset_17447, sext_i64_i32(seghist_tblock_sizze_16567)) && ((local_tid_17423 - squot32(local_tid_17423, wave_sizze_17425) * wave_sizze_17425) == 0 && (squot32(local_tid_17423, wave_sizze_17425) & (2 * skip_waves_17448 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_17441 = ((__local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423 + offset_17447)];\n                }\n                // apply reduction operation\n                {\n                    int64_t max_res_17442 = smax64(eta_p_17440, eta_p_17441);\n                    \n                    eta_p_17440 = max_res_17442;\n                }\n                // write result of operation\n                {\n                    ((__local int64_t *) red_arr_i64_mem_17427)[sext_i3",
                                    "2_i64(local_tid_17423)] = eta_p_17440;\n                }\n            }\n            skip_waves_17448 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_17423) == (int64_t) 0) {\n                eta_p_block_res_acc_17439 = eta_p_17440;\n            } else {\n                eta_p_block_res_acc_17439 = (int64_t) 0;\n            }\n        }\n        if (blocks_per_segment_17414 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_17423 == 0) {\n                    ((__global int64_t *) mem_16955)[bucket_id_17381] = eta_p_block_res_acc_17439;\n                }\n            }\n        } else {\n            int32_t old_counter_17449;\n            bool is_last_block_17450;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_17423 == 0) {\n                    ((__global int64_t *) segred_tmp_mem_17418)[sext_i32_i64(virt_tblock_id_17434)] = eta_p_block_res_acc_17439;\n                    mem_fence_global();\n                    old_counter_17449 = atomic_add_i32_global(&((volatile __global int *) counters_mem_17420)[srem64(flat_segment_id_17435, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_17429)[(int64_t) 0] = old_counter_17449 == sext_i64_i32(blocks_per_segment_17414 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_17450 = ((__local bool *) sync_arr_mem_17429)[(int64_t) 0];\n            if (is_last_block_17450) {\n                if (local_tid_17423 == 0) {\n                    old_counter_17449 = atomic_add_i32_global(&((volatile __global int *) counters_mem_17420)[srem64(flat_segment_id_17435, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_1", "7414));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_17451 = sdiv_up64(blocks_per_segment_17414, seghist_tblock_sizze_16567);\n                    \n                    eta_p_16575 = (int64_t) 0;\n                    for (int64_t i_17452 = 0; i_17452 < read_per_thread_17451; i_17452++) {\n                        int64_t block_res_id_17453 = sext_i32_i64(local_tid_17423) * read_per_thread_17451 + i_17452;\n                        int64_t index_of_block_res_17454 = flat_segment_id_17435 * blocks_per_segment_17414 + block_res_id_17453;\n                        \n                        if (slt64(block_res_id_17453, blocks_per_segment_17414)) {\n                            eta_p_16576 = ((__global int64_t *) segred_tmp_mem_17418)[index_of_block_res_17454];\n                            \n                            int64_t max_res_16577 = smax64(eta_p_16575, eta_p_16576);\n                            \n                            eta_p_16575 = max_res_16577;\n                        }\n                    }\n                }\n                ((__local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423)] = eta_p_16575;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_17455;\n                    int32_t skip_waves_17456 = 1;\n                    int64_t eta_p_17440;\n                    int64_t eta_p_17441;\n                    \n                    offset_17455 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_17423, sext_i64_i32(seghist_tblock_sizze_16567))) {\n                            eta_p_17440 = ((__local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423 + offset_17455)];\n                        }\n                    }\n                    offset_17455 = 1;\n                    while (slt32(off", "set_17455, wave_sizze_17425)) {\n                        if (slt32(local_tid_17423 + offset_17455, sext_i64_i32(seghist_tblock_sizze_16567)) && ((local_tid_17423 - squot32(local_tid_17423, wave_sizze_17425) * wave_sizze_17425) & (2 * offset_17455 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_17441 = ((volatile __local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423 + offset_17455)];\n                            }\n                            // apply reduction operation\n                            {\n                                int64_t max_res_17442 = smax64(eta_p_17440, eta_p_17441);\n                                \n                                eta_p_17440 = max_res_17442;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423)] = eta_p_17440;\n                            }\n                        }\n                        offset_17455 *= 2;\n                    }\n                    while (slt32(skip_waves_17456, squot32(sext_i64_i32(seghist_tblock_sizze_16567) + wave_sizze_17425 - 1, wave_sizze_17425))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_17455 = skip_waves_17456 * wave_sizze_17425;\n                        if (slt32(local_tid_17423 + offset_17455, sext_i64_i32(seghist_tblock_sizze_16567)) && ((local_tid_17423 - squot32(local_tid_17423, wave_sizze_17425) * wave_sizze_17425) == 0 && (squot32(local_tid_17423, wave_sizze_17425) & (2 * skip_waves_17456 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_17441 = ((__local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423 + offset_17455)];\n                            }\n                            // apply",
                                    " reduction operation\n                            {\n                                int64_t max_res_17442 = smax64(eta_p_17440, eta_p_17441);\n                                \n                                eta_p_17440 = max_res_17442;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int64_t *) red_arr_i64_mem_17427)[sext_i32_i64(local_tid_17423)] = eta_p_17440;\n                            }\n                        }\n                        skip_waves_17456 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_17423 == 0) {\n                            ((__global int64_t *) mem_16955)[bucket_id_17381] = eta_p_17440;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_16567\n    #undef chunk_sizze_17384\n}\nFUTHARK_KERNEL_SIZED(replicated_iota_6108zisegred_nonseg_16564_dim1, 1, 1)\nvoid replicated_iota_6108zisegred_nonseg_16564(__global int *global_failure, int64_t n_9632, int64_t num_tblocks_16559, int64_t num_threads_17247, __global unsigned char *mem_16951, __global unsigned char *mem_16953, __global unsigned char *counters_mem_17243, __global unsigned char *segred_tmp_mem_17245)\n{\n    #define segred_tblock_sizze_16557 (replicated_iota_6108zisegred_nonseg_16564zisegred_tblock_sizze_16557)\n    #define chunk_sizze_17242 (replicated_iota_6108zisegred_nonseg_16564zichunk_sizze_17242)\n    \n    volatile __local unsigned char *sync_arr_mem_17255_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_17255_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i64_mem_17253_backing_0 = &shared_mem[sync_arr_mem_17255_backing_1_offset];\n    const", " int64_t red_arr_i64_mem_17253_backing_0_offset = sync_arr_mem_17255_backing_1_offset + ((int64_t) 8 * segred_tblock_sizze_16557 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16557, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17249;\n    int32_t tblock_sizze_17252;\n    int32_t wave_sizze_17251;\n    int32_t block_id_17250;\n    int32_t global_tid_17248;\n    int64_t phys_tid_16564;\n    __local unsigned char *red_arr_i64_mem_17253;\n    __local unsigned char *sync_arr_mem_17255;\n    int64_t dummy_16562;\n    int64_t gtid_16563;\n    int64_t q_17257;\n    int64_t eta_p_block_res_acc_17258;\n    int64_t eta_p_12631;\n    int64_t eta_p_12632;\n    int64_t tblock_id_in_segment_17262;\n    int64_t block_base_offset_17263;\n    int32_t offset_17266;\n    int32_t skip_waves_17267;\n    int64_t eta_p_17259;\n    int64_t eta_p_17260;\n    int32_t old_counter_17268;\n    bool is_last_block_17269;\n    \n    local_tid_17249 = get_local_id(0);\n    tblock_sizze_17252 = get_local_size(0);\n    wave_sizze_17251 = LOCKSTEP_WIDTH;\n    block_id_17250 = get_tblock_id(0);\n    global_tid_17248 = block_id_17250 * tblock_sizze_17252 + local_tid_17249;\n    phys_tid_16564 = sext_i32_i64(global_tid_17248);\n    red_arr_i64_mem_17253 = (__local unsigned char *) red_arr_i64_mem_17253_backing_0;\n    sync_arr_mem_17255 = (__local unsigned char *) sync_arr_mem_17255_backing_1;\n    dummy_16562 = (int64_t) 0;\n    gtid_16563 = (int64_t) 0;\n    q_17257 = sdiv_up64(n_9632, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_16557 * num_tblocks_16559)) * chunk_sizze_17242);\n    // ne-initialise the outer (per-block) accumulator(s)\n    {\n        eta_p_block_res_acc_17258 = (int64_t) 0;\n    }\n    tblock_id_in_segment_17262 = squot64(phys_tid_16564, segred_tblock_sizze_16557);\n    block_base_offset_17263 = tblock_id_in_segment_17262 * q_17257 * segred_tblock_sizze_16557;\n    for (int64_t i_17264 = 0; i_17264 < q_17257; i_17264++) {\n        int64_t block_", "offset_17265 = block_base_offset_17263 + i_17264 * segred_tblock_sizze_16557;\n        \n        gtid_16563 = phys_tid_16564 + num_threads_17247 * i_17264;\n        if (slt64(gtid_16563, n_9632)) {\n            // apply map function(s)\n            {\n                // apply map function\n                {\n                    int64_t x_16546 = ((__global int64_t *) mem_16951)[gtid_16563];\n                    \n                    // load accumulator(s)\n                    {\n                        eta_p_12631 = eta_p_block_res_acc_17258;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_12632 = x_16546;\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int64_t defunc_0_op_res_12633 = add64(eta_p_12631, eta_p_12632);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_17258 = defunc_0_op_res_12633;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // store accs. prims go in lmem; non-prims in params (in global mem)\n    {\n        ((__local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249)] = eta_p_block_res_acc_17258;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_17267 = 1;\n    offset_17266 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_17249, sext_i64_i32(segred_tblock_sizze_16557))) {\n            eta_p_17259 = ((__local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249 + offset_17266)];\n        }\n    }\n    offset_17266 = 1;\n    while (slt32(offset_17266, wave_sizze_17251)) {\n        if (slt32(local_tid_17249 + offset_17266, sext_i64_i32(segred_tblock_sizze_16557)) && ((local_tid_17249 - squot32(local_tid_17249, wave_sizze_17251) * wave_sizze_17251) & (2 * offset_17266 - 1)) == 0) {",
                                    "\n            // read array element\n            {\n                eta_p_17260 = ((volatile __local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249 + offset_17266)];\n            }\n            // apply reduction operation\n            {\n                int64_t defunc_0_op_res_17261 = add64(eta_p_17259, eta_p_17260);\n                \n                eta_p_17259 = defunc_0_op_res_17261;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249)] = eta_p_17259;\n            }\n        }\n        offset_17266 *= 2;\n    }\n    while (slt32(skip_waves_17267, squot32(sext_i64_i32(segred_tblock_sizze_16557) + wave_sizze_17251 - 1, wave_sizze_17251))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_17266 = skip_waves_17267 * wave_sizze_17251;\n        if (slt32(local_tid_17249 + offset_17266, sext_i64_i32(segred_tblock_sizze_16557)) && ((local_tid_17249 - squot32(local_tid_17249, wave_sizze_17251) * wave_sizze_17251) == 0 && (squot32(local_tid_17249, wave_sizze_17251) & (2 * skip_waves_17267 - 1)) == 0)) {\n            // read array element\n            {\n                eta_p_17260 = ((__local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249 + offset_17266)];\n            }\n            // apply reduction operation\n            {\n                int64_t defunc_0_op_res_17261 = add64(eta_p_17259, eta_p_17260);\n                \n                eta_p_17259 = defunc_0_op_res_17261;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249)] = eta_p_17259;\n            }\n        }\n        skip_waves_17267 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // thread 0 updates per-block acc(s); rest reset to ne\n    {\n        if (sext_i32_i64(local_tid_17249) == (int64_t) 0) {\n            eta_p_block_res_acc_17258 = eta_p_1", "7259;\n        } else {\n            eta_p_block_res_acc_17258 = (int64_t) 0;\n        }\n    }\n    // first thread in block saves block result to global memory\n    {\n        if (local_tid_17249 == 0) {\n            ((__global int64_t *) segred_tmp_mem_17245)[sext_i32_i64(block_id_17250)] = eta_p_block_res_acc_17258;\n            mem_fence_global();\n            old_counter_17268 = atomic_add_i32_global(&((volatile __global int *) counters_mem_17243)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_17255)[(int64_t) 0] = old_counter_17268 == sext_i64_i32(num_tblocks_16559 - (int64_t) 1);\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_block_17269 = ((__local bool *) sync_arr_mem_17255)[(int64_t) 0];\n    if (is_last_block_17269) {\n        if (local_tid_17249 == 0) {\n            old_counter_17268 = atomic_add_i32_global(&((volatile __global int *) counters_mem_17243)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_16559));\n        }\n        // read in the per-block-results\n        {\n            int64_t read_per_thread_17270 = sdiv_up64(num_tblocks_16559, segred_tblock_sizze_16557);\n            \n            eta_p_12631 = (int64_t) 0;\n            for (int64_t i_17271 = 0; i_17271 < read_per_thread_17270; i_17271++) {\n                int64_t block_res_id_17272 = sext_i32_i64(local_tid_17249) * read_per_thread_17270 + i_17271;\n                int64_t index_of_block_res_17273 = block_res_id_17272;\n                \n                if (slt64(block_res_id_17272, num_tblocks_16559)) {\n                    eta_p_12632 = ((__global int64_t *) segred_tmp_mem_17245)[index_of_block_res_17273];\n                    \n                    int64_t defunc_0_op_res_12633 = add64(eta_p_12631, eta_p_12632);\n                    \n                    eta_p_12631 = defunc_0_op_res_12633;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249)] = eta_p_12631;\n        barrie", "r(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-block results\n        {\n            int32_t offset_17274;\n            int32_t skip_waves_17275 = 1;\n            int64_t eta_p_17259;\n            int64_t eta_p_17260;\n            \n            offset_17274 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_17249, sext_i64_i32(segred_tblock_sizze_16557))) {\n                    eta_p_17259 = ((__local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249 + offset_17274)];\n                }\n            }\n            offset_17274 = 1;\n            while (slt32(offset_17274, wave_sizze_17251)) {\n                if (slt32(local_tid_17249 + offset_17274, sext_i64_i32(segred_tblock_sizze_16557)) && ((local_tid_17249 - squot32(local_tid_17249, wave_sizze_17251) * wave_sizze_17251) & (2 * offset_17274 - 1)) == 0) {\n                    // read array element\n                    {\n                        eta_p_17260 = ((volatile __local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249 + offset_17274)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t defunc_0_op_res_17261 = add64(eta_p_17259, eta_p_17260);\n                        \n                        eta_p_17259 = defunc_0_op_res_17261;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249)] = eta_p_17259;\n                    }\n                }\n                offset_17274 *= 2;\n            }\n            while (slt32(skip_waves_17275, squot32(sext_i64_i32(segred_tblock_sizze_16557) + wave_sizze_17251 - 1, wave_sizze_17251))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_17274 = skip_waves_17275 * wave_sizze_17251;\n                if (slt32(local_tid_17249 + offset_17274, sext_i64_i32(segred_tblock_s",
                                    "izze_16557)) && ((local_tid_17249 - squot32(local_tid_17249, wave_sizze_17251) * wave_sizze_17251) == 0 && (squot32(local_tid_17249, wave_sizze_17251) & (2 * skip_waves_17275 - 1)) == 0)) {\n                    // read array element\n                    {\n                        eta_p_17260 = ((__local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249 + offset_17274)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t defunc_0_op_res_17261 = add64(eta_p_17259, eta_p_17260);\n                        \n                        eta_p_17259 = defunc_0_op_res_17261;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_i64_mem_17253)[sext_i32_i64(local_tid_17249)] = eta_p_17259;\n                    }\n                }\n                skip_waves_17275 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // and back to memory with the final result\n            {\n                if (local_tid_17249 == 0) {\n                    ((__global int64_t *) mem_16953)[(int64_t) 0] = eta_p_17259;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_tblock_sizze_16557\n    #undef chunk_sizze_17242\n}\nFUTHARK_KERNEL_SIZED(replicated_iota_6108zisegred_small_17383_dim1, 1, 1)\nvoid replicated_iota_6108zisegred_small_17383(__global int *global_failure, int64_t defunc_0_reduce_res_14478, int64_t num_tblocks_16569, int64_t num_subhistos_17297, int64_t segment_sizze_nonzzero_17385, __global unsigned char *mem_16955, __global unsigned char *defunc_0_map_res_subhistos_mem_17298)\n{\n    #define seghist_tblock_sizze_16567 (replicated_iota_6108zisegred_small_17383ziseghist_tblock_sizze_16567)\n    \n    volatile __local unsigned char *red_arr_i64_mem_17392_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i64_mem_17392_backing_0_offset = 0 + ((int64_t) 8 * seghist_tbl", "ock_sizze_16567 + srem64((int64_t) 8 - srem64((int64_t) 8 * seghist_tblock_sizze_16567, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17388;\n    int32_t tblock_sizze_17391;\n    int32_t wave_sizze_17390;\n    int32_t block_id_17389;\n    int32_t global_tid_17387;\n    int64_t flat_gtid_17383;\n    __local unsigned char *red_arr_i64_mem_17392;\n    int32_t phys_tblock_id_17394;\n    int32_t iterations_17395;\n    \n    local_tid_17388 = get_local_id(0);\n    tblock_sizze_17391 = get_local_size(0);\n    wave_sizze_17390 = LOCKSTEP_WIDTH;\n    block_id_17389 = get_tblock_id(0);\n    global_tid_17387 = block_id_17389 * tblock_sizze_17391 + local_tid_17388;\n    flat_gtid_17383 = sext_i32_i64(global_tid_17387);\n    red_arr_i64_mem_17392 = (__local unsigned char *) red_arr_i64_mem_17392_backing_0;\n    phys_tblock_id_17394 = get_tblock_id(0);\n    iterations_17395 = sdiv_up32(sext_i64_i32(sdiv_up64(defunc_0_reduce_res_14478, squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385))) - phys_tblock_id_17394, sext_i64_i32(num_tblocks_16569));\n    for (int32_t i_17396 = 0; i_17396 < iterations_17395; i_17396++) {\n        int32_t virt_tblock_id_17397;\n        int64_t slice_17398;\n        int64_t bucket_id_17381;\n        int64_t remnant_17399;\n        int64_t subhistogram_id_17382;\n        \n        virt_tblock_id_17397 = phys_tblock_id_17394 + i_17396 * sext_i64_i32(num_tblocks_16569);\n        slice_17398 = defunc_0_reduce_res_14478;\n        bucket_id_17381 = squot64(sext_i32_i64(local_tid_17388), segment_sizze_nonzzero_17385) + sext_i32_i64(virt_tblock_id_17397) * squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385);\n        remnant_17399 = squot64(sext_i32_i64(local_tid_17388), segment_sizze_nonzzero_17385) + sext_i32_i64(virt_tblock_id_17397) * squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385) - bucket_id_17381;\n        subhistogram_id_17382 = srem64(sext_i32_i64(local_tid_17388), num_subhisto", "s_17297);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_17297) && (slt64(bucket_id_17381, defunc_0_reduce_res_14478) && slt64(sext_i32_i64(local_tid_17388), num_subhistos_17297 * squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385)))) {\n                // save results to be reduced\n                {\n                    int64_t tmp_17400 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_17298)[subhistogram_id_17382 * defunc_0_reduce_res_14478 + bucket_id_17381];\n                    \n                    ((__local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388)] = tmp_17400;\n                }\n            } else {\n                ((__local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388)] = (int64_t) 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_17297)) {\n            // perform segmented scan to imitate reduction\n            {\n                int64_t eta_p_16575;\n                int64_t eta_p_16576;\n                int64_t eta_p_17401;\n                int64_t eta_p_17402;\n                bool ltid_in_bounds_17404 = slt64(sext_i32_i64(local_tid_17388), num_subhistos_17297 * squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385));\n                int32_t skip_threads_17405;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_17404) {\n                        eta_p_16576 = ((volatile __local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388)];\n                        if ((local_tid_17388 - squot32(local_tid_17388, 32) * 32) == 0) {\n                            eta_p_16575 = eta_p_16576;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_17405 = 1;\n                    while (slt32(skip_thre",
                                    "ads_17405, 32)) {\n                        bool thread_active_17406 = sle32(skip_threads_17405, local_tid_17388 - squot32(local_tid_17388, 32) * 32) && ltid_in_bounds_17404;\n                        \n                        if (thread_active_17406) {\n                            // read operands\n                            {\n                                eta_p_16575 = ((volatile __local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388) - sext_i32_i64(skip_threads_17405)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_17407 = slt64(srem64(sext_i32_i64(local_tid_17388), num_subhistos_17297), sext_i32_i64(local_tid_17388) - sext_i32_i64(local_tid_17388 - skip_threads_17405));\n                            \n                            if (thread_active_17406 && inactive_17407) {\n                                eta_p_16575 = eta_p_16576;\n                            }\n                            if (thread_active_17406) {\n                                if (!inactive_17407) {\n                                    int64_t max_res_16577 = smax64(eta_p_16575, eta_p_16576);\n                                    \n                                    eta_p_16575 = max_res_16577;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_17390, skip_threads_17405)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_17406) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388)] = eta_p_16575;\n                                eta_p_16576 = eta_p_16575;\n                            }\n                        }\n                        if (sle32(wave_sizze_17390, skip_threads_", "17405)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_17405 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_17388 - squot32(local_tid_17388, 32) * 32) == 31 && ltid_in_bounds_17404) {\n                        ((volatile __local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(squot32(local_tid_17388, 32))] = eta_p_16575;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_17408;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_17388, 32) == 0 && ltid_in_bounds_17404) {\n                            eta_p_17402 = ((volatile __local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388)];\n                            if ((local_tid_17388 - squot32(local_tid_17388, 32) * 32) == 0) {\n                                eta_p_17401 = eta_p_17402;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_17408 = 1;\n                        while (slt32(skip_threads_17408, 32)) {\n                            bool thread_active_17409 = sle32(skip_threads_17408, local_tid_17388 - squot32(local_tid_17388, 32) * 32) && (squot32(local_tid_17388, 32) == 0 && ltid_in_bounds_17404);\n                            \n                            if (thread_active_17409) {\n                                // read operands\n                                {\n                                    eta_p_17401 = ((volatile __local in", "t64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388) - sext_i32_i64(skip_threads_17408)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_17410 = slt64(srem64(sext_i32_i64(local_tid_17388 * 32 + 32 - 1), num_subhistos_17297), sext_i32_i64(local_tid_17388 * 32 + 32 - 1) - sext_i32_i64((local_tid_17388 - skip_threads_17408) * 32 + 32 - 1));\n                                \n                                if (thread_active_17409 && inactive_17410) {\n                                    eta_p_17401 = eta_p_17402;\n                                }\n                                if (thread_active_17409) {\n                                    if (!inactive_17410) {\n                                        int64_t max_res_17403 = smax64(eta_p_17401, eta_p_17402);\n                                        \n                                        eta_p_17401 = max_res_17403;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_17390, skip_threads_17408)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_17409) {\n                                // write result\n                                {\n                                    ((volatile __local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388)] = eta_p_17401;\n                                    eta_p_17402 = eta_p_17401;\n                                }\n                            }\n                            if (sle32(wave_sizze_17390, skip_threads_17408)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_17408 *= 2;\n                        }\n                    }\n                }\n              ",
                                    "  barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_17411 = squot32(local_tid_17388, 32) == 0 || !ltid_in_bounds_17404;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_17411) {\n                            eta_p_16576 = eta_p_16575;\n                            eta_p_16575 = ((__local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(squot32(local_tid_17388, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_17412 = slt64(srem64(sext_i32_i64(local_tid_17388), num_subhistos_17297), sext_i32_i64(local_tid_17388) - sext_i32_i64(squot32(local_tid_17388, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_17411) {\n                            if (inactive_17412) {\n                                eta_p_16575 = eta_p_16576;\n                            }\n                        }\n                        if (!no_carry_in_17411) {\n                            if (!inactive_17412) {\n                                int64_t max_res_16577 = smax64(eta_p_16575, eta_p_16576);\n                                \n                                eta_p_16575 = max_res_16577;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_17411) {\n                            ((__local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388)] = eta_p_16575;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_17388, 32) == 0 && ltid_in_bounds_17404) {\n                        ((__", "local int64_t *) red_arr_i64_mem_17392)[sext_i32_i64(local_tid_17388)] = eta_p_16576;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_17397) * squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385) + sext_i32_i64(local_tid_17388), defunc_0_reduce_res_14478) && slt64(sext_i32_i64(local_tid_17388), squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385))) {\n                int64_t tmp_17413 = ((__local int64_t *) red_arr_i64_mem_17392)[(sext_i32_i64(local_tid_17388) + (int64_t) 1) * segment_sizze_nonzzero_17385 - (int64_t) 1];\n                \n                ((__global int64_t *) mem_16955)[sext_i32_i64(virt_tblock_id_17397) * squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385) + sext_i32_i64(local_tid_17388)] = tmp_17413;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_16567\n}\nFUTHARK_KERNEL_SIZED(replicated_iota_6108zisegscan_16554_dim1, 1, 1)\nvoid replicated_iota_6108zisegscan_16554(__global int *global_failure, int64_t n_9632, int64_t num_tblocks_16551, int64_t num_virt_blocks_17104, int64_t num_virt_threads_17105, __global unsigned char *reps_mem_16946, __global unsigned char *mem_16949, __global unsigned char *mem_16951, __global unsigned char *status_flags_mem_17106, __global unsigned char *aggregates_mem_17128, __global unsigned char *incprefixes_mem_17130, __global unsigned char *global_dynid_mem_17132)\n{\n    #define segscan_tblock_sizze_16549 (replicated_iota_6108zisegscan_16554zisegscan_tblock_sizze_16549)\n    #define chunk_sizze_17103 (replicated_iota_6108zisegscan_16554zichunk_sizze_17103)\n    \n    volatile __local unsigned char *local_mem_17162_backing_0 = &shared_mem[0];\n    const i", "nt64_t local_mem_17162_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16549), chunk_sizze_17103 * segscan_tblock_sizze_16549 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16549), chunk_sizze_17103 * segscan_tblock_sizze_16549 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17155;\n    int32_t tblock_sizze_17158;\n    int32_t wave_sizze_17157;\n    int32_t block_id_17156;\n    int32_t global_tid_17154;\n    int64_t phys_tid_16554;\n    int32_t chunk_sizze_32b_17159;\n    int64_t byte_offsets_17160;\n    int64_t warp_byte_offset_17161;\n    __local unsigned char *local_mem_17162;\n    int64_t trans_arr_len_17163;\n    int64_t phys_block_id_17169;\n    int64_t virtloop_bound_17170;\n    \n    local_tid_17155 = get_local_id(0);\n    tblock_sizze_17158 = get_local_size(0);\n    wave_sizze_17157 = LOCKSTEP_WIDTH;\n    block_id_17156 = get_tblock_id(0);\n    global_tid_17154 = block_id_17156 * tblock_sizze_17158 + local_tid_17155;\n    phys_tid_16554 = sext_i32_i64(global_tid_17154);\n    chunk_sizze_32b_17159 = sext_i64_i32(chunk_sizze_17103);\n    byte_offsets_17160 = segscan_tblock_sizze_16549 * (int64_t) 8;\n    warp_byte_offset_17161 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_17162 = (__local unsigned char *) local_mem_17162_backing_0;\n    trans_arr_len_17163 = chunk_sizze_17103 * segscan_tblock_sizze_16549;\n    phys_block_id_17169 = get_tblock_id(0);\n    virtloop_bound_17170 = sdiv_up64(num_virt_blocks_17104 - phys_block_id_17169, num_tblocks_16551);\n    for (int64_t virtloop_i_17171 = 0; virtloop_i_17171 < virtloop_bound_17170; virtloop_i_17171++) {\n        int64_t dynamic_id_17172;\n        int64_t block_offset_17173;\n        int64_t sgm_idx_17174;\n        int32_t boundary_17175;\n        int32_t segsizze_compact_17176;\n        int64_t private_mem_17177[chunk_sizze_17103];\n     ",
                                    "   int64_t thd_offset_17179;\n        int64_t acc_17195;\n        int64_t prefix_17205;\n        bool block_new_sgm_17206;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_17155 == 0) {\n                dynamic_id_17172 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_17132)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_17162)[(int64_t) 0] = dynamic_id_17172;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_17172 == num_virt_blocks_17104 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_17132)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_17172 = ((__local int32_t *) local_mem_17162)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_17173 = dynamic_id_17172 * chunk_sizze_17103 * segscan_tblock_sizze_16549;\n        sgm_idx_17174 = smod64(block_offset_17173, n_9632);\n        boundary_17175 = sext_i64_i32(smin64(chunk_sizze_17103 * segscan_tblock_sizze_16549, n_9632 - sgm_idx_17174));\n        segsizze_compact_17176 = sext_i64_i32(smin64(chunk_sizze_17103 * segscan_tblock_sizze_16549, n_9632));\n        thd_offset_17179 = block_offset_17173 + sext_i32_i64(local_tid_17155);\n        // Load and map\n        {\n            for (int64_t i_17180 = 0; i_17180 < chunk_sizze_17103; i_17180++) {\n                int64_t virt_tid_17181 = thd_offset_17179 + i_17180 * segscan_tblock_sizze_16549;\n                int64_t slice_17182 = n_9632;\n                int64_t gtid_16553 = virt_tid_17181;\n                int64_t remnant_17183 = virt_tid_17181 - gtid_16553;\n                \n                if (slt64(virt_tid_17181, n_9632)) {\n                    int64_t x_14475 = ((__g", "lobal int64_t *) reps_mem_16946)[gtid_16553];\n                    \n                    ((__global int64_t *) mem_16951)[gtid_16553] = x_14475;\n                    private_mem_17177[i_17180] = x_14475;\n                } else {\n                    private_mem_17177[i_17180] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_17184 = 0; i_17184 < chunk_sizze_17103; i_17184++) {\n                int64_t sharedIdx_17185 = sext_i32_i64(local_tid_17155) + i_17184 * segscan_tblock_sizze_16549;\n                int64_t tmp_17186 = private_mem_17177[i_17184];\n                \n                ((__local int64_t *) local_mem_17162)[sharedIdx_17185] = tmp_17186;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17187 = 0; i_17187 < chunk_sizze_17103; i_17187++) {\n                int64_t sharedIdx_17188 = sext_i32_i64(local_tid_17155) * chunk_sizze_17103 + i_17187;\n                int64_t tmp_17189 = ((__local int64_t *) local_mem_17162)[sharedIdx_17188];\n                \n                private_mem_17177[i_17187] = tmp_17189;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_17190 = 0; i_17190 < chunk_sizze_17103 - (int64_t) 1; i_17190++) {\n                int64_t eta_p_12640;\n                int64_t eta_p_12641;\n                \n                eta_p_12640 = private_mem_17177[i_17190];\n                eta_p_12641 = private_mem_17177[i_17190 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_12642 = add64(eta_p_12640, eta_p_12641);\n                \n                private_mem_17177[i_17190 + (int64_t) 1] = defunc_0_op_res_12642;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_17191 = private_mem_17177[chunk_sizze_17103 - (int64_t) 1];\n            \n            ((__local int64_t *) local", "_mem_17162)[sext_i32_i64(local_tid_17155)] = tmp_17191;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_17192;\n            int64_t eta_p_17193;\n            int64_t eta_p_17196;\n            int64_t eta_p_17197;\n            bool ltid_in_bounds_17199 = slt64(sext_i32_i64(local_tid_17155), num_virt_threads_17105);\n            int32_t skip_threads_17200;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_17199) {\n                    eta_p_17193 = ((volatile __local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)];\n                    if ((local_tid_17155 - squot32(local_tid_17155, 32) * 32) == 0) {\n                        eta_p_17192 = eta_p_17193;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_17200 = 1;\n                while (slt32(skip_threads_17200, 32)) {\n                    bool thread_active_17201 = sle32(skip_threads_17200, local_tid_17155 - squot32(local_tid_17155, 32) * 32) && ltid_in_bounds_17199;\n                    \n                    if (thread_active_17201) {\n                        // read operands\n                        {\n                            eta_p_17192 = ((volatile __local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155) - sext_i32_i64(skip_threads_17200)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_17201) {\n                            int64_t defunc_0_op_res_17194 = add64(eta_p_17192, eta_p_17193);\n                            \n                            eta_p_17192 = defunc_0_op_res_17194;\n                        }\n                    }\n                    if (sle32(wave_sizze_17157, skip_threads_17200)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n              ",
                                    "      }\n                    if (thread_active_17201) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)] = eta_p_17192;\n                            eta_p_17193 = eta_p_17192;\n                        }\n                    }\n                    if (sle32(wave_sizze_17157, skip_threads_17200)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_17200 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_17155 - squot32(local_tid_17155, 32) * 32) == 31 && ltid_in_bounds_17199) {\n                    ((volatile __local int64_t *) local_mem_17162)[sext_i32_i64(squot32(local_tid_17155, 32))] = eta_p_17192;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_17202;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_17155, 32) == 0 && ltid_in_bounds_17199) {\n                        eta_p_17197 = ((volatile __local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)];\n                        if ((local_tid_17155 - squot32(local_tid_17155, 32) * 32) == 0) {\n                            eta_p_17196 = eta_p_17197;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_17202 = 1;\n                    while (slt32(skip_threads_17202, 32)) {\n                        bool thread_active_17203 = sle32(skip_threads_17202, local_tid_17155 - squot32(local_tid_17155, 32) * 32) && (squot32(local_tid_17155, 32)", " == 0 && ltid_in_bounds_17199);\n                        \n                        if (thread_active_17203) {\n                            // read operands\n                            {\n                                eta_p_17196 = ((volatile __local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155) - sext_i32_i64(skip_threads_17202)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_17203) {\n                                int64_t defunc_0_op_res_17198 = add64(eta_p_17196, eta_p_17197);\n                                \n                                eta_p_17196 = defunc_0_op_res_17198;\n                            }\n                        }\n                        if (sle32(wave_sizze_17157, skip_threads_17202)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_17203) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)] = eta_p_17196;\n                                eta_p_17197 = eta_p_17196;\n                            }\n                        }\n                        if (sle32(wave_sizze_17157, skip_threads_17202)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_17202 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_17204 = squot32(local_tid_17155, 32) == 0 || !ltid_in_bounds_17199;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_17204) {\n                        eta_p_17193 = eta_p_17192;\n                        eta_p_17192 = ((__local in", "t64_t *) local_mem_17162)[sext_i32_i64(squot32(local_tid_17155, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_17204) {\n                        int64_t defunc_0_op_res_17194 = add64(eta_p_17192, eta_p_17193);\n                        \n                        eta_p_17192 = defunc_0_op_res_17194;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_17204) {\n                        ((__local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)] = eta_p_17192;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_17155, 32) == 0 && ltid_in_bounds_17199) {\n                    ((__local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)] = eta_p_17193;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_17155 == 0) {\n                acc_17195 = ((__local int64_t *) local_mem_17162)[segscan_tblock_sizze_16549 - (int64_t) 1];\n            } else {\n                acc_17195 = ((__local int64_t *) local_mem_17162)[sext_i32_i64(local_tid_17155) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_17205 = (int64_t) 0;\n        block_new_sgm_17206 = sgm_idx_17174 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_17206 && local_tid_17155 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_17130)[dynamic_id_17172] = acc_17195;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_17106)[dynamic_id_17172] = (int8_t) 2;\n                acc_17195 = (int64_t) 0;\n            }\n            if (!block_new_sgm_17206 && slt32",
                                    "(local_tid_17155, wave_sizze_17157)) {\n                if (local_tid_17155 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_17128)[dynamic_id_17172] = acc_17195;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_17106)[dynamic_id_17172] = (int8_t) 1;\n                    \n                    int8_t tmp_17207 = ((volatile __global int8_t *) status_flags_mem_17106)[dynamic_id_17172 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_17162)[(int64_t) 0] = tmp_17207;\n                }\n                mem_fence_local();\n                \n                int8_t status_17208 = ((__local int8_t *) local_mem_17162)[(int64_t) 0];\n                \n                if (status_17208 == (int8_t) 2) {\n                    if (local_tid_17155 == 0) {\n                        prefix_17205 = ((volatile __global int64_t *) incprefixes_mem_17130)[dynamic_id_17172 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_17209 = sext_i64_i32(dynamic_id_17172 - sext_i32_i64(wave_sizze_17157));\n                    \n                    while (slt32(wave_sizze_17157 * -1, readOffset_17209)) {\n                        int32_t read_i_17210 = readOffset_17209 + local_tid_17155;\n                        int64_t aggr_17211 = (int64_t) 0;\n                        int8_t flag_17212 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_17210)) {\n                            flag_17212 = ((volatile __global int8_t *) status_flags_mem_17106)[sext_i32_i64(read_i_17210)];\n                            if (flag_17212 == (int8_t) 2) {\n                                aggr_17211 = ((volatile __global int64_t *) incprefixes_mem_17130)[sext_i32_i64(read_i_17210)];\n                            } else if (flag_17212 == (int8_t) 1) {\n                                aggr_17211 = ((volatile __global int64_t *) aggregates_mem_1712", "8)[sext_i32_i64(read_i_17210)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_17162)[(int64_t) 4 + sext_i32_i64(local_tid_17155)] = aggr_17211;\n                        ((__local int8_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)] = flag_17212;\n                        flag_17212 = ((__local int8_t *) local_mem_17162)[sext_i32_i64(wave_sizze_17157) - (int64_t) 1];\n                        if (slt8(flag_17212, (int8_t) 2)) {\n                            int8_t flg_x_17216;\n                            int8_t flg_y_17217;\n                            int64_t eta_p_17213;\n                            int64_t eta_p_17214;\n                            int32_t skip_threads_17218;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_17217 = ((volatile __local int8_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)];\n                                eta_p_17214 = ((volatile __local int64_t *) local_mem_17162)[(int64_t) 4 + sext_i32_i64(local_tid_17155)];\n                                if ((local_tid_17155 - squot32(local_tid_17155, 32) * 32) == 0) {\n                                    eta_p_17213 = eta_p_17214;\n                                    flg_x_17216 = flg_y_17217;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_17218 = 1;\n                                while (slt32(skip_threads_17218, 32)) {\n                                    if (sle32(skip_threads_17218, local_tid_17155 - squot32(local_tid_17155, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_17216 = ((volatile __local int8_t *) local_mem_17162)[sext_i32_i64(local_tid_17", "155) - sext_i32_i64(skip_threads_17218)];\n                                            eta_p_17213 = ((volatile __local int64_t *) local_mem_17162)[(int64_t) 4 + (sext_i32_i64(local_tid_17155) - sext_i32_i64(skip_threads_17218))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_17217 == (int8_t) 2 || flg_y_17217 == (int8_t) 0) {\n                                                flg_x_17216 = flg_y_17217;\n                                                eta_p_17213 = eta_p_17214;\n                                            } else {\n                                                int64_t defunc_0_op_res_17215 = add64(eta_p_17213, eta_p_17214);\n                                                \n                                                eta_p_17213 = defunc_0_op_res_17215;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_17162)[sext_i32_i64(local_tid_17155)] = flg_x_17216;\n                                            flg_y_17217 = flg_x_17216;\n                                            ((volatile __local int64_t *) local_mem_17162)[(int64_t) 4 + sext_i32_i64(local_tid_17155)] = eta_p_17213;\n                                            eta_p_17214 = eta_p_17213;\n                                        }\n                                    }\n                                    skip_threads_17218 *= 2;\n                                }\n                            }\n                        }\n                        flag_17212 = ((__local int8_t *) local_mem_17162)[sext_i32_i64(wave_sizze_17157) - (int64_t) 1];\n                        aggr_17211 = ((__local int64_t *) local_mem_17162)[(int64_t) 4 + (sext_i32_i64",
                                    "(wave_sizze_17157) - (int64_t) 1)];\n                        if (flag_17212 == (int8_t) 2) {\n                            readOffset_17209 = wave_sizze_17157 * -1;\n                        } else if (flag_17212 == (int8_t) 1) {\n                            readOffset_17209 -= wave_sizze_17157;\n                        }\n                        if (slt8((int8_t) 0, flag_17212)) {\n                            int64_t eta_p_17219 = aggr_17211;\n                            int64_t eta_p_17220 = prefix_17205;\n                            int64_t defunc_0_op_res_17221 = add64(eta_p_17219, eta_p_17220);\n                            \n                            prefix_17205 = defunc_0_op_res_17221;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_17155 == 0) {\n                    if (boundary_17175 == sext_i64_i32(segscan_tblock_sizze_16549 * chunk_sizze_17103)) {\n                        int64_t eta_p_17222 = prefix_17205;\n                        int64_t eta_p_17223 = acc_17195;\n                        int64_t defunc_0_op_res_17224 = add64(eta_p_17222, eta_p_17223);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_17130)[dynamic_id_17172] = defunc_0_op_res_17224;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_17106)[dynamic_id_17172] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_17162)[(int64_t) 4] = prefix_17205;\n                    acc_17195 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_17172 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_17205 = ((__local int64_t *) local_mem_17162)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_17225;\n            int64_t eta_p_17226;", "\n            int64_t eta_p_17228 = prefix_17205;\n            int64_t eta_p_17229 = acc_17195;\n            \n            if (slt32(local_tid_17155 * chunk_sizze_32b_17159, boundary_17175) && !block_new_sgm_17206) {\n                int64_t defunc_0_op_res_17230 = add64(eta_p_17228, eta_p_17229);\n                \n                eta_p_17225 = defunc_0_op_res_17230;\n            } else {\n                eta_p_17225 = acc_17195;\n            }\n            \n            int32_t stopping_point_17231 = segsizze_compact_17176 - srem32(local_tid_17155 * chunk_sizze_32b_17159 - 1 + segsizze_compact_17176 - boundary_17175, segsizze_compact_17176);\n            \n            for (int64_t i_17232 = 0; i_17232 < chunk_sizze_17103; i_17232++) {\n                if (slt32(sext_i64_i32(i_17232), stopping_point_17231 - 1)) {\n                    eta_p_17226 = private_mem_17177[i_17232];\n                    \n                    int64_t defunc_0_op_res_17227 = add64(eta_p_17225, eta_p_17226);\n                    \n                    private_mem_17177[i_17232] = defunc_0_op_res_17227;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_17233 = 0; i_17233 < chunk_sizze_17103; i_17233++) {\n                int64_t sharedIdx_17234 = sext_i32_i64(local_tid_17155) * chunk_sizze_17103 + i_17233;\n                int64_t tmp_17235 = private_mem_17177[i_17233];\n                \n                ((__local int64_t *) local_mem_17162)[sharedIdx_17234] = tmp_17235;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17236 = 0; i_17236 < chunk_sizze_17103; i_17236++) {\n                int64_t flat_idx_17237 = thd_offset_17179 + i_17236 * segscan_tblock_sizze_16549;\n                int64_t slice_17238 = n_9632;\n                int64_t gtid_16553 = flat_idx_17237;\n                int64_t remnant_17239 = flat_idx_17237 - gtid_16553;\n                \n                if (slt64", "(flat_idx_17237, n_9632)) {\n                    int64_t tmp_17240 = ((__local int64_t *) local_mem_17162)[flat_idx_17237 - block_offset_17173];\n                    \n                    ((__global int64_t *) mem_16949)[gtid_16553] = tmp_17240;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16549\n    #undef chunk_sizze_17103\n}\nFUTHARK_KERNEL_SIZED(replicated_iota_6108zisegscan_16591_dim1, 1, 1)\nvoid replicated_iota_6108zisegscan_16591(__global int *global_failure, int64_t defunc_0_reduce_res_14478, int64_t num_tblocks_16588, int64_t num_virt_blocks_17463, int64_t num_virt_threads_17464, __global unsigned char *mem_16955, __global unsigned char *mem_16958, __global unsigned char *mem_16960, __global unsigned char *status_flags_mem_17465, __global unsigned char *aggregates_mem_17467, __global unsigned char *incprefixes_mem_17469, __global unsigned char *aggregates_mem_17471, __global unsigned char *incprefixes_mem_17473, __global unsigned char *global_dynid_mem_17475)\n{\n    #define segscan_tblock_sizze_16586 (replicated_iota_6108zisegscan_16591zisegscan_tblock_sizze_16586)\n    #define chunk_sizze_17462 (replicated_iota_6108zisegscan_16591zichunk_sizze_17462)\n    \n    volatile __local unsigned char *local_mem_17487_backing_0 = &shared_mem[0];\n    const int64_t local_mem_17487_backing_0_offset = 0 + (smax64(smax64((int64_t) 320, sdiv_up64(segscan_tblock_sizze_16586, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16586), smax64(chunk_sizze_17462 * segscan_tblock_sizze_16586, chunk_sizze_17462 * segscan_tblock_sizze_16586 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 320, sdiv_up64(segscan_tblock_sizze_16586, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16586), smax64(chunk_sizze_17462 * segscan_tblock_sizze_16586, chunk_sizze_17462 * segscan_tblock_sizze_16586 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    \n  ",
                                    "  if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_17478;\n    int32_t tblock_sizze_17481;\n    int32_t wave_sizze_17480;\n    int32_t block_id_17479;\n    int32_t global_tid_17477;\n    int64_t phys_tid_16591;\n    int32_t chunk_sizze_32b_17482;\n    int64_t byte_offsets_17483;\n    int64_t byte_offsets_17484;\n    int64_t warp_byte_offset_17485;\n    int64_t warp_byte_offset_17486;\n    __local unsigned char *local_mem_17487;\n    int64_t trans_arr_len_17488;\n    int64_t phys_block_id_17497;\n    int64_t virtloop_bound_17498;\n    \n    local_tid_17478 = get_local_id(0);\n    tblock_sizze_17481 = get_local_size(0);\n    wave_sizze_17480 = LOCKSTEP_WIDTH;\n    block_id_17479 = get_tblock_id(0);\n    global_tid_17477 = block_id_17479 * tblock_sizze_17481 + local_tid_17478;\n    phys_tid_16591 = sext_i32_i64(global_tid_17477);\n    chunk_sizze_32b_17482 = sext_i64_i32(chunk_sizze_17462);\n    byte_offsets_17483 = segscan_tblock_sizze_16586;\n    byte_offsets_17484 = sdiv_up64(byte_offsets_17483, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_16586 * (int64_t) 8;\n    warp_byte_offset_17485 = (int64_t) 64;\n    warp_byte_offset_17486 = sdiv_up64(warp_byte_offset_17485, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_17487 = (__local unsigned char *) local_mem_17487_backing_0;\n    trans_arr_len_17488 = chunk_sizze_17462 * segscan_tblock_sizze_16586;\n    phys_block_id_17497 = get_tblock_id(0);\n    virtloop_bound_17498 = sdiv_up64(num_virt_blocks_17463 - phys_block_id_17497, num_tblocks_16588);\n    for (int64_t virtloop_i_17499 = 0; virtloop_i_17499 < virtloop_bound_17498; virtloop_i_17499++) {\n        int64_t dynamic_id_17500;\n        int64_t block_offset_17501;\n        int64_t sgm_idx_17502;\n        int32_t boundary_17503;\n        int32_t segsizze_compact_17504;\n        bool private_mem_17505[chunk_sizze_17462];\n        int64_t private_mem_17507[chunk_sizze_17462];\n        int64_t thd_offset_17509;\n        bool acc", "_17536;\n        int64_t acc_17537;\n        bool prefix_17551;\n        int64_t prefix_17552;\n        bool block_new_sgm_17553;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_17478 == 0) {\n                dynamic_id_17500 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_17475)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_17487)[(int64_t) 0] = dynamic_id_17500;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_17500 == num_virt_blocks_17463 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_17475)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_17500 = ((__local int32_t *) local_mem_17487)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_17501 = dynamic_id_17500 * chunk_sizze_17462 * segscan_tblock_sizze_16586;\n        sgm_idx_17502 = smod64(block_offset_17501, defunc_0_reduce_res_14478);\n        boundary_17503 = sext_i64_i32(smin64(chunk_sizze_17462 * segscan_tblock_sizze_16586, defunc_0_reduce_res_14478 - sgm_idx_17502));\n        segsizze_compact_17504 = sext_i64_i32(smin64(chunk_sizze_17462 * segscan_tblock_sizze_16586, defunc_0_reduce_res_14478));\n        thd_offset_17509 = block_offset_17501 + sext_i32_i64(local_tid_17478);\n        // Load and map\n        {\n            for (int64_t i_17510 = 0; i_17510 < chunk_sizze_17462; i_17510++) {\n                int64_t virt_tid_17511 = thd_offset_17509 + i_17510 * segscan_tblock_sizze_16586;\n                int64_t slice_17512 = defunc_0_reduce_res_14478;\n                int64_t gtid_16590 = virt_tid_17511;\n                int64_t remnant_17513 = virt_tid_17511 - gtid_16590;\n                \n              ", "  if (slt64(virt_tid_17511, defunc_0_reduce_res_14478)) {\n                    int64_t eta_p_14452 = ((__global int64_t *) mem_16955)[gtid_16590];\n                    bool lifted_lambda_res_14454 = slt64((int64_t) 0, eta_p_14452);\n                    \n                    private_mem_17505[i_17510] = lifted_lambda_res_14454;\n                    private_mem_17507[i_17510] = eta_p_14452;\n                } else {\n                    private_mem_17505[i_17510] = 0;\n                    private_mem_17507[i_17510] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_17514 = 0; i_17514 < chunk_sizze_17462; i_17514++) {\n                int64_t sharedIdx_17515 = sext_i32_i64(local_tid_17478) + i_17514 * segscan_tblock_sizze_16586;\n                bool tmp_17516 = private_mem_17505[i_17514];\n                \n                ((__local bool *) local_mem_17487)[sharedIdx_17515] = tmp_17516;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17517 = 0; i_17517 < chunk_sizze_17462; i_17517++) {\n                int64_t sharedIdx_17518 = sext_i32_i64(local_tid_17478) * chunk_sizze_17462 + i_17517;\n                bool tmp_17519 = ((__local bool *) local_mem_17487)[sharedIdx_17518];\n                \n                private_mem_17505[i_17517] = tmp_17519;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17520 = 0; i_17520 < chunk_sizze_17462; i_17520++) {\n                int64_t sharedIdx_17521 = sext_i32_i64(local_tid_17478) + i_17520 * segscan_tblock_sizze_16586;\n                int64_t tmp_17522 = private_mem_17507[i_17520];\n                \n                ((__local int64_t *) local_mem_17487)[sharedIdx_17521] = tmp_17522;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17523 = 0; i_17523 < chunk_sizze_17462; i_17523++) {\n                int64_t sharedIdx_17524 = sext_i32_i6",
                                    "4(local_tid_17478) * chunk_sizze_17462 + i_17523;\n                int64_t tmp_17525 = ((__local int64_t *) local_mem_17487)[sharedIdx_17524];\n                \n                private_mem_17507[i_17523] = tmp_17525;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_17526 = 0; i_17526 < chunk_sizze_17462 - (int64_t) 1; i_17526++) {\n                bool eta_p_12798;\n                bool eta_p_12800;\n                \n                eta_p_12798 = private_mem_17505[i_17526];\n                eta_p_12800 = private_mem_17505[i_17526 + (int64_t) 1];\n                \n                int64_t eta_p_12799;\n                int64_t eta_p_12801;\n                \n                eta_p_12799 = private_mem_17507[i_17526];\n                eta_p_12801 = private_mem_17507[i_17526 + (int64_t) 1];\n                \n                bool tmp_12802 = eta_p_12798 || eta_p_12800;\n                int64_t tmp_12803;\n                \n                if (eta_p_12800) {\n                    tmp_12803 = eta_p_12801;\n                } else {\n                    int64_t defunc_0_op_res_12804 = add64(eta_p_12799, eta_p_12801);\n                    \n                    tmp_12803 = defunc_0_op_res_12804;\n                }\n                private_mem_17505[i_17526 + (int64_t) 1] = tmp_12802;\n                private_mem_17507[i_17526 + (int64_t) 1] = tmp_12803;\n            }\n        }\n        // Publish results in shared memory\n        {\n            bool tmp_17527 = private_mem_17505[chunk_sizze_17462 - (int64_t) 1];\n            \n            ((__local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478)] = tmp_17527;\n            \n            int64_t tmp_17528 = private_mem_17507[chunk_sizze_17462 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + sext_i32_i64(local_tid_17478)] = tmp_17528;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan res", "ults (with warp scan)\n        {\n            bool eta_p_17529;\n            int64_t eta_p_17530;\n            bool eta_p_17531;\n            int64_t eta_p_17532;\n            bool eta_p_17538;\n            int64_t eta_p_17539;\n            bool eta_p_17540;\n            int64_t eta_p_17541;\n            bool ltid_in_bounds_17545 = slt64(sext_i32_i64(local_tid_17478), num_virt_threads_17464);\n            int32_t skip_threads_17546;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_17545) {\n                    eta_p_17531 = ((volatile __local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478)];\n                    eta_p_17532 = ((volatile __local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + sext_i32_i64(local_tid_17478)];\n                    if ((local_tid_17478 - squot32(local_tid_17478, 32) * 32) == 0) {\n                        eta_p_17529 = eta_p_17531;\n                        eta_p_17530 = eta_p_17532;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_17546 = 1;\n                while (slt32(skip_threads_17546, 32)) {\n                    bool thread_active_17547 = sle32(skip_threads_17546, local_tid_17478 - squot32(local_tid_17478, 32) * 32) && ltid_in_bounds_17545;\n                    \n                    if (thread_active_17547) {\n                        // read operands\n                        {\n                            eta_p_17529 = ((volatile __local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478) - sext_i32_i64(skip_threads_17546)];\n                            eta_p_17530 = ((volatile __local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + (sext_i32_i64(local_tid_17478) - sext_i32_i64(skip_threads_17546))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (th", "read_active_17547) {\n                            bool tmp_17533 = eta_p_17529 || eta_p_17531;\n                            int64_t tmp_17534;\n                            \n                            if (eta_p_17531) {\n                                tmp_17534 = eta_p_17532;\n                            } else {\n                                int64_t defunc_0_op_res_17535 = add64(eta_p_17530, eta_p_17532);\n                                \n                                tmp_17534 = defunc_0_op_res_17535;\n                            }\n                            eta_p_17529 = tmp_17533;\n                            eta_p_17530 = tmp_17534;\n                        }\n                    }\n                    if (sle32(wave_sizze_17480, skip_threads_17546)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_17547) {\n                        // write result\n                        {\n                            ((volatile __local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478)] = eta_p_17529;\n                            eta_p_17531 = eta_p_17529;\n                            ((volatile __local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + sext_i32_i64(local_tid_17478)] = eta_p_17530;\n                            eta_p_17532 = eta_p_17530;\n                        }\n                    }\n                    if (sle32(wave_sizze_17480, skip_threads_17546)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_17546 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_17478 - squot32(local_tid_17478, 32) * 32) == 31 && ltid_in_bounds_17545) {\n                    ((volatile __local bool *) local_mem_17487)[sext_i32_i64(squot32(local_tid_17478, 32))] = eta_p_17529;\n                    ((vola",
                                    "tile __local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + sext_i32_i64(squot32(local_tid_17478, 32))] = eta_p_17530;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_17548;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_17478, 32) == 0 && ltid_in_bounds_17545) {\n                        eta_p_17540 = ((volatile __local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478)];\n                        eta_p_17541 = ((volatile __local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + sext_i32_i64(local_tid_17478)];\n                        if ((local_tid_17478 - squot32(local_tid_17478, 32) * 32) == 0) {\n                            eta_p_17538 = eta_p_17540;\n                            eta_p_17539 = eta_p_17541;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_17548 = 1;\n                    while (slt32(skip_threads_17548, 32)) {\n                        bool thread_active_17549 = sle32(skip_threads_17548, local_tid_17478 - squot32(local_tid_17478, 32) * 32) && (squot32(local_tid_17478, 32) == 0 && ltid_in_bounds_17545);\n                        \n                        if (thread_active_17549) {\n                            // read operands\n                            {\n                                eta_p_17538 = ((volatile __local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478) - sext_i32_i64(skip_threads_17548)];\n                                eta_p_17539 = ((volatile __local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + (sext_i32_i64(local_tid_17478) - sext_i32_i64(skip_threads_17548))];\n                            }\n", "                        }\n                        // perform operation\n                        {\n                            if (thread_active_17549) {\n                                bool tmp_17542 = eta_p_17538 || eta_p_17540;\n                                int64_t tmp_17543;\n                                \n                                if (eta_p_17540) {\n                                    tmp_17543 = eta_p_17541;\n                                } else {\n                                    int64_t defunc_0_op_res_17544 = add64(eta_p_17539, eta_p_17541);\n                                    \n                                    tmp_17543 = defunc_0_op_res_17544;\n                                }\n                                eta_p_17538 = tmp_17542;\n                                eta_p_17539 = tmp_17543;\n                            }\n                        }\n                        if (sle32(wave_sizze_17480, skip_threads_17548)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_17549) {\n                            // write result\n                            {\n                                ((volatile __local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478)] = eta_p_17538;\n                                eta_p_17540 = eta_p_17538;\n                                ((volatile __local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + sext_i32_i64(local_tid_17478)] = eta_p_17539;\n                                eta_p_17541 = eta_p_17539;\n                            }\n                        }\n                        if (sle32(wave_sizze_17480, skip_threads_17548)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_17548 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_17550 = squot32(local_tid_1", "7478, 32) == 0 || !ltid_in_bounds_17545;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_17550) {\n                        eta_p_17531 = eta_p_17529;\n                        eta_p_17532 = eta_p_17530;\n                        eta_p_17529 = ((__local bool *) local_mem_17487)[sext_i32_i64(squot32(local_tid_17478, 32)) - (int64_t) 1];\n                        eta_p_17530 = ((__local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_17478, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_17550) {\n                        bool tmp_17533 = eta_p_17529 || eta_p_17531;\n                        int64_t tmp_17534;\n                        \n                        if (eta_p_17531) {\n                            tmp_17534 = eta_p_17532;\n                        } else {\n                            int64_t defunc_0_op_res_17535 = add64(eta_p_17530, eta_p_17532);\n                            \n                            tmp_17534 = defunc_0_op_res_17535;\n                        }\n                        eta_p_17529 = tmp_17533;\n                        eta_p_17530 = tmp_17534;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_17550) {\n                        ((__local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478)] = eta_p_17529;\n                        ((__local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + sext_i32_i64(local_tid_17478)] = eta_p_17530;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_17478, 32) == 0 && ltid_in_bounds_17545) {\n     ",
                                    "               ((__local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478)] = eta_p_17531;\n                    ((__local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + sext_i32_i64(local_tid_17478)] = eta_p_17532;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_17478 == 0) {\n                acc_17536 = ((__local bool *) local_mem_17487)[segscan_tblock_sizze_16586 - (int64_t) 1];\n                acc_17537 = ((__local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + (segscan_tblock_sizze_16586 - (int64_t) 1)];\n            } else {\n                acc_17536 = ((__local bool *) local_mem_17487)[sext_i32_i64(local_tid_17478) - (int64_t) 1];\n                acc_17537 = ((__local int64_t *) local_mem_17487)[squot64(byte_offsets_17483, (int64_t) 8) + (sext_i32_i64(local_tid_17478) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_17551 = 0;\n        prefix_17552 = (int64_t) 0;\n        block_new_sgm_17553 = sgm_idx_17502 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_17553 && local_tid_17478 == 0) {\n                ((volatile __global bool *) incprefixes_mem_17469)[dynamic_id_17500] = acc_17536;\n                ((volatile __global int64_t *) incprefixes_mem_17473)[dynamic_id_17500] = acc_17537;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_17465)[dynamic_id_17500] = (int8_t) 2;\n                acc_17536 = 0;\n                acc_17537 = (int64_t) 0;\n            }\n            if (!block_new_sgm_17553 && slt32(local_tid_17478, wave_sizze_17480)) {\n                if (local_tid_17478 == 0) {\n                    ((volatile __global bool *) aggregates_mem_17467)[dynamic_id_17500] = acc_17536;\n                    ((volatile __global int64_t *) aggregates_mem_17471)[dynamic_id_17500] = acc_17537;\n         ", "           mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_17465)[dynamic_id_17500] = (int8_t) 1;\n                    \n                    int8_t tmp_17554 = ((volatile __global int8_t *) status_flags_mem_17465)[dynamic_id_17500 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_17487)[(int64_t) 0] = tmp_17554;\n                }\n                mem_fence_local();\n                \n                int8_t status_17555 = ((__local int8_t *) local_mem_17487)[(int64_t) 0];\n                \n                if (status_17555 == (int8_t) 2) {\n                    if (local_tid_17478 == 0) {\n                        prefix_17551 = ((volatile __global bool *) incprefixes_mem_17469)[dynamic_id_17500 - (int64_t) 1];\n                        prefix_17552 = ((volatile __global int64_t *) incprefixes_mem_17473)[dynamic_id_17500 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_17556 = sext_i64_i32(dynamic_id_17500 - sext_i32_i64(wave_sizze_17480));\n                    \n                    while (slt32(wave_sizze_17480 * -1, readOffset_17556)) {\n                        int32_t read_i_17557 = readOffset_17556 + local_tid_17478;\n                        bool aggr_17558 = 0;\n                        int64_t aggr_17559 = (int64_t) 0;\n                        int8_t flag_17560 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_17557)) {\n                            flag_17560 = ((volatile __global int8_t *) status_flags_mem_17465)[sext_i32_i64(read_i_17557)];\n                            if (flag_17560 == (int8_t) 2) {\n                                aggr_17558 = ((volatile __global bool *) incprefixes_mem_17469)[sext_i32_i64(read_i_17557)];\n                                aggr_17559 = ((volatile __global int64_t *) incprefixes_mem_17473)[sext_i32_i64(read_i_17557)];\n                            } else if (flag_17560 == (int8_t) 1) ", "{\n                                aggr_17558 = ((volatile __global bool *) aggregates_mem_17467)[sext_i32_i64(read_i_17557)];\n                                aggr_17559 = ((volatile __global int64_t *) aggregates_mem_17471)[sext_i32_i64(read_i_17557)];\n                            }\n                        }\n                        ((__local bool *) local_mem_17487)[(int64_t) 32 + sext_i32_i64(local_tid_17478)] = aggr_17558;\n                        ((__local int64_t *) local_mem_17487)[squot64(warp_byte_offset_17485, (int64_t) 8) + sext_i32_i64(local_tid_17478)] = aggr_17559;\n                        ((__local int8_t *) local_mem_17487)[sext_i32_i64(local_tid_17478)] = flag_17560;\n                        flag_17560 = ((__local int8_t *) local_mem_17487)[sext_i32_i64(wave_sizze_17480) - (int64_t) 1];\n                        if (slt8(flag_17560, (int8_t) 2)) {\n                            int8_t flg_x_17568;\n                            int8_t flg_y_17569;\n                            bool eta_p_17561;\n                            int64_t eta_p_17562;\n                            bool eta_p_17563;\n                            int64_t eta_p_17564;\n                            int32_t skip_threads_17570;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_17569 = ((volatile __local int8_t *) local_mem_17487)[sext_i32_i64(local_tid_17478)];\n                                eta_p_17563 = ((volatile __local bool *) local_mem_17487)[(int64_t) 32 + sext_i32_i64(local_tid_17478)];\n                                eta_p_17564 = ((volatile __local int64_t *) local_mem_17487)[squot64(warp_byte_offset_17485, (int64_t) 8) + sext_i32_i64(local_tid_17478)];\n                                if ((local_tid_17478 - squot32(local_tid_17478, 32) * 32) == 0) {\n                                    eta_p_17561 = eta_p_17563;\n                                    eta_p_17562 = eta_p_17564;\n             ",
                                    "                       flg_x_17568 = flg_y_17569;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_17570 = 1;\n                                while (slt32(skip_threads_17570, 32)) {\n                                    if (sle32(skip_threads_17570, local_tid_17478 - squot32(local_tid_17478, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_17568 = ((volatile __local int8_t *) local_mem_17487)[sext_i32_i64(local_tid_17478) - sext_i32_i64(skip_threads_17570)];\n                                            eta_p_17561 = ((volatile __local bool *) local_mem_17487)[(int64_t) 32 + (sext_i32_i64(local_tid_17478) - sext_i32_i64(skip_threads_17570))];\n                                            eta_p_17562 = ((volatile __local int64_t *) local_mem_17487)[squot64(warp_byte_offset_17485, (int64_t) 8) + (sext_i32_i64(local_tid_17478) - sext_i32_i64(skip_threads_17570))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_17569 == (int8_t) 2 || flg_y_17569 == (int8_t) 0) {\n                                                flg_x_17568 = flg_y_17569;\n                                                eta_p_17561 = eta_p_17563;\n                                                eta_p_17562 = eta_p_17564;\n                                            } else {\n                                                bool tmp_17565 = eta_p_17561 || eta_p_17563;\n                                                int64_t tmp_17566;\n                                                \n                                                if (eta_p_17563) {\n                                                ", "    tmp_17566 = eta_p_17564;\n                                                } else {\n                                                    int64_t defunc_0_op_res_17567 = add64(eta_p_17562, eta_p_17564);\n                                                    \n                                                    tmp_17566 = defunc_0_op_res_17567;\n                                                }\n                                                eta_p_17561 = tmp_17565;\n                                                eta_p_17562 = tmp_17566;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_17487)[sext_i32_i64(local_tid_17478)] = flg_x_17568;\n                                            flg_y_17569 = flg_x_17568;\n                                            ((volatile __local bool *) local_mem_17487)[(int64_t) 32 + sext_i32_i64(local_tid_17478)] = eta_p_17561;\n                                            eta_p_17563 = eta_p_17561;\n                                            ((volatile __local int64_t *) local_mem_17487)[squot64(warp_byte_offset_17485, (int64_t) 8) + sext_i32_i64(local_tid_17478)] = eta_p_17562;\n                                            eta_p_17564 = eta_p_17562;\n                                        }\n                                    }\n                                    skip_threads_17570 *= 2;\n                                }\n                            }\n                        }\n                        flag_17560 = ((__local int8_t *) local_mem_17487)[sext_i32_i64(wave_sizze_17480) - (int64_t) 1];\n                        aggr_17558 = ((__local bool *) local_mem_17487)[(int64_t) 32 + (sext_i32_i64(wave_sizze_17480) - (int64_t) 1)];\n                        aggr_17559 = ((__local int64_t *) local_mem_17487)[squot64(warp_byte_offset_17485", ", (int64_t) 8) + (sext_i32_i64(wave_sizze_17480) - (int64_t) 1)];\n                        if (flag_17560 == (int8_t) 2) {\n                            readOffset_17556 = wave_sizze_17480 * -1;\n                        } else if (flag_17560 == (int8_t) 1) {\n                            readOffset_17556 -= wave_sizze_17480;\n                        }\n                        if (slt8((int8_t) 0, flag_17560)) {\n                            bool eta_p_17571 = aggr_17558;\n                            int64_t eta_p_17572 = aggr_17559;\n                            bool eta_p_17573 = prefix_17551;\n                            int64_t eta_p_17574 = prefix_17552;\n                            bool tmp_17575 = eta_p_17571 || eta_p_17573;\n                            int64_t tmp_17576;\n                            \n                            if (eta_p_17573) {\n                                tmp_17576 = eta_p_17574;\n                            } else {\n                                int64_t defunc_0_op_res_17577 = add64(eta_p_17572, eta_p_17574);\n                                \n                                tmp_17576 = defunc_0_op_res_17577;\n                            }\n                            prefix_17551 = tmp_17575;\n                            prefix_17552 = tmp_17576;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_17478 == 0) {\n                    if (boundary_17503 == sext_i64_i32(segscan_tblock_sizze_16586 * chunk_sizze_17462)) {\n                        bool eta_p_17578 = prefix_17551;\n                        int64_t eta_p_17579 = prefix_17552;\n                        bool eta_p_17580 = acc_17536;\n                        int64_t eta_p_17581 = acc_17537;\n                        bool tmp_17582 = eta_p_17578 || eta_p_17580;\n                        int64_t tmp_17583;\n                        \n                        if (eta_p_17580) {\n                            tmp_17583 = eta_p_17581;\n  ",
                                    "                      } else {\n                            int64_t defunc_0_op_res_17584 = add64(eta_p_17579, eta_p_17581);\n                            \n                            tmp_17583 = defunc_0_op_res_17584;\n                        }\n                        ((volatile __global bool *) incprefixes_mem_17469)[dynamic_id_17500] = tmp_17582;\n                        ((volatile __global int64_t *) incprefixes_mem_17473)[dynamic_id_17500] = tmp_17583;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_17465)[dynamic_id_17500] = (int8_t) 2;\n                    }\n                    ((__local bool *) local_mem_17487)[(int64_t) 32] = prefix_17551;\n                    ((__local int64_t *) local_mem_17487)[squot64(warp_byte_offset_17485, (int64_t) 8)] = prefix_17552;\n                    acc_17536 = 0;\n                    acc_17537 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_17500 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_17551 = ((__local bool *) local_mem_17487)[(int64_t) 32];\n                prefix_17552 = ((__local int64_t *) local_mem_17487)[squot64(warp_byte_offset_17485, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            bool eta_p_17585;\n            bool eta_p_17587;\n            bool eta_p_17592 = prefix_17551;\n            bool eta_p_17594 = acc_17536;\n            int64_t eta_p_17586;\n            int64_t eta_p_17588;\n            int64_t eta_p_17593 = prefix_17552;\n            int64_t eta_p_17595 = acc_17537;\n            \n            if (slt32(local_tid_17478 * chunk_sizze_32b_17482, boundary_17503) && !block_new_sgm_17553) {\n                bool tmp_17596 = eta_p_17592 || eta_p_17594;\n                int64_t tmp_17597;\n                \n                if (eta_p_17594) {\n                    tmp_17597 = eta_p_17595;\n                } else {\n", "                    int64_t defunc_0_op_res_17598 = add64(eta_p_17593, eta_p_17595);\n                    \n                    tmp_17597 = defunc_0_op_res_17598;\n                }\n                eta_p_17585 = tmp_17596;\n                eta_p_17586 = tmp_17597;\n            } else {\n                eta_p_17585 = acc_17536;\n                eta_p_17586 = acc_17537;\n            }\n            \n            int32_t stopping_point_17599 = segsizze_compact_17504 - srem32(local_tid_17478 * chunk_sizze_32b_17482 - 1 + segsizze_compact_17504 - boundary_17503, segsizze_compact_17504);\n            \n            for (int64_t i_17600 = 0; i_17600 < chunk_sizze_17462; i_17600++) {\n                if (slt32(sext_i64_i32(i_17600), stopping_point_17599 - 1)) {\n                    eta_p_17587 = private_mem_17505[i_17600];\n                    eta_p_17588 = private_mem_17507[i_17600];\n                    \n                    bool tmp_17589 = eta_p_17585 || eta_p_17587;\n                    int64_t tmp_17590;\n                    \n                    if (eta_p_17587) {\n                        tmp_17590 = eta_p_17588;\n                    } else {\n                        int64_t defunc_0_op_res_17591 = add64(eta_p_17586, eta_p_17588);\n                        \n                        tmp_17590 = defunc_0_op_res_17591;\n                    }\n                    private_mem_17505[i_17600] = tmp_17589;\n                    private_mem_17507[i_17600] = tmp_17590;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_17601 = 0; i_17601 < chunk_sizze_17462; i_17601++) {\n                int64_t sharedIdx_17602 = sext_i32_i64(local_tid_17478) * chunk_sizze_17462 + i_17601;\n                bool tmp_17603 = private_mem_17505[i_17601];\n                \n                ((__local bool *) local_mem_17487)[sharedIdx_17602] = tmp_17603;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for", " (int64_t i_17604 = 0; i_17604 < chunk_sizze_17462; i_17604++) {\n                int64_t flat_idx_17605 = thd_offset_17509 + i_17604 * segscan_tblock_sizze_16586;\n                int64_t slice_17606 = defunc_0_reduce_res_14478;\n                int64_t gtid_16590 = flat_idx_17605;\n                int64_t remnant_17607 = flat_idx_17605 - gtid_16590;\n                \n                if (slt64(flat_idx_17605, defunc_0_reduce_res_14478)) {\n                    bool tmp_17608 = ((__local bool *) local_mem_17487)[flat_idx_17605 - block_offset_17501];\n                    \n                    ((__global bool *) mem_16958)[gtid_16590] = tmp_17608;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17609 = 0; i_17609 < chunk_sizze_17462; i_17609++) {\n                int64_t sharedIdx_17610 = sext_i32_i64(local_tid_17478) * chunk_sizze_17462 + i_17609;\n                int64_t tmp_17611 = private_mem_17507[i_17609];\n                \n                ((__local int64_t *) local_mem_17487)[sharedIdx_17610] = tmp_17611;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_17612 = 0; i_17612 < chunk_sizze_17462; i_17612++) {\n                int64_t flat_idx_17613 = thd_offset_17509 + i_17612 * segscan_tblock_sizze_16586;\n                int64_t slice_17614 = defunc_0_reduce_res_14478;\n                int64_t gtid_16590 = flat_idx_17613;\n                int64_t remnant_17615 = flat_idx_17613 - gtid_16590;\n                \n                if (slt64(flat_idx_17613, defunc_0_reduce_res_14478)) {\n                    int64_t tmp_17616 = ((__local int64_t *) local_mem_17487)[flat_idx_17613 - block_offset_17501];\n                    \n                    ((__global int64_t *) mem_16960)[gtid_16590] = tmp_17616;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_16586\n    #undef chunk_sizze_17462\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 51;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "replicated_iota_6108zisegscan_16591_dim1";
        values[0] = *ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16585;
    }
    {
        names[1] = "replicated_iota_6108zisegscan_16591zisegscan_tblock_sizze_16586";
        values[1] = *ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16585;
    }
    {
        names[2] = "replicated_iota_6108zisegscan_16591zichunk_sizze_17462";
        values[2] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[3] = "replicated_iota_6108zisegred_large_17383_dim1";
        values[3] = *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566;
    }
    {
        names[4] = "replicated_iota_6108zisegred_large_17383ziseghist_tblock_sizze_16567";
        values[4] = *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566;
    }
    {
        names[5] = "replicated_iota_6108zisegred_large_17383zichunk_sizze_17384";
        values[5] = (int64_t) 1;
    }
    {
        names[6] = "replicated_iota_6108zisegred_small_17383_dim1";
        values[6] = *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566;
    }
    {
        names[7] = "replicated_iota_6108zisegred_small_17383ziseghist_tblock_sizze_16567";
        values[7] = *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566;
    }
    {
        names[8] = "replicated_iota_6108ziseghist_global_16574_dim1";
        values[8] = *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566;
    }
    {
        names[9] = "replicated_iota_6108ziseghist_global_16574ziseghist_tblock_sizze_16567";
        values[9] = *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566;
    }
    {
        names[10] = "replicated_iota_6108ziseghist_local_16574_dim1";
        values[10] = ctx->max_thread_block_size;
    }
    {
        names[11] = "replicated_iota_6108ziseghist_local_16574zimax_tblock_sizze_17307";
        values[11] = ctx->max_thread_block_size;
    }
    {
        names[12] = "replicated_iota_6108zisegred_nonseg_16564_dim1";
        values[12] = *ctx->tuning_params.replicated_iota_6108zisegred_tblock_sizze_16556;
    }
    {
        names[13] = "replicated_iota_6108zisegred_nonseg_16564zisegred_tblock_sizze_16557";
        values[13] = *ctx->tuning_params.replicated_iota_6108zisegred_tblock_sizze_16556;
    }
    {
        names[14] = "replicated_iota_6108zisegred_nonseg_16564zichunk_sizze_17242";
        values[14] = (int64_t) 1;
    }
    {
        names[15] = "replicated_iota_6108zisegscan_16554_dim1";
        values[15] = *ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16548;
    }
    {
        names[16] = "replicated_iota_6108zisegscan_16554zisegscan_tblock_sizze_16549";
        values[16] = *ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16548;
    }
    {
        names[17] = "replicated_iota_6108zisegscan_16554zichunk_sizze_17103";
        values[17] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[18] = "mainzisegmap_16903_dim1";
        values[18] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16878;
    }
    {
        names[19] = "mainzisegmap_16903zisegmap_tblock_sizze_16899";
        values[19] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16878;
    }
    {
        names[20] = "mainzisegmap_16868_dim1";
        values[20] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16870;
    }
    {
        names[21] = "mainzisegmap_16868zisegmap_tblock_sizze_16871";
        values[21] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16870;
    }
    {
        names[22] = "mainzisegmap_16860_dim1";
        values[22] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16862;
    }
    {
        names[23] = "mainzisegmap_16860zisegmap_tblock_sizze_16863";
        values[23] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16862;
    }
    {
        names[24] = "mainzisegscan_16858_dim1";
        values[24] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16852;
    }
    {
        names[25] = "mainzisegscan_16858zisegscan_tblock_sizze_16853";
        values[25] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16852;
    }
    {
        names[26] = "mainzisegscan_16858zichunk_sizze_18224";
        values[26] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[27] = "mainzisegmap_16842_dim1";
        values[27] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16820;
    }
    {
        names[28] = "mainzisegmap_16842zisegmap_tblock_sizze_16836";
        values[28] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16820;
    }
    {
        names[29] = "mainzisegmap_16810_dim1";
        values[29] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16812;
    }
    {
        names[30] = "mainzisegmap_16810zisegmap_tblock_sizze_16813";
        values[30] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16812;
    }
    {
        names[31] = "mainzisegscan_16725_dim1";
        values[31] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16719;
    }
    {
        names[32] = "mainzisegscan_16725zisegscan_tblock_sizze_16720";
        values[32] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16719;
    }
    {
        names[33] = "mainzisegscan_16725zichunk_sizze_17701";
        values[33] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[34] = "mainzisegscan_16717_dim1";
        values[34] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16711;
    }
    {
        names[35] = "mainzisegscan_16717zisegscan_tblock_sizze_16712";
        values[35] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16711;
    }
    {
        names[36] = "mainzisegscan_16717zichunk_sizze_17491";
        values[36] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[37] = "mainzisegmap_16697_dim1";
        values[37] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16674;
    }
    {
        names[38] = "mainzisegmap_16697zisegmap_tblock_sizze_16692";
        values[38] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16674;
    }
    {
        names[39] = "mainzisegmap_16660_dim1";
        values[39] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16639;
    }
    {
        names[40] = "mainzisegmap_16660zisegmap_tblock_sizze_16655";
        values[40] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16639;
    }
    {
        names[41] = "mainzisegmap_16632_dim1";
        values[41] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16619;
    }
    {
        names[42] = "mainzisegmap_16632zisegmap_tblock_sizze_16628";
        values[42] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16619;
    }
    {
        names[43] = "mainzisegscan_16615_dim1";
        values[43] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16609;
    }
    {
        names[44] = "mainzisegscan_16615zisegscan_tblock_sizze_16610";
        values[44] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16609;
    }
    {
        names[45] = "mainzisegscan_16615zichunk_sizze_17329";
        values[45] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[46] = "mainzisegmap_16601_dim1";
        values[46] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16603;
    }
    {
        names[47] = "mainzisegmap_16601zisegmap_tblock_sizze_16604";
        values[47] = *ctx->tuning_params.mainzisegmap_tblock_sizze_16603;
    }
    {
        names[48] = "mainzisegscan_16599_dim1";
        values[48] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16593;
    }
    {
        names[49] = "mainzisegscan_16599zisegscan_tblock_sizze_16594";
        values[49] = *ctx->tuning_params.mainzisegscan_tblock_sizze_16593;
    }
    {
        names[50] = "mainzisegscan_16599zichunk_sizze_17102";
        values[50] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  lib/github.com/diku-dk/sorts/quick_sort.fut:29:35-59\n   #1  lib/github.com/diku-dk/sorts/quick_sort.fut:29:61-65\n   #2  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #3  naiveCompiler.fut:10:40-49\n   #4  naiveCompiler.fut:15:1-18:42\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  lib/github.com/diku-dk/sorts/quick_sort.fut:9:17-22\n   #1  lib/github.com/diku-dk/sorts/quick_sort.fut:9:24-28\n   #2  lib/github.com/diku-dk/sorts/quick_sort.fut:37:15-69\n   #3  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #4  naiveCompiler.fut:10:40-49\n   #5  naiveCompiler.fut:15:1-18:42\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  lib/github.com/diku-dk/sorts/quick_sort.fut:45:55-66\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #4  naiveCompiler.fut:10:40-49\n   #5  naiveCompiler.fut:15:1-18:42\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  lib/github.com/diku-dk/sorts/quick_sort.fut:45:49-54\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #4  naiveCompiler.fut:10:40-49\n   #5  naiveCompiler.fut:15:1-18:42\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  lib/github.com/diku-dk/sorts/quick_sort.fut:75:23-28\n   #1  lib/github.com/diku-dk/sorts/quick_sort.fut:75:30-32\n   #2  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #3  naiveCompiler.fut:10:40-49\n   #4  naiveCompiler.fut:15:1-18:42\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  lib/github.com/diku-dk/sorts/quick_sort.fut:68:28-35\n   #1  /prelude/soacs.fut:75:28-29\n   #2  /prelude/soacs.fut:75:32-45\n   #3  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #4  naiveCompiler.fut:10:40-49\n   #5  naiveCompiler.fut:15:1-18:42\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  naiveCompiler.fut:12:27-44\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  naiveCompiler.fut:12:52-58\n   #4  naiveCompiler.fut:15:1-18:42\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhreplicate_boolzireplicate_17295;
    gpu_kernel builtinzhreplicate_i32zireplicate_17142;
    gpu_kernel builtinzhreplicate_i64zireplicate_17445;
    gpu_kernel builtinzhreplicate_i8zireplicate_17112;
    gpu_kernel mainzisegmap_16601;
    gpu_kernel mainzisegmap_16632;
    gpu_kernel mainzisegmap_16660;
    gpu_kernel mainzisegmap_16697;
    gpu_kernel mainzisegmap_16810;
    gpu_kernel mainzisegmap_16842;
    gpu_kernel mainzisegmap_16860;
    gpu_kernel mainzisegmap_16868;
    gpu_kernel mainzisegmap_16903;
    gpu_kernel mainzisegscan_16599;
    gpu_kernel mainzisegscan_16615;
    gpu_kernel mainzisegscan_16717;
    gpu_kernel mainzisegscan_16725;
    gpu_kernel mainzisegscan_16858;
    gpu_kernel replicated_iota_6108ziseghist_global_16574;
    gpu_kernel replicated_iota_6108ziseghist_local_16574;
    gpu_kernel replicated_iota_6108zisegred_large_17383;
    gpu_kernel replicated_iota_6108zisegred_nonseg_16564;
    gpu_kernel replicated_iota_6108zisegred_small_17383;
    gpu_kernel replicated_iota_6108zisegscan_16554;
    gpu_kernel replicated_iota_6108zisegscan_16591;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_boolzireplicate_17295, "builtinzhreplicate_boolzireplicate_17295");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_17142, "builtinzhreplicate_i32zireplicate_17142");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i64zireplicate_17445, "builtinzhreplicate_i64zireplicate_17445");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_17112, "builtinzhreplicate_i8zireplicate_17112");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16601, "mainzisegmap_16601");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16632, "mainzisegmap_16632");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16660, "mainzisegmap_16660");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16697, "mainzisegmap_16697");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16810, "mainzisegmap_16810");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16842, "mainzisegmap_16842");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16860, "mainzisegmap_16860");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16868, "mainzisegmap_16868");
    gpu_create_kernel(ctx, &ctx->program->mainzisegmap_16903, "mainzisegmap_16903");
    gpu_create_kernel(ctx, &ctx->program->mainzisegscan_16599, "mainzisegscan_16599");
    gpu_create_kernel(ctx, &ctx->program->mainzisegscan_16615, "mainzisegscan_16615");
    gpu_create_kernel(ctx, &ctx->program->mainzisegscan_16717, "mainzisegscan_16717");
    gpu_create_kernel(ctx, &ctx->program->mainzisegscan_16725, "mainzisegscan_16725");
    gpu_create_kernel(ctx, &ctx->program->mainzisegscan_16858, "mainzisegscan_16858");
    gpu_create_kernel(ctx, &ctx->program->replicated_iota_6108ziseghist_global_16574, "replicated_iota_6108ziseghist_global_16574");
    gpu_create_kernel(ctx, &ctx->program->replicated_iota_6108ziseghist_local_16574, "replicated_iota_6108ziseghist_local_16574");
    gpu_create_kernel(ctx, &ctx->program->replicated_iota_6108zisegred_large_17383, "replicated_iota_6108zisegred_large_17383");
    gpu_create_kernel(ctx, &ctx->program->replicated_iota_6108zisegred_nonseg_16564, "replicated_iota_6108zisegred_nonseg_16564");
    gpu_create_kernel(ctx, &ctx->program->replicated_iota_6108zisegred_small_17383, "replicated_iota_6108zisegred_small_17383");
    gpu_create_kernel(ctx, &ctx->program->replicated_iota_6108zisegscan_16554, "replicated_iota_6108zisegscan_16554");
    gpu_create_kernel(ctx, &ctx->program->replicated_iota_6108zisegscan_16591, "replicated_iota_6108zisegscan_16591");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_boolzireplicate_17295);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_17142);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_17445);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_17112);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16601);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16632);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16660);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16697);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16810);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16842);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16860);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16868);
    gpu_free_kernel(ctx, ctx->program->mainzisegmap_16903);
    gpu_free_kernel(ctx, ctx->program->mainzisegscan_16599);
    gpu_free_kernel(ctx, ctx->program->mainzisegscan_16615);
    gpu_free_kernel(ctx, ctx->program->mainzisegscan_16717);
    gpu_free_kernel(ctx, ctx->program->mainzisegscan_16725);
    gpu_free_kernel(ctx, ctx->program->mainzisegscan_16858);
    gpu_free_kernel(ctx, ctx->program->replicated_iota_6108ziseghist_global_16574);
    gpu_free_kernel(ctx, ctx->program->replicated_iota_6108ziseghist_local_16574);
    gpu_free_kernel(ctx, ctx->program->replicated_iota_6108zisegred_large_17383);
    gpu_free_kernel(ctx, ctx->program->replicated_iota_6108zisegred_nonseg_16564);
    gpu_free_kernel(ctx, ctx->program->replicated_iota_6108zisegred_small_17383);
    gpu_free_kernel(ctx, ctx->program->replicated_iota_6108zisegscan_16554);
    gpu_free_kernel(ctx, ctx->program->replicated_iota_6108zisegscan_16591);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhreplicate_boolzitblock_sizze_17299 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_17146 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_17449 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_17116 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.mainzisegmap_num_tblocks_16605 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.mainzisegmap_num_tblocks_16814 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.mainzisegmap_num_tblocks_16822 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.mainzisegmap_num_tblocks_16864 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.mainzisegmap_num_tblocks_16872 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16603 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16619 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16639 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16674 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16812 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16820 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16862 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16870 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.mainzisegmap_tblock_sizze_16878 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.mainzisegscan_num_tblocks_16595 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.mainzisegscan_num_tblocks_16611 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.mainzisegscan_num_tblocks_16713 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.mainzisegscan_num_tblocks_16721 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.mainzisegscan_num_tblocks_16854 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.mainzisegscan_tblock_sizze_16593 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.mainzisegscan_tblock_sizze_16609 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.mainzisegscan_tblock_sizze_16711 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.mainzisegscan_tblock_sizze_16719 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.mainzisegscan_tblock_sizze_16852 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.replicated_iota_6108zihist_L2_17359 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.replicated_iota_6108zihist_L_17306 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.replicated_iota_6108ziseghist_num_tblocks_16568 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.replicated_iota_6108zisegred_num_tblocks_16558 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.replicated_iota_6108zisegred_tblock_sizze_16556 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.replicated_iota_6108zisegscan_num_tblocks_16550 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.replicated_iota_6108zisegscan_num_tblocks_16587 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16548 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16585 = &ctx->cfg->tuning_params[37];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_17290, int64_t num_elems_17291, bool val_17292);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_17137, int64_t num_elems_17138, int32_t val_17139);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_17440, int64_t num_elems_17441, int64_t val_17442);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_17107, int64_t num_elems_17108, int8_t val_17109);
FUTHARK_FUN_ATTR int futrts_cmp_5210(struct futhark_context *ctx, bool *out_prim_out_18361, float a_10315, int32_t aii_10316, float b_10317, int32_t bii_10318);
FUTHARK_FUN_ATTR int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_18362, struct memblock_device ks_mem_16946, struct memblock_device shp_mem_16947, struct memblock_device A_mem_16948, int64_t m_12436, int64_t n_12437);
FUTHARK_FUN_ATTR int futrts_replicated_iota_6108(struct futhark_context *ctx, struct memblock_device *mem_out_p_18369, int64_t *out_prim_out_18370, struct memblock_device reps_mem_16946, int64_t n_9632);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_17243 (ctx->constants->counters_mem_17243)
    #define counters_mem_17420 (ctx->constants->counters_mem_17420)
    #define global_dynid_mem_17132 (ctx->constants->global_dynid_mem_17132)
    #define global_dynid_mem_17135 (ctx->constants->global_dynid_mem_17135)
    #define global_dynid_mem_17338 (ctx->constants->global_dynid_mem_17338)
    #define global_dynid_mem_17475 (ctx->constants->global_dynid_mem_17475)
    #define global_dynid_mem_17508 (ctx->constants->global_dynid_mem_17508)
    #define global_dynid_mem_17738 (ctx->constants->global_dynid_mem_17738)
    #define global_dynid_mem_18233 (ctx->constants->global_dynid_mem_18233)
    counters_mem_17243.references = NULL;
    counters_mem_17420.references = NULL;
    global_dynid_mem_17132.references = NULL;
    global_dynid_mem_17135.references = NULL;
    global_dynid_mem_17338.references = NULL;
    global_dynid_mem_17475.references = NULL;
    global_dynid_mem_17508.references = NULL;
    global_dynid_mem_17738.references = NULL;
    global_dynid_mem_18233.references = NULL;
    if (memblock_alloc_device(ctx, &global_dynid_mem_17132, (int64_t) 4, "global_dynid_mem_17132")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_17132, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_17243, (int64_t) 80, "counters_mem_17243")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_17243, (int64_t) 20, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_17420, (int64_t) 81920, "counters_mem_17420")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_17420, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_17475, (int64_t) 4, "global_dynid_mem_17475")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_17475, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_17135, (int64_t) 4, "global_dynid_mem_17135")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_17135, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_17338, (int64_t) 4, "global_dynid_mem_17338")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_17338, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_17508, (int64_t) 4, "global_dynid_mem_17508")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_17508, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_17738, (int64_t) 4, "global_dynid_mem_17738")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_17738, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_18233, (int64_t) 4, "global_dynid_mem_18233")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_18233, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_17243
    #undef counters_mem_17420
    #undef global_dynid_mem_17132
    #undef global_dynid_mem_17135
    #undef global_dynid_mem_17338
    #undef global_dynid_mem_17475
    #undef global_dynid_mem_17508
    #undef global_dynid_mem_17738
    #undef global_dynid_mem_18233
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_17243, "ctx->constants->counters_mem_17243") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_17420, "ctx->constants->counters_mem_17420") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_17132, "ctx->constants->global_dynid_mem_17132") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_17135, "ctx->constants->global_dynid_mem_17135") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_17338, "ctx->constants->global_dynid_mem_17338") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_17475, "ctx->constants->global_dynid_mem_17475") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_17508, "ctx->constants->global_dynid_mem_17508") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_17738, "ctx->constants->global_dynid_mem_17738") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_18233, "ctx->constants->global_dynid_mem_18233") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhreplicate_boolzireplicate_17295(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, bool arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_boolzireplicate_17295, "builtin#replicate_bool.replicate_17295", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_17142(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_17142, "builtin#replicate_i32.replicate_17142", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i64zireplicate_17445(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_17445, "builtin#replicate_i64.replicate_17445", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_17112(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_17112, "builtin#replicate_i8.replicate_17112", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegscan_16599(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegscan_16599, "main.segscan_16599", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16601(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16601, "main.segmap_16601", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegscan_16615(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegscan_16615, "main.segscan_16615", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16632(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16632, "main.segmap_16632", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16660(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16660, "main.segmap_16660", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16697(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16697, "main.segmap_16697", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegscan_16717(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[19] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17};
        size_t args_sizes[19] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegscan_16717, "main.segscan_16717", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 19, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegscan_16725(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17, gpu_mem arg18, gpu_mem arg19, gpu_mem arg20, gpu_mem arg21, gpu_mem arg22, gpu_mem arg23, gpu_mem arg24, gpu_mem arg25, gpu_mem arg26, gpu_mem arg27, gpu_mem arg28, gpu_mem arg29, gpu_mem arg30, gpu_mem arg31, gpu_mem arg32, gpu_mem arg33, gpu_mem arg34, gpu_mem arg35, gpu_mem arg36, gpu_mem arg37, gpu_mem arg38, gpu_mem arg39, gpu_mem arg40, gpu_mem arg41, gpu_mem arg42)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[46] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17, &arg18, &arg19, &arg20, &arg21, &arg22, &arg23, &arg24, &arg25, &arg26, &arg27, &arg28, &arg29, &arg30, &arg31, &arg32, &arg33, &arg34, &arg35, &arg36, &arg37, &arg38, &arg39, &arg40, &arg41, &arg42};
        size_t args_sizes[46] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17), sizeof(arg18), sizeof(arg19), sizeof(arg20), sizeof(arg21), sizeof(arg22), sizeof(arg23), sizeof(arg24), sizeof(arg25), sizeof(arg26), sizeof(arg27), sizeof(arg28), sizeof(arg29), sizeof(arg30), sizeof(arg31), sizeof(arg32), sizeof(arg33), sizeof(arg34), sizeof(arg35), sizeof(arg36), sizeof(arg37), sizeof(arg38), sizeof(arg39), sizeof(arg40), sizeof(arg41), sizeof(arg42)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegscan_16725, "main.segscan_16725", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 46, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16810(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16810, "main.segmap_16810", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16842(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16842, "main.segmap_16842", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegscan_16858(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegscan_16858, "main.segscan_16858", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16860(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16860, "main.segmap_16860", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16868(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[20] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16};
        size_t args_sizes[20] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16868, "main.segmap_16868", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 20, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_mainzisegmap_16903(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->mainzisegmap_16903, "main.segmap_16903", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_replicated_iota_6108zisegscan_16554(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->replicated_iota_6108zisegscan_16554, "replicated_iota_6108.segscan_16554", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_replicated_iota_6108zisegred_nonseg_16564(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->replicated_iota_6108zisegred_nonseg_16564, "replicated_iota_6108.segred_nonseg_16564", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_replicated_iota_6108ziseghist_local_16574(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->replicated_iota_6108ziseghist_local_16574, "replicated_iota_6108.seghist_local_16574", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_replicated_iota_6108ziseghist_global_16574(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->replicated_iota_6108ziseghist_global_16574, "replicated_iota_6108.seghist_global_16574", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_replicated_iota_6108zisegred_small_17383(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->replicated_iota_6108zisegred_small_17383, "replicated_iota_6108.segred_small_17383", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_replicated_iota_6108zisegred_large_17383(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->replicated_iota_6108zisegred_large_17383, "replicated_iota_6108.segred_large_17383", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_replicated_iota_6108zisegscan_16591(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->replicated_iota_6108zisegscan_16591, "replicated_iota_6108.segscan_16591", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_17290, int64_t num_elems_17291, bool val_17292)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_17243 = ctx->constants->counters_mem_17243;
    struct memblock_device counters_mem_17420 = ctx->constants->counters_mem_17420;
    struct memblock_device global_dynid_mem_17132 = ctx->constants->global_dynid_mem_17132;
    struct memblock_device global_dynid_mem_17135 = ctx->constants->global_dynid_mem_17135;
    struct memblock_device global_dynid_mem_17338 = ctx->constants->global_dynid_mem_17338;
    struct memblock_device global_dynid_mem_17475 = ctx->constants->global_dynid_mem_17475;
    struct memblock_device global_dynid_mem_17508 = ctx->constants->global_dynid_mem_17508;
    struct memblock_device global_dynid_mem_17738 = ctx->constants->global_dynid_mem_17738;
    struct memblock_device global_dynid_mem_18233 = ctx->constants->global_dynid_mem_18233;
    int64_t replicate_n_17294 = num_elems_17291;
    int64_t tblock_sizze_17299;
    
    tblock_sizze_17299 = *ctx->tuning_params.builtinzhreplicate_boolzitblock_sizze_17299;
    
    int64_t virt_num_tblocks_17300 = sdiv_up64(replicate_n_17294, tblock_sizze_17299);
    int64_t num_tblocks_17301 = smin64(virt_num_tblocks_17300, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_boolzireplicate_17295(ctx, num_tblocks_17301, 1, 1, tblock_sizze_17299, 1, 1, (int64_t) 0, num_elems_17291, val_17292, replicate_n_17294, virt_num_tblocks_17300, num_tblocks_17301, mem_17290.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_17137, int64_t num_elems_17138, int32_t val_17139)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_17243 = ctx->constants->counters_mem_17243;
    struct memblock_device counters_mem_17420 = ctx->constants->counters_mem_17420;
    struct memblock_device global_dynid_mem_17132 = ctx->constants->global_dynid_mem_17132;
    struct memblock_device global_dynid_mem_17135 = ctx->constants->global_dynid_mem_17135;
    struct memblock_device global_dynid_mem_17338 = ctx->constants->global_dynid_mem_17338;
    struct memblock_device global_dynid_mem_17475 = ctx->constants->global_dynid_mem_17475;
    struct memblock_device global_dynid_mem_17508 = ctx->constants->global_dynid_mem_17508;
    struct memblock_device global_dynid_mem_17738 = ctx->constants->global_dynid_mem_17738;
    struct memblock_device global_dynid_mem_18233 = ctx->constants->global_dynid_mem_18233;
    int64_t replicate_n_17141 = num_elems_17138;
    int64_t tblock_sizze_17146;
    
    tblock_sizze_17146 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_17146;
    
    int64_t virt_num_tblocks_17147 = sdiv_up64(replicate_n_17141, tblock_sizze_17146);
    int64_t num_tblocks_17148 = smin64(virt_num_tblocks_17147, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_17142(ctx, num_tblocks_17148, 1, 1, tblock_sizze_17146, 1, 1, (int64_t) 0, num_elems_17138, val_17139, replicate_n_17141, virt_num_tblocks_17147, num_tblocks_17148, mem_17137.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_17440, int64_t num_elems_17441, int64_t val_17442)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_17243 = ctx->constants->counters_mem_17243;
    struct memblock_device counters_mem_17420 = ctx->constants->counters_mem_17420;
    struct memblock_device global_dynid_mem_17132 = ctx->constants->global_dynid_mem_17132;
    struct memblock_device global_dynid_mem_17135 = ctx->constants->global_dynid_mem_17135;
    struct memblock_device global_dynid_mem_17338 = ctx->constants->global_dynid_mem_17338;
    struct memblock_device global_dynid_mem_17475 = ctx->constants->global_dynid_mem_17475;
    struct memblock_device global_dynid_mem_17508 = ctx->constants->global_dynid_mem_17508;
    struct memblock_device global_dynid_mem_17738 = ctx->constants->global_dynid_mem_17738;
    struct memblock_device global_dynid_mem_18233 = ctx->constants->global_dynid_mem_18233;
    int64_t replicate_n_17444 = num_elems_17441;
    int64_t tblock_sizze_17449;
    
    tblock_sizze_17449 = *ctx->tuning_params.builtinzhreplicate_i64zitblock_sizze_17449;
    
    int64_t virt_num_tblocks_17450 = sdiv_up64(replicate_n_17444, tblock_sizze_17449);
    int64_t num_tblocks_17451 = smin64(virt_num_tblocks_17450, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i64zireplicate_17445(ctx, num_tblocks_17451, 1, 1, tblock_sizze_17449, 1, 1, (int64_t) 0, num_elems_17441, val_17442, replicate_n_17444, virt_num_tblocks_17450, num_tblocks_17451, mem_17440.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_17107, int64_t num_elems_17108, int8_t val_17109)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_17243 = ctx->constants->counters_mem_17243;
    struct memblock_device counters_mem_17420 = ctx->constants->counters_mem_17420;
    struct memblock_device global_dynid_mem_17132 = ctx->constants->global_dynid_mem_17132;
    struct memblock_device global_dynid_mem_17135 = ctx->constants->global_dynid_mem_17135;
    struct memblock_device global_dynid_mem_17338 = ctx->constants->global_dynid_mem_17338;
    struct memblock_device global_dynid_mem_17475 = ctx->constants->global_dynid_mem_17475;
    struct memblock_device global_dynid_mem_17508 = ctx->constants->global_dynid_mem_17508;
    struct memblock_device global_dynid_mem_17738 = ctx->constants->global_dynid_mem_17738;
    struct memblock_device global_dynid_mem_18233 = ctx->constants->global_dynid_mem_18233;
    int64_t replicate_n_17111 = num_elems_17108;
    int64_t tblock_sizze_17116;
    
    tblock_sizze_17116 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_17116;
    
    int64_t virt_num_tblocks_17117 = sdiv_up64(replicate_n_17111, tblock_sizze_17116);
    int64_t num_tblocks_17118 = smin64(virt_num_tblocks_17117, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_17112(ctx, num_tblocks_17118, 1, 1, tblock_sizze_17116, 1, 1, (int64_t) 0, num_elems_17108, val_17109, replicate_n_17111, virt_num_tblocks_17117, num_tblocks_17118, mem_17107.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_cmp_5210(struct futhark_context *ctx, bool *out_prim_out_18361, float a_10315, int32_t aii_10316, float b_10317, int32_t bii_10318)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_17243 = ctx->constants->counters_mem_17243;
    struct memblock_device counters_mem_17420 = ctx->constants->counters_mem_17420;
    struct memblock_device global_dynid_mem_17132 = ctx->constants->global_dynid_mem_17132;
    struct memblock_device global_dynid_mem_17135 = ctx->constants->global_dynid_mem_17135;
    struct memblock_device global_dynid_mem_17338 = ctx->constants->global_dynid_mem_17338;
    struct memblock_device global_dynid_mem_17475 = ctx->constants->global_dynid_mem_17475;
    struct memblock_device global_dynid_mem_17508 = ctx->constants->global_dynid_mem_17508;
    struct memblock_device global_dynid_mem_17738 = ctx->constants->global_dynid_mem_17738;
    struct memblock_device global_dynid_mem_18233 = ctx->constants->global_dynid_mem_18233;
    bool prim_out_17096;
    bool cond_10319 = aii_10316 == bii_10318;
    bool cmp_res_t_res_10321 = a_10315 <= b_10317;
    bool cmp_res_f_res_10322 = sle32(aii_10316, bii_10318);
    bool x_12442 = cond_10319 && cmp_res_t_res_10321;
    bool x_12443 = !cond_10319;
    bool y_12444 = cmp_res_f_res_10322 && x_12443;
    bool cmp_res_10320 = x_12442 || y_12444;
    
    prim_out_17096 = cmp_res_10320;
    *out_prim_out_18361 = prim_out_17096;
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_18362, struct memblock_device ks_mem_16946, struct memblock_device shp_mem_16947, struct memblock_device A_mem_16948, int64_t m_12436, int64_t n_12437)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_17095;
    
    mem_17095.references = NULL;
    
    struct memblock_device mem_param_tmp_17461;
    
    mem_param_tmp_17461.references = NULL;
    
    struct memblock_device mem_param_tmp_17460;
    
    mem_param_tmp_17460.references = NULL;
    
    struct memblock_device mem_17075;
    
    mem_17075.references = NULL;
    
    struct memblock_device mem_17073;
    
    mem_17073.references = NULL;
    
    struct memblock_device mem_17065;
    
    mem_17065.references = NULL;
    
    struct memblock_device mem_17061;
    
    mem_17061.references = NULL;
    
    struct memblock_device incprefixes_mem_18231;
    
    incprefixes_mem_18231.references = NULL;
    
    struct memblock_device aggregates_mem_18229;
    
    aggregates_mem_18229.references = NULL;
    
    struct memblock_device status_flags_mem_18227;
    
    status_flags_mem_18227.references = NULL;
    
    struct memblock_device mem_17071;
    
    mem_17071.references = NULL;
    
    struct memblock_device mem_17069;
    
    mem_17069.references = NULL;
    
    struct memblock_device mem_17058;
    
    mem_17058.references = NULL;
    
    struct memblock_device mem_17048;
    
    mem_17048.references = NULL;
    
    struct memblock_device mem_17026;
    
    mem_17026.references = NULL;
    
    struct memblock_device mem_17024;
    
    mem_17024.references = NULL;
    
    struct memblock_device mem_17022;
    
    mem_17022.references = NULL;
    
    struct memblock_device incprefixes_mem_17736;
    
    incprefixes_mem_17736.references = NULL;
    
    struct memblock_device aggregates_mem_17734;
    
    aggregates_mem_17734.references = NULL;
    
    struct memblock_device incprefixes_mem_17732;
    
    incprefixes_mem_17732.references = NULL;
    
    struct memblock_device aggregates_mem_17730;
    
    aggregates_mem_17730.references = NULL;
    
    struct memblock_device incprefixes_mem_17728;
    
    incprefixes_mem_17728.references = NULL;
    
    struct memblock_device aggregates_mem_17726;
    
    aggregates_mem_17726.references = NULL;
    
    struct memblock_device incprefixes_mem_17724;
    
    incprefixes_mem_17724.references = NULL;
    
    struct memblock_device aggregates_mem_17722;
    
    aggregates_mem_17722.references = NULL;
    
    struct memblock_device incprefixes_mem_17720;
    
    incprefixes_mem_17720.references = NULL;
    
    struct memblock_device aggregates_mem_17718;
    
    aggregates_mem_17718.references = NULL;
    
    struct memblock_device incprefixes_mem_17716;
    
    incprefixes_mem_17716.references = NULL;
    
    struct memblock_device aggregates_mem_17714;
    
    aggregates_mem_17714.references = NULL;
    
    struct memblock_device incprefixes_mem_17712;
    
    incprefixes_mem_17712.references = NULL;
    
    struct memblock_device aggregates_mem_17710;
    
    aggregates_mem_17710.references = NULL;
    
    struct memblock_device incprefixes_mem_17708;
    
    incprefixes_mem_17708.references = NULL;
    
    struct memblock_device aggregates_mem_17706;
    
    aggregates_mem_17706.references = NULL;
    
    struct memblock_device status_flags_mem_17704;
    
    status_flags_mem_17704.references = NULL;
    
    struct memblock_device mem_17020;
    
    mem_17020.references = NULL;
    
    struct memblock_device mem_17018;
    
    mem_17018.references = NULL;
    
    struct memblock_device mem_17016;
    
    mem_17016.references = NULL;
    
    struct memblock_device mem_17014;
    
    mem_17014.references = NULL;
    
    struct memblock_device mem_17012;
    
    mem_17012.references = NULL;
    
    struct memblock_device mem_17010;
    
    mem_17010.references = NULL;
    
    struct memblock_device mem_17008;
    
    mem_17008.references = NULL;
    
    struct memblock_device mem_17007;
    
    mem_17007.references = NULL;
    
    struct memblock_device mem_17005;
    
    mem_17005.references = NULL;
    
    struct memblock_device mem_17003;
    
    mem_17003.references = NULL;
    
    struct memblock_device mem_17001;
    
    mem_17001.references = NULL;
    
    struct memblock_device incprefixes_mem_17506;
    
    incprefixes_mem_17506.references = NULL;
    
    struct memblock_device aggregates_mem_17504;
    
    aggregates_mem_17504.references = NULL;
    
    struct memblock_device incprefixes_mem_17502;
    
    incprefixes_mem_17502.references = NULL;
    
    struct memblock_device aggregates_mem_17500;
    
    aggregates_mem_17500.references = NULL;
    
    struct memblock_device incprefixes_mem_17498;
    
    incprefixes_mem_17498.references = NULL;
    
    struct memblock_device aggregates_mem_17496;
    
    aggregates_mem_17496.references = NULL;
    
    struct memblock_device status_flags_mem_17494;
    
    status_flags_mem_17494.references = NULL;
    
    struct memblock_device mem_16999;
    
    mem_16999.references = NULL;
    
    struct memblock_device mem_16998;
    
    mem_16998.references = NULL;
    
    struct memblock_device mem_16996;
    
    mem_16996.references = NULL;
    
    struct memblock_device mem_16994;
    
    mem_16994.references = NULL;
    
    struct memblock_device mem_16992;
    
    mem_16992.references = NULL;
    
    struct memblock_device mem_16990;
    
    mem_16990.references = NULL;
    
    struct memblock_device ext_mem_16988;
    
    ext_mem_16988.references = NULL;
    
    struct memblock_device mem_16986;
    
    mem_16986.references = NULL;
    
    struct memblock_device mem_16984;
    
    mem_16984.references = NULL;
    
    struct memblock_device mem_16982;
    
    mem_16982.references = NULL;
    
    struct memblock_device mem_param_16979;
    
    mem_param_16979.references = NULL;
    
    struct memblock_device mem_param_16976;
    
    mem_param_16976.references = NULL;
    
    struct memblock_device ext_mem_17086;
    
    ext_mem_17086.references = NULL;
    
    struct memblock_device ext_mem_17087;
    
    ext_mem_17087.references = NULL;
    
    struct memblock_device mem_16967;
    
    mem_16967.references = NULL;
    
    struct memblock_device mem_16966;
    
    mem_16966.references = NULL;
    
    struct memblock_device mem_16965;
    
    mem_16965.references = NULL;
    
    struct memblock_device mem_16963;
    
    mem_16963.references = NULL;
    
    struct memblock_device ext_mem_17092;
    
    ext_mem_17092.references = NULL;
    
    struct memblock_device incprefixes_mem_17336;
    
    incprefixes_mem_17336.references = NULL;
    
    struct memblock_device aggregates_mem_17334;
    
    aggregates_mem_17334.references = NULL;
    
    struct memblock_device status_flags_mem_17332;
    
    status_flags_mem_17332.references = NULL;
    
    struct memblock_device mem_16961;
    
    mem_16961.references = NULL;
    
    struct memblock_device mem_16954;
    
    mem_16954.references = NULL;
    
    struct memblock_device incprefixes_mem_17133;
    
    incprefixes_mem_17133.references = NULL;
    
    struct memblock_device aggregates_mem_17131;
    
    aggregates_mem_17131.references = NULL;
    
    struct memblock_device incprefixes_mem_17129;
    
    incprefixes_mem_17129.references = NULL;
    
    struct memblock_device aggregates_mem_17127;
    
    aggregates_mem_17127.references = NULL;
    
    struct memblock_device status_flags_mem_17105;
    
    status_flags_mem_17105.references = NULL;
    
    struct memblock_device mem_16953;
    
    mem_16953.references = NULL;
    
    struct memblock_device mem_16951;
    
    mem_16951.references = NULL;
    
    struct memblock_device mem_out_17096;
    
    mem_out_17096.references = NULL;
    
    struct memblock_device counters_mem_17243 = ctx->constants->counters_mem_17243;
    struct memblock_device counters_mem_17420 = ctx->constants->counters_mem_17420;
    struct memblock_device global_dynid_mem_17132 = ctx->constants->global_dynid_mem_17132;
    struct memblock_device global_dynid_mem_17135 = ctx->constants->global_dynid_mem_17135;
    struct memblock_device global_dynid_mem_17338 = ctx->constants->global_dynid_mem_17338;
    struct memblock_device global_dynid_mem_17475 = ctx->constants->global_dynid_mem_17475;
    struct memblock_device global_dynid_mem_17508 = ctx->constants->global_dynid_mem_17508;
    struct memblock_device global_dynid_mem_17738 = ctx->constants->global_dynid_mem_17738;
    struct memblock_device global_dynid_mem_18233 = ctx->constants->global_dynid_mem_18233;
    int64_t bytes_16950 = (int64_t) 8 * m_12436;
    int64_t bytes_16952 = (int64_t) 4 * m_12436;
    int64_t bytes_16957 = (int64_t) 4 * n_12437;
    int64_t segscan_tblock_sizze_16594;
    
    segscan_tblock_sizze_16594 = *ctx->tuning_params.mainzisegscan_tblock_sizze_16593;
    
    int64_t num_tblocks_16596;
    int64_t max_num_tblocks_17097;
    
    max_num_tblocks_17097 = *ctx->tuning_params.mainzisegscan_num_tblocks_16595;
    num_tblocks_16596 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_12436, segscan_tblock_sizze_16594), max_num_tblocks_17097)));
    if (memblock_alloc_device(ctx, &mem_16951, bytes_16950, "mem_16951")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_16953, bytes_16952, "mem_16953")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, m_12436)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_17098;
        
        shared_memory_17098 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_17099;
        
        thread_block_sizze_17099 = ctx->max_thread_block_size;
        
        int64_t registers_17100;
        
        registers_17100 = ctx->max_registers;
        
        int64_t thread_block_sizze_17101;
        
        thread_block_sizze_17101 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_17102 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_17098, thread_block_sizze_17099), (int64_t) 8), squot64(squot64(registers_17100, thread_block_sizze_17101) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_17103 = sdiv_up64(m_12436, segscan_tblock_sizze_16594 * chunk_sizze_17102);
        int64_t num_virt_threads_17104 = num_virt_blocks_17103 * segscan_tblock_sizze_16594;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_17102, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_17105, num_virt_blocks_17103, "status_flags_mem_17105")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_17105, num_virt_blocks_17103, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_17127, (int64_t) 8 * num_virt_blocks_17103, "aggregates_mem_17127")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_17129, (int64_t) 8 * num_virt_blocks_17103, "incprefixes_mem_17129")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_17131, (int64_t) 4 * num_virt_blocks_17103, "aggregates_mem_17131")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_17133, (int64_t) 4 * num_virt_blocks_17103, "incprefixes_mem_17133")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_mainzisegscan_16599(ctx, num_tblocks_16596, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_16593, 1, 1, smax64(smax64((int64_t) 416, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_16594, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_16594), smax64(chunk_sizze_17102 * segscan_tblock_sizze_16594 * (int64_t) 8, chunk_sizze_17102 * segscan_tblock_sizze_16594 * (int64_t) 4)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 416, sdiv_up64((int64_t) 8 * segscan_tblock_sizze_16594, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_16594), smax64(chunk_sizze_17102 * segscan_tblock_sizze_16594 * (int64_t) 8, chunk_sizze_17102 * segscan_tblock_sizze_16594 * (int64_t) 4)), (int64_t) 8), (int64_t) 8), m_12436, num_tblocks_16596, num_virt_blocks_17103, num_virt_threads_17104, shp_mem_16947.mem, mem_16951.mem, mem_16953.mem, status_flags_mem_17105.mem, aggregates_mem_17127.mem, incprefixes_mem_17129.mem, aggregates_mem_17131.mem, incprefixes_mem_17133.mem, global_dynid_mem_17135.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_alloc_device(ctx, &mem_16954, n_12437, "mem_16954")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_16954, n_12437, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_16604;
    
    segmap_tblock_sizze_16604 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16603;
    
    int64_t num_tblocks_16606;
    int64_t max_num_tblocks_17310;
    
    max_num_tblocks_17310 = *ctx->tuning_params.mainzisegmap_num_tblocks_16605;
    num_tblocks_16606 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_12436, segmap_tblock_sizze_16604), max_num_tblocks_17310)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_17311 = sext_i64_i32(sdiv_up64(m_12436, segmap_tblock_sizze_16604));
    
    {
        err = gpu_kernel_mainzisegmap_16601(ctx, num_tblocks_16606, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16603, 1, 1, (int64_t) 0, m_12436, n_12437, num_tblocks_16606, virt_num_tblocks_17311, mem_16951.mem, mem_16954.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_16951, "mem_16951") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_16610;
    
    segscan_tblock_sizze_16610 = *ctx->tuning_params.mainzisegscan_tblock_sizze_16609;
    
    int64_t num_tblocks_16612;
    int64_t max_num_tblocks_17324;
    
    max_num_tblocks_17324 = *ctx->tuning_params.mainzisegscan_num_tblocks_16611;
    num_tblocks_16612 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_12437, segscan_tblock_sizze_16610), max_num_tblocks_17324)));
    if (memblock_alloc_device(ctx, &mem_16961, bytes_16957, "mem_16961")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, n_12437)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_17325;
        
        shared_memory_17325 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_17326;
        
        thread_block_sizze_17326 = ctx->max_thread_block_size;
        
        int64_t registers_17327;
        
        registers_17327 = ctx->max_registers;
        
        int64_t thread_block_sizze_17328;
        
        thread_block_sizze_17328 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_17329 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_17325, thread_block_sizze_17326), (int64_t) 4), squot64(squot64(registers_17327, thread_block_sizze_17328) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_17330 = sdiv_up64(n_12437, segscan_tblock_sizze_16610 * chunk_sizze_17329);
        int64_t num_virt_threads_17331 = num_virt_blocks_17330 * segscan_tblock_sizze_16610;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_17329, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_17332, num_virt_blocks_17330, "status_flags_mem_17332")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_17332, num_virt_blocks_17330, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_17334, (int64_t) 4 * num_virt_blocks_17330, "aggregates_mem_17334")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_17336, (int64_t) 4 * num_virt_blocks_17330, "incprefixes_mem_17336")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_mainzisegscan_16615(ctx, num_tblocks_16612, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_16609, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_16610), chunk_sizze_17329 * segscan_tblock_sizze_16610 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_16610), chunk_sizze_17329 * segscan_tblock_sizze_16610 * (int64_t) 4), (int64_t) 8), (int64_t) 8), n_12437, num_tblocks_16612, num_virt_blocks_17330, num_virt_threads_17331, mem_16954.mem, mem_16961.mem, status_flags_mem_17332.mem, aggregates_mem_17334.mem, incprefixes_mem_17336.mem, global_dynid_mem_17338.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_16954, "mem_16954") != 0)
        return 1;
    
    int64_t segmap_tblock_sizze_16628;
    
    segmap_tblock_sizze_16628 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16619;
    
    int64_t segmap_usable_groups_16629 = sdiv_up64(n_12437, segmap_tblock_sizze_16628);
    
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_17427 = sext_i64_i32(sdiv_up64(n_12437, segmap_tblock_sizze_16628));
    
    {
        err = gpu_kernel_mainzisegmap_16632(ctx, segmap_usable_groups_16629, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16619, 1, 1, (int64_t) 0, n_12437, mem_16961.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    // Trace: unknown location
    {
        fprintf(ctx->log, "%s", "unknown location: ");
        for (int64_t nest_i_17436 = 0; nest_i_17436 < n_12437; nest_i_17436++) {
            float read_res_18363;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_18363, A_mem_16948.mem, nest_i_17436 * sizeof(float), sizeof(float))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            float arr_elem_17437 = read_res_18363;
            
            fprintf(ctx->log, "%f%s", (double) arr_elem_17437, " ");
        }
        fprintf(ctx->log, "%s", "\n");
    }
    // Trace: unknown location
    {
        fprintf(ctx->log, "%s", "unknown location: ");
        for (int64_t nest_i_17438 = 0; nest_i_17438 < n_12437; nest_i_17438++) {
            int32_t read_res_18364;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_18364, mem_16961.mem, nest_i_17438 * sizeof(int32_t), sizeof(int32_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int32_t arr_elem_17439 = read_res_18364;
            
            fprintf(ctx->log, "%d%s", arr_elem_17439, " ");
        }
        fprintf(ctx->log, "%s", "\n");
    }
    
    bool cond_14117 = slt64(n_12437, (int64_t) 2);
    int64_t segmap_tblock_sizze_16655;
    
    segmap_tblock_sizze_16655 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16639;
    
    int64_t segmap_tblock_sizze_16692;
    
    segmap_tblock_sizze_16692 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16674;
    
    int64_t segscan_tblock_sizze_16712;
    
    segscan_tblock_sizze_16712 = *ctx->tuning_params.mainzisegscan_tblock_sizze_16711;
    
    int64_t segscan_tblock_sizze_16720;
    
    segscan_tblock_sizze_16720 = *ctx->tuning_params.mainzisegscan_tblock_sizze_16719;
    
    int64_t segmap_tblock_sizze_16813;
    
    segmap_tblock_sizze_16813 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16812;
    
    int64_t segmap_tblock_sizze_16836;
    
    segmap_tblock_sizze_16836 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16820;
    
    int64_t segscan_tblock_sizze_16853;
    
    segscan_tblock_sizze_16853 = *ctx->tuning_params.mainzisegscan_tblock_sizze_16852;
    
    int64_t segmap_tblock_sizze_16863;
    
    segmap_tblock_sizze_16863 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16862;
    
    int64_t segmap_tblock_sizze_16871;
    
    segmap_tblock_sizze_16871 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16870;
    if (cond_14117) {
        if (memblock_set_device(ctx, &ext_mem_17092, &A_mem_16948, "A_mem_16948") != 0)
            return 1;
    } else {
        if (memblock_alloc_device(ctx, &mem_16963, bytes_16957, "mem_16963")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_16963.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, A_mem_16948.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_12437})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_16965, bytes_16957, "mem_16965")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_16965.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_16961.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {n_12437})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_16966, (int64_t) 8, "mem_16966")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_16966, (int64_t) 1, (int64_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_16967, (int64_t) 8, "mem_16967")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i64(ctx, mem_16967, (int64_t) 1, n_12437) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t defunc_0_qsort_res_f_res_14124;
        bool defunc_0_qsort_res_f_res_14125;
        int64_t loop_dz2085U_14130;
        bool loop_while_14131;
        
        if (memblock_set_device(ctx, &mem_param_16976, &mem_16966, "mem_16966") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_16979, &mem_16967, "mem_16967") != 0)
            return 1;
        loop_dz2085U_14130 = (int64_t) 1;
        loop_while_14131 = 1;
        while (loop_while_14131) {
            int64_t dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136 = mul64((int64_t) 2, loop_dz2085U_14130);
            int64_t segmap_usable_groups_16656 = sdiv_up64(loop_dz2085U_14130, segmap_tblock_sizze_16655);
            int64_t bytes_16981 = (int64_t) 4 * loop_dz2085U_14130;
            
            if (memblock_alloc_device(ctx, &mem_16982, bytes_16981, "mem_16982")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_16984, bytes_16981, "mem_16984")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_17468 = sext_i64_i32(sdiv_up64(loop_dz2085U_14130, segmap_tblock_sizze_16655));
            
            {
                err = gpu_kernel_mainzisegmap_16660(ctx, segmap_usable_groups_16656, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16639, 1, 1, (int64_t) 0, n_12437, loop_dz2085U_14130, mem_16963.mem, mem_16965.mem, mem_param_16976.mem, mem_param_16979.mem, mem_16982.mem, mem_16984.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            
            int64_t bytes_16985 = (int64_t) 8 * loop_dz2085U_14130;
            
            if (memblock_alloc_device(ctx, &mem_16986, bytes_16985, "mem_16986")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_16986.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_16979.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {loop_dz2085U_14130})) != 0)
                goto cleanup;
            
            int64_t idxs_14149;
            
            if (futrts_replicated_iota_6108(ctx, &ext_mem_16988, &idxs_14149, mem_16986, loop_dz2085U_14130) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_unref_device(ctx, &mem_16986, "mem_16986") != 0)
                return 1;
            
            int64_t segmap_usable_groups_16693 = sdiv_up64(idxs_14149, segmap_tblock_sizze_16692);
            int64_t bytes_16991 = (int64_t) 8 * idxs_14149;
            
            if (memblock_alloc_device(ctx, &mem_16990, idxs_14149, "mem_16990")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_16992, bytes_16991, "mem_16992")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_17477 = sext_i64_i32(sdiv_up64(idxs_14149, segmap_tblock_sizze_16692));
            
            {
                err = gpu_kernel_mainzisegmap_16697(ctx, segmap_usable_groups_16693, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16674, 1, 1, (int64_t) 0, loop_dz2085U_14130, idxs_14149, mem_param_16976.mem, ext_mem_16988.mem, mem_16990.mem, mem_16992.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            
            bool y_14229 = slt64((int64_t) 0, idxs_14149);
            bool index_certs_14230;
            
            if (!y_14229) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) idxs_14149, "].", "-> #0  lib/github.com/diku-dk/sorts/quick_sort.fut:52:8-29\n   #1  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #2  naiveCompiler.fut:10:40-49\n   #3  naiveCompiler.fut:15:1-18:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            bool write_tmp_18365 = 1;
            
            if ((err = gpu_scalar_to_device(ctx, mem_16990.mem, (int64_t) 0 * sizeof(bool), sizeof(bool), &write_tmp_18365)) != 0)
                goto cleanup;
            
            int64_t num_tblocks_16714;
            int64_t max_num_tblocks_17486;
            
            max_num_tblocks_17486 = *ctx->tuning_params.mainzisegscan_num_tblocks_16713;
            num_tblocks_16714 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(idxs_14149, segscan_tblock_sizze_16712), max_num_tblocks_17486)));
            if (memblock_alloc_device(ctx, &mem_16994, idxs_14149, "mem_16994")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_16996, bytes_16991, "mem_16996")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_16998, bytes_16991, "mem_16998")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_16999, idxs_14149, "mem_16999")) {
                err = 1;
                goto cleanup;
            }
            if (slt64((int64_t) 0, idxs_14149)) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegScan");
                
                int64_t shared_memory_17487;
                
                shared_memory_17487 = ctx->max_shared_memory;
                
                int64_t thread_block_sizze_17488;
                
                thread_block_sizze_17488 = ctx->max_thread_block_size;
                
                int64_t registers_17489;
                
                registers_17489 = ctx->max_registers;
                
                int64_t thread_block_sizze_17490;
                
                thread_block_sizze_17490 = ctx->max_thread_block_size;
                
                int64_t chunk_sizze_17491 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_17487, thread_block_sizze_17488), (int64_t) 8), squot64(squot64(registers_17489, thread_block_sizze_17490) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
                int64_t num_virt_blocks_17492 = sdiv_up64(idxs_14149, segscan_tblock_sizze_16712 * chunk_sizze_17491);
                int64_t num_virt_threads_17493 = num_virt_blocks_17492 * segscan_tblock_sizze_16712;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_17491, '\n');
                if (memblock_alloc_device(ctx, &status_flags_mem_17494, num_virt_blocks_17492, "status_flags_mem_17494")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_17494, num_virt_blocks_17492, (int8_t) 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17496, num_virt_blocks_17492, "aggregates_mem_17496")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17498, num_virt_blocks_17492, "incprefixes_mem_17498")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17500, (int64_t) 8 * num_virt_blocks_17492, "aggregates_mem_17500")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17502, (int64_t) 8 * num_virt_blocks_17492, "incprefixes_mem_17502")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17504, (int64_t) 8 * num_virt_blocks_17492, "aggregates_mem_17504")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17506, (int64_t) 8 * num_virt_blocks_17492, "incprefixes_mem_17506")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_mainzisegscan_16717(ctx, num_tblocks_16714, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_16711, 1, 1, smax64(smax64((int64_t) 576, sdiv_up64(sdiv_up64(segscan_tblock_sizze_16712, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16712, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16712), smax64(smax64(chunk_sizze_17491 * segscan_tblock_sizze_16712, chunk_sizze_17491 * segscan_tblock_sizze_16712 * (int64_t) 8), chunk_sizze_17491 * segscan_tblock_sizze_16712 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 576, sdiv_up64(sdiv_up64(segscan_tblock_sizze_16712, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16712, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16712), smax64(smax64(chunk_sizze_17491 * segscan_tblock_sizze_16712, chunk_sizze_17491 * segscan_tblock_sizze_16712 * (int64_t) 8), chunk_sizze_17491 * segscan_tblock_sizze_16712 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), idxs_14149, num_tblocks_16714, num_virt_blocks_17492, num_virt_threads_17493, mem_16990.mem, mem_16992.mem, mem_16994.mem, mem_16996.mem, mem_16998.mem, mem_16999.mem, status_flags_mem_17494.mem, aggregates_mem_17496.mem, incprefixes_mem_17498.mem, aggregates_mem_17500.mem, incprefixes_mem_17502.mem, aggregates_mem_17504.mem, incprefixes_mem_17506.mem, global_dynid_mem_17508.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
            }
            if (memblock_unref_device(ctx, &mem_16994, "mem_16994") != 0)
                return 1;
            
            int64_t num_tblocks_16722;
            int64_t max_num_tblocks_17696;
            
            max_num_tblocks_17696 = *ctx->tuning_params.mainzisegscan_num_tblocks_16721;
            num_tblocks_16722 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(idxs_14149, segscan_tblock_sizze_16720), max_num_tblocks_17696)));
            
            int64_t bytes_17015 = (int64_t) 4 * idxs_14149;
            
            if (memblock_alloc_device(ctx, &mem_17001, idxs_14149, "mem_17001")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17003, bytes_16991, "mem_17003")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17005, bytes_16991, "mem_17005")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17007, bytes_16991, "mem_17007")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17008, idxs_14149, "mem_17008")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17010, bytes_16991, "mem_17010")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17012, bytes_16991, "mem_17012")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17014, bytes_16991, "mem_17014")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17016, bytes_17015, "mem_17016")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17018, bytes_17015, "mem_17018")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17020, bytes_16991, "mem_17020")) {
                err = 1;
                goto cleanup;
            }
            if (slt64((int64_t) 0, idxs_14149)) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegScan");
                
                int64_t shared_memory_17697;
                
                shared_memory_17697 = ctx->max_shared_memory;
                
                int64_t thread_block_sizze_17698;
                
                thread_block_sizze_17698 = ctx->max_thread_block_size;
                
                int64_t registers_17699;
                
                registers_17699 = ctx->max_registers;
                
                int64_t thread_block_sizze_17700;
                
                thread_block_sizze_17700 = ctx->max_thread_block_size;
                
                int64_t chunk_sizze_17701 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_17697, thread_block_sizze_17698), (int64_t) 8), squot64(squot64(registers_17699, thread_block_sizze_17700) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
                int64_t num_virt_blocks_17702 = sdiv_up64(idxs_14149, segscan_tblock_sizze_16720 * chunk_sizze_17701);
                int64_t num_virt_threads_17703 = num_virt_blocks_17702 * segscan_tblock_sizze_16720;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_17701, '\n');
                if (memblock_alloc_device(ctx, &status_flags_mem_17704, num_virt_blocks_17702, "status_flags_mem_17704")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_17704, num_virt_blocks_17702, (int8_t) 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17706, num_virt_blocks_17702, "aggregates_mem_17706")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17708, num_virt_blocks_17702, "incprefixes_mem_17708")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17710, (int64_t) 8 * num_virt_blocks_17702, "aggregates_mem_17710")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17712, (int64_t) 8 * num_virt_blocks_17702, "incprefixes_mem_17712")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17714, (int64_t) 8 * num_virt_blocks_17702, "aggregates_mem_17714")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17716, (int64_t) 8 * num_virt_blocks_17702, "incprefixes_mem_17716")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17718, (int64_t) 8 * num_virt_blocks_17702, "aggregates_mem_17718")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17720, (int64_t) 8 * num_virt_blocks_17702, "incprefixes_mem_17720")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17722, num_virt_blocks_17702, "aggregates_mem_17722")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17724, num_virt_blocks_17702, "incprefixes_mem_17724")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17726, (int64_t) 8 * num_virt_blocks_17702, "aggregates_mem_17726")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17728, (int64_t) 8 * num_virt_blocks_17702, "incprefixes_mem_17728")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17730, (int64_t) 8 * num_virt_blocks_17702, "aggregates_mem_17730")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17732, (int64_t) 8 * num_virt_blocks_17702, "incprefixes_mem_17732")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_17734, (int64_t) 8 * num_virt_blocks_17702, "aggregates_mem_17734")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_17736, (int64_t) 8 * num_virt_blocks_17702, "incprefixes_mem_17736")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_mainzisegscan_16725(ctx, num_tblocks_16722, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_16719, 1, 1, smax64(smax64((int64_t) 1632, sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 1) + segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720), smax64(smax64(smax64(smax64(smax64(smax64(smax64(chunk_sizze_17701 * segscan_tblock_sizze_16720, chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 1632, sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(sdiv_up64(segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 1) + segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16720), smax64(smax64(smax64(smax64(smax64(smax64(smax64(chunk_sizze_17701 * segscan_tblock_sizze_16720, chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8), chunk_sizze_17701 * segscan_tblock_sizze_16720 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), n_12437, loop_dz2085U_14130, idxs_14149, num_tblocks_16722, num_virt_blocks_17702, num_virt_threads_17703, mem_16963.mem, mem_16965.mem, mem_16982.mem, mem_16984.mem, ext_mem_16988.mem, mem_16990.mem, mem_16992.mem, mem_16996.mem, mem_17001.mem, mem_17003.mem, mem_17005.mem, mem_17007.mem, mem_17008.mem, mem_17010.mem, mem_17012.mem, mem_17014.mem, mem_17016.mem, mem_17018.mem, mem_17020.mem, status_flags_mem_17704.mem, aggregates_mem_17706.mem, incprefixes_mem_17708.mem, aggregates_mem_17710.mem, incprefixes_mem_17712.mem, aggregates_mem_17714.mem, incprefixes_mem_17716.mem, aggregates_mem_17718.mem, incprefixes_mem_17720.mem, aggregates_mem_17722.mem, incprefixes_mem_17724.mem, aggregates_mem_17726.mem, incprefixes_mem_17728.mem, aggregates_mem_17730.mem, incprefixes_mem_17732.mem, aggregates_mem_17734.mem, incprefixes_mem_17736.mem, global_dynid_mem_17738.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
            }
            if (memblock_unref_device(ctx, &mem_16982, "mem_16982") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16984, "mem_16984") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16990, "mem_16990") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16992, "mem_16992") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16996, "mem_16996") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17001, "mem_17001") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17008, "mem_17008") != 0)
                return 1;
            
            int64_t num_segments_t_res_14268;
            
            if (y_14229) {
                int64_t tmp_16482 = sub64(idxs_14149, (int64_t) 1);
                bool x_16483 = sle64((int64_t) 0, tmp_16482);
                bool y_16484 = slt64(tmp_16482, idxs_14149);
                bool bounds_check_16485 = x_16483 && y_16484;
                bool index_certs_16486;
                
                if (!bounds_check_16485) {
                    set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_16482, "] out of bounds for array of shape [", (long long) idxs_14149, "].", "-> #0  /prelude/array.fut:28:29-37\n   #1  lib/github.com/diku-dk/segmented/segmented.fut:29:36-60\n   #2  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #3  naiveCompiler.fut:10:40-49\n   #4  naiveCompiler.fut:15:1-18:42\n"));
                    err = FUTHARK_PROGRAM_ERROR;
                    goto cleanup;
                }
                
                int64_t read_res_18366;
                
                if ((err = gpu_scalar_from_device(ctx, &read_res_18366, mem_16998.mem, tmp_16482 * sizeof(int64_t), sizeof(int64_t))) != 0)
                    goto cleanup;
                if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                    err = 1;
                    goto cleanup;
                }
                
                int64_t last_res_16487 = read_res_18366;
                
                num_segments_t_res_14268 = last_res_16487;
            } else {
                num_segments_t_res_14268 = (int64_t) 0;
            }
            
            int64_t num_segments_14275;
            
            if (y_14229) {
                num_segments_14275 = num_segments_t_res_14268;
            } else {
                num_segments_14275 = (int64_t) 0;
            }
            
            int64_t bytes_17021 = (int64_t) 8 * num_segments_14275;
            
            if (memblock_alloc_device(ctx, &mem_17022, bytes_17021, "mem_17022")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i64(ctx, mem_17022, num_segments_14275, (int64_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17024, bytes_17021, "mem_17024")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i64(ctx, mem_17024, num_segments_14275, (int64_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17026, bytes_17021, "mem_17026")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i64(ctx, mem_17026, num_segments_14275, (int64_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t num_tblocks_16815;
            int64_t max_num_tblocks_18191;
            
            max_num_tblocks_18191 = *ctx->tuning_params.mainzisegmap_num_tblocks_16814;
            num_tblocks_16815 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(idxs_14149, segmap_tblock_sizze_16813), max_num_tblocks_18191)));
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_18192 = sext_i64_i32(sdiv_up64(idxs_14149, segmap_tblock_sizze_16813));
            
            {
                err = gpu_kernel_mainzisegmap_16810(ctx, num_tblocks_16815, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16812, 1, 1, (int64_t) 0, idxs_14149, num_segments_14275, num_tblocks_16815, virt_num_tblocks_18192, mem_16998.mem, mem_16999.mem, mem_17010.mem, mem_17012.mem, mem_17014.mem, mem_17022.mem, mem_17024.mem, mem_17026.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_16998, "mem_16998") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_16999, "mem_16999") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17010, "mem_17010") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17012, "mem_17012") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17014, "mem_17014") != 0)
                return 1;
            
            bool eq_x_y_14291 = loop_dz2085U_14130 == num_segments_t_res_14268;
            bool eq_x_zz_14292 = loop_dz2085U_14130 == (int64_t) 0;
            bool p_and_eq_x_y_14293 = y_14229 && eq_x_y_14291;
            bool not_p_14294 = !y_14229;
            bool p_and_eq_x_y_14295 = eq_x_zz_14292 && not_p_14294;
            bool dim_match_14296 = p_and_eq_x_y_14293 || p_and_eq_x_y_14295;
            bool empty_or_match_cert_14297;
            
            if (!dim_match_14296) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (desugared) shape [", (long long) num_segments_14275, "] cannot match shape of type `[", (long long) loop_dz2085U_14130, "](i64, i64, i64)`.", "-> #0  lib/github.com/diku-dk/sorts/quick_sort.fut:55:14-79\n   #1  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #2  naiveCompiler.fut:10:40-49\n   #3  naiveCompiler.fut:15:1-18:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t num_tblocks_16837;
            int64_t max_num_tblocks_18205;
            
            max_num_tblocks_18205 = *ctx->tuning_params.mainzisegmap_num_tblocks_16822;
            num_tblocks_16837 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2085U_14130, segmap_tblock_sizze_16836), max_num_tblocks_18205)));
            
            int64_t binop_y_17039 = loop_dz2085U_14130 - (int64_t) 1;
            int64_t binop_x_17041 = smax64((int64_t) 0, binop_y_17039);
            int64_t binop_y_17044 = smax64((int64_t) 0, loop_dz2085U_14130);
            int64_t binop_y_17045 = binop_x_17041 + binop_y_17044;
            int64_t binop_y_17046 = (int64_t) 1 + binop_y_17045;
            int64_t bytes_17047 = (int64_t) 8 * binop_y_17046;
            
            if (memblock_alloc_device(ctx, &mem_17048, bytes_17047, "mem_17048")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17058, bytes_17047, "mem_17058")) {
                err = 1;
                goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_18206 = sext_i64_i32(sdiv_up64(loop_dz2085U_14130, segmap_tblock_sizze_16836));
            
            {
                err = gpu_kernel_mainzisegmap_16842(ctx, num_tblocks_16837, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16820, 1, 1, (int64_t) 0, loop_dz2085U_14130, num_tblocks_16837, virt_num_tblocks_18206, mem_param_16976.mem, mem_17022.mem, mem_17024.mem, mem_17026.mem, mem_17048.mem, mem_17058.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_17026, "mem_17026") != 0)
                return 1;
            
            int64_t bytes_17060 = (int64_t) 16 * loop_dz2085U_14130;
            int64_t num_tblocks_16855;
            int64_t max_num_tblocks_18219;
            
            max_num_tblocks_18219 = *ctx->tuning_params.mainzisegscan_num_tblocks_16854;
            num_tblocks_16855 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, segscan_tblock_sizze_16853), max_num_tblocks_18219)));
            if (memblock_alloc_device(ctx, &mem_17069, bytes_17060, "mem_17069")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &mem_17071, bytes_17060, "mem_17071")) {
                err = 1;
                goto cleanup;
            }
            if (slt64((int64_t) 0, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136)) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "\n# SegScan");
                
                int64_t shared_memory_18220;
                
                shared_memory_18220 = ctx->max_shared_memory;
                
                int64_t thread_block_sizze_18221;
                
                thread_block_sizze_18221 = ctx->max_thread_block_size;
                
                int64_t registers_18222;
                
                registers_18222 = ctx->max_registers;
                
                int64_t thread_block_sizze_18223;
                
                thread_block_sizze_18223 = ctx->max_thread_block_size;
                
                int64_t chunk_sizze_18224 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_18220, thread_block_sizze_18221), (int64_t) 8), squot64(squot64(registers_18222, thread_block_sizze_18223) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
                int64_t num_virt_blocks_18225 = sdiv_up64(dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, segscan_tblock_sizze_16853 * chunk_sizze_18224);
                int64_t num_virt_threads_18226 = num_virt_blocks_18225 * segscan_tblock_sizze_16853;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_18224, '\n');
                if (memblock_alloc_device(ctx, &status_flags_mem_18227, num_virt_blocks_18225, "status_flags_mem_18227")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_18227, num_virt_blocks_18225, (int8_t) 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &aggregates_mem_18229, (int64_t) 8 * num_virt_blocks_18225, "aggregates_mem_18229")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &incprefixes_mem_18231, (int64_t) 8 * num_virt_blocks_18225, "incprefixes_mem_18231")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_mainzisegscan_16858(ctx, num_tblocks_16855, 1, 1, *ctx->tuning_params.mainzisegscan_tblock_sizze_16852, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16853), chunk_sizze_18224 * segscan_tblock_sizze_16853 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16853), chunk_sizze_18224 * segscan_tblock_sizze_16853 * (int64_t) 8), (int64_t) 8), (int64_t) 8), loop_dz2085U_14130, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, num_tblocks_16855, num_virt_blocks_18225, num_virt_threads_18226, mem_17058.mem, mem_17069.mem, mem_17071.mem, status_flags_mem_18227.mem, aggregates_mem_18229.mem, incprefixes_mem_18231.mem, global_dynid_mem_18233.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "");
            }
            
            bool cond_14322 = dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136 == (int64_t) 0;
            bool x_14323 = !cond_14322;
            int64_t tmp_14324 = sub64(dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, (int64_t) 1);
            bool x_14325 = sle64((int64_t) 0, tmp_14324);
            bool y_14326 = slt64(tmp_14324, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136);
            bool bounds_check_14327 = x_14325 && y_14326;
            bool protect_assert_disj_14328 = cond_14322 || bounds_check_14327;
            bool index_certs_14329;
            
            if (!protect_assert_disj_14328) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_14324, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #3  naiveCompiler.fut:10:40-49\n   #4  naiveCompiler.fut:15:1-18:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t m_f_res_14330;
            
            if (x_14323) {
                int64_t read_res_18367;
                
                if ((err = gpu_scalar_from_device(ctx, &read_res_18367, mem_17069.mem, tmp_14324 * sizeof(int64_t), sizeof(int64_t))) != 0)
                    goto cleanup;
                if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                    err = 1;
                    goto cleanup;
                }
                
                int64_t x_16489 = read_res_18367;
                
                m_f_res_14330 = x_16489;
            } else {
                m_f_res_14330 = (int64_t) 0;
            }
            
            int64_t m_14332;
            
            if (cond_14322) {
                m_14332 = (int64_t) 0;
            } else {
                m_14332 = m_f_res_14330;
            }
            
            int64_t m_14342 = sub64(m_14332, (int64_t) 1);
            bool i_p_m_t_s_leq_w_14344 = slt64(m_14342, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136);
            bool zzero_leq_i_p_m_t_s_14343 = sle64((int64_t) 0, m_14342);
            bool y_14346 = zzero_leq_i_p_m_t_s_14343 && i_p_m_t_s_leq_w_14344;
            bool i_lte_j_14345 = sle64((int64_t) 0, m_14332);
            bool forwards_ok_14347 = i_lte_j_14345 && y_14346;
            bool eq_x_zz_14339 = (int64_t) 0 == m_f_res_14330;
            bool p_and_eq_x_y_14340 = x_14323 && eq_x_zz_14339;
            bool empty_slice_14341 = cond_14322 || p_and_eq_x_y_14340;
            bool ok_or_empty_14348 = empty_slice_14341 || forwards_ok_14347;
            bool index_certs_14349;
            
            if (!ok_or_empty_14348) {
                set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_14332, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  lib/github.com/diku-dk/sorts/quick_sort.fut:90:24-27\n   #3  naiveCompiler.fut:10:40-49\n   #4  naiveCompiler.fut:15:1-18:42\n"));
                err = FUTHARK_PROGRAM_ERROR;
                goto cleanup;
            }
            
            int64_t bytes_17072 = (int64_t) 8 * m_14332;
            
            if (memblock_alloc_device(ctx, &mem_17061, bytes_17060, "mem_17061")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 2, mem_17061.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, mem_17048.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, loop_dz2085U_14130}, (int64_t []) {loop_dz2085U_14130, (int64_t) 2})) != 0)
                goto cleanup;
            if (memblock_alloc_device(ctx, &mem_17065, bytes_17060, "mem_17065")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 2, mem_17065.mem, (int64_t) 0, (int64_t []) {(int64_t) 2, (int64_t) 1}, mem_17058.mem, (int64_t) 0, (int64_t []) {(int64_t) 1, loop_dz2085U_14130}, (int64_t []) {loop_dz2085U_14130, (int64_t) 2})) != 0)
                goto cleanup;
            if (memblock_alloc_device(ctx, &mem_17073, bytes_17072, "mem_17073")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_17073.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_17065.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_14332})) != 0)
                goto cleanup;
            if (memblock_unref_device(ctx, &mem_17065, "mem_17065") != 0)
                return 1;
            if (memblock_alloc_device(ctx, &mem_17075, bytes_17072, "mem_17075")) {
                err = 1;
                goto cleanup;
            }
            if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_17075.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_17061.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_14332})) != 0)
                goto cleanup;
            if (memblock_unref_device(ctx, &mem_17061, "mem_17061") != 0)
                return 1;
            
            int64_t num_tblocks_16865;
            int64_t max_num_tblocks_18322;
            
            max_num_tblocks_18322 = *ctx->tuning_params.mainzisegmap_num_tblocks_16864;
            num_tblocks_16865 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, segmap_tblock_sizze_16863), max_num_tblocks_18322)));
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_18323 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, segmap_tblock_sizze_16863));
            
            {
                err = gpu_kernel_mainzisegmap_16860(ctx, num_tblocks_16865, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16862, 1, 1, (int64_t) 0, loop_dz2085U_14130, dzlz7bUZLztZRz20Ukz20U2z7dUzg_14136, m_14332, num_tblocks_16865, virt_num_tblocks_18323, mem_17048.mem, mem_17058.mem, mem_17069.mem, mem_17071.mem, mem_17073.mem, mem_17075.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &mem_17048, "mem_17048") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17058, "mem_17058") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17069, "mem_17069") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17071, "mem_17071") != 0)
                return 1;
            
            int64_t num_tblocks_16873;
            int64_t max_num_tblocks_18336;
            
            max_num_tblocks_18336 = *ctx->tuning_params.mainzisegmap_num_tblocks_16872;
            num_tblocks_16873 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(idxs_14149, segmap_tblock_sizze_16871), max_num_tblocks_18336)));
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegMap");
            
            int32_t virt_num_tblocks_18337 = sext_i64_i32(sdiv_up64(idxs_14149, segmap_tblock_sizze_16871));
            
            {
                err = gpu_kernel_mainzisegmap_16868(ctx, num_tblocks_16873, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16870, 1, 1, (int64_t) 0, n_12437, loop_dz2085U_14130, idxs_14149, num_tblocks_16873, virt_num_tblocks_18337, mem_16963.mem, mem_16965.mem, mem_param_16976.mem, ext_mem_16988.mem, mem_17003.mem, mem_17005.mem, mem_17007.mem, mem_17016.mem, mem_17018.mem, mem_17020.mem, mem_17022.mem, mem_17024.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
            if (memblock_unref_device(ctx, &ext_mem_16988, "ext_mem_16988") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17003, "mem_17003") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17005, "mem_17005") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17007, "mem_17007") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17016, "mem_17016") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17018, "mem_17018") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17020, "mem_17020") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17022, "mem_17022") != 0)
                return 1;
            if (memblock_unref_device(ctx, &mem_17024, "mem_17024") != 0)
                return 1;
            
            bool loop_cond_14422 = slt64((int64_t) 0, m_14332);
            
            if (memblock_set_device(ctx, &mem_param_tmp_17460, &mem_17075, "mem_17075") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_17461, &mem_17073, "mem_17073") != 0)
                return 1;
            
            int64_t loop_dz2085U_tmp_17462 = m_14332;
            bool loop_while_tmp_17463 = loop_cond_14422;
            
            if (memblock_set_device(ctx, &mem_param_16976, &mem_param_tmp_17460, "mem_param_tmp_17460") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_16979, &mem_param_tmp_17461, "mem_param_tmp_17461") != 0)
                return 1;
            loop_dz2085U_14130 = loop_dz2085U_tmp_17462;
            loop_while_14131 = loop_while_tmp_17463;
        }
        if (memblock_set_device(ctx, &ext_mem_17087, &mem_param_16976, "mem_param_16976") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_17086, &mem_param_16979, "mem_param_16979") != 0)
            return 1;
        defunc_0_qsort_res_f_res_14124 = loop_dz2085U_14130;
        defunc_0_qsort_res_f_res_14125 = loop_while_14131;
        if (memblock_unref_device(ctx, &mem_16965, "mem_16965") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16966, "mem_16966") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16967, "mem_16967") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_17092, &mem_16963, "mem_16963") != 0)
            return 1;
    }
    if (memblock_unref_device(ctx, &mem_16961, "mem_16961") != 0)
        return 1;
    // Trace: naiveCompiler.fut:10:20-50
    {
        fprintf(ctx->log, "%s", "naiveCompiler.fut:10:20-50: ");
        for (int64_t nest_i_18350 = 0; nest_i_18350 < n_12437; nest_i_18350++) {
            float read_res_18368;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_18368, ext_mem_17092.mem, nest_i_18350 * sizeof(float), sizeof(float))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            float arr_elem_18351 = read_res_18368;
            
            fprintf(ctx->log, "%f%s", (double) arr_elem_18351, " ");
        }
        fprintf(ctx->log, "%s", "\n");
    }
    
    int64_t segmap_tblock_sizze_16899;
    
    segmap_tblock_sizze_16899 = *ctx->tuning_params.mainzisegmap_tblock_sizze_16878;
    
    int64_t segmap_usable_groups_16900 = sdiv_up64(m_12436, segmap_tblock_sizze_16899);
    
    if (memblock_alloc_device(ctx, &mem_17095, bytes_16952, "mem_17095")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_18352 = sext_i64_i32(sdiv_up64(m_12436, segmap_tblock_sizze_16899));
    
    {
        err = gpu_kernel_mainzisegmap_16903(ctx, segmap_usable_groups_16900, 1, 1, *ctx->tuning_params.mainzisegmap_tblock_sizze_16878, 1, 1, (int64_t) 0, m_12436, n_12437, ks_mem_16946.mem, mem_16953.mem, ext_mem_17092.mem, mem_17095.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_16953, "mem_16953") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_17092, "ext_mem_17092") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_17096, &mem_17095, "mem_17095") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_18362, &mem_out_17096, "mem_out_17096") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_17095, "mem_17095") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_17461, "mem_param_tmp_17461") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_17460, "mem_param_tmp_17460") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17075, "mem_17075") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17073, "mem_17073") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17065, "mem_17065") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17061, "mem_17061") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_18231, "incprefixes_mem_18231") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_18229, "aggregates_mem_18229") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_18227, "status_flags_mem_18227") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17071, "mem_17071") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17069, "mem_17069") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17058, "mem_17058") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17048, "mem_17048") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17026, "mem_17026") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17024, "mem_17024") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17022, "mem_17022") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17736, "incprefixes_mem_17736") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17734, "aggregates_mem_17734") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17732, "incprefixes_mem_17732") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17730, "aggregates_mem_17730") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17728, "incprefixes_mem_17728") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17726, "aggregates_mem_17726") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17724, "incprefixes_mem_17724") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17722, "aggregates_mem_17722") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17720, "incprefixes_mem_17720") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17718, "aggregates_mem_17718") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17716, "incprefixes_mem_17716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17714, "aggregates_mem_17714") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17712, "incprefixes_mem_17712") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17710, "aggregates_mem_17710") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17708, "incprefixes_mem_17708") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17706, "aggregates_mem_17706") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_17704, "status_flags_mem_17704") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17020, "mem_17020") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17018, "mem_17018") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17016, "mem_17016") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17014, "mem_17014") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17012, "mem_17012") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17010, "mem_17010") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17008, "mem_17008") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17007, "mem_17007") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17005, "mem_17005") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17003, "mem_17003") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_17001, "mem_17001") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17506, "incprefixes_mem_17506") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17504, "aggregates_mem_17504") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17502, "incprefixes_mem_17502") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17500, "aggregates_mem_17500") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17498, "incprefixes_mem_17498") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17496, "aggregates_mem_17496") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_17494, "status_flags_mem_17494") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16999, "mem_16999") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16998, "mem_16998") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16996, "mem_16996") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16994, "mem_16994") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16992, "mem_16992") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16990, "mem_16990") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_16988, "ext_mem_16988") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16986, "mem_16986") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16984, "mem_16984") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16982, "mem_16982") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_16979, "mem_param_16979") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_16976, "mem_param_16976") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_17086, "ext_mem_17086") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_17087, "ext_mem_17087") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16967, "mem_16967") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16966, "mem_16966") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16965, "mem_16965") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16963, "mem_16963") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_17092, "ext_mem_17092") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17336, "incprefixes_mem_17336") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17334, "aggregates_mem_17334") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_17332, "status_flags_mem_17332") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16961, "mem_16961") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16954, "mem_16954") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17133, "incprefixes_mem_17133") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17131, "aggregates_mem_17131") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17129, "incprefixes_mem_17129") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17127, "aggregates_mem_17127") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_17105, "status_flags_mem_17105") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16953, "mem_16953") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16951, "mem_16951") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_17096, "mem_out_17096") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_replicated_iota_6108(struct futhark_context *ctx, struct memblock_device *mem_out_p_18369, int64_t *out_prim_out_18370, struct memblock_device reps_mem_16946, int64_t n_9632)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device incprefixes_mem_17473;
    
    incprefixes_mem_17473.references = NULL;
    
    struct memblock_device aggregates_mem_17471;
    
    aggregates_mem_17471.references = NULL;
    
    struct memblock_device incprefixes_mem_17469;
    
    incprefixes_mem_17469.references = NULL;
    
    struct memblock_device aggregates_mem_17467;
    
    aggregates_mem_17467.references = NULL;
    
    struct memblock_device status_flags_mem_17465;
    
    status_flags_mem_17465.references = NULL;
    
    struct memblock_device mem_16960;
    
    mem_16960.references = NULL;
    
    struct memblock_device mem_16958;
    
    mem_16958.references = NULL;
    
    struct memblock_device segred_tmp_mem_17418;
    
    segred_tmp_mem_17418.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_17298;
    
    defunc_0_map_res_subhistos_mem_17298.references = NULL;
    
    struct memblock_device mem_16955;
    
    mem_16955.references = NULL;
    
    struct memblock_device segred_tmp_mem_17245;
    
    segred_tmp_mem_17245.references = NULL;
    
    struct memblock_device mem_16953;
    
    mem_16953.references = NULL;
    
    struct memblock_device incprefixes_mem_17130;
    
    incprefixes_mem_17130.references = NULL;
    
    struct memblock_device aggregates_mem_17128;
    
    aggregates_mem_17128.references = NULL;
    
    struct memblock_device status_flags_mem_17106;
    
    status_flags_mem_17106.references = NULL;
    
    struct memblock_device mem_16951;
    
    mem_16951.references = NULL;
    
    struct memblock_device mem_16949;
    
    mem_16949.references = NULL;
    
    struct memblock_device mem_out_17096;
    
    mem_out_17096.references = NULL;
    
    struct memblock_device counters_mem_17243 = ctx->constants->counters_mem_17243;
    struct memblock_device counters_mem_17420 = ctx->constants->counters_mem_17420;
    struct memblock_device global_dynid_mem_17132 = ctx->constants->global_dynid_mem_17132;
    struct memblock_device global_dynid_mem_17135 = ctx->constants->global_dynid_mem_17135;
    struct memblock_device global_dynid_mem_17338 = ctx->constants->global_dynid_mem_17338;
    struct memblock_device global_dynid_mem_17475 = ctx->constants->global_dynid_mem_17475;
    struct memblock_device global_dynid_mem_17508 = ctx->constants->global_dynid_mem_17508;
    struct memblock_device global_dynid_mem_17738 = ctx->constants->global_dynid_mem_17738;
    struct memblock_device global_dynid_mem_18233 = ctx->constants->global_dynid_mem_18233;
    int64_t prim_out_17097;
    int64_t segscan_tblock_sizze_16549;
    
    segscan_tblock_sizze_16549 = *ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16548;
    
    int64_t num_tblocks_16551;
    int64_t max_num_tblocks_17098;
    
    max_num_tblocks_17098 = *ctx->tuning_params.replicated_iota_6108zisegscan_num_tblocks_16550;
    num_tblocks_16551 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_9632, segscan_tblock_sizze_16549), max_num_tblocks_17098)));
    
    int64_t bytes_16948 = (int64_t) 8 * n_9632;
    
    if (memblock_alloc_device(ctx, &mem_16949, bytes_16948, "mem_16949")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_16951, bytes_16948, "mem_16951")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, n_9632)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_17099;
        
        shared_memory_17099 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_17100;
        
        thread_block_sizze_17100 = ctx->max_thread_block_size;
        
        int64_t registers_17101;
        
        registers_17101 = ctx->max_registers;
        
        int64_t thread_block_sizze_17102;
        
        thread_block_sizze_17102 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_17103 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_17099, thread_block_sizze_17100), (int64_t) 8), squot64(squot64(registers_17101, thread_block_sizze_17102) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_17104 = sdiv_up64(n_9632, segscan_tblock_sizze_16549 * chunk_sizze_17103);
        int64_t num_virt_threads_17105 = num_virt_blocks_17104 * segscan_tblock_sizze_16549;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_17103, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_17106, num_virt_blocks_17104, "status_flags_mem_17106")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_17106, num_virt_blocks_17104, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_17128, (int64_t) 8 * num_virt_blocks_17104, "aggregates_mem_17128")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_17130, (int64_t) 8 * num_virt_blocks_17104, "incprefixes_mem_17130")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_replicated_iota_6108zisegscan_16554(ctx, num_tblocks_16551, 1, 1, *ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16548, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16549), chunk_sizze_17103 * segscan_tblock_sizze_16549 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_16549), chunk_sizze_17103 * segscan_tblock_sizze_16549 * (int64_t) 8), (int64_t) 8), (int64_t) 8), n_9632, num_tblocks_16551, num_virt_blocks_17104, num_virt_threads_17105, reps_mem_16946.mem, mem_16949.mem, mem_16951.mem, status_flags_mem_17106.mem, aggregates_mem_17128.mem, incprefixes_mem_17130.mem, global_dynid_mem_17132.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segred_tblock_sizze_16557;
    
    segred_tblock_sizze_16557 = *ctx->tuning_params.replicated_iota_6108zisegred_tblock_sizze_16556;
    
    int64_t num_tblocks_16559;
    int64_t max_num_tblocks_17241;
    
    max_num_tblocks_17241 = *ctx->tuning_params.replicated_iota_6108zisegred_num_tblocks_16558;
    num_tblocks_16559 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_9632, segred_tblock_sizze_16557), max_num_tblocks_17241)));
    if (memblock_alloc_device(ctx, &mem_16953, (int64_t) 8, "mem_16953")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    
    int64_t chunk_sizze_17242 = (int64_t) 1;
    
    if (memblock_alloc_device(ctx, &segred_tmp_mem_17245, (int64_t) 8 * num_tblocks_16559, "segred_tmp_mem_17245")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_17247 = num_tblocks_16559 * segred_tblock_sizze_16557;
    
    {
        err = gpu_kernel_replicated_iota_6108zisegred_nonseg_16564(ctx, num_tblocks_16559, 1, 1, *ctx->tuning_params.replicated_iota_6108zisegred_tblock_sizze_16556, 1, 1, 8 + ((int64_t) 8 * segred_tblock_sizze_16557 + srem64((int64_t) 8 - srem64((int64_t) 8 * segred_tblock_sizze_16557, (int64_t) 8), (int64_t) 8)), n_9632, num_tblocks_16559, num_threads_17247, mem_16951.mem, mem_16953.mem, counters_mem_17243.mem, segred_tmp_mem_17245.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_16951, "mem_16951") != 0)
        return 1;
    
    int64_t read_res_18371;
    
    if ((err = gpu_scalar_from_device(ctx, &read_res_18371, mem_16953.mem, (int64_t) 0 * sizeof(int64_t), sizeof(int64_t))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t defunc_0_reduce_res_14478 = read_res_18371;
    
    if (memblock_unref_device(ctx, &mem_16953, "mem_16953") != 0)
        return 1;
    
    int64_t bytes_16954 = (int64_t) 8 * defunc_0_reduce_res_14478;
    
    if (memblock_alloc_device(ctx, &mem_16955, bytes_16954, "mem_16955")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_16955, defunc_0_reduce_res_14478, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t seghist_tblock_sizze_16567;
    
    seghist_tblock_sizze_16567 = *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566;
    
    int64_t num_tblocks_16569;
    int64_t max_num_tblocks_17296;
    
    max_num_tblocks_17296 = *ctx->tuning_params.replicated_iota_6108ziseghist_num_tblocks_16568;
    num_tblocks_16569 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(n_9632, seghist_tblock_sizze_16567), max_num_tblocks_17296)));
    
    int64_t num_subhistos_17297;
    int64_t h_17300 = (int64_t) 8 * defunc_0_reduce_res_14478;
    int64_t seg_h_17301 = (int64_t) 8 * defunc_0_reduce_res_14478;
    
    if (!(seg_h_17301 == (int64_t) 0)) {
        int64_t hist_H_17302 = defunc_0_reduce_res_14478;
        int64_t hist_el_sizze_17303 = sdiv_up64(h_17300, hist_H_17302);
        int64_t hist_N_17304 = n_9632;
        int32_t hist_RF_17305 = 1;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegHist");
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_16569 * seghist_tblock_sizze_16567), '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_16567, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_17302, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_17304, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_17303, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_17305, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_17300, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_17301, '\n');
        
        int64_t hist_L_17306;
        
        hist_L_17306 = *ctx->tuning_params.replicated_iota_6108zihist_L_17306;
        
        int64_t max_tblock_sizze_17307;
        
        max_tblock_sizze_17307 = ctx->max_thread_block_size;
        
        int64_t num_tblocks_17308 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_16569 * seghist_tblock_sizze_16567)), max_tblock_sizze_17307);
        double hist_m_prime_17309 = sitofp_i64_f64(smin64(squot64(hist_L_17306, hist_el_sizze_17303), sdiv_up64(hist_N_17304, num_tblocks_17308))) / sitofp_i64_f64(hist_H_17302);
        int64_t hist_M0_17310 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_17309), max_tblock_sizze_17307));
        int64_t hist_Nout_17311 = (int64_t) 1;
        int64_t hist_Nin_17312 = n_9632;
        int64_t work_asymp_M_max_17313 = squot64(hist_Nout_17311 * hist_N_17304, (int64_t) 2 * num_tblocks_17308 * hist_H_17302);
        int32_t hist_M_17314 = sext_i64_i32(smin64(hist_M0_17310, work_asymp_M_max_17313));
        int64_t hist_C_17315 = sdiv_up64(max_tblock_sizze_17307, sext_i32_i64(smax32(1, hist_M_17314)));
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_17310, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_17313, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_17315, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_17307, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_17314, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_17302 * hist_el_sizze_17303 * sext_i32_i64(hist_M_17314)), '\n');
        
        int64_t local_mem_needed_17316 = hist_el_sizze_17303 * sext_i32_i64(hist_M_17314);
        int32_t hist_S_17317 = sext_i64_i32(sdiv_up64(hist_H_17302 * local_mem_needed_17316 + (int64_t) 1, hist_L_17306));
        
        if (sle64(hist_H_17302, hist_Nin_17312) && (sle64(local_mem_needed_17316, hist_L_17306) && (sle32(hist_S_17317, 3) && (sle64(hist_C_17315, max_tblock_sizze_17307) && slt32(0, hist_M_17314))))) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using shared memory");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_17302, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_17314, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_17315, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_17317, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_17314, '\n');
            num_subhistos_17297 = num_tblocks_17308;
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_17297, '\n');
            if (num_subhistos_17297 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_17298, &mem_16955, "mem_16955") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_17298, num_subhistos_17297 * defunc_0_reduce_res_14478 * (int64_t) 8, "defunc_0_map_res_subhistos_mem_17298")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i64(ctx, defunc_0_map_res_subhistos_mem_17298, num_subhistos_17297 * defunc_0_reduce_res_14478, (int64_t) 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, defunc_0_map_res_subhistos_mem_17298.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_16955.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {defunc_0_reduce_res_14478})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_17318 = 0; chk_i_17318 < hist_S_17317; chk_i_17318++) {
                int64_t num_segments_17319 = (int64_t) 1;
                int64_t hist_H_chk_17320 = sdiv_up64(defunc_0_reduce_res_14478, sext_i32_i64(hist_S_17317));
                int64_t histo_sizze_17321 = hist_H_chk_17320;
                int32_t init_per_thread_17322 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_17314) * histo_sizze_17321, max_tblock_sizze_17307));
                
                {
                    err = gpu_kernel_replicated_iota_6108ziseghist_local_16574(ctx, num_tblocks_17308, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 8 * (hist_M_17314 * hist_H_chk_17320) + srem64((int64_t) 8 - srem64((int64_t) 8 * (hist_M_17314 * hist_H_chk_17320), (int64_t) 8), (int64_t) 8), n_9632, defunc_0_reduce_res_14478, num_subhistos_17297, num_tblocks_17308, hist_M_17314, chk_i_17318, num_segments_17319, hist_H_chk_17320, histo_sizze_17321, init_per_thread_17322, mem_16949.mem, defunc_0_map_res_subhistos_mem_17298.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        } else {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using global memory");
            
            int64_t hist_H_17354 = defunc_0_reduce_res_14478;
            double hist_RF_17355 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
            int32_t hist_el_sizze_17356 = 8;
            double hist_C_max_17357 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_16569 * seghist_tblock_sizze_16567)), sitofp_i32_f64(hist_H_17354) / 2.0);
            int32_t hist_M_min_17358 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_16569 * seghist_tblock_sizze_16567)) / hist_C_max_17357)));
            int64_t hist_L2_17359;
            
            hist_L2_17359 = *ctx->tuning_params.replicated_iota_6108zihist_L2_17359;
            
            double hist_RACE_exp_17360 = fmax64(1.0, 0.75 * hist_RF_17355 / (64.0 / sitofp_i32_f64(hist_el_sizze_17356)));
            int32_t hist_S_17361;
            
            if (slt64(n_9632, hist_H_17354)) {
                hist_S_17361 = 1;
            } else {
                hist_S_17361 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_17358) * hist_H_17354 * sext_i32_i64(hist_el_sizze_17356), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_17359) * hist_RACE_exp_17360)));
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_17360, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_17361, '\n');
            
            int64_t hist_H_chk_17362 = sdiv_up64(defunc_0_reduce_res_14478, sext_i32_i64(hist_S_17361));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_17362, '\n');
            
            double hist_k_max_17363 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_17359) / sitofp_i32_f64(8)) * hist_RACE_exp_17360, sitofp_i32_f64(n_9632)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_16569 * seghist_tblock_sizze_16567));
            int64_t hist_u_17364 = (int64_t) 2;
            double hist_C_17365 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_16569 * seghist_tblock_sizze_16567)), sitofp_i32_f64(hist_u_17364 * hist_H_chk_17362) / hist_k_max_17363);
            int32_t hist_M_17366 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_17363, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_17366, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_17365, '\n');
            num_subhistos_17297 = sext_i32_i64(hist_M_17366);
            if (hist_M_17366 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_17298, &mem_16955, "mem_16955") != 0)
                    return 1;
            } else if (num_subhistos_17297 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_17298, &mem_16955, "mem_16955") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_17298, num_subhistos_17297 * defunc_0_reduce_res_14478 * (int64_t) 8, "defunc_0_map_res_subhistos_mem_17298")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i64(ctx, defunc_0_map_res_subhistos_mem_17298, num_subhistos_17297 * defunc_0_reduce_res_14478, (int64_t) 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, defunc_0_map_res_subhistos_mem_17298.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_16955.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {defunc_0_reduce_res_14478})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_17367 = 0; chk_i_17367 < hist_S_17361; chk_i_17367++) {
                int64_t hist_H_chk_17368 = sdiv_up64(defunc_0_reduce_res_14478, sext_i32_i64(hist_S_17361));
                
                {
                    err = gpu_kernel_replicated_iota_6108ziseghist_global_16574(ctx, num_tblocks_16569, 1, 1, *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566, 1, 1, (int64_t) 0, n_9632, defunc_0_reduce_res_14478, num_tblocks_16569, num_subhistos_17297, chk_i_17367, hist_H_chk_17368, mem_16949.mem, defunc_0_map_res_subhistos_mem_17298.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        }
        if (num_subhistos_17297 == (int64_t) 1) {
            if (memblock_set_device(ctx, &mem_16955, &defunc_0_map_res_subhistos_mem_17298, "defunc_0_map_res_subhistos_mem_17298") != 0)
                return 1;
        } else {
            int64_t chunk_sizze_17384 = (int64_t) 1;
            
            if (slt64(num_subhistos_17297 * (int64_t) 2, seghist_tblock_sizze_16567 * chunk_sizze_17384)) {
                int64_t segment_sizze_nonzzero_17385 = smax64((int64_t) 1, num_subhistos_17297);
                int64_t num_threads_17386 = seghist_tblock_sizze_16567 * seghist_tblock_sizze_16567;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-small");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) defunc_0_reduce_res_14478, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_17297, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385), '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(defunc_0_reduce_res_14478, squot64(seghist_tblock_sizze_16567, segment_sizze_nonzzero_17385))), '\n');
                {
                    err = gpu_kernel_replicated_iota_6108zisegred_small_17383(ctx, num_tblocks_16569, 1, 1, *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566, 1, 1, (int64_t) 8 * seghist_tblock_sizze_16567 + srem64((int64_t) 8 - srem64((int64_t) 8 * seghist_tblock_sizze_16567, (int64_t) 8), (int64_t) 8), defunc_0_reduce_res_14478, num_tblocks_16569, num_subhistos_17297, segment_sizze_nonzzero_17385, mem_16955.mem, defunc_0_map_res_subhistos_mem_17298.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            } else {
                int64_t blocks_per_segment_17414 = sdiv_up64(num_tblocks_16569, smax64((int64_t) 1, defunc_0_reduce_res_14478));
                int64_t q_17415 = sdiv_up64(num_subhistos_17297, seghist_tblock_sizze_16567 * blocks_per_segment_17414 * chunk_sizze_17384);
                int64_t num_virtblocks_17416 = blocks_per_segment_17414 * defunc_0_reduce_res_14478;
                int64_t threads_per_segment_17417 = blocks_per_segment_17414 * seghist_tblock_sizze_16567;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-large");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) defunc_0_reduce_res_14478, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_17297, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_17416, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_16569, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_16567, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_17415, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_17414, '\n');
                if (memblock_alloc_device(ctx, &segred_tmp_mem_17418, (int64_t) 8 * num_virtblocks_17416, "segred_tmp_mem_17418")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_replicated_iota_6108zisegred_large_17383(ctx, num_tblocks_16569, 1, 1, *ctx->tuning_params.replicated_iota_6108ziseghist_tblock_sizze_16566, 1, 1, 8 + ((int64_t) 8 * seghist_tblock_sizze_16567 + srem64((int64_t) 8 - srem64((int64_t) 8 * seghist_tblock_sizze_16567, (int64_t) 8), (int64_t) 8)), defunc_0_reduce_res_14478, num_tblocks_16569, num_subhistos_17297, blocks_per_segment_17414, q_17415, num_virtblocks_17416, threads_per_segment_17417, mem_16955.mem, defunc_0_map_res_subhistos_mem_17298.mem, segred_tmp_mem_17418.mem, counters_mem_17420.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_16949, "mem_16949") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_16586;
    
    segscan_tblock_sizze_16586 = *ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16585;
    
    int64_t num_tblocks_16588;
    int64_t max_num_tblocks_17457;
    
    max_num_tblocks_17457 = *ctx->tuning_params.replicated_iota_6108zisegscan_num_tblocks_16587;
    num_tblocks_16588 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(defunc_0_reduce_res_14478, segscan_tblock_sizze_16586), max_num_tblocks_17457)));
    if (memblock_alloc_device(ctx, &mem_16958, defunc_0_reduce_res_14478, "mem_16958")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_16960, bytes_16954, "mem_16960")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, defunc_0_reduce_res_14478)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_17458;
        
        shared_memory_17458 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_17459;
        
        thread_block_sizze_17459 = ctx->max_thread_block_size;
        
        int64_t registers_17460;
        
        registers_17460 = ctx->max_registers;
        
        int64_t thread_block_sizze_17461;
        
        thread_block_sizze_17461 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_17462 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_17458, thread_block_sizze_17459), (int64_t) 8), squot64(squot64(registers_17460, thread_block_sizze_17461) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_17463 = sdiv_up64(defunc_0_reduce_res_14478, segscan_tblock_sizze_16586 * chunk_sizze_17462);
        int64_t num_virt_threads_17464 = num_virt_blocks_17463 * segscan_tblock_sizze_16586;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_17462, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_17465, num_virt_blocks_17463, "status_flags_mem_17465")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_17465, num_virt_blocks_17463, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_17467, num_virt_blocks_17463, "aggregates_mem_17467")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_17469, num_virt_blocks_17463, "incprefixes_mem_17469")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_17471, (int64_t) 8 * num_virt_blocks_17463, "aggregates_mem_17471")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_17473, (int64_t) 8 * num_virt_blocks_17463, "incprefixes_mem_17473")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_replicated_iota_6108zisegscan_16591(ctx, num_tblocks_16588, 1, 1, *ctx->tuning_params.replicated_iota_6108zisegscan_tblock_sizze_16585, 1, 1, smax64(smax64((int64_t) 320, sdiv_up64(segscan_tblock_sizze_16586, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16586), smax64(chunk_sizze_17462 * segscan_tblock_sizze_16586, chunk_sizze_17462 * segscan_tblock_sizze_16586 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 320, sdiv_up64(segscan_tblock_sizze_16586, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_16586), smax64(chunk_sizze_17462 * segscan_tblock_sizze_16586, chunk_sizze_17462 * segscan_tblock_sizze_16586 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), defunc_0_reduce_res_14478, num_tblocks_16588, num_virt_blocks_17463, num_virt_threads_17464, mem_16955.mem, mem_16958.mem, mem_16960.mem, status_flags_mem_17465.mem, aggregates_mem_17467.mem, incprefixes_mem_17469.mem, aggregates_mem_17471.mem, incprefixes_mem_17473.mem, global_dynid_mem_17475.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_16955, "mem_16955") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_16958, "mem_16958") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_17096, &mem_16960, "mem_16960") != 0)
        return 1;
    prim_out_17097 = defunc_0_reduce_res_14478;
    if (memblock_set_device(ctx, &*mem_out_p_18369, &mem_out_17096, "mem_out_17096") != 0)
        return 1;
    *out_prim_out_18370 = prim_out_17097;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &incprefixes_mem_17473, "incprefixes_mem_17473") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17471, "aggregates_mem_17471") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17469, "incprefixes_mem_17469") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17467, "aggregates_mem_17467") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_17465, "status_flags_mem_17465") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16960, "mem_16960") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16958, "mem_16958") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_17418, "segred_tmp_mem_17418") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_17298, "defunc_0_map_res_subhistos_mem_17298") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16955, "mem_16955") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_17245, "segred_tmp_mem_17245") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16953, "mem_16953") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_17130, "incprefixes_mem_17130") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_17128, "aggregates_mem_17128") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_17106, "status_flags_mem_17106") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16951, "mem_16951") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_16949, "mem_16949") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_17096, "mem_out_17096") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_main(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_f32_1d *in2)
{
    int64_t m_12436 = (int64_t) 0;
    int64_t n_12437 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_17096;
    
    mem_out_17096.references = NULL;
    
    struct memblock_device A_mem_16948;
    
    A_mem_16948.references = NULL;
    
    struct memblock_device shp_mem_16947;
    
    shp_mem_16947.references = NULL;
    
    struct memblock_device ks_mem_16946;
    
    ks_mem_16946.references = NULL;
    ks_mem_16946 = in0->mem;
    m_12436 = in0->shape[0];
    shp_mem_16947 = in1->mem;
    m_12436 = in1->shape[0];
    A_mem_16948 = in2->mem;
    n_12437 = in2->shape[0];
    if (!(m_12436 == in0->shape[0] && (m_12436 == in1->shape[0] && n_12437 == in2->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_main(ctx, &mem_out_17096, ks_mem_16946, shp_mem_16947, A_mem_16948, m_12436, n_12437);
        if (ret == 0) {
            struct memblock_device counters_mem_17243 = ctx->constants->counters_mem_17243;
            struct memblock_device counters_mem_17420 = ctx->constants->counters_mem_17420;
            struct memblock_device global_dynid_mem_17132 = ctx->constants->global_dynid_mem_17132;
            struct memblock_device global_dynid_mem_17135 = ctx->constants->global_dynid_mem_17135;
            struct memblock_device global_dynid_mem_17338 = ctx->constants->global_dynid_mem_17338;
            struct memblock_device global_dynid_mem_17475 = ctx->constants->global_dynid_mem_17475;
            struct memblock_device global_dynid_mem_17508 = ctx->constants->global_dynid_mem_17508;
            struct memblock_device global_dynid_mem_17738 = ctx->constants->global_dynid_mem_17738;
            struct memblock_device global_dynid_mem_18233 = ctx->constants->global_dynid_mem_18233;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_17096;
            (*out0)->shape[0] = m_12436;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
