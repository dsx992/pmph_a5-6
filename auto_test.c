// Generated by Futhark 0.25.24.
// git: 0bb3d37e788daf859346a635efd215ab37aa72f6
// Compiled with GHC 9.6.6.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_f32_1d;
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0);
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data);
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
struct futhark_i32_1d;
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0);
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data);
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);

// Opaque values



// Entry points
int futhark_entry_compiler(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_f32_1d *in2);
int futhark_entry_human(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_f32_1d *in3);
int futhark_entry_human_regular(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_f32_1d *in3);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h
#include <getopt.h>
#include <ctype.h>
#include <inttypes.h>
static const char *entry_point = "main";
// Start of values.h.

//// Text I/O

typedef int (*writer)(FILE*, const void*);
typedef int (*bin_reader)(void*);
typedef int (*str_reader)(const char *, void*);

struct array_reader {
  char* elems;
  int64_t n_elems_space;
  int64_t elem_size;
  int64_t n_elems_used;
  int64_t *shape;
  str_reader elem_reader;
};

static void skipspaces(FILE *f) {
  int c;
  do {
    c = getc(f);
  } while (isspace(c));

  if (c != EOF) {
    ungetc(c, f);
  }
}

static int constituent(char c) {
  return isalnum(c) || c == '.' || c == '-' || c == '+' || c == '_';
}

// Produces an empty token only on EOF.
static void next_token(FILE *f, char *buf, int bufsize) {
 start:
  skipspaces(f);

  int i = 0;
  while (i < bufsize) {
    int c = getc(f);
    buf[i] = (char)c;

    if (c == EOF) {
      buf[i] = 0;
      return;
    } else if (c == '-' && i == 1 && buf[0] == '-') {
      // Line comment, so skip to end of line and start over.
      for (; c != '\n' && c != EOF; c = getc(f));
      goto start;
    } else if (!constituent((char)c)) {
      if (i == 0) {
        // We permit single-character tokens that are not
        // constituents; this lets things like ']' and ',' be
        // tokens.
        buf[i+1] = 0;
        return;
      } else {
        ungetc(c, f);
        buf[i] = 0;
        return;
      }
    }

    i++;
  }

  buf[bufsize-1] = 0;
}

static int next_token_is(FILE *f, char *buf, int bufsize, const char* expected) {
  next_token(f, buf, bufsize);
  return strcmp(buf, expected) == 0;
}

static void remove_underscores(char *buf) {
  char *w = buf;

  for (char *r = buf; *r; r++) {
    if (*r != '_') {
      *w++ = *r;
    }
  }

  *w++ = 0;
}

static int read_str_elem(char *buf, struct array_reader *reader) {
  int ret;
  if (reader->n_elems_used == reader->n_elems_space) {
    reader->n_elems_space *= 2;
    reader->elems = (char*) realloc(reader->elems,
                                    (size_t)(reader->n_elems_space * reader->elem_size));
  }

  ret = reader->elem_reader(buf, reader->elems + reader->n_elems_used * reader->elem_size);

  if (ret == 0) {
    reader->n_elems_used++;
  }

  return ret;
}

static int read_str_array_elems(FILE *f,
                                char *buf, int bufsize,
                                struct array_reader *reader, int64_t dims) {
  int ret = 1;
  int expect_elem = 1;
  char *knows_dimsize = (char*) calloc((size_t)dims, sizeof(char));
  int cur_dim = (int)dims-1;
  int64_t *elems_read_in_dim = (int64_t*) calloc((size_t)dims, sizeof(int64_t));

  while (1) {
    next_token(f, buf, bufsize);
    if (strcmp(buf, "]") == 0) {
      expect_elem = 0;
      if (knows_dimsize[cur_dim]) {
        if (reader->shape[cur_dim] != elems_read_in_dim[cur_dim]) {
          ret = 1;
          break;
        }
      } else {
        knows_dimsize[cur_dim] = 1;
        reader->shape[cur_dim] = elems_read_in_dim[cur_dim];
      }
      if (cur_dim == 0) {
        ret = 0;
        break;
      } else {
        cur_dim--;
        elems_read_in_dim[cur_dim]++;
      }
    } else if (!expect_elem && strcmp(buf, ",") == 0) {
      expect_elem = 1;
    } else if (expect_elem) {
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else if (cur_dim == dims - 1) {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        expect_elem = 0;
        elems_read_in_dim[cur_dim]++;
      } else {
        ret = 1;
        break;
      }
    } else {
      ret = 1;
      break;
    }
  }

  free(knows_dimsize);
  free(elems_read_in_dim);
  return ret;
}

static int read_str_empty_array(FILE *f, char *buf, int bufsize,
                                const char *type_name, int64_t *shape, int64_t dims) {
  if (strlen(buf) == 0) {
    // EOF
    return 1;
  }

  if (strcmp(buf, "empty") != 0) {
    return 1;
  }

  if (!next_token_is(f, buf, bufsize, "(")) {
    return 1;
  }

  for (int i = 0; i < dims; i++) {
    if (!next_token_is(f, buf, bufsize, "[")) {
      return 1;
    }

    next_token(f, buf, bufsize);

    if (sscanf(buf, "%"SCNu64, (uint64_t*)&shape[i]) != 1) {
      return 1;
    }

    if (!next_token_is(f, buf, bufsize, "]")) {
      return 1;
    }
  }

  if (!next_token_is(f, buf, bufsize, type_name)) {
    return 1;
  }


  if (!next_token_is(f, buf, bufsize, ")")) {
    return 1;
  }

  // Check whether the array really is empty.
  for (int i = 0; i < dims; i++) {
    if (shape[i] == 0) {
      return 0;
    }
  }

  // Not an empty array!
  return 1;
}

static int read_str_array(FILE *f,
                          int64_t elem_size, str_reader elem_reader,
                          const char *type_name,
                          void **data, int64_t *shape, int64_t dims) {
  int ret;
  struct array_reader reader;
  char buf[100];

  int dims_seen;
  for (dims_seen = 0; dims_seen < dims; dims_seen++) {
    if (!next_token_is(f, buf, sizeof(buf), "[")) {
      break;
    }
  }

  if (dims_seen == 0) {
    return read_str_empty_array(f, buf, sizeof(buf), type_name, shape, dims);
  }

  if (dims_seen != dims) {
    return 1;
  }

  reader.shape = shape;
  reader.n_elems_used = 0;
  reader.elem_size = elem_size;
  reader.n_elems_space = 16;
  reader.elems = (char*) realloc(*data, (size_t)(elem_size*reader.n_elems_space));
  reader.elem_reader = elem_reader;

  ret = read_str_array_elems(f, buf, sizeof(buf), &reader, dims);

  *data = reader.elems;

  return ret;
}

#define READ_STR(MACRO, PTR, SUFFIX)                                   \
  remove_underscores(buf);                                              \
  int j;                                                                \
  if (sscanf(buf, "%"MACRO"%n", (PTR*)dest, &j) == 1) {                 \
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, SUFFIX) == 0);     \
  } else {                                                              \
    return 1;                                                           \
  }

static int read_str_i8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNi8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(int8_t*)dest = (int8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "i8") == 0);
  } else {
    return 1;
  }
}

static int read_str_u8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNu8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(uint8_t*)dest = (uint8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "u8") == 0);
  } else {
    return 1;
  }
}

static int read_str_i16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "i16");
}

static int read_str_u16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "u16");
}

static int read_str_i32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "i32");
}

static int read_str_u32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "u32");
}

static int read_str_i64(char *buf, void* dest) {
  READ_STR(SCNi64, int64_t, "i64");
}

static int read_str_u64(char *buf, void* dest) {
  // FIXME: This is not correct, as SCNu64 only permits decimal
  // literals.  However, SCNi64 does not handle very large numbers
  // correctly (it's really for signed numbers, so that's fair).
  READ_STR(SCNu64, uint64_t, "u64");
}

static int read_str_f16(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f16.nan") == 0) {
    *(uint16_t*)dest = float2halfbits(NAN);
    return 0;
  } else if (strcmp(buf, "f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(INFINITY);
    return 0;
  } else if (strcmp(buf, "-f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(-INFINITY);
    return 0;
  } else {
    int j;
    float x;
    if (sscanf(buf, "%f%n", &x, &j) == 1) {
      if (strcmp(buf+j, "") == 0 || strcmp(buf+j, "f16") == 0) {
        *(uint16_t*)dest = float2halfbits(x);
        return 0;
      }
    }
    return 1;
  }
}

static int read_str_f32(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f32.nan") == 0) {
    *(float*)dest = (float)NAN;
    return 0;
  } else if (strcmp(buf, "f32.inf") == 0) {
    *(float*)dest = (float)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f32.inf") == 0) {
    *(float*)dest = (float)-INFINITY;
    return 0;
  } else {
    READ_STR("f", float, "f32");
  }
}

static int read_str_f64(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f64.nan") == 0) {
    *(double*)dest = (double)NAN;
    return 0;
  } else if (strcmp(buf, "f64.inf") == 0) {
    *(double*)dest = (double)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f64.inf") == 0) {
    *(double*)dest = (double)-INFINITY;
    return 0;
  } else {
    READ_STR("lf", double, "f64");
  }
}

static int read_str_bool(char *buf, void* dest) {
  if (strcmp(buf, "true") == 0) {
    *(char*)dest = 1;
    return 0;
  } else if (strcmp(buf, "false") == 0) {
    *(char*)dest = 0;
    return 0;
  } else {
    return 1;
  }
}

static int write_str_i8(FILE *out, int8_t *src) {
  return fprintf(out, "%hhdi8", *src);
}

static int write_str_u8(FILE *out, uint8_t *src) {
  return fprintf(out, "%hhuu8", *src);
}

static int write_str_i16(FILE *out, int16_t *src) {
  return fprintf(out, "%hdi16", *src);
}

static int write_str_u16(FILE *out, uint16_t *src) {
  return fprintf(out, "%huu16", *src);
}

static int write_str_i32(FILE *out, int32_t *src) {
  return fprintf(out, "%di32", *src);
}

static int write_str_u32(FILE *out, uint32_t *src) {
  return fprintf(out, "%uu32", *src);
}

static int write_str_i64(FILE *out, int64_t *src) {
  return fprintf(out, "%"PRIi64"i64", *src);
}

static int write_str_u64(FILE *out, uint64_t *src) {
  return fprintf(out, "%"PRIu64"u64", *src);
}

static int write_str_f16(FILE *out, uint16_t *src) {
  float x = halfbits2float(*src);
  if (isnan(x)) {
    return fprintf(out, "f16.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f16.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f16.inf");
  } else {
    return fprintf(out, "%.*ff16", FLT_DIG, x);
  }
}

static int write_str_f32(FILE *out, float *src) {
  float x = *src;
  if (isnan(x)) {
    return fprintf(out, "f32.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f32.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f32.inf");
  } else {
    return fprintf(out, "%.*ff32", FLT_DIG, x);
  }
}

static int write_str_f64(FILE *out, double *src) {
  double x = *src;
  if (isnan(x)) {
    return fprintf(out, "f64.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f64.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f64.inf");
  } else {
    return fprintf(out, "%.*ff64", DBL_DIG, x);
  }
}

static int write_str_bool(FILE *out, void *src) {
  return fprintf(out, *(char*)src ? "true" : "false");
}

//// Binary I/O

#define BINARY_FORMAT_VERSION 2
#define IS_BIG_ENDIAN (!*(unsigned char *)&(uint16_t){1})

static void flip_bytes(size_t elem_size, unsigned char *elem) {
  for (size_t j=0; j<elem_size/2; j++) {
    unsigned char head = elem[j];
    size_t tail_index = elem_size-1-j;
    elem[j] = elem[tail_index];
    elem[tail_index] = head;
  }
}

// On Windows we need to explicitly set the file mode to not mangle
// newline characters.  On *nix there is no difference.
#ifdef _WIN32
#include <io.h>
#include <fcntl.h>
static void set_binary_mode(FILE *f) {
  setmode(fileno(f), O_BINARY);
}
#else
static void set_binary_mode(FILE *f) {
  (void)f;
}
#endif

static int read_byte(FILE *f, void* dest) {
  size_t num_elems_read = fread(dest, 1, 1, f);
  return num_elems_read == 1 ? 0 : 1;
}

//// Types

struct primtype_info_t {
  const char binname[4]; // Used for parsing binary data.
  const char* type_name; // Same name as in Futhark.
  const int64_t size; // in bytes
  const writer write_str; // Write in text format.
  const str_reader read_str; // Read in text format.
};

static const struct primtype_info_t i8_info =
  {.binname = "  i8", .type_name = "i8",   .size = 1,
   .write_str = (writer)write_str_i8, .read_str = (str_reader)read_str_i8};
static const struct primtype_info_t i16_info =
  {.binname = " i16", .type_name = "i16",  .size = 2,
   .write_str = (writer)write_str_i16, .read_str = (str_reader)read_str_i16};
static const struct primtype_info_t i32_info =
  {.binname = " i32", .type_name = "i32",  .size = 4,
   .write_str = (writer)write_str_i32, .read_str = (str_reader)read_str_i32};
static const struct primtype_info_t i64_info =
  {.binname = " i64", .type_name = "i64",  .size = 8,
   .write_str = (writer)write_str_i64, .read_str = (str_reader)read_str_i64};
static const struct primtype_info_t u8_info =
  {.binname = "  u8", .type_name = "u8",   .size = 1,
   .write_str = (writer)write_str_u8, .read_str = (str_reader)read_str_u8};
static const struct primtype_info_t u16_info =
  {.binname = " u16", .type_name = "u16",  .size = 2,
   .write_str = (writer)write_str_u16, .read_str = (str_reader)read_str_u16};
static const struct primtype_info_t u32_info =
  {.binname = " u32", .type_name = "u32",  .size = 4,
   .write_str = (writer)write_str_u32, .read_str = (str_reader)read_str_u32};
static const struct primtype_info_t u64_info =
  {.binname = " u64", .type_name = "u64",  .size = 8,
   .write_str = (writer)write_str_u64, .read_str = (str_reader)read_str_u64};
static const struct primtype_info_t f16_info =
  {.binname = " f16", .type_name = "f16",  .size = 2,
   .write_str = (writer)write_str_f16, .read_str = (str_reader)read_str_f16};
static const struct primtype_info_t f32_info =
  {.binname = " f32", .type_name = "f32",  .size = 4,
   .write_str = (writer)write_str_f32, .read_str = (str_reader)read_str_f32};
static const struct primtype_info_t f64_info =
  {.binname = " f64", .type_name = "f64",  .size = 8,
   .write_str = (writer)write_str_f64, .read_str = (str_reader)read_str_f64};
static const struct primtype_info_t bool_info =
  {.binname = "bool", .type_name = "bool", .size = 1,
   .write_str = (writer)write_str_bool, .read_str = (str_reader)read_str_bool};

static const struct primtype_info_t* primtypes[] = {
  &i8_info, &i16_info, &i32_info, &i64_info,
  &u8_info, &u16_info, &u32_info, &u64_info,
  &f16_info, &f32_info, &f64_info,
  &bool_info,
  NULL // NULL-terminated
};

// General value interface.  All endian business taken care of at
// lower layers.

static int read_is_binary(FILE *f) {
  skipspaces(f);
  int c = getc(f);
  if (c == 'b') {
    int8_t bin_version;
    int ret = read_byte(f, &bin_version);

    if (ret != 0) { futhark_panic(1, "binary-input: could not read version.\n"); }

    if (bin_version != BINARY_FORMAT_VERSION) {
      futhark_panic(1, "binary-input: File uses version %i, but I only understand version %i.\n",
            bin_version, BINARY_FORMAT_VERSION);
    }

    return 1;
  }
  ungetc(c, f);
  return 0;
}

static const struct primtype_info_t* read_bin_read_type_enum(FILE *f) {
  char read_binname[4];

  int num_matched = fscanf(f, "%4c", read_binname);
  if (num_matched != 1) { futhark_panic(1, "binary-input: Couldn't read element type.\n"); }

  const struct primtype_info_t **type = primtypes;

  for (; *type != NULL; type++) {
    // I compare the 4 characters manually instead of using strncmp because
    // this allows any value to be used, also NULL bytes
    if (memcmp(read_binname, (*type)->binname, 4) == 0) {
      return *type;
    }
  }
  futhark_panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname);
  return NULL;
}

static void read_bin_ensure_scalar(FILE *f, const struct primtype_info_t *expected_type) {
  int8_t bin_dims;
  int ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != 0) {
    futhark_panic(1, "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
          bin_dims);
  }

  const struct primtype_info_t *bin_type = read_bin_read_type_enum(f);
  if (bin_type != expected_type) {
    futhark_panic(1, "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
          expected_type->type_name,
          bin_type->type_name);
  }
}

//// High-level interface

static int read_bin_array(FILE *f,
                          const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  int ret;

  int8_t bin_dims;
  ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != dims) {
    futhark_panic(1, "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
          dims, bin_dims);
  }

  const struct primtype_info_t *bin_primtype = read_bin_read_type_enum(f);
  if (expected_type != bin_primtype) {
    futhark_panic(1, "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
          dims, expected_type->type_name, dims, bin_primtype->type_name);
  }

  int64_t elem_count = 1;
  for (int i=0; i<dims; i++) {
    int64_t bin_shape;
    ret = (int)fread(&bin_shape, sizeof(bin_shape), 1, f);
    if (ret != 1) {
      futhark_panic(1, "binary-input: Couldn't read size for dimension %i of array.\n", i);
    }
    if (IS_BIG_ENDIAN) {
      flip_bytes(sizeof(bin_shape), (unsigned char*) &bin_shape);
    }
    elem_count *= bin_shape;
    shape[i] = bin_shape;
  }

  int64_t elem_size = expected_type->size;
  void* tmp = realloc(*data, (size_t)(elem_count * elem_size));
  if (tmp == NULL) {
    futhark_panic(1, "binary-input: Failed to allocate array of size %i.\n",
          elem_count * elem_size);
  }
  *data = tmp;

  int64_t num_elems_read = (int64_t)fread(*data, (size_t)elem_size, (size_t)elem_count, f);
  if (num_elems_read != elem_count) {
    futhark_panic(1, "binary-input: tried to read %i elements of an array, but only got %i elements.\n",
          elem_count, num_elems_read);
  }

  // If we're on big endian platform we must change all multibyte elements
  // from using little endian to big endian
  if (IS_BIG_ENDIAN && elem_size != 1) {
    flip_bytes((size_t)elem_size, (unsigned char*) *data);
  }

  return 0;
}

static int read_array(FILE *f, const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  if (!read_is_binary(f)) {
    return read_str_array(f, expected_type->size, (str_reader)expected_type->read_str, expected_type->type_name, data, shape, dims);
  } else {
    return read_bin_array(f, expected_type, data, shape, dims);
  }
}

static int end_of_input(FILE *f) {
  skipspaces(f);
  char token[2];
  next_token(f, token, sizeof(token));
  if (strcmp(token, "") == 0) {
    return 0;
  } else {
    return 1;
  }
}

static int write_str_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  if (rank==0) {
    elem_type->write_str(out, (const void*)data);
  } else {
    int64_t len = (int64_t)shape[0];
    int64_t slice_size = 1;

    int64_t elem_size = elem_type->size;
    for (int8_t i = 1; i < rank; i++) {
      slice_size *= shape[i];
    }

    if (len*slice_size == 0) {
      fprintf(out, "empty(");
      for (int64_t i = 0; i < rank; i++) {
        fprintf(out, "[%"PRIi64"]", shape[i]);
      }
      fprintf(out, "%s", elem_type->type_name);
      fprintf(out, ")");
    } else if (rank==1) {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        elem_type->write_str(out, (const void*) (data + i * elem_size));
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    } else {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        write_str_array(out, elem_type, data + i * slice_size * elem_size, shape+1, rank-1);
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    }
  }
  return 0;
}

static int write_bin_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  int64_t num_elems = 1;
  for (int64_t i = 0; i < rank; i++) {
    num_elems *= shape[i];
  }

  fputc('b', out);
  fputc((char)BINARY_FORMAT_VERSION, out);
  fwrite(&rank, sizeof(int8_t), 1, out);
  fwrite(elem_type->binname, 4, 1, out);
  if (shape != NULL) {
    fwrite(shape, sizeof(int64_t), (size_t)rank, out);
  }

  if (IS_BIG_ENDIAN) {
    for (int64_t i = 0; i < num_elems; i++) {
      const unsigned char *elem = data+i*elem_type->size;
      for (int64_t j = 0; j < elem_type->size; j++) {
        fwrite(&elem[elem_type->size-j], 1, 1, out);
      }
    }
  } else {
    fwrite(data, (size_t)elem_type->size, (size_t)num_elems, out);
  }

  return 0;
}

static int write_array(FILE *out, int write_binary,
                       const struct primtype_info_t *elem_type,
                       const void *data,
                       const int64_t *shape,
                       const int8_t rank) {
  if (write_binary) {
    return write_bin_array(out, elem_type, data, shape, rank);
  } else {
    return write_str_array(out, elem_type, data, shape, rank);
  }
}

static int read_scalar(FILE *f,
                       const struct primtype_info_t *expected_type, void *dest) {
  if (!read_is_binary(f)) {
    char buf[100];
    next_token(f, buf, sizeof(buf));
    return expected_type->read_str(buf, dest);
  } else {
    read_bin_ensure_scalar(f, expected_type);
    size_t elem_size = (size_t)expected_type->size;
    size_t num_elems_read = fread(dest, elem_size, 1, f);
    if (IS_BIG_ENDIAN) {
      flip_bytes(elem_size, (unsigned char*) dest);
    }
    return num_elems_read == 1 ? 0 : 1;
  }
}

static int write_scalar(FILE *out, int write_binary, const struct primtype_info_t *type, void *src) {
  if (write_binary) {
    return write_bin_array(out, type, src, NULL, 0);
  } else {
    return type->write_str(out, src);
  }
}

// End of values.h.

// Start of server.h.

// Forward declarations of things that we technically don't know until
// the application header file is included, but which we need.
struct futhark_context_config;
struct futhark_context;
char *futhark_context_get_error(struct futhark_context *ctx);
int futhark_context_sync(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value);
int futhark_get_tuning_param_count(void);
const char* futhark_get_tuning_param_name(int i);
const char* futhark_get_tuning_param_class(int i);

typedef int (*restore_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef void (*store_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef int (*free_fn)(const void*, struct futhark_context*, void*);
typedef int (*project_fn)(struct futhark_context*, void*, const void*);
typedef int (*new_fn)(struct futhark_context*, void**, const void*[]);

struct field {
  const char *name;
  const struct type *type;
  project_fn project;
};

struct record {
  int num_fields;
  const struct field* fields;
  new_fn new;
};

struct type {
  const char *name;
  restore_fn restore;
  store_fn store;
  free_fn free;
  const void *aux;
  const struct record *record;
};

int free_scalar(const void *aux, struct futhark_context *ctx, void *p) {
  (void)aux;
  (void)ctx;
  (void)p;
  // Nothing to do.
  return 0;
}

#define DEF_SCALAR_TYPE(T)                                      \
  int restore_##T(const void *aux, FILE *f,                     \
                  struct futhark_context *ctx, void *p) {       \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    return read_scalar(f, &T##_info, p);                        \
  }                                                             \
                                                                \
  void store_##T(const void *aux, FILE *f,                      \
                 struct futhark_context *ctx, void *p) {        \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    write_scalar(f, 1, &T##_info, p);                           \
  }                                                             \
                                                                \
  struct type type_##T =                                        \
    { .name = #T,                                               \
      .restore = restore_##T,                                   \
      .store = store_##T,                                       \
      .free = free_scalar                                       \
    }                                                           \

DEF_SCALAR_TYPE(i8);
DEF_SCALAR_TYPE(i16);
DEF_SCALAR_TYPE(i32);
DEF_SCALAR_TYPE(i64);
DEF_SCALAR_TYPE(u8);
DEF_SCALAR_TYPE(u16);
DEF_SCALAR_TYPE(u32);
DEF_SCALAR_TYPE(u64);
DEF_SCALAR_TYPE(f16);
DEF_SCALAR_TYPE(f32);
DEF_SCALAR_TYPE(f64);
DEF_SCALAR_TYPE(bool);

struct value {
  const struct type *type;
  union {
    void *v_ptr;
    int8_t  v_i8;
    int16_t v_i16;
    int32_t v_i32;
    int64_t v_i64;

    uint8_t  v_u8;
    uint16_t v_u16;
    uint32_t v_u32;
    uint64_t v_u64;

    uint16_t v_f16;
    float v_f32;
    double v_f64;

    bool v_bool;
  } value;
};

void* value_ptr(struct value *v) {
  if (v->type == &type_i8) {
    return &v->value.v_i8;
  }
  if (v->type == &type_i16) {
    return &v->value.v_i16;
  }
  if (v->type == &type_i32) {
    return &v->value.v_i32;
  }
  if (v->type == &type_i64) {
    return &v->value.v_i64;
  }
  if (v->type == &type_u8) {
    return &v->value.v_u8;
  }
  if (v->type == &type_u16) {
    return &v->value.v_u16;
  }
  if (v->type == &type_u32) {
    return &v->value.v_u32;
  }
  if (v->type == &type_u64) {
    return &v->value.v_u64;
  }
  if (v->type == &type_f16) {
    return &v->value.v_f16;
  }
  if (v->type == &type_f32) {
    return &v->value.v_f32;
  }
  if (v->type == &type_f64) {
    return &v->value.v_f64;
  }
  if (v->type == &type_bool) {
    return &v->value.v_bool;
  }
  return &v->value.v_ptr;
}

struct variable {
  // NULL name indicates free slot.  Name is owned by this struct.
  char *name;
  struct value value;
};

typedef int (*entry_point_fn)(struct futhark_context*, void**, void**);

struct entry_point {
  const char *name;
  entry_point_fn f;
  const char** tuning_params;
  const struct type **out_types;
  bool *out_unique;
  const struct type **in_types;
  bool *in_unique;
};

int entry_num_ins(struct entry_point *e) {
  int count = 0;
  while (e->in_types[count]) {
    count++;
  }
  return count;
}

int entry_num_outs(struct entry_point *e) {
  int count = 0;
  while (e->out_types[count]) {
    count++;
  }
  return count;
}

struct futhark_prog {
  // Last entry point identified by NULL name.
  struct entry_point *entry_points;
  // Last type identified by NULL name.
  const struct type **types;
};

struct server_state {
  struct futhark_prog prog;
  struct futhark_context_config *cfg;
  struct futhark_context *ctx;
  int variables_capacity;
  struct variable *variables;
};

struct variable* get_variable(struct server_state *s,
                              const char *name) {
  for (int i = 0; i < s->variables_capacity; i++) {
    if (s->variables[i].name != NULL &&
        strcmp(s->variables[i].name, name) == 0) {
      return &s->variables[i];
    }
  }

  return NULL;
}

struct variable* create_variable(struct server_state *s,
                                 const char *name,
                                 const struct type *type) {
  int found = -1;
  for (int i = 0; i < s->variables_capacity; i++) {
    if (found == -1 && s->variables[i].name == NULL) {
      found = i;
    } else if (s->variables[i].name != NULL &&
               strcmp(s->variables[i].name, name) == 0) {
      return NULL;
    }
  }

  if (found != -1) {
    // Found a free spot.
    s->variables[found].name = strdup(name);
    s->variables[found].value.type = type;
    return &s->variables[found];
  }

  // Need to grow the buffer.
  found = s->variables_capacity;
  s->variables_capacity *= 2;
  s->variables = realloc(s->variables,
                         s->variables_capacity * sizeof(struct variable));

  s->variables[found].name = strdup(name);
  s->variables[found].value.type = type;

  for (int i = found+1; i < s->variables_capacity; i++) {
    s->variables[i].name = NULL;
  }

  return &s->variables[found];
}

void drop_variable(struct variable *v) {
  free(v->name);
  v->name = NULL;
}

int arg_exists(const char *args[], int i) {
  return args[i] != NULL;
}

const char* get_arg(const char *args[], int i) {
  if (!arg_exists(args, i)) {
    futhark_panic(1, "Insufficient command args.\n");
  }
  return args[i];
}

const struct type* get_type(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.types[i]; i++) {
    if (strcmp(s->prog.types[i]->name, name) == 0) {
      return s->prog.types[i];
    }
  }

  futhark_panic(1, "Unknown type %s\n", name);
  return NULL;
}

struct entry_point* get_entry_point(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    if (strcmp(s->prog.entry_points[i].name, name) == 0) {
      return &s->prog.entry_points[i];
    }
  }

  return NULL;
}

// Print the command-done marker, indicating that we are ready for
// more input.
void ok(void) {
  printf("%%%%%% OK\n");
  fflush(stdout);
}

// Print the failure marker.  Output is now an error message until the
// next ok().
void failure(void) {
  printf("%%%%%% FAILURE\n");
}

void error_check(struct server_state *s, int err) {
  if (err != 0) {
    failure();
    char *error = futhark_context_get_error(s->ctx);
    if (error != NULL) {
      puts(error);
    }
    free(error);
  }
}

void cmd_call(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);

  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  int num_ins = entry_num_ins(e);
  // +1 to avoid zero-size arrays, which is UB.
  void* outs[num_outs+1];
  void* ins[num_ins+1];

  for (int i = 0; i < num_ins; i++) {
    const char *in_name = get_arg(args, 1+num_outs+i);
    struct variable *v = get_variable(s, in_name);
    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", in_name);
      return;
    }
    if (v->value.type != e->in_types[i]) {
      failure();
      printf("Wrong input type.  Expected %s, got %s.\n",
             e->in_types[i]->name, v->value.type->name);
      return;
    }
    ins[i] = value_ptr(&v->value);
  }

  for (int i = 0; i < num_outs; i++) {
    const char *out_name = get_arg(args, 1+i);
    struct variable *v = create_variable(s, out_name, e->out_types[i]);
    if (v == NULL) {
      failure();
      printf("Variable already exists: %s\n", out_name);
      return;
    }
    outs[i] = value_ptr(&v->value);
  }

  int64_t t_start = get_wall_time();
  int err = e->f(s->ctx, outs, ins);
  err |= futhark_context_sync(s->ctx);
  int64_t t_end = get_wall_time();
  long long int elapsed_usec = t_end - t_start;
  printf("runtime: %lld\n", elapsed_usec);

  error_check(s, err);
  if (err != 0) {
    // Need to uncreate the output variables, which would otherwise be left
    // in an uninitialised state.
    for (int i = 0; i < num_outs; i++) {
      const char *out_name = get_arg(args, 1+i);
      struct variable *v = get_variable(s, out_name);
      if (v) {
        drop_variable(v);
      }
    }
  }
}

void cmd_restore(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "rb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
    return;
  }

  int bad = 0;
  int values = 0;
  for (int i = 1; arg_exists(args, i); i+=2, values++) {
    const char *vname = get_arg(args, i);
    const char *type = get_arg(args, i+1);

    const struct type *t = get_type(s, type);
    struct variable *v = create_variable(s, vname, t);

    if (v == NULL) {
      bad = 1;
      failure();
      printf("Variable already exists: %s\n", vname);
      break;
    }

    errno = 0;
    if (t->restore(t->aux, f, s->ctx, value_ptr(&v->value)) != 0) {
      bad = 1;
      failure();
      printf("Failed to restore variable %s.\n"
             "Possibly malformed data in %s (errno: %s)\n",
             vname, fname, strerror(errno));
      drop_variable(v);
      break;
    }
  }

  if (!bad && end_of_input(f) != 0) {
    failure();
    printf("Expected EOF after reading %d values from %s\n",
           values, fname);
  }

  fclose(f);

  if (!bad) {
    int err = futhark_context_sync(s->ctx);
    error_check(s, err);
  }
}

void cmd_store(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "wb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
  } else {
    for (int i = 1; arg_exists(args, i); i++) {
      const char *vname = get_arg(args, i);
      struct variable *v = get_variable(s, vname);

      if (v == NULL) {
        failure();
        printf("Unknown variable: %s\n", vname);
        return;
      }

      const struct type *t = v->value.type;
      t->store(t->aux, f, s->ctx, value_ptr(&v->value));
    }
    fclose(f);
  }
}

void cmd_free(struct server_state *s, const char *args[]) {
  for (int i = 0; arg_exists(args, i); i++) {
    const char *name = get_arg(args, i);
    struct variable *v = get_variable(s, name);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", name);
      return;
    }

    const struct type *t = v->value.type;

    int err = t->free(t->aux, s->ctx, value_ptr(&v->value));
    error_check(s, err);
    drop_variable(v);
  }
}

void cmd_rename(struct server_state *s, const char *args[]) {
  const char *oldname = get_arg(args, 0);
  const char *newname = get_arg(args, 1);
  struct variable *old = get_variable(s, oldname);
  struct variable *new = get_variable(s, newname);

  if (old == NULL) {
    failure();
    printf("Unknown variable: %s\n", oldname);
    return;
  }

  if (new != NULL) {
    failure();
    printf("Variable already exists: %s\n", newname);
    return;
  }

  free(old->name);
  old->name = strdup(newname);
}

void cmd_inputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_ins = entry_num_ins(e);
  for (int i = 0; i < num_ins; i++) {
    if (e->in_unique[i]) {
      putchar('*');
    }
    puts(e->in_types[i]->name);
  }
}

void cmd_outputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  for (int i = 0; i < num_outs; i++) {
    if (e->out_unique[i]) {
      putchar('*');
    }
    puts(e->out_types[i]->name);
  }
}

void cmd_clear(struct server_state *s, const char *args[]) {
  (void)args;
  int err = 0;
  for (int i = 0; i < s->variables_capacity; i++) {
    struct variable *v = &s->variables[i];
    if (v->name != NULL) {
      err |= v->value.type->free(v->value.type->aux, s->ctx, value_ptr(&v->value));
      drop_variable(v);
    }
  }
  err |= futhark_context_clear_caches(s->ctx);
  error_check(s, err);
}

void cmd_pause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_pause_profiling(s->ctx);
}

void cmd_unpause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_unpause_profiling(s->ctx);
}

void cmd_report(struct server_state *s, const char *args[]) {
  (void)args;
  char *report = futhark_context_report(s->ctx);
  if (report) {
    puts(report);
  } else {
    failure();
    report = futhark_context_get_error(s->ctx);
    if (report) {
      puts(report);
    } else {
      puts("Failed to produce profiling report.\n");
    }
  }
  free(report);
}

void cmd_set_tuning_param(struct server_state *s, const char *args[]) {
  const char *param = get_arg(args, 0);
  const char *val_s = get_arg(args, 1);
  size_t val = atol(val_s);
  int err = futhark_context_config_set_tuning_param(s->cfg, param, val);

  error_check(s, err);

  if (err != 0) {
    printf("Failed to set tuning parameter %s to %ld\n", param, (long)val);
  }
}

void cmd_tuning_params(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  const char **params = e->tuning_params;
  for (int i = 0; params[i] != NULL; i++) {
    printf("%s\n", params[i]);
  }
}

void cmd_tuning_param_class(struct server_state *s, const char *args[]) {
  (void)s;
  const char *param = get_arg(args, 0);

  int n = futhark_get_tuning_param_count();

  for (int i = 0; i < n; i++) {
    if (strcmp(futhark_get_tuning_param_name(i), param) == 0) {
      printf("%s\n", futhark_get_tuning_param_class(i));
      return;
    }
  }

  failure();
  printf("Unknown tuning parameter: %s\n", param);
}

void cmd_fields(struct server_state *s, const char *args[]) {
  const char *type = get_arg(args, 0);
  const struct type *t = get_type(s, type);
  const struct record *r = t->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  for (int i = 0; i < r->num_fields; i++) {
    const struct field f = r->fields[i];
    printf("%s %s\n", f.name, f.type->name);
  }
}

void cmd_project(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *from_name = get_arg(args, 1);
  const char *field_name = get_arg(args, 2);

  struct variable *from = get_variable(s, from_name);

  if (from == NULL) {
    failure();
    printf("Unknown variable: %s\n", from_name);
    return;
  }

  const struct type *from_type = from->value.type;
  const struct record *r = from_type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  const struct field *field = NULL;
  for (int i = 0; i < r->num_fields; i++) {
    if (strcmp(r->fields[i].name, field_name) == 0) {
      field = &r->fields[i];
      break;
    }
  }

  if (field == NULL) {
    failure();
    printf("No such field\n");
  }

  struct variable *to = create_variable(s, to_name, field->type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  field->project(s->ctx, value_ptr(&to->value), from->value.value.v_ptr);
}

void cmd_new(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *type_name = get_arg(args, 1);
  const struct type *type = get_type(s, type_name);
  struct variable *to = create_variable(s, to_name, type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  const struct record* r = type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  int num_args = 0;
  for (int i = 2; arg_exists(args, i); i++) {
    num_args++;
  }

  if (num_args != r->num_fields) {
    failure();
    printf("%d fields expected but %d values provided.\n", num_args, r->num_fields);
    return;
  }

  const void** value_ptrs = alloca(num_args * sizeof(void*));

  for (int i = 0; i < num_args; i++) {
    struct variable* v = get_variable(s, args[2+i]);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", args[2+i]);
      return;
    }

    if (strcmp(v->value.type->name, r->fields[i].type->name) != 0) {
      failure();
      printf("Field %s mismatch: expected type %s, got %s\n",
             r->fields[i].name, r->fields[i].type->name, v->value.type->name);
      return;
    }

    value_ptrs[i] = value_ptr(&v->value);
  }

  r->new(s->ctx, value_ptr(&to->value), value_ptrs);
}

void cmd_entry_points(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    puts(s->prog.entry_points[i].name);
  }
}

void cmd_types(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.types[i] != NULL; i++) {
    puts(s->prog.types[i]->name);
  }
}

char *next_word(char **line) {
  char *p = *line;

  while (isspace(*p)) {
    p++;
  }

  if (*p == 0) {
    return NULL;
  }

  if (*p == '"') {
    char *save = p+1;
    // Skip ahead till closing quote.
    p++;

    while (*p && *p != '"') {
      p++;
    }

    if (*p == '"') {
      *p = 0;
      *line = p+1;
      return save;
    } else {
      return NULL;
    }
  } else {
    char *save = p;
    // Skip ahead till next whitespace.

    while (*p && !isspace(*p)) {
      p++;
    }

    if (*p) {
      *p = 0;
      *line = p+1;
    } else {
      *line = p;
    }
    return save;
  }
}

void process_line(struct server_state *s, char *line) {
  int max_num_tokens = 1000;
  const char* tokens[max_num_tokens];
  int num_tokens = 0;

  while ((tokens[num_tokens] = next_word(&line)) != NULL) {
    num_tokens++;
    if (num_tokens == max_num_tokens) {
      futhark_panic(1, "Line too long.\n");
    }
  }

  const char *command = tokens[0];

  if (command == NULL) {
    failure();
    printf("Empty line\n");
  } else if (strcmp(command, "call") == 0) {
    cmd_call(s, tokens+1);
  } else if (strcmp(command, "restore") == 0) {
    cmd_restore(s, tokens+1);
  } else if (strcmp(command, "store") == 0) {
    cmd_store(s, tokens+1);
  } else if (strcmp(command, "free") == 0) {
    cmd_free(s, tokens+1);
  } else if (strcmp(command, "rename") == 0) {
    cmd_rename(s, tokens+1);
  } else if (strcmp(command, "inputs") == 0) {
    cmd_inputs(s, tokens+1);
  } else if (strcmp(command, "outputs") == 0) {
    cmd_outputs(s, tokens+1);
  } else if (strcmp(command, "clear") == 0) {
    cmd_clear(s, tokens+1);
  } else if (strcmp(command, "pause_profiling") == 0) {
    cmd_pause_profiling(s, tokens+1);
  } else if (strcmp(command, "unpause_profiling") == 0) {
    cmd_unpause_profiling(s, tokens+1);
  } else if (strcmp(command, "report") == 0) {
    cmd_report(s, tokens+1);
  } else if (strcmp(command, "set_tuning_param") == 0) {
    cmd_set_tuning_param(s, tokens+1);
  } else if (strcmp(command, "tuning_params") == 0) {
    cmd_tuning_params(s, tokens+1);
  } else if (strcmp(command, "tuning_param_class") == 0) {
    cmd_tuning_param_class(s, tokens+1);
  } else if (strcmp(command, "fields") == 0) {
    cmd_fields(s, tokens+1);
  } else if (strcmp(command, "new") == 0) {
    cmd_new(s, tokens+1);
  } else if (strcmp(command, "project") == 0) {
    cmd_project(s, tokens+1);
  } else if (strcmp(command, "entry_points") == 0) {
    cmd_entry_points(s, tokens+1);
  } else if (strcmp(command, "types") == 0) {
    cmd_types(s, tokens+1);
  } else {
    futhark_panic(1, "Unknown command: %s\n", command);
  }
}

void run_server(struct futhark_prog *prog,
                struct futhark_context_config *cfg,
                struct futhark_context *ctx) {
  char *line = NULL;
  size_t buflen = 0;
  ssize_t linelen;

  struct server_state s = {
    .cfg = cfg,
    .ctx = ctx,
    .variables_capacity = 100,
    .prog = *prog
  };

  s.variables = malloc(s.variables_capacity * sizeof(struct variable));

  for (int i = 0; i < s.variables_capacity; i++) {
    s.variables[i].name = NULL;
  }

  ok();
  while ((linelen = getline(&line, &buflen, stdin)) > 0) {
    process_line(&s, line);
    ok();
  }

  free(s.variables);
  free(line);
}

// The aux struct lets us write generic method implementations without
// code duplication.

typedef void* (*array_new_fn)(struct futhark_context *, const void*, const int64_t*);
typedef const int64_t* (*array_shape_fn)(struct futhark_context*, void*);
typedef int (*array_values_fn)(struct futhark_context*, void*, void*);
typedef int (*array_free_fn)(struct futhark_context*, void*);

struct array_aux {
  int rank;
  const struct primtype_info_t* info;
  const char *name;
  array_new_fn new;
  array_shape_fn shape;
  array_values_fn values;
  array_free_fn free;
};

int restore_array(const struct array_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *data = NULL;
  int64_t shape[aux->rank];
  if (read_array(f, aux->info, &data, shape, aux->rank) != 0) {
    return 1;
  }

  void *arr = aux->new(ctx, data, shape);
  if (arr == NULL) {
    return 1;
  }
  int err = futhark_context_sync(ctx);
  *(void**)p = arr;
  free(data);
  return err;
}

void store_array(const struct array_aux *aux, FILE *f,
                 struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  const int64_t *shape = aux->shape(ctx, arr);
  int64_t size = sizeof(aux->info->size);
  for (int i = 0; i < aux->rank; i++) {
    size *= shape[i];
  }
  int32_t *data = malloc(size);
  assert(aux->values(ctx, arr, data) == 0);
  assert(futhark_context_sync(ctx) == 0);
  assert(write_array(f, 1, aux->info, data, shape, aux->rank) == 0);
  free(data);
}

int free_array(const struct array_aux *aux,
               struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  return aux->free(ctx, arr);
}

typedef void* (*opaque_restore_fn)(struct futhark_context*, void*);
typedef int (*opaque_store_fn)(struct futhark_context*, const void*, void **, size_t *);
typedef int (*opaque_free_fn)(struct futhark_context*, void*);

struct opaque_aux {
  opaque_restore_fn restore;
  opaque_store_fn store;
  opaque_free_fn free;
};

int restore_opaque(const struct opaque_aux *aux, FILE *f,
                   struct futhark_context *ctx, void *p) {
  // We have a problem: we need to load data from 'f', since the
  // restore function takes a pointer, but we don't know how much we
  // need (and cannot possibly).  So we do something hacky: we read
  // *all* of the file, pass all of the data to the restore function
  // (which doesn't care if there's extra at the end), then we compute
  // how much space the the object actually takes in serialised form
  // and rewind the file to that position.  The only downside is more IO.
  size_t start = ftell(f);
  size_t size;
  char *bytes = fslurp_file(f, &size);
  void *obj = aux->restore(ctx, bytes);
  free(bytes);
  if (obj != NULL) {
    *(void**)p = obj;
    size_t obj_size;
    (void)aux->store(ctx, obj, NULL, &obj_size);
    fseek(f, start+obj_size, SEEK_SET);
    return 0;
  } else {
    fseek(f, start, SEEK_SET);
    return 1;
  }
}

void store_opaque(const struct opaque_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  size_t obj_size;
  void *data = NULL;
  (void)aux->store(ctx, obj, &data, &obj_size);
  assert(futhark_context_sync(ctx) == 0);
  fwrite(data, sizeof(char), obj_size, f);
  free(data);
}

int free_opaque(const struct opaque_aux *aux,
                struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  return aux->free(ctx, obj);
}

// End of server.h.

// Start of tuning.h.


int is_blank_line_or_comment(const char *s) {
  size_t i = strspn(s, " \t\n");
  return s[i] == '\0' || // Line is blank.
         strncmp(s + i, "--", 2) == 0; // Line is comment.
}

static char* load_tuning_file(const char *fname,
                              void *cfg,
                              int (*set_tuning_param)(void*, const char*, size_t)) {
  const int max_line_len = 1024;
  char* line = (char*) malloc(max_line_len);

  FILE *f = fopen(fname, "r");

  if (f == NULL) {
    snprintf(line, max_line_len, "Cannot open file: %s", strerror(errno));
    return line;
  }

  int lineno = 0;
  while (fgets(line, max_line_len, f) != NULL) {
    lineno++;
    if (is_blank_line_or_comment(line)) {
      continue;
    }
    char *eql = strstr(line, "=");
    if (eql) {
      *eql = 0;
      char *endptr;
      int value = strtol(eql+1, &endptr, 10);
      if (*endptr && *endptr != '\n') {
        snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
                 lineno);
        return line;
      }
      if (set_tuning_param(cfg, line, (size_t)value) != 0) {
        char* err = (char*) malloc(max_line_len + 50);
        snprintf(err, max_line_len + 50, "Unknown name '%s' on line %d.", line, lineno);
        free(line);
        return err;
      }
    } else {
      snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
               lineno);
      return line;
    }
  }

  free(line);

  return NULL;
}

// End of tuning.h.

const struct type type_ZMZNf32;
const struct type type_ZMZNi32;
void *futhark_new_f32_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_f32_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNf32_aux = {.name ="[]f32", .rank =1, .info =&f32_info, .new =(array_new_fn) futhark_new_f32_1d_wrap, .free =(array_free_fn) futhark_free_f32_1d, .shape =(array_shape_fn) futhark_shape_f32_1d, .values =(array_values_fn) futhark_values_f32_1d};
const struct type type_ZMZNf32 = {.name ="[]f32", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNf32_aux};
void *futhark_new_i32_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_i32_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNi32_aux = {.name ="[]i32", .rank =1, .info =&i32_info, .new =(array_new_fn) futhark_new_i32_1d_wrap, .free =(array_free_fn) futhark_free_i32_1d, .shape =(array_shape_fn) futhark_shape_i32_1d, .values =(array_values_fn) futhark_values_i32_1d};
const struct type type_ZMZNi32 = {.name ="[]i32", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNi32_aux};
const struct type *compiler_out_types[] = {&type_ZMZNf32, NULL};
bool compiler_out_unique[] = {true};
const struct type *compiler_in_types[] = {&type_ZMZNi32, &type_ZMZNi32, &type_ZMZNf32, NULL};
bool compiler_in_unique[] = {false, false, false};
const char *compiler_tuning_params[] = {"builtin#replicate_bool.tblock_size_23057", "builtin#replicate_f32.tblock_size_22894", "builtin#replicate_i32.tblock_size_22950", "builtin#replicate_i8.tblock_size_22924", "compiler.hist_L2_23598", "compiler.hist_L2_23759", "compiler.hist_L2_23920", "compiler.hist_L_23545", "compiler.hist_L_23706", "compiler.hist_L_23867", "compiler.seghist_num_tblocks_22646", "compiler.seghist_num_tblocks_22662", "compiler.seghist_num_tblocks_22678", "compiler.seghist_tblock_size_22644", "compiler.seghist_tblock_size_22660", "compiler.seghist_tblock_size_22676", "compiler.segmap_num_tblocks_22552", "compiler.segmap_num_tblocks_22640", "compiler.segmap_num_tblocks_22761", "compiler.segmap_tblock_size_22550", "compiler.segmap_tblock_size_22566", "compiler.segmap_tblock_size_22594", "compiler.segmap_tblock_size_22638", "compiler.segmap_tblock_size_22694", "compiler.segmap_tblock_size_22759", "compiler.segscan_num_tblocks_22542", "compiler.segscan_num_tblocks_22558", "compiler.segscan_num_tblocks_22586", "compiler.segscan_num_tblocks_22630", "compiler.segscan_num_tblocks_22751", "compiler.segscan_tblock_size_22540", "compiler.segscan_tblock_size_22556", "compiler.segscan_tblock_size_22584", "compiler.segscan_tblock_size_22628", "compiler.segscan_tblock_size_22749", NULL};
int call_compiler(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f32_1d * *out0 = outs[0];
    struct futhark_i32_1d * in0 = *(struct futhark_i32_1d * *) ins[0];
    struct futhark_i32_1d * in1 = *(struct futhark_i32_1d * *) ins[1];
    struct futhark_f32_1d * in2 = *(struct futhark_f32_1d * *) ins[2];
    
    return futhark_entry_compiler(ctx, out0, in0, in1, in2);
}
const struct type *human_out_types[] = {&type_ZMZNf32, NULL};
bool human_out_unique[] = {true};
const struct type *human_in_types[] = {&type_ZMZNi32, &type_ZMZNi32, &type_ZMZNi32, &type_ZMZNf32, NULL};
bool human_in_unique[] = {false, false, false, false};
const char *human_tuning_params[] = {"builtin#replicate_f32.tblock_size_22894", "builtin#replicate_i32.tblock_size_22950", "builtin#replicate_i8.tblock_size_22924", "human.hist_L2_23152", "human.hist_L_23090", "human.seghist_num_tblocks_22059", "human.seghist_tblock_size_22057", "human.segmap_num_tblocks_22156", "human.segmap_tblock_size_21982", "human.segmap_tblock_size_22020", "human.segmap_tblock_size_22079", "human.segmap_tblock_size_22154", "human.segscan_num_tblocks_21974", "human.segscan_num_tblocks_22146", "human.segscan_tblock_size_21972", "human.segscan_tblock_size_22144", NULL};
int call_human(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f32_1d * *out0 = outs[0];
    struct futhark_i32_1d * in0 = *(struct futhark_i32_1d * *) ins[0];
    struct futhark_i32_1d * in1 = *(struct futhark_i32_1d * *) ins[1];
    struct futhark_i32_1d * in2 = *(struct futhark_i32_1d * *) ins[2];
    struct futhark_f32_1d * in3 = *(struct futhark_f32_1d * *) ins[3];
    
    return futhark_entry_human(ctx, out0, in0, in1, in2, in3);
}
const struct type *human_regular_out_types[] = {&type_ZMZNf32, NULL};
bool human_regular_out_unique[] = {true};
const struct type *human_regular_in_types[] = {&type_ZMZNi32, &type_ZMZNi32, &type_ZMZNi32, &type_ZMZNf32, NULL};
bool human_regular_in_unique[] = {false, false, false, false};
const char *human_regular_tuning_params[] = {"builtin#replicate_bool.tblock_size_23057", "builtin#replicate_i32.tblock_size_22950", "builtin#replicate_i8.tblock_size_22924", "human_regular.hist_L2_23417", "human_regular.hist_L2_23864", "human_regular.hist_L_23355", "human_regular.hist_L_23802", "human_regular.seghist_num_tblocks_22271", "human_regular.seghist_num_tblocks_22445", "human_regular.seghist_tblock_size_22269", "human_regular.seghist_tblock_size_22443", "human_regular.segmap_num_tblocks_22172", "human_regular.segmap_num_tblocks_22360", "human_regular.segmap_num_tblocks_22536", "human_regular.segmap_tblock_size_22170", "human_regular.segmap_tblock_size_22194", "human_regular.segmap_tblock_size_22236", "human_regular.segmap_tblock_size_22293", "human_regular.segmap_tblock_size_22358", "human_regular.segmap_tblock_size_22374", "human_regular.segmap_tblock_size_22410", "human_regular.segmap_tblock_size_22467", "human_regular.segmap_tblock_size_22534", "human_regular.segscan_num_tblocks_22162", "human_regular.segscan_num_tblocks_22178", "human_regular.segscan_num_tblocks_22186", "human_regular.segscan_num_tblocks_22350", "human_regular.segscan_num_tblocks_22366", "human_regular.segscan_num_tblocks_22526", "human_regular.segscan_tblock_size_22160", "human_regular.segscan_tblock_size_22176", "human_regular.segscan_tblock_size_22184", "human_regular.segscan_tblock_size_22348", "human_regular.segscan_tblock_size_22364", "human_regular.segscan_tblock_size_22524", NULL};
int call_human_regular(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f32_1d * *out0 = outs[0];
    struct futhark_i32_1d * in0 = *(struct futhark_i32_1d * *) ins[0];
    struct futhark_i32_1d * in1 = *(struct futhark_i32_1d * *) ins[1];
    struct futhark_i32_1d * in2 = *(struct futhark_i32_1d * *) ins[2];
    struct futhark_f32_1d * in3 = *(struct futhark_f32_1d * *) ins[3];
    
    return futhark_entry_human_regular(ctx, out0, in0, in1, in2, in3);
}
const struct type *types[] = {&type_i8, &type_i16, &type_i32, &type_i64, &type_u8, &type_u16, &type_u32, &type_u64, &type_f16, &type_f32, &type_f64, &type_bool, &type_ZMZNf32, &type_ZMZNi32, NULL};
struct entry_point entry_points[] = {{.name ="compiler", .f =call_compiler, .tuning_params =compiler_tuning_params, .in_types =compiler_in_types, .out_types =compiler_out_types, .in_unique =compiler_in_unique, .out_unique =compiler_out_unique}, {.name ="human", .f =call_human, .tuning_params =human_tuning_params, .in_types =human_in_types, .out_types =human_out_types, .in_unique =human_in_unique, .out_unique =human_out_unique}, {.name ="human_regular", .f =call_human_regular, .tuning_params =human_regular_tuning_params, .in_types =human_regular_in_types, .out_types =human_regular_out_types, .in_unique =human_regular_in_unique, .out_unique =human_regular_out_unique}, {.name =NULL}};
struct futhark_prog prog = {.types =types, .entry_points =entry_points};
int parse_options(struct futhark_context_config *cfg, int argc, char *const argv[])
{
    int ch;
    static struct option long_options[] = {{"debugging", no_argument, NULL, 1}, {"log", no_argument, NULL, 2}, {"profile", no_argument, NULL, 3}, {"help", no_argument, NULL, 4}, {"print-params", no_argument, NULL, 5}, {"param", required_argument, NULL, 6}, {"tuning", required_argument, NULL, 7}, {"cache-file", required_argument, NULL, 8}, {"device", required_argument, NULL, 9}, {"default-thread-block-size", required_argument, NULL, 10}, {"default-grid-size", required_argument, NULL, 11}, {"default-group-size", required_argument, NULL, 12}, {"default-num-groups", required_argument, NULL, 13}, {"default-tile-size", required_argument, NULL, 14}, {"default-reg-tile-size", required_argument, NULL, 15}, {"default-registers", required_argument, NULL, 16}, {"default-cache", required_argument, NULL, 17}, {"default-threshold", required_argument, NULL, 18}, {"unified-memory", required_argument, NULL, 19}, {"dump-cuda", required_argument, NULL, 20}, {"load-cuda", required_argument, NULL, 21}, {"dump-ptx", required_argument, NULL, 22}, {"load-ptx", required_argument, NULL, 23}, {"nvrtc-option", required_argument, NULL, 24}, {0, 0, 0, 0}};
    static char *option_descriptions = "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n";
    
    while ((ch = getopt_long(argc, argv, ":DLPhd:", long_options, NULL)) != -1) {
        if (ch == 1 || ch == 'D')
            futhark_context_config_set_debugging(cfg, 1);
        if (ch == 2 || ch == 'L')
            futhark_context_config_set_logging(cfg, 1);
        if (ch == 3 || ch == 'P')
            futhark_context_config_set_profiling(cfg, 1);
        if (ch == 4 || ch == 'h') {
            printf("Usage: %s [OPTIONS]...\nOptions:\n\n%s\nFor more information, consult the Futhark User's Guide or the man pages.\n", fut_progname, option_descriptions);
            exit(0);
        }
        if (ch == 5) {
            int n = futhark_get_tuning_param_count();
            
            for (int i = 0; i < n; i++)
                printf("%s (%s)\n", futhark_get_tuning_param_name(i), futhark_get_tuning_param_class(i));
            exit(0);
        }
        if (ch == 6) {
            char *name = optarg;
            char *equals = strstr(optarg, "=");
            char *value_str = equals != NULL ? equals + 1 : optarg;
            int value = atoi(value_str);
            
            if (equals != NULL) {
                *equals = 0;
                if (futhark_context_config_set_tuning_param(cfg, name, value) != 0)
                    futhark_panic(1, "Unknown size: %s\n", name);
            } else
                futhark_panic(1, "Invalid argument for size option: %s\n", optarg);
        }
        if (ch == 7) {
            char *ret = load_tuning_file(optarg, cfg, (int (*)(void *, const char *, size_t)) futhark_context_config_set_tuning_param);
            
            if (ret != NULL)
                futhark_panic(1, "When loading tuning file '%s': %s\n", optarg, ret);
        }
        if (ch == 8)
            futhark_context_config_set_cache_file(cfg, optarg);
        if (ch == 9 || ch == 'd')
            futhark_context_config_set_device(cfg, optarg);
        if (ch == 10)
            futhark_context_config_set_default_thread_block_size(cfg, atoi(optarg));
        if (ch == 11)
            futhark_context_config_set_default_grid_size(cfg, atoi(optarg));
        if (ch == 12)
            futhark_context_config_set_default_group_size(cfg, atoi(optarg));
        if (ch == 13)
            futhark_context_config_set_default_num_groups(cfg, atoi(optarg));
        if (ch == 14)
            futhark_context_config_set_default_tile_size(cfg, atoi(optarg));
        if (ch == 15)
            futhark_context_config_set_default_reg_tile_size(cfg, atoi(optarg));
        if (ch == 16)
            futhark_context_config_set_default_registers(cfg, atoi(optarg));
        if (ch == 17)
            futhark_context_config_set_default_cache(cfg, atoi(optarg));
        if (ch == 18)
            futhark_context_config_set_default_threshold(cfg, atoi(optarg));
        if (ch == 19)
            futhark_context_config_set_unified_memory(cfg, atoi(optarg));
        if (ch == 20) {
            const char *prog = futhark_context_config_get_program(cfg);
            
            if (dump_file(optarg, prog, strlen(prog)) != 0) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            exit(0);
        }
        if (ch == 21) {
            size_t n;
            const char *s = slurp_file(optarg, &n);
            
            if (s == NULL) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            futhark_context_config_set_program(cfg, s);
        }
        if (ch == 22) {
            futhark_context_config_dump_ptx_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 23)
            futhark_context_config_load_ptx_from(cfg, optarg);
        if (ch == 24)
            futhark_context_config_add_nvrtc_option(cfg, optarg);
        if (ch == ':')
            futhark_panic(-1, "Missing argument for option %s\n", argv[optind - 1]);
        if (ch == '?') {
            fprintf(stderr, "Usage: %s [OPTIONS]...\nOptions:\n\n%s\n", fut_progname, "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n");
            futhark_panic(1, "Unknown option: %s\n", argv[optind - 1]);
        }
    }
    return optind;
}
int main(int argc, char **argv)
{
    fut_progname = argv[0];
    
    struct futhark_context_config *cfg = futhark_context_config_new();
    
    assert(cfg != NULL);
    
    int parsed_options = parse_options(cfg, argc, argv);
    
    argc -= parsed_options;
    argv += parsed_options;
    if (argc != 0)
        futhark_panic(1, "Excess non-option: %s\n", argv[0]);
    
    struct futhark_context *ctx = futhark_context_new(cfg);
    
    assert(ctx != NULL);
    futhark_context_set_logging_file(ctx, stdout);
    
    char *error = futhark_context_get_error(ctx);
    
    if (error != NULL)
        futhark_panic(1, "Error during context initialisation:\n%s", error);
    if (entry_point != NULL)
        run_server(&prog, cfg, ctx);
    futhark_context_free(ctx);
    futhark_context_config_free(cfg);
}

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_23223;
    struct memblock_device counters_mem_23488;
    struct memblock_device counters_mem_23659;
    struct memblock_device counters_mem_23820;
    struct memblock_device counters_mem_23935;
    struct memblock_device counters_mem_23981;
    struct memblock_device global_dynid_mem_22919;
    struct memblock_device global_dynid_mem_22939;
    struct memblock_device global_dynid_mem_22951;
    struct memblock_device global_dynid_mem_23080;
    struct memblock_device global_dynid_mem_23096;
    struct memblock_device global_dynid_mem_23220;
    struct memblock_device global_dynid_mem_23236;
    struct memblock_device global_dynid_mem_23289;
    struct memblock_device global_dynid_mem_23340;
    struct memblock_device global_dynid_mem_23554;
    struct memblock_device global_dynid_mem_23683;
    struct memblock_device global_dynid_mem_24001;
    struct memblock_device global_dynid_mem_24041;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhreplicate_boolzitblock_sizze_23057;
    int64_t *builtinzhreplicate_f32zitblock_sizze_22894;
    int64_t *builtinzhreplicate_i32zitblock_sizze_22950;
    int64_t *builtinzhreplicate_i8zitblock_sizze_22924;
    int64_t *compilerzihist_L2_23598;
    int64_t *compilerzihist_L2_23759;
    int64_t *compilerzihist_L2_23920;
    int64_t *compilerzihist_L_23545;
    int64_t *compilerzihist_L_23706;
    int64_t *compilerzihist_L_23867;
    int64_t *compilerziseghist_num_tblocks_22646;
    int64_t *compilerziseghist_num_tblocks_22662;
    int64_t *compilerziseghist_num_tblocks_22678;
    int64_t *compilerziseghist_tblock_sizze_22644;
    int64_t *compilerziseghist_tblock_sizze_22660;
    int64_t *compilerziseghist_tblock_sizze_22676;
    int64_t *compilerzisegmap_num_tblocks_22552;
    int64_t *compilerzisegmap_num_tblocks_22640;
    int64_t *compilerzisegmap_num_tblocks_22761;
    int64_t *compilerzisegmap_tblock_sizze_22550;
    int64_t *compilerzisegmap_tblock_sizze_22566;
    int64_t *compilerzisegmap_tblock_sizze_22594;
    int64_t *compilerzisegmap_tblock_sizze_22638;
    int64_t *compilerzisegmap_tblock_sizze_22694;
    int64_t *compilerzisegmap_tblock_sizze_22759;
    int64_t *compilerzisegscan_num_tblocks_22542;
    int64_t *compilerzisegscan_num_tblocks_22558;
    int64_t *compilerzisegscan_num_tblocks_22586;
    int64_t *compilerzisegscan_num_tblocks_22630;
    int64_t *compilerzisegscan_num_tblocks_22751;
    int64_t *compilerzisegscan_tblock_sizze_22540;
    int64_t *compilerzisegscan_tblock_sizze_22556;
    int64_t *compilerzisegscan_tblock_sizze_22584;
    int64_t *compilerzisegscan_tblock_sizze_22628;
    int64_t *compilerzisegscan_tblock_sizze_22749;
    int64_t *humanzihist_L2_23152;
    int64_t *humanzihist_L_23090;
    int64_t *humanziseghist_num_tblocks_22059;
    int64_t *humanziseghist_tblock_sizze_22057;
    int64_t *humanzisegmap_num_tblocks_22156;
    int64_t *humanzisegmap_tblock_sizze_21982;
    int64_t *humanzisegmap_tblock_sizze_22020;
    int64_t *humanzisegmap_tblock_sizze_22079;
    int64_t *humanzisegmap_tblock_sizze_22154;
    int64_t *humanzisegscan_num_tblocks_21974;
    int64_t *humanzisegscan_num_tblocks_22146;
    int64_t *humanzisegscan_tblock_sizze_21972;
    int64_t *humanzisegscan_tblock_sizze_22144;
    int64_t *human_regularzihist_L2_23417;
    int64_t *human_regularzihist_L2_23864;
    int64_t *human_regularzihist_L_23355;
    int64_t *human_regularzihist_L_23802;
    int64_t *human_regularziseghist_num_tblocks_22271;
    int64_t *human_regularziseghist_num_tblocks_22445;
    int64_t *human_regularziseghist_tblock_sizze_22269;
    int64_t *human_regularziseghist_tblock_sizze_22443;
    int64_t *human_regularzisegmap_num_tblocks_22172;
    int64_t *human_regularzisegmap_num_tblocks_22360;
    int64_t *human_regularzisegmap_num_tblocks_22536;
    int64_t *human_regularzisegmap_tblock_sizze_22170;
    int64_t *human_regularzisegmap_tblock_sizze_22194;
    int64_t *human_regularzisegmap_tblock_sizze_22236;
    int64_t *human_regularzisegmap_tblock_sizze_22293;
    int64_t *human_regularzisegmap_tblock_sizze_22358;
    int64_t *human_regularzisegmap_tblock_sizze_22374;
    int64_t *human_regularzisegmap_tblock_sizze_22410;
    int64_t *human_regularzisegmap_tblock_sizze_22467;
    int64_t *human_regularzisegmap_tblock_sizze_22534;
    int64_t *human_regularzisegscan_num_tblocks_22162;
    int64_t *human_regularzisegscan_num_tblocks_22178;
    int64_t *human_regularzisegscan_num_tblocks_22186;
    int64_t *human_regularzisegscan_num_tblocks_22350;
    int64_t *human_regularzisegscan_num_tblocks_22366;
    int64_t *human_regularzisegscan_num_tblocks_22526;
    int64_t *human_regularzisegscan_tblock_sizze_22160;
    int64_t *human_regularzisegscan_tblock_sizze_22176;
    int64_t *human_regularzisegscan_tblock_sizze_22184;
    int64_t *human_regularzisegscan_tblock_sizze_22348;
    int64_t *human_regularzisegscan_tblock_sizze_22364;
    int64_t *human_regularzisegscan_tblock_sizze_22524;
};
static const int num_tuning_params = 80;
static const char *tuning_param_names[] = {"builtin#replicate_bool.tblock_size_23057", "builtin#replicate_f32.tblock_size_22894", "builtin#replicate_i32.tblock_size_22950", "builtin#replicate_i8.tblock_size_22924", "compiler.hist_L2_23598", "compiler.hist_L2_23759", "compiler.hist_L2_23920", "compiler.hist_L_23545", "compiler.hist_L_23706", "compiler.hist_L_23867", "compiler.seghist_num_tblocks_22646", "compiler.seghist_num_tblocks_22662", "compiler.seghist_num_tblocks_22678", "compiler.seghist_tblock_size_22644", "compiler.seghist_tblock_size_22660", "compiler.seghist_tblock_size_22676", "compiler.segmap_num_tblocks_22552", "compiler.segmap_num_tblocks_22640", "compiler.segmap_num_tblocks_22761", "compiler.segmap_tblock_size_22550", "compiler.segmap_tblock_size_22566", "compiler.segmap_tblock_size_22594", "compiler.segmap_tblock_size_22638", "compiler.segmap_tblock_size_22694", "compiler.segmap_tblock_size_22759", "compiler.segscan_num_tblocks_22542", "compiler.segscan_num_tblocks_22558", "compiler.segscan_num_tblocks_22586", "compiler.segscan_num_tblocks_22630", "compiler.segscan_num_tblocks_22751", "compiler.segscan_tblock_size_22540", "compiler.segscan_tblock_size_22556", "compiler.segscan_tblock_size_22584", "compiler.segscan_tblock_size_22628", "compiler.segscan_tblock_size_22749", "human.hist_L2_23152", "human.hist_L_23090", "human.seghist_num_tblocks_22059", "human.seghist_tblock_size_22057", "human.segmap_num_tblocks_22156", "human.segmap_tblock_size_21982", "human.segmap_tblock_size_22020", "human.segmap_tblock_size_22079", "human.segmap_tblock_size_22154", "human.segscan_num_tblocks_21974", "human.segscan_num_tblocks_22146", "human.segscan_tblock_size_21972", "human.segscan_tblock_size_22144", "human_regular.hist_L2_23417", "human_regular.hist_L2_23864", "human_regular.hist_L_23355", "human_regular.hist_L_23802", "human_regular.seghist_num_tblocks_22271", "human_regular.seghist_num_tblocks_22445", "human_regular.seghist_tblock_size_22269", "human_regular.seghist_tblock_size_22443", "human_regular.segmap_num_tblocks_22172", "human_regular.segmap_num_tblocks_22360", "human_regular.segmap_num_tblocks_22536", "human_regular.segmap_tblock_size_22170", "human_regular.segmap_tblock_size_22194", "human_regular.segmap_tblock_size_22236", "human_regular.segmap_tblock_size_22293", "human_regular.segmap_tblock_size_22358", "human_regular.segmap_tblock_size_22374", "human_regular.segmap_tblock_size_22410", "human_regular.segmap_tblock_size_22467", "human_regular.segmap_tblock_size_22534", "human_regular.segscan_num_tblocks_22162", "human_regular.segscan_num_tblocks_22178", "human_regular.segscan_num_tblocks_22186", "human_regular.segscan_num_tblocks_22350", "human_regular.segscan_num_tblocks_22366", "human_regular.segscan_num_tblocks_22526", "human_regular.segscan_tblock_size_22160", "human_regular.segscan_tblock_size_22176", "human_regular.segscan_tblock_size_22184", "human_regular.segscan_tblock_size_22348", "human_regular.segscan_tblock_size_22364", "human_regular.segscan_tblock_size_22524", NULL};
static const char *tuning_param_vars[] = {"builtinzhreplicate_boolzitblock_sizze_23057", "builtinzhreplicate_f32zitblock_sizze_22894", "builtinzhreplicate_i32zitblock_sizze_22950", "builtinzhreplicate_i8zitblock_sizze_22924", "compilerzihist_L2_23598", "compilerzihist_L2_23759", "compilerzihist_L2_23920", "compilerzihist_L_23545", "compilerzihist_L_23706", "compilerzihist_L_23867", "compilerziseghist_num_tblocks_22646", "compilerziseghist_num_tblocks_22662", "compilerziseghist_num_tblocks_22678", "compilerziseghist_tblock_sizze_22644", "compilerziseghist_tblock_sizze_22660", "compilerziseghist_tblock_sizze_22676", "compilerzisegmap_num_tblocks_22552", "compilerzisegmap_num_tblocks_22640", "compilerzisegmap_num_tblocks_22761", "compilerzisegmap_tblock_sizze_22550", "compilerzisegmap_tblock_sizze_22566", "compilerzisegmap_tblock_sizze_22594", "compilerzisegmap_tblock_sizze_22638", "compilerzisegmap_tblock_sizze_22694", "compilerzisegmap_tblock_sizze_22759", "compilerzisegscan_num_tblocks_22542", "compilerzisegscan_num_tblocks_22558", "compilerzisegscan_num_tblocks_22586", "compilerzisegscan_num_tblocks_22630", "compilerzisegscan_num_tblocks_22751", "compilerzisegscan_tblock_sizze_22540", "compilerzisegscan_tblock_sizze_22556", "compilerzisegscan_tblock_sizze_22584", "compilerzisegscan_tblock_sizze_22628", "compilerzisegscan_tblock_sizze_22749", "humanzihist_L2_23152", "humanzihist_L_23090", "humanziseghist_num_tblocks_22059", "humanziseghist_tblock_sizze_22057", "humanzisegmap_num_tblocks_22156", "humanzisegmap_tblock_sizze_21982", "humanzisegmap_tblock_sizze_22020", "humanzisegmap_tblock_sizze_22079", "humanzisegmap_tblock_sizze_22154", "humanzisegscan_num_tblocks_21974", "humanzisegscan_num_tblocks_22146", "humanzisegscan_tblock_sizze_21972", "humanzisegscan_tblock_sizze_22144", "human_regularzihist_L2_23417", "human_regularzihist_L2_23864", "human_regularzihist_L_23355", "human_regularzihist_L_23802", "human_regularziseghist_num_tblocks_22271", "human_regularziseghist_num_tblocks_22445", "human_regularziseghist_tblock_sizze_22269", "human_regularziseghist_tblock_sizze_22443", "human_regularzisegmap_num_tblocks_22172", "human_regularzisegmap_num_tblocks_22360", "human_regularzisegmap_num_tblocks_22536", "human_regularzisegmap_tblock_sizze_22170", "human_regularzisegmap_tblock_sizze_22194", "human_regularzisegmap_tblock_sizze_22236", "human_regularzisegmap_tblock_sizze_22293", "human_regularzisegmap_tblock_sizze_22358", "human_regularzisegmap_tblock_sizze_22374", "human_regularzisegmap_tblock_sizze_22410", "human_regularzisegmap_tblock_sizze_22467", "human_regularzisegmap_tblock_sizze_22534", "human_regularzisegscan_num_tblocks_22162", "human_regularzisegscan_num_tblocks_22178", "human_regularzisegscan_num_tblocks_22186", "human_regularzisegscan_num_tblocks_22350", "human_regularzisegscan_num_tblocks_22366", "human_regularzisegscan_num_tblocks_22526", "human_regularzisegscan_tblock_sizze_22160", "human_regularzisegscan_tblock_sizze_22176", "human_regularzisegscan_tblock_sizze_22184", "human_regularzisegscan_tblock_sizze_22348", "human_regularzisegscan_tblock_sizze_22364", "human_regularzisegscan_tblock_sizze_22524", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "cache", "cache", "cache", "shared_memory", "shared_memory", "shared_memory", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "cache", "shared_memory", "grid_size", "thread_block_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "cache", "cache", "shared_memory", "shared_memory", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 0;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhreplicate_boolzireplicate_23053(int64_t num_elems_23049, unsigned char val_23050_bits, int64_t replicate_n_23052, int64_t virt_num_tblocks_23058, int64_t num_tblocks_23059, __global unsigned char *mem_23048)\n{\n    bool val_23050 = val_23050_bits;\n    int32_t replicate_ltid_23054;\n    int32_t tblock_sizze_23056;\n    int32_t replicate_gid_23055;\n    int32_t replicate_gtid_23053;\n    int32_t phys_tblock_id_23060;\n    int32_t iterations_23061;\n    \n    replicate_ltid_23054 = get_local_id(0);\n    tblock_sizze_23056 = get_local_size(0);\n    replicate_gid_23055 = get_tblock_id(0);\n    replicate_gtid_23053 = replicate_gid_23055 * tblock_sizze_23056 + replicate_ltid_23054;\n    phys_tblock_id_23060 = get_tblock_id(0);\n    iterations_23061 = sdiv_up32(sext_i64_i32(virt_num_tblocks_23058) - phys_tblock_id_23060, sext_i64_i32(num_tblocks_23059));\n    for (int32_t i_23062 = 0; i_23062 < iterations_23061; i_23062++) {\n        int32_t virt_tblock_id_23063;\n        int64_t global_tid_23064;\n        int64_t slice_23066;\n        int64_t rep_i_23065;\n        int64_t remnant_23067;\n        \n        virt_tblock_id_23063 = phys_tblock_id_23060 + i_23062 * sext_i64_i32(num_tblocks_23059);\n        global_tid_23064 = sext_i32_i64(virt_tblock_id_23063) * sext_i32_i64(tblock_sizze_23056) + sext_i32_i64(replicate_ltid_23054);\n        slice_23066 = num_elems_23049;\n        rep_i_23065 = global_tid_23064;\n        remnant_23067 = global_tid_23064 - rep_i_23065;\n        if (slt64(global_tid_23064, replicate_n_23052)) {\n            ((__global bool *) mem_23048)[rep_i_23065] = val_23050;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_f32zireplicate_22890(int64_t num_elems_22886, float val_22887, int64_t repli", "cate_n_22889, int64_t virt_num_tblocks_22895, int64_t num_tblocks_22896, __global unsigned char *mem_22885)\n{\n    int32_t replicate_ltid_22891;\n    int32_t tblock_sizze_22893;\n    int32_t replicate_gid_22892;\n    int32_t replicate_gtid_22890;\n    int32_t phys_tblock_id_22897;\n    int32_t iterations_22898;\n    \n    replicate_ltid_22891 = get_local_id(0);\n    tblock_sizze_22893 = get_local_size(0);\n    replicate_gid_22892 = get_tblock_id(0);\n    replicate_gtid_22890 = replicate_gid_22892 * tblock_sizze_22893 + replicate_ltid_22891;\n    phys_tblock_id_22897 = get_tblock_id(0);\n    iterations_22898 = sdiv_up32(sext_i64_i32(virt_num_tblocks_22895) - phys_tblock_id_22897, sext_i64_i32(num_tblocks_22896));\n    for (int32_t i_22899 = 0; i_22899 < iterations_22898; i_22899++) {\n        int32_t virt_tblock_id_22900;\n        int64_t global_tid_22901;\n        int64_t slice_22903;\n        int64_t rep_i_22902;\n        int64_t remnant_22904;\n        \n        virt_tblock_id_22900 = phys_tblock_id_22897 + i_22899 * sext_i64_i32(num_tblocks_22896);\n        global_tid_22901 = sext_i32_i64(virt_tblock_id_22900) * sext_i32_i64(tblock_sizze_22893) + sext_i32_i64(replicate_ltid_22891);\n        slice_22903 = num_elems_22886;\n        rep_i_22902 = global_tid_22901;\n        remnant_22904 = global_tid_22901 - rep_i_22902;\n        if (slt64(global_tid_22901, replicate_n_22889)) {\n            ((__global float *) mem_22885)[rep_i_22902] = val_22887;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_22946(int64_t num_elems_22942, int32_t val_22943, int64_t replicate_n_22945, int64_t virt_num_tblocks_22951, int64_t num_tblocks_22952, __global unsigned char *mem_22941)\n{\n    int32_t replicate_ltid_22947;\n    int32_t tblock_sizze_22949;\n    int32_t replicate_gid_22948;\n    int32_t replicate_gtid_22946;\n    int32_t phys_tblock_id_22953;\n    int32_t iterations_22954;\n    \n    replicate_ltid_2",
                                    "2947 = get_local_id(0);\n    tblock_sizze_22949 = get_local_size(0);\n    replicate_gid_22948 = get_tblock_id(0);\n    replicate_gtid_22946 = replicate_gid_22948 * tblock_sizze_22949 + replicate_ltid_22947;\n    phys_tblock_id_22953 = get_tblock_id(0);\n    iterations_22954 = sdiv_up32(sext_i64_i32(virt_num_tblocks_22951) - phys_tblock_id_22953, sext_i64_i32(num_tblocks_22952));\n    for (int32_t i_22955 = 0; i_22955 < iterations_22954; i_22955++) {\n        int32_t virt_tblock_id_22956;\n        int64_t global_tid_22957;\n        int64_t slice_22959;\n        int64_t rep_i_22958;\n        int64_t remnant_22960;\n        \n        virt_tblock_id_22956 = phys_tblock_id_22953 + i_22955 * sext_i64_i32(num_tblocks_22952);\n        global_tid_22957 = sext_i32_i64(virt_tblock_id_22956) * sext_i32_i64(tblock_sizze_22949) + sext_i32_i64(replicate_ltid_22947);\n        slice_22959 = num_elems_22942;\n        rep_i_22958 = global_tid_22957;\n        remnant_22960 = global_tid_22957 - rep_i_22958;\n        if (slt64(global_tid_22957, replicate_n_22945)) {\n            ((__global int32_t *) mem_22941)[rep_i_22958] = val_22943;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_22920(int64_t num_elems_22916, int8_t val_22917, int64_t replicate_n_22919, int64_t virt_num_tblocks_22925, int64_t num_tblocks_22926, __global unsigned char *mem_22915)\n{\n    int32_t replicate_ltid_22921;\n    int32_t tblock_sizze_22923;\n    int32_t replicate_gid_22922;\n    int32_t replicate_gtid_22920;\n    int32_t phys_tblock_id_22927;\n    int32_t iterations_22928;\n    \n    replicate_ltid_22921 = get_local_id(0);\n    tblock_sizze_22923 = get_local_size(0);\n    replicate_gid_22922 = get_tblock_id(0);\n    replicate_gtid_22920 = replicate_gid_22922 * tblock_sizze_22923 + replicate_ltid_22921;\n    phys_tblock_id_22927 = get_tblock_id(0);\n    iterations_22928 = sdiv_up32(sext_i64_i32(virt_num_tblocks_22925) - phys_tblock", "_id_22927, sext_i64_i32(num_tblocks_22926));\n    for (int32_t i_22929 = 0; i_22929 < iterations_22928; i_22929++) {\n        int32_t virt_tblock_id_22930;\n        int64_t global_tid_22931;\n        int64_t slice_22933;\n        int64_t rep_i_22932;\n        int64_t remnant_22934;\n        \n        virt_tblock_id_22930 = phys_tblock_id_22927 + i_22929 * sext_i64_i32(num_tblocks_22926);\n        global_tid_22931 = sext_i32_i64(virt_tblock_id_22930) * sext_i32_i64(tblock_sizze_22923) + sext_i32_i64(replicate_ltid_22921);\n        slice_22933 = num_elems_22916;\n        rep_i_22932 = global_tid_22931;\n        remnant_22934 = global_tid_22931 - rep_i_22932;\n        if (slt64(global_tid_22931, replicate_n_22919)) {\n            ((__global int8_t *) mem_22915)[rep_i_22932] = val_22917;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(compilerziseghist_global_22652_dim1, 1, 1)\nvoid compilerziseghist_global_22652(__global int *global_failure, int64_t mz2080U_19405, int64_t m_21053, int64_t num_tblocks_22647, int64_t num_subhistos_23536, int32_t chk_i_23606, int64_t hist_H_chk_23607, __global unsigned char *mem_22821, __global unsigned char *defunc_0_map_res_subhistos_mem_23537)\n{\n    #define seghist_tblock_sizze_22645 (compilerziseghist_global_22652ziseghist_tblock_sizze_22645)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23609;\n    int32_t tblock_sizze_23612;\n    int32_t wave_sizze_23611;\n    int32_t block_id_23610;\n    int32_t global_tid_23608;\n    int64_t phys_tid_22652;\n    int32_t subhisto_ind_23613;\n    int64_t num_chunks_23614;\n    \n    local_tid_23609 = get_local_id(0);\n    tblock_sizze_23612 = get_local_size(0);\n    wave_sizze_23611 = LOCKSTEP_WIDTH;\n    block_id_23610 = get_tblock_id(0);\n    global_tid_23608 = block_id_23610 * tblock_sizze_23612 + local_tid_23609;\n    phys_tid_22652 = sext_i32_i64(global_tid_23608);\n    subhisto_ind_23613 = squot32(global_tid_23608, sd", "iv_up32(sext_i64_i32(seghist_tblock_sizze_22645 * num_tblocks_22647), sext_i64_i32(num_subhistos_23536)));\n    num_chunks_23614 = sdiv_up64(m_21053, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22645 * num_tblocks_22647)));\n    for (int64_t chunk_i_23615 = 0; chunk_i_23615 < num_chunks_23614; chunk_i_23615++) {\n        int64_t i_23616 = chunk_i_23615 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22645 * num_tblocks_22647)) + sext_i32_i64(global_tid_23608);\n        \n        if (slt64(i_23616, m_21053)) {\n            int64_t slice_23617;\n            int64_t gtid_22651;\n            int64_t remnant_23618;\n            \n            slice_23617 = m_21053;\n            gtid_22651 = i_23616;\n            remnant_23618 = i_23616 - gtid_22651;\n            if (slt64(i_23616, m_21053)) {\n                int32_t eta_p_22656;\n                int64_t i32_res_22658;\n                \n                eta_p_22656 = ((__global int32_t *) mem_22821)[gtid_22651];\n                i32_res_22658 = sext_i32_i64(eta_p_22656);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_23606) * hist_H_chk_23607, i32_res_22658) && (slt64(i32_res_22658, sext_i32_i64(chk_i_23606) * hist_H_chk_23607 + hist_H_chk_23607) && (sle64((int64_t) 0, i32_res_22658) && slt64(i32_res_22658, mz2080U_19405)))) {\n                        int32_t eta_p_22653;\n                        int32_t eta_p_22654 = 1;\n                        int32_t old_23619;\n                        \n                        old_23619 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_23537)[sext_i32_i64(subhisto_ind_23613) * mz2080U_19405 + i32_res_22658], (int) eta_p_22654);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_22645\n}\nFUTHARK_KERNEL_SIZED(compilerziseghist_global_22668_dim1, 1, 1)\nvoid compilerziseghist_gl",
                                    "obal_22668(__global int *global_failure, int64_t mz2080U_19405, int64_t m_21094, int64_t num_tblocks_22663, int64_t num_subhistos_23697, int32_t chk_i_23767, int64_t hist_H_chk_23768, __global unsigned char *mem_22819, __global unsigned char *defunc_0_map_res_subhistos_mem_23698)\n{\n    #define seghist_tblock_sizze_22661 (compilerziseghist_global_22668ziseghist_tblock_sizze_22661)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23770;\n    int32_t tblock_sizze_23773;\n    int32_t wave_sizze_23772;\n    int32_t block_id_23771;\n    int32_t global_tid_23769;\n    int64_t phys_tid_22668;\n    int32_t subhisto_ind_23774;\n    int64_t num_chunks_23775;\n    \n    local_tid_23770 = get_local_id(0);\n    tblock_sizze_23773 = get_local_size(0);\n    wave_sizze_23772 = LOCKSTEP_WIDTH;\n    block_id_23771 = get_tblock_id(0);\n    global_tid_23769 = block_id_23771 * tblock_sizze_23773 + local_tid_23770;\n    phys_tid_22668 = sext_i32_i64(global_tid_23769);\n    subhisto_ind_23774 = squot32(global_tid_23769, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_22661 * num_tblocks_22663), sext_i64_i32(num_subhistos_23697)));\n    num_chunks_23775 = sdiv_up64(m_21094, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22661 * num_tblocks_22663)));\n    for (int64_t chunk_i_23776 = 0; chunk_i_23776 < num_chunks_23775; chunk_i_23776++) {\n        int64_t i_23777 = chunk_i_23776 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22661 * num_tblocks_22663)) + sext_i32_i64(global_tid_23769);\n        \n        if (slt64(i_23777, m_21094)) {\n            int64_t slice_23778;\n            int64_t gtid_22667;\n            int64_t remnant_23779;\n            \n            slice_23778 = m_21094;\n            gtid_22667 = i_23777;\n            remnant_23779 = i_23777 - gtid_22667;\n            if (slt64(i_23777, m_21094)) {\n                int32_t eta_p_22672;\n                int64_t i32_res_22674;\n                \n                eta_p_22672 = ((__global int32_t *) mem_22819)[gtid_22667];\n                i32", "_res_22674 = sext_i32_i64(eta_p_22672);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_23767) * hist_H_chk_23768, i32_res_22674) && (slt64(i32_res_22674, sext_i32_i64(chk_i_23767) * hist_H_chk_23768 + hist_H_chk_23768) && (sle64((int64_t) 0, i32_res_22674) && slt64(i32_res_22674, mz2080U_19405)))) {\n                        int32_t eta_p_22669;\n                        int32_t eta_p_22670 = 1;\n                        int32_t old_23780;\n                        \n                        old_23780 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_23698)[sext_i32_i64(subhisto_ind_23774) * mz2080U_19405 + i32_res_22674], (int) eta_p_22670);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_22661\n}\nFUTHARK_KERNEL_SIZED(compilerziseghist_global_22684_dim1, 1, 1)\nvoid compilerziseghist_global_22684(__global int *global_failure, int64_t mz2080U_19405, int64_t m_21135, int64_t num_tblocks_22679, int64_t num_subhistos_23858, int32_t chk_i_23928, int64_t hist_H_chk_23929, __global unsigned char *mem_22817, __global unsigned char *defunc_0_map_res_subhistos_mem_23859)\n{\n    #define seghist_tblock_sizze_22677 (compilerziseghist_global_22684ziseghist_tblock_sizze_22677)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23931;\n    int32_t tblock_sizze_23934;\n    int32_t wave_sizze_23933;\n    int32_t block_id_23932;\n    int32_t global_tid_23930;\n    int64_t phys_tid_22684;\n    int32_t subhisto_ind_23935;\n    int64_t num_chunks_23936;\n    \n    local_tid_23931 = get_local_id(0);\n    tblock_sizze_23934 = get_local_size(0);\n    wave_sizze_23933 = LOCKSTEP_WIDTH;\n    block_id_23932 = get_tblock_id(0);\n    global_tid_23930 = block_id_23932 * tblock_sizze_23934 + local_tid_23931;\n    phys_tid_22684 = sext_i32_i64(global_tid_23930);\n    sub", "histo_ind_23935 = squot32(global_tid_23930, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_22677 * num_tblocks_22679), sext_i64_i32(num_subhistos_23858)));\n    num_chunks_23936 = sdiv_up64(m_21135, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22677 * num_tblocks_22679)));\n    for (int64_t chunk_i_23937 = 0; chunk_i_23937 < num_chunks_23936; chunk_i_23937++) {\n        int64_t i_23938 = chunk_i_23937 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22677 * num_tblocks_22679)) + sext_i32_i64(global_tid_23930);\n        \n        if (slt64(i_23938, m_21135)) {\n            int64_t slice_23939;\n            int64_t gtid_22683;\n            int64_t remnant_23940;\n            \n            slice_23939 = m_21135;\n            gtid_22683 = i_23938;\n            remnant_23940 = i_23938 - gtid_22683;\n            if (slt64(i_23938, m_21135)) {\n                int32_t eta_p_22688;\n                int64_t i32_res_22690;\n                \n                eta_p_22688 = ((__global int32_t *) mem_22817)[gtid_22683];\n                i32_res_22690 = sext_i32_i64(eta_p_22688);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_23928) * hist_H_chk_23929, i32_res_22690) && (slt64(i32_res_22690, sext_i32_i64(chk_i_23928) * hist_H_chk_23929 + hist_H_chk_23929) && (sle64((int64_t) 0, i32_res_22690) && slt64(i32_res_22690, mz2080U_19405)))) {\n                        int32_t eta_p_22685;\n                        int32_t eta_p_22686 = 1;\n                        int32_t old_23941;\n                        \n                        old_23941 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_23859)[sext_i32_i64(subhisto_ind_23935) * mz2080U_19405 + i32_res_22690], (int) eta_p_22686);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_22677\n}\nFUTHARK_KERNEL_SIZED(compilerziseghist_loca",
                                    "l_22652_dim1, 1, 1)\nvoid compilerziseghist_local_22652(__global int *global_failure, int64_t mz2080U_19405, int64_t m_21053, int64_t num_subhistos_23536, int64_t num_tblocks_23547, int32_t hist_M_23553, int32_t chk_i_23557, int64_t num_segments_23558, int64_t hist_H_chk_23559, int64_t histo_sizze_23560, int32_t init_per_thread_23561, __global unsigned char *mem_22821, __global unsigned char *defunc_0_map_res_subhistos_mem_23537)\n{\n    #define max_tblock_sizze_23546 (compilerziseghist_local_22652zimax_tblock_sizze_23546)\n    \n    volatile __local unsigned char *subhistogram_local_mem_23575_backing_0 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_23575_backing_0_offset = 0 + ((int64_t) 4 * (hist_M_23553 * hist_H_chk_23559) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23553 * hist_H_chk_23559), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23563;\n    int32_t tblock_sizze_23566;\n    int32_t wave_sizze_23565;\n    int32_t block_id_23564;\n    int32_t global_tid_23562;\n    int64_t phys_tid_22652;\n    int32_t phys_tblock_id_23567;\n    int32_t iterations_23568;\n    \n    local_tid_23563 = get_local_id(0);\n    tblock_sizze_23566 = get_local_size(0);\n    wave_sizze_23565 = LOCKSTEP_WIDTH;\n    block_id_23564 = get_tblock_id(0);\n    global_tid_23562 = block_id_23564 * tblock_sizze_23566 + local_tid_23563;\n    phys_tid_22652 = sext_i32_i64(global_tid_23562);\n    phys_tblock_id_23567 = get_tblock_id(0);\n    iterations_23568 = sdiv_up32(sext_i64_i32(num_tblocks_23547 * num_segments_23558) - phys_tblock_id_23567, sext_i64_i32(num_tblocks_23547));\n    for (int32_t i_23569 = 0; i_23569 < iterations_23568; i_23569++) {\n        int32_t virt_tblock_id_23570;\n        int32_t flat_segment_id_23571;\n        int32_t gid_in_segment_23572;\n        int32_t pgtid_in_segment_23573;\n        int32_t threads_per_segment_23574;\n        __local unsigned char *subhistogram_local_mem_23575;\n        int32_t thread_local_subhist", "o_i_23577;\n        int64_t num_chunks_23584;\n        \n        virt_tblock_id_23570 = phys_tblock_id_23567 + i_23569 * sext_i64_i32(num_tblocks_23547);\n        flat_segment_id_23571 = squot32(virt_tblock_id_23570, sext_i64_i32(num_tblocks_23547));\n        gid_in_segment_23572 = srem32(virt_tblock_id_23570, sext_i64_i32(num_tblocks_23547));\n        pgtid_in_segment_23573 = gid_in_segment_23572 * sext_i64_i32(max_tblock_sizze_23546) + local_tid_23563;\n        threads_per_segment_23574 = sext_i64_i32(num_tblocks_23547 * max_tblock_sizze_23546);\n        subhistogram_local_mem_23575 = (__local unsigned char *) subhistogram_local_mem_23575_backing_0;\n        thread_local_subhisto_i_23577 = srem32(local_tid_23563, hist_M_23553);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_23578 = 0; local_i_23578 < init_per_thread_23561; local_i_23578++) {\n                int32_t j_23579 = local_i_23578 * sext_i64_i32(max_tblock_sizze_23546) + local_tid_23563;\n                int32_t j_offset_23580 = hist_M_23553 * sext_i64_i32(histo_sizze_23560) * gid_in_segment_23572 + j_23579;\n                int32_t local_subhisto_i_23581 = squot32(j_23579, sext_i64_i32(histo_sizze_23560));\n                int32_t global_subhisto_i_23582 = squot32(j_offset_23580, sext_i64_i32(histo_sizze_23560));\n                \n                if (slt32(j_23579, hist_M_23553 * sext_i64_i32(histo_sizze_23560))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_23582 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23536)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23579, sext_i64_i32(histo_sizze_23560))) + sext_i32_i64(chk_i_23557) * hist_H_chk_23559) && slt64(sext_i32_i64(srem32(j_23579, sext_i64_i32(histo_sizze_23560))) + sext_i32_i64(chk_i_23557) * hist_H_chk_23559, mz2080U_19405)))) {\n                            ", "int32_t tmp_23583 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23537)[sext_i32_i64(srem32(j_23579, sext_i64_i32(histo_sizze_23560))) + sext_i32_i64(chk_i_23557) * hist_H_chk_23559];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23575)[sext_i32_i64(local_subhisto_i_23581) * hist_H_chk_23559 + sext_i32_i64(srem32(j_23579, sext_i64_i32(histo_sizze_23560)))] = tmp_23583;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_23575)[sext_i32_i64(local_subhisto_i_23581) * hist_H_chk_23559 + sext_i32_i64(srem32(j_23579, sext_i64_i32(histo_sizze_23560)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_23584 = sdiv_up64(m_21053, sext_i32_i64(threads_per_segment_23574));\n        for (int64_t chunk_i_23585 = 0; chunk_i_23585 < num_chunks_23584; chunk_i_23585++) {\n            int64_t i_23586 = chunk_i_23585 * sext_i32_i64(threads_per_segment_23574) + sext_i32_i64(pgtid_in_segment_23573);\n            \n            if (slt64(i_23586, m_21053)) {\n                int64_t gtid_22651;\n                int32_t eta_p_22656;\n                int64_t i32_res_22658;\n                \n                gtid_22651 = i_23586;\n                eta_p_22656 = ((__global int32_t *) mem_22821)[gtid_22651];\n                i32_res_22658 = sext_i32_i64(eta_p_22656);\n                if (chk_i_23557 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, i32_res_22658) && slt64(i32_res_22658, mz2080U_19405)) && (sle64(sext_i32_i64(chk_i_23557) * hist_H_chk_23559, i32_res_22658) && slt64(i32_res_22658, sext_i32_i64(chk_i_23557) * hist_H_chk_23559 + hist_H_chk_23559))) {\n                        int32_t eta_p_22653;\n                        int32_t eta_p_2",
                                    "2654 = 1;\n                        int32_t old_23587;\n                        \n                        old_23587 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23575)[sext_i32_i64(thread_local_subhisto_i_23577) * hist_H_chk_23559 + (i32_res_22658 - sext_i32_i64(chk_i_23557) * hist_H_chk_23559)], (int) eta_p_22654);\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_23588 = smin64(hist_H_chk_23559, mz2080U_19405 - sext_i32_i64(chk_i_23557) * hist_H_chk_23559);\n            int32_t histo_sizze_23589 = sext_i64_i32(trunc_H_23588);\n            \n            for (int32_t local_i_23590 = 0; local_i_23590 < init_per_thread_23561; local_i_23590++) {\n                int32_t j_23591 = local_i_23590 * sext_i64_i32(max_tblock_sizze_23546) + local_tid_23563;\n                \n                if (slt32(j_23591, histo_sizze_23589)) {\n                    int32_t eta_p_22653;\n                    int32_t eta_p_22654;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_22653 = ((__local int32_t *) subhistogram_local_mem_23575)[sext_i32_i64(j_23591)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_23592 = 0; subhisto_id_23592 < hist_M_23553 - 1; subhisto_id_23592++) {\n                            eta_p_22654 = ((__local int32_t *) subhistogram_local_mem_23575)[(sext_i32_i64(subhisto_id_23592) + (int64_t) 1) * hist_H_chk_23559 + sext_i32_i64(j_23591)];\n                            \n                            int32_t defunc_0_op_res_22655 = add32(eta_p_22653, eta_p_22654);\n                            \n                            eta_p_22653 = defunc_0_op_res_22655;\n            ", "            }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_23537)[srem64(sext_i32_i64(virt_tblock_id_23570), num_tblocks_23547) * mz2080U_19405 + (sext_i32_i64(j_23591) + sext_i32_i64(chk_i_23557) * hist_H_chk_23559)] = eta_p_22653;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_23546\n}\nFUTHARK_KERNEL_SIZED(compilerziseghist_local_22668_dim1, 1, 1)\nvoid compilerziseghist_local_22668(__global int *global_failure, int64_t mz2080U_19405, int64_t m_21094, int64_t num_subhistos_23697, int64_t num_tblocks_23708, int32_t hist_M_23714, int32_t chk_i_23718, int64_t num_segments_23719, int64_t hist_H_chk_23720, int64_t histo_sizze_23721, int32_t init_per_thread_23722, __global unsigned char *mem_22819, __global unsigned char *defunc_0_map_res_subhistos_mem_23698)\n{\n    #define max_tblock_sizze_23707 (compilerziseghist_local_22668zimax_tblock_sizze_23707)\n    \n    volatile __local unsigned char *subhistogram_local_mem_23736_backing_0 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_23736_backing_0_offset = 0 + ((int64_t) 4 * (hist_M_23714 * hist_H_chk_23720) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23714 * hist_H_chk_23720), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23724;\n    int32_t tblock_sizze_23727;\n    int32_t wave_sizze_23726;\n    int32_t block_id_23725;\n    int32_t global_tid_23723;\n    int64_t phys_tid_22668;\n    int32_t phys_tblock_id_23728;\n    int32_t iterations_23729;\n    \n    local_tid_23724 = get_local_id(0);\n    tblock_sizze_23727 = get_local_size(0);\n    wave_sizze_23726 = LOCKSTEP_WIDTH;\n    block_id_23725 = get_tblock_id(0);\n    global_tid_23723 = block_id_23725 * tblock_sizze_23727 + local_tid_2372", "4;\n    phys_tid_22668 = sext_i32_i64(global_tid_23723);\n    phys_tblock_id_23728 = get_tblock_id(0);\n    iterations_23729 = sdiv_up32(sext_i64_i32(num_tblocks_23708 * num_segments_23719) - phys_tblock_id_23728, sext_i64_i32(num_tblocks_23708));\n    for (int32_t i_23730 = 0; i_23730 < iterations_23729; i_23730++) {\n        int32_t virt_tblock_id_23731;\n        int32_t flat_segment_id_23732;\n        int32_t gid_in_segment_23733;\n        int32_t pgtid_in_segment_23734;\n        int32_t threads_per_segment_23735;\n        __local unsigned char *subhistogram_local_mem_23736;\n        int32_t thread_local_subhisto_i_23738;\n        int64_t num_chunks_23745;\n        \n        virt_tblock_id_23731 = phys_tblock_id_23728 + i_23730 * sext_i64_i32(num_tblocks_23708);\n        flat_segment_id_23732 = squot32(virt_tblock_id_23731, sext_i64_i32(num_tblocks_23708));\n        gid_in_segment_23733 = srem32(virt_tblock_id_23731, sext_i64_i32(num_tblocks_23708));\n        pgtid_in_segment_23734 = gid_in_segment_23733 * sext_i64_i32(max_tblock_sizze_23707) + local_tid_23724;\n        threads_per_segment_23735 = sext_i64_i32(num_tblocks_23708 * max_tblock_sizze_23707);\n        subhistogram_local_mem_23736 = (__local unsigned char *) subhistogram_local_mem_23736_backing_0;\n        thread_local_subhisto_i_23738 = srem32(local_tid_23724, hist_M_23714);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_23739 = 0; local_i_23739 < init_per_thread_23722; local_i_23739++) {\n                int32_t j_23740 = local_i_23739 * sext_i64_i32(max_tblock_sizze_23707) + local_tid_23724;\n                int32_t j_offset_23741 = hist_M_23714 * sext_i64_i32(histo_sizze_23721) * gid_in_segment_23733 + j_23740;\n                int32_t local_subhisto_i_23742 = squot32(j_23740, sext_i64_i32(histo_sizze_23721));\n                int32_t global_subhisto_i_23743 = squot32(j_offset_23741, sext_i64_i32(histo_sizze_23721));\n                \n                if (slt32(j_23740, hist_M_2",
                                    "3714 * sext_i64_i32(histo_sizze_23721))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_23743 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23697)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23740, sext_i64_i32(histo_sizze_23721))) + sext_i32_i64(chk_i_23718) * hist_H_chk_23720) && slt64(sext_i32_i64(srem32(j_23740, sext_i64_i32(histo_sizze_23721))) + sext_i32_i64(chk_i_23718) * hist_H_chk_23720, mz2080U_19405)))) {\n                            int32_t tmp_23744 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23698)[sext_i32_i64(srem32(j_23740, sext_i64_i32(histo_sizze_23721))) + sext_i32_i64(chk_i_23718) * hist_H_chk_23720];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23736)[sext_i32_i64(local_subhisto_i_23742) * hist_H_chk_23720 + sext_i32_i64(srem32(j_23740, sext_i64_i32(histo_sizze_23721)))] = tmp_23744;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_23736)[sext_i32_i64(local_subhisto_i_23742) * hist_H_chk_23720 + sext_i32_i64(srem32(j_23740, sext_i64_i32(histo_sizze_23721)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_23745 = sdiv_up64(m_21094, sext_i32_i64(threads_per_segment_23735));\n        for (int64_t chunk_i_23746 = 0; chunk_i_23746 < num_chunks_23745; chunk_i_23746++) {\n            int64_t i_23747 = chunk_i_23746 * sext_i32_i64(threads_per_segment_23735) + sext_i32_i64(pgtid_in_segment_23734);\n            \n            if (slt64(i_23747, m_21094)) {\n                int64_t gtid_22667;\n                int32_t eta_p_22672;\n                int64_t i32_res_22674;\n                \n                gtid_22667 = i_23747;\n                eta_p_22672 = ((__global int32_t *) mem_2", "2819)[gtid_22667];\n                i32_res_22674 = sext_i32_i64(eta_p_22672);\n                if (chk_i_23718 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, i32_res_22674) && slt64(i32_res_22674, mz2080U_19405)) && (sle64(sext_i32_i64(chk_i_23718) * hist_H_chk_23720, i32_res_22674) && slt64(i32_res_22674, sext_i32_i64(chk_i_23718) * hist_H_chk_23720 + hist_H_chk_23720))) {\n                        int32_t eta_p_22669;\n                        int32_t eta_p_22670 = 1;\n                        int32_t old_23748;\n                        \n                        old_23748 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23736)[sext_i32_i64(thread_local_subhisto_i_23738) * hist_H_chk_23720 + (i32_res_22674 - sext_i32_i64(chk_i_23718) * hist_H_chk_23720)], (int) eta_p_22670);\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_23749 = smin64(hist_H_chk_23720, mz2080U_19405 - sext_i32_i64(chk_i_23718) * hist_H_chk_23720);\n            int32_t histo_sizze_23750 = sext_i64_i32(trunc_H_23749);\n            \n            for (int32_t local_i_23751 = 0; local_i_23751 < init_per_thread_23722; local_i_23751++) {\n                int32_t j_23752 = local_i_23751 * sext_i64_i32(max_tblock_sizze_23707) + local_tid_23724;\n                \n                if (slt32(j_23752, histo_sizze_23750)) {\n                    int32_t eta_p_22669;\n                    int32_t eta_p_22670;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_22669 = ((__local int32_t *) subhistogram_local_mem_23736)[sext_i32_i64(j_23752)];\n                    }\n                    ", "// Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_23753 = 0; subhisto_id_23753 < hist_M_23714 - 1; subhisto_id_23753++) {\n                            eta_p_22670 = ((__local int32_t *) subhistogram_local_mem_23736)[(sext_i32_i64(subhisto_id_23753) + (int64_t) 1) * hist_H_chk_23720 + sext_i32_i64(j_23752)];\n                            \n                            int32_t defunc_0_op_res_22671 = add32(eta_p_22669, eta_p_22670);\n                            \n                            eta_p_22669 = defunc_0_op_res_22671;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_23698)[srem64(sext_i32_i64(virt_tblock_id_23731), num_tblocks_23708) * mz2080U_19405 + (sext_i32_i64(j_23752) + sext_i32_i64(chk_i_23718) * hist_H_chk_23720)] = eta_p_22669;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_23707\n}\nFUTHARK_KERNEL_SIZED(compilerziseghist_local_22684_dim1, 1, 1)\nvoid compilerziseghist_local_22684(__global int *global_failure, int64_t mz2080U_19405, int64_t m_21135, int64_t num_subhistos_23858, int64_t num_tblocks_23869, int32_t hist_M_23875, int32_t chk_i_23879, int64_t num_segments_23880, int64_t hist_H_chk_23881, int64_t histo_sizze_23882, int32_t init_per_thread_23883, __global unsigned char *mem_22817, __global unsigned char *defunc_0_map_res_subhistos_mem_23859)\n{\n    #define max_tblock_sizze_23868 (compilerziseghist_local_22684zimax_tblock_sizze_23868)\n    \n    volatile __local unsigned char *subhistogram_local_mem_23897_backing_0 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_23897_backing_0_offset = 0 + ((int64_t) 4 * (hist_M_23875 * hist_H_chk_23881) + srem64((int64_t) 8 - srem64((int6",
                                    "4_t) 4 * (hist_M_23875 * hist_H_chk_23881), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23885;\n    int32_t tblock_sizze_23888;\n    int32_t wave_sizze_23887;\n    int32_t block_id_23886;\n    int32_t global_tid_23884;\n    int64_t phys_tid_22684;\n    int32_t phys_tblock_id_23889;\n    int32_t iterations_23890;\n    \n    local_tid_23885 = get_local_id(0);\n    tblock_sizze_23888 = get_local_size(0);\n    wave_sizze_23887 = LOCKSTEP_WIDTH;\n    block_id_23886 = get_tblock_id(0);\n    global_tid_23884 = block_id_23886 * tblock_sizze_23888 + local_tid_23885;\n    phys_tid_22684 = sext_i32_i64(global_tid_23884);\n    phys_tblock_id_23889 = get_tblock_id(0);\n    iterations_23890 = sdiv_up32(sext_i64_i32(num_tblocks_23869 * num_segments_23880) - phys_tblock_id_23889, sext_i64_i32(num_tblocks_23869));\n    for (int32_t i_23891 = 0; i_23891 < iterations_23890; i_23891++) {\n        int32_t virt_tblock_id_23892;\n        int32_t flat_segment_id_23893;\n        int32_t gid_in_segment_23894;\n        int32_t pgtid_in_segment_23895;\n        int32_t threads_per_segment_23896;\n        __local unsigned char *subhistogram_local_mem_23897;\n        int32_t thread_local_subhisto_i_23899;\n        int64_t num_chunks_23906;\n        \n        virt_tblock_id_23892 = phys_tblock_id_23889 + i_23891 * sext_i64_i32(num_tblocks_23869);\n        flat_segment_id_23893 = squot32(virt_tblock_id_23892, sext_i64_i32(num_tblocks_23869));\n        gid_in_segment_23894 = srem32(virt_tblock_id_23892, sext_i64_i32(num_tblocks_23869));\n        pgtid_in_segment_23895 = gid_in_segment_23894 * sext_i64_i32(max_tblock_sizze_23868) + local_tid_23885;\n        threads_per_segment_23896 = sext_i64_i32(num_tblocks_23869 * max_tblock_sizze_23868);\n        subhistogram_local_mem_23897 = (__local unsigned char *) subhistogram_local_mem_23897_backing_0;\n        thread_local_subhisto_i_23899 = srem32(local_tid_23885, hist_M_23875);\n        // initialize histograms in shared memo", "ry\n        {\n            for (int32_t local_i_23900 = 0; local_i_23900 < init_per_thread_23883; local_i_23900++) {\n                int32_t j_23901 = local_i_23900 * sext_i64_i32(max_tblock_sizze_23868) + local_tid_23885;\n                int32_t j_offset_23902 = hist_M_23875 * sext_i64_i32(histo_sizze_23882) * gid_in_segment_23894 + j_23901;\n                int32_t local_subhisto_i_23903 = squot32(j_23901, sext_i64_i32(histo_sizze_23882));\n                int32_t global_subhisto_i_23904 = squot32(j_offset_23902, sext_i64_i32(histo_sizze_23882));\n                \n                if (slt32(j_23901, hist_M_23875 * sext_i64_i32(histo_sizze_23882))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_23904 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23858)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23901, sext_i64_i32(histo_sizze_23882))) + sext_i32_i64(chk_i_23879) * hist_H_chk_23881) && slt64(sext_i32_i64(srem32(j_23901, sext_i64_i32(histo_sizze_23882))) + sext_i32_i64(chk_i_23879) * hist_H_chk_23881, mz2080U_19405)))) {\n                            int32_t tmp_23905 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23859)[sext_i32_i64(srem32(j_23901, sext_i64_i32(histo_sizze_23882))) + sext_i32_i64(chk_i_23879) * hist_H_chk_23881];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23897)[sext_i32_i64(local_subhisto_i_23903) * hist_H_chk_23881 + sext_i32_i64(srem32(j_23901, sext_i64_i32(histo_sizze_23882)))] = tmp_23905;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_23897)[sext_i32_i64(local_subhisto_i_23903) * hist_H_chk_23881 + sext_i32_i64(srem32(j_23901, sext_i64_i32(histo_sizze_23882)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrie", "r(CLK_LOCAL_MEM_FENCE);\n        num_chunks_23906 = sdiv_up64(m_21135, sext_i32_i64(threads_per_segment_23896));\n        for (int64_t chunk_i_23907 = 0; chunk_i_23907 < num_chunks_23906; chunk_i_23907++) {\n            int64_t i_23908 = chunk_i_23907 * sext_i32_i64(threads_per_segment_23896) + sext_i32_i64(pgtid_in_segment_23895);\n            \n            if (slt64(i_23908, m_21135)) {\n                int64_t gtid_22683;\n                int32_t eta_p_22688;\n                int64_t i32_res_22690;\n                \n                gtid_22683 = i_23908;\n                eta_p_22688 = ((__global int32_t *) mem_22817)[gtid_22683];\n                i32_res_22690 = sext_i32_i64(eta_p_22688);\n                if (chk_i_23879 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, i32_res_22690) && slt64(i32_res_22690, mz2080U_19405)) && (sle64(sext_i32_i64(chk_i_23879) * hist_H_chk_23881, i32_res_22690) && slt64(i32_res_22690, sext_i32_i64(chk_i_23879) * hist_H_chk_23881 + hist_H_chk_23881))) {\n                        int32_t eta_p_22685;\n                        int32_t eta_p_22686 = 1;\n                        int32_t old_23909;\n                        \n                        old_23909 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23897)[sext_i32_i64(thread_local_subhisto_i_23899) * hist_H_chk_23881 + (i32_res_22690 - sext_i32_i64(chk_i_23879) * hist_H_chk_23881)], (int) eta_p_22686);\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_23910 = smin64(hist_H_chk_23881, mz2080U_19405 - sext_i32_i64(chk_i_23879) * hist_H_chk_23881);\n            int32_t histo_sizze_23911 = sext_i64_i32(trunc_H_23910);\n            \n       ",
                                    "     for (int32_t local_i_23912 = 0; local_i_23912 < init_per_thread_23883; local_i_23912++) {\n                int32_t j_23913 = local_i_23912 * sext_i64_i32(max_tblock_sizze_23868) + local_tid_23885;\n                \n                if (slt32(j_23913, histo_sizze_23911)) {\n                    int32_t eta_p_22685;\n                    int32_t eta_p_22686;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_22685 = ((__local int32_t *) subhistogram_local_mem_23897)[sext_i32_i64(j_23913)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_23914 = 0; subhisto_id_23914 < hist_M_23875 - 1; subhisto_id_23914++) {\n                            eta_p_22686 = ((__local int32_t *) subhistogram_local_mem_23897)[(sext_i32_i64(subhisto_id_23914) + (int64_t) 1) * hist_H_chk_23881 + sext_i32_i64(j_23913)];\n                            \n                            int32_t defunc_0_op_res_22687 = add32(eta_p_22685, eta_p_22686);\n                            \n                            eta_p_22685 = defunc_0_op_res_22687;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_23859)[srem64(sext_i32_i64(virt_tblock_id_23892), num_tblocks_23869) * mz2080U_19405 + (sext_i32_i64(j_23913) + sext_i32_i64(chk_i_23879) * hist_H_chk_23881)] = eta_p_22685;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_23868\n}\nFUTHARK_KERNEL_SIZED(compilerzisegmap_22548_dim1, 1, 1)\nvoid compilerzisegmap_22548(__global int *global_failure, int64_t mz2080U_19405, int64_t nz2081U_19406, int64_t num_tblocks_22553, int32_t virt_num_tblock", "s_23069, __global unsigned char *mem_22773, __global unsigned char *mem_22774)\n{\n    #define segmap_tblock_sizze_22551 (compilerzisegmap_22548zisegmap_tblock_sizze_22551)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23071;\n    int32_t tblock_sizze_23074;\n    int32_t wave_sizze_23073;\n    int32_t block_id_23072;\n    int32_t global_tid_23070;\n    int64_t phys_tid_22548;\n    int32_t phys_tblock_id_23075;\n    int32_t iterations_23076;\n    \n    local_tid_23071 = get_local_id(0);\n    tblock_sizze_23074 = get_local_size(0);\n    wave_sizze_23073 = LOCKSTEP_WIDTH;\n    block_id_23072 = get_tblock_id(0);\n    global_tid_23070 = block_id_23072 * tblock_sizze_23074 + local_tid_23071;\n    phys_tid_22548 = sext_i32_i64(global_tid_23070);\n    phys_tblock_id_23075 = get_tblock_id(0);\n    iterations_23076 = sdiv_up32(virt_num_tblocks_23069 - phys_tblock_id_23075, sext_i64_i32(num_tblocks_22553));\n    for (int32_t i_23077 = 0; i_23077 < iterations_23076; i_23077++) {\n        int32_t virt_tblock_id_23078;\n        int64_t global_tid_23079;\n        int64_t slice_23080;\n        int64_t write_i_22547;\n        int64_t remnant_23081;\n        \n        virt_tblock_id_23078 = phys_tblock_id_23075 + i_23077 * sext_i64_i32(num_tblocks_22553);\n        global_tid_23079 = sext_i32_i64(virt_tblock_id_23078) * segmap_tblock_sizze_22551 + sext_i32_i64(local_tid_23071);\n        slice_23080 = mz2080U_19405;\n        write_i_22547 = global_tid_23079;\n        remnant_23081 = global_tid_23079 - write_i_22547;\n        if (slt64(write_i_22547, mz2080U_19405)) {\n            int64_t zv_lhs_21450;\n            int64_t tmp_21451;\n            bool cond_21454;\n            int64_t lifted_lambda_res_21455;\n            \n            zv_lhs_21450 = add64((int64_t) -1, write_i_22547);\n            tmp_21451 = smod64(zv_lhs_21450, mz2080U_19405);\n            cond_21454 = write_i_22547 == (int64_t) 0;\n            if (cond_21454) {\n                lifted_lambda_res_21455 = (int64_t) 0;\n            } ", "else {\n                int64_t lifted_lambda_res_21452 = ((__global int64_t *) mem_22773)[tmp_21451];\n                \n                lifted_lambda_res_21455 = lifted_lambda_res_21452;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21455) && slt64(lifted_lambda_res_21455, nz2081U_19406)) {\n                ((__global bool *) mem_22774)[lifted_lambda_res_21455] = 1;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22551\n}\nFUTHARK_KERNEL_SIZED(compilerzisegmap_22579_dim1, 1, 1)\nvoid compilerzisegmap_22579(__global int *global_failure, int64_t nz2081U_19406, __global unsigned char *mem_22781)\n{\n    #define segmap_tblock_sizze_22575 (compilerzisegmap_22579zisegmap_tblock_sizze_22575)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23187;\n    int32_t tblock_sizze_23190;\n    int32_t wave_sizze_23189;\n    int32_t block_id_23188;\n    int32_t global_tid_23186;\n    int64_t phys_tid_22579;\n    int64_t global_tid_23191;\n    int64_t slice_23192;\n    int64_t gtid_22578;\n    int64_t remnant_23193;\n    \n    local_tid_23187 = get_local_id(0);\n    tblock_sizze_23190 = get_local_size(0);\n    wave_sizze_23189 = LOCKSTEP_WIDTH;\n    block_id_23188 = get_tblock_id(0);\n    global_tid_23186 = block_id_23188 * tblock_sizze_23190 + local_tid_23187;\n    phys_tid_22579 = sext_i32_i64(global_tid_23186);\n    global_tid_23191 = sext_i32_i64(block_id_23188) * segmap_tblock_sizze_22575 + sext_i32_i64(local_tid_23187);\n    slice_23192 = nz2081U_19406;\n    gtid_22578 = global_tid_23191;\n    remnant_23193 = global_tid_23191 - gtid_22578;\n    if (slt64(gtid_22578, nz2081U_19406)) {\n        int32_t eta_p_22580;\n        int32_t lifted_lambda_res_22582;\n        \n        eta_p_22580 = ((__global int32_t *) mem_22781)[gtid_22578];\n        lifted_lambda_res_22582 = sub32(eta_p_22580, 1);\n        ((__global int32_t *) mem_22781)[gtid_22578] = lifted_lambda_res_22582;",
                                    "\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22575\n}\nFUTHARK_KERNEL_SIZED(compilerzisegmap_22615_dim1, 1, 1)\nvoid compilerzisegmap_22615(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_19405, int64_t loop_dz2083Uz2082U_21002, __global unsigned char *mem_param_22793, __global unsigned char *mem_22799, __global unsigned char *mem_22802)\n{\n    #define segmap_tblock_sizze_22611 (compilerzisegmap_22615zisegmap_tblock_sizze_22611)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23311;\n    int32_t tblock_sizze_23314;\n    int32_t wave_sizze_23313;\n    int32_t block_id_23312;\n    int32_t global_tid_23310;\n    int64_t phys_tid_22615;\n    int64_t global_tid_23315;\n    int64_t slice_23316;\n    int64_t gtid_22614;\n    int64_t remnant_23317;\n    \n    local_tid_23311 = get_local_id(0);\n    tblock_sizze_23314 = get_local_size(0);\n    wave_sizze_23313 = LOCKSTEP_WIDTH;\n    block_id_23312 = get_tblock_id(0);\n    global_tid_23310 = block_id_23312 * tblock_sizze_23314 + local_tid_23311;\n    phys_tid_22615 = sext_i32_i64(global_tid_23310);\n    global_tid_23315 = sext_i32_i64(block_id_23312) * segmap_tblock_sizze_22611 + sext_i32_i64(local_tid_23311);\n    slice_23316 = mz2080U_19405;\n    gtid_22614 = global_tid_23315;\n    remnant_23317 = global_tid_23315 - gtid_22614;\n    if (slt64(gtid_22614, mz2080U_19405)) {\n        int32_t eta_p_22616;\n        int32_t lifted_lambda_res_22618;\n        bool cond_22619;\n        int32_t max_res_22620;\n        int64_t tmp_22621;\n        bool x_22622;\n        bool y_22623;\n        bool bounds_check_22624;\n        bool index_certs_22625;\n        float lifted_lambda_res_22626;\n        \n        eta_p_22616 = ((__global int32_t *) mem_22799)[gtid_22614];\n        lifted_lambda_res_22618 = add32(-1, eta_p_22616);\n        cond_22619 = slt32(0, lifted_lambda_res_22618);\n        if (cond_22619) {\n            max_res_22620 = lifted_lambda_res_22618;\n        }", " else {\n            max_res_22620 = 0;\n        }\n        tmp_22621 = sext_i32_i64(max_res_22620);\n        x_22622 = sle64((int64_t) 0, tmp_22621);\n        y_22623 = slt64(tmp_22621, loop_dz2083Uz2082U_21002);\n        bounds_check_22624 = x_22622 && y_22623;\n        if (!bounds_check_22624) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_22621;\n                    global_failure_args[1] = (int64_t) loop_dz2083Uz2082U_21002;\n                    ;\n                }\n                return;\n            }\n        }\n        lifted_lambda_res_22626 = ((__global float *) mem_param_22793)[tmp_22621];\n        ((__global float *) mem_22802)[gtid_22614] = lifted_lambda_res_22626;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22611\n}\nFUTHARK_KERNEL_SIZED(compilerzisegmap_22636_dim1, 1, 1)\nvoid compilerzisegmap_22636(__global int *global_failure, int64_t loop_dz2083Uz2082U_21002, int64_t m_21053, int64_t m_21094, int64_t m_21135, int64_t num_tblocks_22641, int32_t virt_num_tblocks_23522, __global unsigned char *mem_param_22790, __global unsigned char *mem_22805, __global unsigned char *mem_22807, __global unsigned char *mem_22809, __global unsigned char *mem_22811, __global unsigned char *mem_22813, __global unsigned char *mem_22815, __global unsigned char *mem_22817, __global unsigned char *mem_22819, __global unsigned char *mem_22821)\n{\n    #define segmap_tblock_sizze_22639 (compilerzisegmap_22636zisegmap_tblock_sizze_22639)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23524;\n    int32_t tblock_sizze_23527;\n    int32_t wave_sizze_23526;\n    int32_t block_id_23525;\n    int32_t global_tid_23523;\n    int64_t phys_tid_22636;\n    int32_t phys_tblock_id_23528;\n    int32_t iterations_23529;\n    \n    local_tid_23524 = get_local_id(0);\n    tblock_sizze_23527 = get_local_size(0);\n    wave_sizze_23526 = LOCKSTEP_WIDTH;\n    block_id_23525 = ", "get_tblock_id(0);\n    global_tid_23523 = block_id_23525 * tblock_sizze_23527 + local_tid_23524;\n    phys_tid_22636 = sext_i32_i64(global_tid_23523);\n    phys_tblock_id_23528 = get_tblock_id(0);\n    iterations_23529 = sdiv_up32(virt_num_tblocks_23522 - phys_tblock_id_23528, sext_i64_i32(num_tblocks_22641));\n    for (int32_t i_23530 = 0; i_23530 < iterations_23529; i_23530++) {\n        int32_t virt_tblock_id_23531;\n        int64_t global_tid_23532;\n        int64_t slice_23533;\n        int64_t write_i_22635;\n        int64_t remnant_23534;\n        \n        virt_tblock_id_23531 = phys_tblock_id_23528 + i_23530 * sext_i64_i32(num_tblocks_22641);\n        global_tid_23532 = sext_i32_i64(virt_tblock_id_23531) * segmap_tblock_sizze_22639 + sext_i32_i64(local_tid_23524);\n        slice_23533 = loop_dz2083Uz2082U_21002;\n        write_i_22635 = global_tid_23532;\n        remnant_23534 = global_tid_23532 - write_i_22635;\n        if (slt64(write_i_22635, loop_dz2083Uz2082U_21002)) {\n            int64_t eta_p_21814;\n            int32_t write_value_21816;\n            int64_t eta_p_21817;\n            int64_t eta_p_21820;\n            bool cond_21823;\n            int64_t lifted_lambda_res_21824;\n            bool cond_21827;\n            int64_t lifted_lambda_res_21828;\n            bool cond_21831;\n            int64_t lifted_lambda_res_21832;\n            \n            eta_p_21814 = ((__global int64_t *) mem_22811)[write_i_22635];\n            write_value_21816 = ((__global int32_t *) mem_param_22790)[write_i_22635];\n            eta_p_21817 = ((__global int64_t *) mem_22813)[write_i_22635];\n            eta_p_21820 = ((__global int64_t *) mem_22815)[write_i_22635];\n            cond_21823 = eta_p_21820 == (int64_t) 1;\n            if (cond_21823) {\n                int64_t eta_p_21821;\n                int64_t lifted_lambda_res_t_res_21905;\n                \n                eta_p_21821 = ((__global int64_t *) mem_22805)[write_i_22635];\n                lifted_lambda_res_t_res_21905 = sub64(eta_p_218",
                                    "21, (int64_t) 1);\n                lifted_lambda_res_21824 = lifted_lambda_res_t_res_21905;\n            } else {\n                lifted_lambda_res_21824 = (int64_t) -1;\n            }\n            cond_21827 = eta_p_21817 == (int64_t) 1;\n            if (cond_21827) {\n                int64_t eta_p_21818;\n                int64_t lifted_lambda_res_t_res_21906;\n                \n                eta_p_21818 = ((__global int64_t *) mem_22807)[write_i_22635];\n                lifted_lambda_res_t_res_21906 = sub64(eta_p_21818, (int64_t) 1);\n                lifted_lambda_res_21828 = lifted_lambda_res_t_res_21906;\n            } else {\n                lifted_lambda_res_21828 = (int64_t) -1;\n            }\n            cond_21831 = eta_p_21814 == (int64_t) 1;\n            if (cond_21831) {\n                int64_t eta_p_21815;\n                int64_t lifted_lambda_res_t_res_21907;\n                \n                eta_p_21815 = ((__global int64_t *) mem_22809)[write_i_22635];\n                lifted_lambda_res_t_res_21907 = sub64(eta_p_21815, (int64_t) 1);\n                lifted_lambda_res_21832 = lifted_lambda_res_t_res_21907;\n            } else {\n                lifted_lambda_res_21832 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21832) && slt64(lifted_lambda_res_21832, m_21135)) {\n                ((__global int32_t *) mem_22817)[lifted_lambda_res_21832] = write_value_21816;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21828) && slt64(lifted_lambda_res_21828, m_21094)) {\n                ((__global int32_t *) mem_22819)[lifted_lambda_res_21828] = write_value_21816;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21824) && slt64(lifted_lambda_res_21824, m_21053)) {\n                ((__global int32_t *) mem_22821)[lifted_lambda_res_21824] = write_value_21816;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22639", "\n}\nFUTHARK_KERNEL_SIZED(compilerzisegmap_22727_dim1, 1, 1)\nvoid compilerzisegmap_22727(__global int *global_failure, int64_t mz2080U_19405, __global unsigned char *mem_param_22784, __global unsigned char *mem_param_22787, __global unsigned char *mem_param_22796, __global unsigned char *mem_22802, __global unsigned char *mem_22824, __global unsigned char *mem_22827, __global unsigned char *mem_22830, __global unsigned char *mem_22834, __global unsigned char *mem_22836, __global unsigned char *mem_22838, __global unsigned char *mem_22840)\n{\n    #define segmap_tblock_sizze_22720 (compilerzisegmap_22727zisegmap_tblock_sizze_22720)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24020;\n    int32_t tblock_sizze_24023;\n    int32_t wave_sizze_24022;\n    int32_t block_id_24021;\n    int32_t global_tid_24019;\n    int64_t phys_tid_22727;\n    int64_t global_tid_24024;\n    int64_t slice_24025;\n    int64_t gtid_22726;\n    int64_t remnant_24026;\n    \n    local_tid_24020 = get_local_id(0);\n    tblock_sizze_24023 = get_local_size(0);\n    wave_sizze_24022 = LOCKSTEP_WIDTH;\n    block_id_24021 = get_tblock_id(0);\n    global_tid_24019 = block_id_24021 * tblock_sizze_24023 + local_tid_24020;\n    phys_tid_22727 = sext_i32_i64(global_tid_24019);\n    global_tid_24024 = sext_i32_i64(block_id_24021) * segmap_tblock_sizze_22720 + sext_i32_i64(local_tid_24020);\n    slice_24025 = mz2080U_19405;\n    gtid_22726 = global_tid_24024;\n    remnant_24026 = global_tid_24024 - gtid_22726;\n    if (slt64(gtid_22726, mz2080U_19405)) {\n        int32_t eta_p_22728;\n        int32_t eta_p_22730;\n        int32_t eta_p_22731;\n        int32_t eta_p_22732;\n        bool cond_22735;\n        int32_t lifted_lambda_res_22736;\n        bool cond_22742;\n        float lifted_lambda_res_22743;\n        int32_t lifted_lambda_res_22744;\n        int32_t lifted_lambda_res_22747;\n        \n        eta_p_22728 = ((__global int32_t *) mem_22824)[gtid_22726];\n        eta_p_22730 = ((__global int32_t *) mem_param", "_22784)[gtid_22726];\n        eta_p_22731 = ((__global int32_t *) mem_22827)[gtid_22726];\n        eta_p_22732 = ((__global int32_t *) mem_param_22787)[gtid_22726];\n        cond_22735 = eta_p_22732 == 0;\n        if (cond_22735) {\n            lifted_lambda_res_22736 = -1;\n        } else {\n            bool cond_22737;\n            int32_t lifted_lambda_res_f_res_22738;\n            \n            cond_22737 = sle32(eta_p_22730, eta_p_22728);\n            if (cond_22737) {\n                lifted_lambda_res_f_res_22738 = 0;\n            } else {\n                int32_t zlze_rhs_22739;\n                bool cond_22740;\n                int32_t lifted_lambda_res_f_res_f_res_22741;\n                \n                zlze_rhs_22739 = add32(eta_p_22728, eta_p_22731);\n                cond_22740 = sle32(eta_p_22730, zlze_rhs_22739);\n                if (cond_22740) {\n                    lifted_lambda_res_f_res_f_res_22741 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_22741 = 2;\n                }\n                lifted_lambda_res_f_res_22738 = lifted_lambda_res_f_res_f_res_22741;\n            }\n            lifted_lambda_res_22736 = lifted_lambda_res_f_res_22738;\n        }\n        cond_22742 = lifted_lambda_res_22736 == 1;\n        if (cond_22742) {\n            float eta_p_22734 = ((__global float *) mem_22802)[gtid_22726];\n            \n            lifted_lambda_res_22743 = eta_p_22734;\n        } else {\n            float eta_p_22733 = ((__global float *) mem_param_22796)[gtid_22726];\n            \n            lifted_lambda_res_22743 = eta_p_22733;\n        }\n        if (lifted_lambda_res_22736 == -1) {\n            lifted_lambda_res_22744 = -1;\n        } else if (lifted_lambda_res_22736 == 0) {\n            lifted_lambda_res_22744 = eta_p_22730;\n        } else if (lifted_lambda_res_22736 == 1) {\n            lifted_lambda_res_22744 = -1;\n        } else if (lifted_lambda_res_22736 == 2) {\n            int32_t zm_lhs_22745;\n            int32_t case_res_22746;\n        ",
                                    "    \n            zm_lhs_22745 = sub32(eta_p_22730, eta_p_22728);\n            case_res_22746 = sub32(zm_lhs_22745, eta_p_22731);\n            lifted_lambda_res_22744 = case_res_22746;\n        } else {\n            lifted_lambda_res_22744 = -1;\n        }\n        if (lifted_lambda_res_22736 == -1) {\n            lifted_lambda_res_22747 = 0;\n        } else if (lifted_lambda_res_22736 == 0) {\n            lifted_lambda_res_22747 = eta_p_22728;\n        } else if (lifted_lambda_res_22736 == 1) {\n            lifted_lambda_res_22747 = 0;\n        } else if (lifted_lambda_res_22736 == 2) {\n            int32_t eta_p_22729 = ((__global int32_t *) mem_22830)[gtid_22726];\n            \n            lifted_lambda_res_22747 = eta_p_22729;\n        } else {\n            lifted_lambda_res_22747 = -1;\n        }\n        ((__global int32_t *) mem_22834)[gtid_22726] = lifted_lambda_res_22747;\n        ((__global int32_t *) mem_22836)[gtid_22726] = lifted_lambda_res_22744;\n        ((__global float *) mem_22838)[gtid_22726] = lifted_lambda_res_22743;\n        ((__global int32_t *) mem_22840)[gtid_22726] = lifted_lambda_res_22736;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22720\n}\nFUTHARK_KERNEL_SIZED(compilerzisegmap_22757_dim1, 1, 1)\nvoid compilerzisegmap_22757(__global int *global_failure, int64_t loop_dz2083Uz2082U_21002, int64_t m_21249, int64_t num_tblocks_22762, int32_t virt_num_tblocks_24131, __global unsigned char *mem_param_22790, __global unsigned char *mem_param_22793, __global unsigned char *mem_22843, __global unsigned char *mem_22845, __global unsigned char *mem_22847, __global unsigned char *mem_22849)\n{\n    #define segmap_tblock_sizze_22760 (compilerzisegmap_22757zisegmap_tblock_sizze_22760)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24133;\n    int32_t tblock_sizze_24136;\n    int32_t wave_sizze_24135;\n    int32_t block_id_24134;\n    int32_t global_tid_24132;\n    int64_t phys_tid_22757;\n    int32_t phys_tblock_id_24137;\n    int32_t it", "erations_24138;\n    \n    local_tid_24133 = get_local_id(0);\n    tblock_sizze_24136 = get_local_size(0);\n    wave_sizze_24135 = LOCKSTEP_WIDTH;\n    block_id_24134 = get_tblock_id(0);\n    global_tid_24132 = block_id_24134 * tblock_sizze_24136 + local_tid_24133;\n    phys_tid_22757 = sext_i32_i64(global_tid_24132);\n    phys_tblock_id_24137 = get_tblock_id(0);\n    iterations_24138 = sdiv_up32(virt_num_tblocks_24131 - phys_tblock_id_24137, sext_i64_i32(num_tblocks_22762));\n    for (int32_t i_24139 = 0; i_24139 < iterations_24138; i_24139++) {\n        int32_t virt_tblock_id_24140;\n        int64_t global_tid_24141;\n        int64_t slice_24142;\n        int64_t write_i_22756;\n        int64_t remnant_24143;\n        \n        virt_tblock_id_24140 = phys_tblock_id_24137 + i_24139 * sext_i64_i32(num_tblocks_22762);\n        global_tid_24141 = sext_i32_i64(virt_tblock_id_24140) * segmap_tblock_sizze_22760 + sext_i32_i64(local_tid_24133);\n        slice_24142 = loop_dz2083Uz2082U_21002;\n        write_i_22756 = global_tid_24141;\n        remnant_24143 = global_tid_24141 - write_i_22756;\n        if (slt64(write_i_22756, loop_dz2083Uz2082U_21002)) {\n            int64_t eta_p_21473;\n            float write_value_21475;\n            int32_t write_value_21476;\n            bool cond_21477;\n            int64_t lifted_lambda_res_21478;\n            \n            eta_p_21473 = ((__global int64_t *) mem_22845)[write_i_22756];\n            write_value_21475 = ((__global float *) mem_param_22793)[write_i_22756];\n            write_value_21476 = ((__global int32_t *) mem_param_22790)[write_i_22756];\n            cond_21477 = eta_p_21473 == (int64_t) 1;\n            if (cond_21477) {\n                int64_t eta_p_21474;\n                int64_t lifted_lambda_res_t_res_21913;\n                \n                eta_p_21474 = ((__global int64_t *) mem_22843)[write_i_22756];\n                lifted_lambda_res_t_res_21913 = sub64(eta_p_21474, (int64_t) 1);\n                lifted_lambda_res_21478 = lifted_lambda_res_", "t_res_21913;\n            } else {\n                lifted_lambda_res_21478 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21478) && slt64(lifted_lambda_res_21478, m_21249)) {\n                ((__global float *) mem_22849)[lifted_lambda_res_21478] = write_value_21475;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21478) && slt64(lifted_lambda_res_21478, m_21249)) {\n                ((__global int32_t *) mem_22847)[lifted_lambda_res_21478] = write_value_21476;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22760\n}\nFUTHARK_KERNEL_SIZED(compilerzisegred_large_23622_dim1, 1, 1)\nvoid compilerzisegred_large_23622(__global int *global_failure, int64_t mz2080U_19405, int64_t num_tblocks_22647, int64_t num_subhistos_23536, int64_t blocks_per_segment_23653, int64_t q_23654, int64_t num_virtblocks_23655, int64_t threads_per_segment_23656, __global unsigned char *mem_22824, __global unsigned char *defunc_0_map_res_subhistos_mem_23537, __global unsigned char *segred_tmp_mem_23657, __global unsigned char *counters_mem_23659)\n{\n    #define seghist_tblock_sizze_22645 (compilerzisegred_large_23622ziseghist_tblock_sizze_22645)\n    #define chunk_sizze_23623 (compilerzisegred_large_23622zichunk_sizze_23623)\n    \n    volatile __local unsigned char *sync_arr_mem_23668_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_23668_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_23666_backing_0 = &shared_mem[sync_arr_mem_23668_backing_1_offset];\n    const int64_t red_arr_i32_mem_23666_backing_0_offset = sync_arr_mem_23668_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22645 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22645, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23662;\n    int32_t tblock_sizze_23665;\n    int3",
                                    "2_t wave_sizze_23664;\n    int32_t block_id_23663;\n    int32_t global_tid_23661;\n    int64_t flat_gtid_23622;\n    __local unsigned char *red_arr_i32_mem_23666;\n    __local unsigned char *sync_arr_mem_23668;\n    int32_t phys_tblock_id_23670;\n    int32_t iterations_23671;\n    \n    local_tid_23662 = get_local_id(0);\n    tblock_sizze_23665 = get_local_size(0);\n    wave_sizze_23664 = LOCKSTEP_WIDTH;\n    block_id_23663 = get_tblock_id(0);\n    global_tid_23661 = block_id_23663 * tblock_sizze_23665 + local_tid_23662;\n    flat_gtid_23622 = sext_i32_i64(global_tid_23661);\n    red_arr_i32_mem_23666 = (__local unsigned char *) red_arr_i32_mem_23666_backing_0;\n    sync_arr_mem_23668 = (__local unsigned char *) sync_arr_mem_23668_backing_1;\n    phys_tblock_id_23670 = get_tblock_id(0);\n    iterations_23671 = sdiv_up32(sext_i64_i32(num_virtblocks_23655) - phys_tblock_id_23670, sext_i64_i32(num_tblocks_22647));\n    for (int32_t i_23672 = 0; i_23672 < iterations_23671; i_23672++) {\n        int32_t virt_tblock_id_23673;\n        int64_t flat_segment_id_23674;\n        int64_t global_tid_23675;\n        int64_t slice_23676;\n        int64_t bucket_id_23620;\n        int64_t remnant_23677;\n        int64_t subhistogram_id_23621;\n        int32_t eta_p_block_res_acc_23678;\n        int32_t eta_p_22653;\n        int32_t eta_p_22654;\n        int64_t tblock_id_in_segment_23682;\n        int64_t block_base_offset_23683;\n        int32_t offset_23686;\n        int32_t skip_waves_23687;\n        int32_t eta_p_23679;\n        int32_t eta_p_23680;\n        \n        virt_tblock_id_23673 = phys_tblock_id_23670 + i_23672 * sext_i64_i32(num_tblocks_22647);\n        flat_segment_id_23674 = squot64(sext_i32_i64(virt_tblock_id_23673), blocks_per_segment_23653);\n        global_tid_23675 = srem64(sext_i32_i64(virt_tblock_id_23673) * seghist_tblock_sizze_22645 + sext_i32_i64(local_tid_23662), threads_per_segment_23656);\n        slice_23676 = mz2080U_19405;\n        bucket_id_23620 = flat_segment_id_23674;\n        remnant_2", "3677 = flat_segment_id_23674 - bucket_id_23620;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_23678 = 0;\n        }\n        tblock_id_in_segment_23682 = squot64(global_tid_23675, seghist_tblock_sizze_22645);\n        block_base_offset_23683 = tblock_id_in_segment_23682 * q_23654 * seghist_tblock_sizze_22645;\n        for (int64_t i_23684 = 0; i_23684 < q_23654; i_23684++) {\n            int64_t block_offset_23685 = block_base_offset_23683 + i_23684 * seghist_tblock_sizze_22645;\n            \n            subhistogram_id_23621 = global_tid_23675 + threads_per_segment_23656 * i_23684;\n            if (slt64(subhistogram_id_23621, num_subhistos_23536)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_22653 = eta_p_block_res_acc_23678;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_22654 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23537)[subhistogram_id_23621 * mz2080U_19405 + bucket_id_23620];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t defunc_0_op_res_22655 = add32(eta_p_22653, eta_p_22654);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_23678 = defunc_0_op_res_22655;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662)] = eta_p_block_res_acc_23678;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_23687 = 1;\n        offset_23686 = 0;\n        // participating threads read initial accumulator\n", "        {\n            if (slt32(local_tid_23662, sext_i64_i32(seghist_tblock_sizze_22645))) {\n                eta_p_23679 = ((__local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662 + offset_23686)];\n            }\n        }\n        offset_23686 = 1;\n        while (slt32(offset_23686, wave_sizze_23664)) {\n            if (slt32(local_tid_23662 + offset_23686, sext_i64_i32(seghist_tblock_sizze_22645)) && ((local_tid_23662 - squot32(local_tid_23662, wave_sizze_23664) * wave_sizze_23664) & (2 * offset_23686 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_23680 = ((volatile __local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662 + offset_23686)];\n                }\n                // apply reduction operation\n                {\n                    int32_t defunc_0_op_res_23681 = add32(eta_p_23679, eta_p_23680);\n                    \n                    eta_p_23679 = defunc_0_op_res_23681;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662)] = eta_p_23679;\n                }\n            }\n            offset_23686 *= 2;\n        }\n        while (slt32(skip_waves_23687, squot32(sext_i64_i32(seghist_tblock_sizze_22645) + wave_sizze_23664 - 1, wave_sizze_23664))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23686 = skip_waves_23687 * wave_sizze_23664;\n            if (slt32(local_tid_23662 + offset_23686, sext_i64_i32(seghist_tblock_sizze_22645)) && ((local_tid_23662 - squot32(local_tid_23662, wave_sizze_23664) * wave_sizze_23664) == 0 && (squot32(local_tid_23662, wave_sizze_23664) & (2 * skip_waves_23687 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_23680 = ((__local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662 + offset_23686)];\n                }\n                // apply reduction operation",
                                    "\n                {\n                    int32_t defunc_0_op_res_23681 = add32(eta_p_23679, eta_p_23680);\n                    \n                    eta_p_23679 = defunc_0_op_res_23681;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662)] = eta_p_23679;\n                }\n            }\n            skip_waves_23687 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_23662) == (int64_t) 0) {\n                eta_p_block_res_acc_23678 = eta_p_23679;\n            } else {\n                eta_p_block_res_acc_23678 = 0;\n            }\n        }\n        if (blocks_per_segment_23653 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_23662 == 0) {\n                    ((__global int32_t *) mem_22824)[bucket_id_23620] = eta_p_block_res_acc_23678;\n                }\n            }\n        } else {\n            int32_t old_counter_23688;\n            bool is_last_block_23689;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_23662 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_23657)[sext_i32_i64(virt_tblock_id_23673)] = eta_p_block_res_acc_23678;\n                    mem_fence_global();\n                    old_counter_23688 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23659)[srem64(flat_segment_id_23674, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_23668)[(int64_t) 0] = old_counter_23688 == sext_i64_i32(blocks_per_segment_23653 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_23689 = ((__local bool *) sync_", "arr_mem_23668)[(int64_t) 0];\n            if (is_last_block_23689) {\n                if (local_tid_23662 == 0) {\n                    old_counter_23688 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23659)[srem64(flat_segment_id_23674, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_23653));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_23690 = sdiv_up64(blocks_per_segment_23653, seghist_tblock_sizze_22645);\n                    \n                    eta_p_22653 = 0;\n                    for (int64_t i_23691 = 0; i_23691 < read_per_thread_23690; i_23691++) {\n                        int64_t block_res_id_23692 = sext_i32_i64(local_tid_23662) * read_per_thread_23690 + i_23691;\n                        int64_t index_of_block_res_23693 = flat_segment_id_23674 * blocks_per_segment_23653 + block_res_id_23692;\n                        \n                        if (slt64(block_res_id_23692, blocks_per_segment_23653)) {\n                            eta_p_22654 = ((__global int32_t *) segred_tmp_mem_23657)[index_of_block_res_23693];\n                            \n                            int32_t defunc_0_op_res_22655 = add32(eta_p_22653, eta_p_22654);\n                            \n                            eta_p_22653 = defunc_0_op_res_22655;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662)] = eta_p_22653;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_23694;\n                    int32_t skip_waves_23695 = 1;\n                    int32_t eta_p_23679;\n                    int32_t eta_p_23680;\n                    \n                    offset_23694 = 0;\n                    // participating threads read initial accumulator\n                    {\n                      ", "  if (slt32(local_tid_23662, sext_i64_i32(seghist_tblock_sizze_22645))) {\n                            eta_p_23679 = ((__local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662 + offset_23694)];\n                        }\n                    }\n                    offset_23694 = 1;\n                    while (slt32(offset_23694, wave_sizze_23664)) {\n                        if (slt32(local_tid_23662 + offset_23694, sext_i64_i32(seghist_tblock_sizze_22645)) && ((local_tid_23662 - squot32(local_tid_23662, wave_sizze_23664) * wave_sizze_23664) & (2 * offset_23694 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_23680 = ((volatile __local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662 + offset_23694)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t defunc_0_op_res_23681 = add32(eta_p_23679, eta_p_23680);\n                                \n                                eta_p_23679 = defunc_0_op_res_23681;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662)] = eta_p_23679;\n                            }\n                        }\n                        offset_23694 *= 2;\n                    }\n                    while (slt32(skip_waves_23695, squot32(sext_i64_i32(seghist_tblock_sizze_22645) + wave_sizze_23664 - 1, wave_sizze_23664))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_23694 = skip_waves_23695 * wave_sizze_23664;\n                        if (slt32(local_tid_23662 + offset_23694, sext_i64_i32(seghist_tblock_sizze_22645)) && ((local_tid_23662 - squot32(local_tid_23662, wave_sizze_23664) * wave_sizze_23664) == 0 && (squot32(local_tid_236",
                                    "62, wave_sizze_23664) & (2 * skip_waves_23695 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_23680 = ((__local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662 + offset_23694)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t defunc_0_op_res_23681 = add32(eta_p_23679, eta_p_23680);\n                                \n                                eta_p_23679 = defunc_0_op_res_23681;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_23666)[sext_i32_i64(local_tid_23662)] = eta_p_23679;\n                            }\n                        }\n                        skip_waves_23695 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_23662 == 0) {\n                            ((__global int32_t *) mem_22824)[bucket_id_23620] = eta_p_23679;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_22645\n    #undef chunk_sizze_23623\n}\nFUTHARK_KERNEL_SIZED(compilerzisegred_large_23783_dim1, 1, 1)\nvoid compilerzisegred_large_23783(__global int *global_failure, int64_t mz2080U_19405, int64_t num_tblocks_22663, int64_t num_subhistos_23697, int64_t blocks_per_segment_23814, int64_t q_23815, int64_t num_virtblocks_23816, int64_t threads_per_segment_23817, __global unsigned char *mem_22827, __global unsigned char *defunc_0_map_res_subhistos_mem_23698, __global unsigned char *segred_tmp_mem_23818, __global unsigned char *counters_mem_23820)", "\n{\n    #define seghist_tblock_sizze_22661 (compilerzisegred_large_23783ziseghist_tblock_sizze_22661)\n    #define chunk_sizze_23784 (compilerzisegred_large_23783zichunk_sizze_23784)\n    \n    volatile __local unsigned char *sync_arr_mem_23829_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_23829_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_23827_backing_0 = &shared_mem[sync_arr_mem_23829_backing_1_offset];\n    const int64_t red_arr_i32_mem_23827_backing_0_offset = sync_arr_mem_23829_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22661 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22661, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23823;\n    int32_t tblock_sizze_23826;\n    int32_t wave_sizze_23825;\n    int32_t block_id_23824;\n    int32_t global_tid_23822;\n    int64_t flat_gtid_23783;\n    __local unsigned char *red_arr_i32_mem_23827;\n    __local unsigned char *sync_arr_mem_23829;\n    int32_t phys_tblock_id_23831;\n    int32_t iterations_23832;\n    \n    local_tid_23823 = get_local_id(0);\n    tblock_sizze_23826 = get_local_size(0);\n    wave_sizze_23825 = LOCKSTEP_WIDTH;\n    block_id_23824 = get_tblock_id(0);\n    global_tid_23822 = block_id_23824 * tblock_sizze_23826 + local_tid_23823;\n    flat_gtid_23783 = sext_i32_i64(global_tid_23822);\n    red_arr_i32_mem_23827 = (__local unsigned char *) red_arr_i32_mem_23827_backing_0;\n    sync_arr_mem_23829 = (__local unsigned char *) sync_arr_mem_23829_backing_1;\n    phys_tblock_id_23831 = get_tblock_id(0);\n    iterations_23832 = sdiv_up32(sext_i64_i32(num_virtblocks_23816) - phys_tblock_id_23831, sext_i64_i32(num_tblocks_22663));\n    for (int32_t i_23833 = 0; i_23833 < iterations_23832; i_23833++) {\n        int32_t virt_tblock_id_23834;\n        int64_t flat_segment_id_23835;\n        int64_t global_tid_23836;\n        int64_t slice_23837;\n        int64_t bucket_id_23781;\n        int64_t remnant_23838;\n ", "       int64_t subhistogram_id_23782;\n        int32_t eta_p_block_res_acc_23839;\n        int32_t eta_p_22669;\n        int32_t eta_p_22670;\n        int64_t tblock_id_in_segment_23843;\n        int64_t block_base_offset_23844;\n        int32_t offset_23847;\n        int32_t skip_waves_23848;\n        int32_t eta_p_23840;\n        int32_t eta_p_23841;\n        \n        virt_tblock_id_23834 = phys_tblock_id_23831 + i_23833 * sext_i64_i32(num_tblocks_22663);\n        flat_segment_id_23835 = squot64(sext_i32_i64(virt_tblock_id_23834), blocks_per_segment_23814);\n        global_tid_23836 = srem64(sext_i32_i64(virt_tblock_id_23834) * seghist_tblock_sizze_22661 + sext_i32_i64(local_tid_23823), threads_per_segment_23817);\n        slice_23837 = mz2080U_19405;\n        bucket_id_23781 = flat_segment_id_23835;\n        remnant_23838 = flat_segment_id_23835 - bucket_id_23781;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_23839 = 0;\n        }\n        tblock_id_in_segment_23843 = squot64(global_tid_23836, seghist_tblock_sizze_22661);\n        block_base_offset_23844 = tblock_id_in_segment_23843 * q_23815 * seghist_tblock_sizze_22661;\n        for (int64_t i_23845 = 0; i_23845 < q_23815; i_23845++) {\n            int64_t block_offset_23846 = block_base_offset_23844 + i_23845 * seghist_tblock_sizze_22661;\n            \n            subhistogram_id_23782 = global_tid_23836 + threads_per_segment_23817 * i_23845;\n            if (slt64(subhistogram_id_23782, num_subhistos_23697)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_22669 = eta_p_block_res_acc_23839;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_22670 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23698)[subhistogram_id_23782 * mz2080U_19405 + bucket_id_23781];\n                    }\n                   ",
                                    " // apply reduction operator(s)\n                    {\n                        int32_t defunc_0_op_res_22671 = add32(eta_p_22669, eta_p_22670);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_23839 = defunc_0_op_res_22671;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823)] = eta_p_block_res_acc_23839;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_23848 = 1;\n        offset_23847 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_23823, sext_i64_i32(seghist_tblock_sizze_22661))) {\n                eta_p_23840 = ((__local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823 + offset_23847)];\n            }\n        }\n        offset_23847 = 1;\n        while (slt32(offset_23847, wave_sizze_23825)) {\n            if (slt32(local_tid_23823 + offset_23847, sext_i64_i32(seghist_tblock_sizze_22661)) && ((local_tid_23823 - squot32(local_tid_23823, wave_sizze_23825) * wave_sizze_23825) & (2 * offset_23847 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_23841 = ((volatile __local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823 + offset_23847)];\n                }\n                // apply reduction operation\n                {\n                    int32_t defunc_0_op_res_23842 = add32(eta_p_23840, eta_p_23841);\n                    \n                    eta_p_23840 = defunc_0_op_res_23842;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823)] = eta_p_23840;\n            ", "    }\n            }\n            offset_23847 *= 2;\n        }\n        while (slt32(skip_waves_23848, squot32(sext_i64_i32(seghist_tblock_sizze_22661) + wave_sizze_23825 - 1, wave_sizze_23825))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23847 = skip_waves_23848 * wave_sizze_23825;\n            if (slt32(local_tid_23823 + offset_23847, sext_i64_i32(seghist_tblock_sizze_22661)) && ((local_tid_23823 - squot32(local_tid_23823, wave_sizze_23825) * wave_sizze_23825) == 0 && (squot32(local_tid_23823, wave_sizze_23825) & (2 * skip_waves_23848 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_23841 = ((__local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823 + offset_23847)];\n                }\n                // apply reduction operation\n                {\n                    int32_t defunc_0_op_res_23842 = add32(eta_p_23840, eta_p_23841);\n                    \n                    eta_p_23840 = defunc_0_op_res_23842;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823)] = eta_p_23840;\n                }\n            }\n            skip_waves_23848 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_23823) == (int64_t) 0) {\n                eta_p_block_res_acc_23839 = eta_p_23840;\n            } else {\n                eta_p_block_res_acc_23839 = 0;\n            }\n        }\n        if (blocks_per_segment_23814 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_23823 == 0) {\n                    ((__global int32_t *) mem_22827)[bucket_id_23781] = eta_p_block_res_acc_23839;\n                }\n            }\n        } else {\n            int32_t old_counter_23849;\n     ", "       bool is_last_block_23850;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_23823 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_23818)[sext_i32_i64(virt_tblock_id_23834)] = eta_p_block_res_acc_23839;\n                    mem_fence_global();\n                    old_counter_23849 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23820)[srem64(flat_segment_id_23835, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_23829)[(int64_t) 0] = old_counter_23849 == sext_i64_i32(blocks_per_segment_23814 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_23850 = ((__local bool *) sync_arr_mem_23829)[(int64_t) 0];\n            if (is_last_block_23850) {\n                if (local_tid_23823 == 0) {\n                    old_counter_23849 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23820)[srem64(flat_segment_id_23835, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_23814));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_23851 = sdiv_up64(blocks_per_segment_23814, seghist_tblock_sizze_22661);\n                    \n                    eta_p_22669 = 0;\n                    for (int64_t i_23852 = 0; i_23852 < read_per_thread_23851; i_23852++) {\n                        int64_t block_res_id_23853 = sext_i32_i64(local_tid_23823) * read_per_thread_23851 + i_23852;\n                        int64_t index_of_block_res_23854 = flat_segment_id_23835 * blocks_per_segment_23814 + block_res_id_23853;\n                        \n                        if (slt64(block_res_id_23853, blocks_per_segment_23814)) {\n                            eta_p_22670 = ((__global int32_t *) segred_tmp_mem_23818)[index_of_block_res_23854];\n                            \n ",
                                    "                           int32_t defunc_0_op_res_22671 = add32(eta_p_22669, eta_p_22670);\n                            \n                            eta_p_22669 = defunc_0_op_res_22671;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823)] = eta_p_22669;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_23855;\n                    int32_t skip_waves_23856 = 1;\n                    int32_t eta_p_23840;\n                    int32_t eta_p_23841;\n                    \n                    offset_23855 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_23823, sext_i64_i32(seghist_tblock_sizze_22661))) {\n                            eta_p_23840 = ((__local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823 + offset_23855)];\n                        }\n                    }\n                    offset_23855 = 1;\n                    while (slt32(offset_23855, wave_sizze_23825)) {\n                        if (slt32(local_tid_23823 + offset_23855, sext_i64_i32(seghist_tblock_sizze_22661)) && ((local_tid_23823 - squot32(local_tid_23823, wave_sizze_23825) * wave_sizze_23825) & (2 * offset_23855 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_23841 = ((volatile __local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823 + offset_23855)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t defunc_0_op_res_23842 = add32(eta_p_23840, eta_p_23841);\n                                \n                                eta_p_23840 = defunc_0_op_res_23842;\n                            }\n                      ", "      // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823)] = eta_p_23840;\n                            }\n                        }\n                        offset_23855 *= 2;\n                    }\n                    while (slt32(skip_waves_23856, squot32(sext_i64_i32(seghist_tblock_sizze_22661) + wave_sizze_23825 - 1, wave_sizze_23825))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_23855 = skip_waves_23856 * wave_sizze_23825;\n                        if (slt32(local_tid_23823 + offset_23855, sext_i64_i32(seghist_tblock_sizze_22661)) && ((local_tid_23823 - squot32(local_tid_23823, wave_sizze_23825) * wave_sizze_23825) == 0 && (squot32(local_tid_23823, wave_sizze_23825) & (2 * skip_waves_23856 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_23841 = ((__local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823 + offset_23855)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t defunc_0_op_res_23842 = add32(eta_p_23840, eta_p_23841);\n                                \n                                eta_p_23840 = defunc_0_op_res_23842;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_23827)[sext_i32_i64(local_tid_23823)] = eta_p_23840;\n                            }\n                        }\n                        skip_waves_23856 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_23823 == 0) {\n                            ((__globa", "l int32_t *) mem_22827)[bucket_id_23781] = eta_p_23840;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_22661\n    #undef chunk_sizze_23784\n}\nFUTHARK_KERNEL_SIZED(compilerzisegred_large_23944_dim1, 1, 1)\nvoid compilerzisegred_large_23944(__global int *global_failure, int64_t mz2080U_19405, int64_t num_tblocks_22679, int64_t num_subhistos_23858, int64_t blocks_per_segment_23975, int64_t q_23976, int64_t num_virtblocks_23977, int64_t threads_per_segment_23978, __global unsigned char *mem_22830, __global unsigned char *defunc_0_map_res_subhistos_mem_23859, __global unsigned char *segred_tmp_mem_23979, __global unsigned char *counters_mem_23981)\n{\n    #define seghist_tblock_sizze_22677 (compilerzisegred_large_23944ziseghist_tblock_sizze_22677)\n    #define chunk_sizze_23945 (compilerzisegred_large_23944zichunk_sizze_23945)\n    \n    volatile __local unsigned char *sync_arr_mem_23990_backing_1 = &shared_mem[0];\n    const int64_t sync_arr_mem_23990_backing_1_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_23988_backing_0 = &shared_mem[sync_arr_mem_23990_backing_1_offset];\n    const int64_t red_arr_i32_mem_23988_backing_0_offset = sync_arr_mem_23990_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22677 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22677, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23984;\n    int32_t tblock_sizze_23987;\n    int32_t wave_sizze_23986;\n    int32_t block_id_23985;\n    int32_t global_tid_23983;\n    int64_t flat_gtid_23944;\n    __local unsigned char *red_arr_i32_mem_23988;\n    __local unsigned char *sync_arr_mem_23990;\n    int32_t phys_tblock_id_23992;\n    int32_t iterations_23993;\n    \n    local_tid_23984 = get_local_id(0);\n    tblock_sizze_23987 = get_local_size(0);\n    wave",
                                    "_sizze_23986 = LOCKSTEP_WIDTH;\n    block_id_23985 = get_tblock_id(0);\n    global_tid_23983 = block_id_23985 * tblock_sizze_23987 + local_tid_23984;\n    flat_gtid_23944 = sext_i32_i64(global_tid_23983);\n    red_arr_i32_mem_23988 = (__local unsigned char *) red_arr_i32_mem_23988_backing_0;\n    sync_arr_mem_23990 = (__local unsigned char *) sync_arr_mem_23990_backing_1;\n    phys_tblock_id_23992 = get_tblock_id(0);\n    iterations_23993 = sdiv_up32(sext_i64_i32(num_virtblocks_23977) - phys_tblock_id_23992, sext_i64_i32(num_tblocks_22679));\n    for (int32_t i_23994 = 0; i_23994 < iterations_23993; i_23994++) {\n        int32_t virt_tblock_id_23995;\n        int64_t flat_segment_id_23996;\n        int64_t global_tid_23997;\n        int64_t slice_23998;\n        int64_t bucket_id_23942;\n        int64_t remnant_23999;\n        int64_t subhistogram_id_23943;\n        int32_t eta_p_block_res_acc_24000;\n        int32_t eta_p_22685;\n        int32_t eta_p_22686;\n        int64_t tblock_id_in_segment_24004;\n        int64_t block_base_offset_24005;\n        int32_t offset_24008;\n        int32_t skip_waves_24009;\n        int32_t eta_p_24001;\n        int32_t eta_p_24002;\n        \n        virt_tblock_id_23995 = phys_tblock_id_23992 + i_23994 * sext_i64_i32(num_tblocks_22679);\n        flat_segment_id_23996 = squot64(sext_i32_i64(virt_tblock_id_23995), blocks_per_segment_23975);\n        global_tid_23997 = srem64(sext_i32_i64(virt_tblock_id_23995) * seghist_tblock_sizze_22677 + sext_i32_i64(local_tid_23984), threads_per_segment_23978);\n        slice_23998 = mz2080U_19405;\n        bucket_id_23942 = flat_segment_id_23996;\n        remnant_23999 = flat_segment_id_23996 - bucket_id_23942;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_24000 = 0;\n        }\n        tblock_id_in_segment_24004 = squot64(global_tid_23997, seghist_tblock_sizze_22677);\n        block_base_offset_24005 = tblock_id_in_segment_24004 * q_23976 * seghist_tblock_sizze_22677;\n", "        for (int64_t i_24006 = 0; i_24006 < q_23976; i_24006++) {\n            int64_t block_offset_24007 = block_base_offset_24005 + i_24006 * seghist_tblock_sizze_22677;\n            \n            subhistogram_id_23943 = global_tid_23997 + threads_per_segment_23978 * i_24006;\n            if (slt64(subhistogram_id_23943, num_subhistos_23858)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_22685 = eta_p_block_res_acc_24000;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_22686 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23859)[subhistogram_id_23943 * mz2080U_19405 + bucket_id_23942];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t defunc_0_op_res_22687 = add32(eta_p_22685, eta_p_22686);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_24000 = defunc_0_op_res_22687;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984)] = eta_p_block_res_acc_24000;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_24009 = 1;\n        offset_24008 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_23984, sext_i64_i32(seghist_tblock_sizze_22677))) {\n                eta_p_24001 = ((__local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984 + offset_24008)];\n            }\n        }\n        offset_24008 = 1;\n        while (slt32(offset_24008, wave_sizze_23986)) {\n            if (slt32(local_tid_23984 + offse", "t_24008, sext_i64_i32(seghist_tblock_sizze_22677)) && ((local_tid_23984 - squot32(local_tid_23984, wave_sizze_23986) * wave_sizze_23986) & (2 * offset_24008 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_24002 = ((volatile __local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984 + offset_24008)];\n                }\n                // apply reduction operation\n                {\n                    int32_t defunc_0_op_res_24003 = add32(eta_p_24001, eta_p_24002);\n                    \n                    eta_p_24001 = defunc_0_op_res_24003;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984)] = eta_p_24001;\n                }\n            }\n            offset_24008 *= 2;\n        }\n        while (slt32(skip_waves_24009, squot32(sext_i64_i32(seghist_tblock_sizze_22677) + wave_sizze_23986 - 1, wave_sizze_23986))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_24008 = skip_waves_24009 * wave_sizze_23986;\n            if (slt32(local_tid_23984 + offset_24008, sext_i64_i32(seghist_tblock_sizze_22677)) && ((local_tid_23984 - squot32(local_tid_23984, wave_sizze_23986) * wave_sizze_23986) == 0 && (squot32(local_tid_23984, wave_sizze_23986) & (2 * skip_waves_24009 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_24002 = ((__local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984 + offset_24008)];\n                }\n                // apply reduction operation\n                {\n                    int32_t defunc_0_op_res_24003 = add32(eta_p_24001, eta_p_24002);\n                    \n                    eta_p_24001 = defunc_0_op_res_24003;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984)] = eta_p_",
                                    "24001;\n                }\n            }\n            skip_waves_24009 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_23984) == (int64_t) 0) {\n                eta_p_block_res_acc_24000 = eta_p_24001;\n            } else {\n                eta_p_block_res_acc_24000 = 0;\n            }\n        }\n        if (blocks_per_segment_23975 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_23984 == 0) {\n                    ((__global int32_t *) mem_22830)[bucket_id_23942] = eta_p_block_res_acc_24000;\n                }\n            }\n        } else {\n            int32_t old_counter_24010;\n            bool is_last_block_24011;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_23984 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_23979)[sext_i32_i64(virt_tblock_id_23995)] = eta_p_block_res_acc_24000;\n                    mem_fence_global();\n                    old_counter_24010 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23981)[srem64(flat_segment_id_23996, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_23990)[(int64_t) 0] = old_counter_24010 == sext_i64_i32(blocks_per_segment_23975 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_24011 = ((__local bool *) sync_arr_mem_23990)[(int64_t) 0];\n            if (is_last_block_24011) {\n                if (local_tid_23984 == 0) {\n                    old_counter_24010 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23981)[srem64(flat_segment_id_23996, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_23975));\n                }\n                ", "// read in the per-block-results\n                {\n                    int64_t read_per_thread_24012 = sdiv_up64(blocks_per_segment_23975, seghist_tblock_sizze_22677);\n                    \n                    eta_p_22685 = 0;\n                    for (int64_t i_24013 = 0; i_24013 < read_per_thread_24012; i_24013++) {\n                        int64_t block_res_id_24014 = sext_i32_i64(local_tid_23984) * read_per_thread_24012 + i_24013;\n                        int64_t index_of_block_res_24015 = flat_segment_id_23996 * blocks_per_segment_23975 + block_res_id_24014;\n                        \n                        if (slt64(block_res_id_24014, blocks_per_segment_23975)) {\n                            eta_p_22686 = ((__global int32_t *) segred_tmp_mem_23979)[index_of_block_res_24015];\n                            \n                            int32_t defunc_0_op_res_22687 = add32(eta_p_22685, eta_p_22686);\n                            \n                            eta_p_22685 = defunc_0_op_res_22687;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984)] = eta_p_22685;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_24016;\n                    int32_t skip_waves_24017 = 1;\n                    int32_t eta_p_24001;\n                    int32_t eta_p_24002;\n                    \n                    offset_24016 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_23984, sext_i64_i32(seghist_tblock_sizze_22677))) {\n                            eta_p_24001 = ((__local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984 + offset_24016)];\n                        }\n                    }\n                    offset_24016 = 1;\n                    while (slt32(offset_24016, wave_sizze_23986)) {\n     ", "                   if (slt32(local_tid_23984 + offset_24016, sext_i64_i32(seghist_tblock_sizze_22677)) && ((local_tid_23984 - squot32(local_tid_23984, wave_sizze_23986) * wave_sizze_23986) & (2 * offset_24016 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_24002 = ((volatile __local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984 + offset_24016)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t defunc_0_op_res_24003 = add32(eta_p_24001, eta_p_24002);\n                                \n                                eta_p_24001 = defunc_0_op_res_24003;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984)] = eta_p_24001;\n                            }\n                        }\n                        offset_24016 *= 2;\n                    }\n                    while (slt32(skip_waves_24017, squot32(sext_i64_i32(seghist_tblock_sizze_22677) + wave_sizze_23986 - 1, wave_sizze_23986))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_24016 = skip_waves_24017 * wave_sizze_23986;\n                        if (slt32(local_tid_23984 + offset_24016, sext_i64_i32(seghist_tblock_sizze_22677)) && ((local_tid_23984 - squot32(local_tid_23984, wave_sizze_23986) * wave_sizze_23986) == 0 && (squot32(local_tid_23984, wave_sizze_23986) & (2 * skip_waves_24017 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_24002 = ((__local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984 + offset_24016)];\n                            }\n                            // apply reduction operation\n ",
                                    "                           {\n                                int32_t defunc_0_op_res_24003 = add32(eta_p_24001, eta_p_24002);\n                                \n                                eta_p_24001 = defunc_0_op_res_24003;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_23988)[sext_i32_i64(local_tid_23984)] = eta_p_24001;\n                            }\n                        }\n                        skip_waves_24017 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_23984 == 0) {\n                            ((__global int32_t *) mem_22830)[bucket_id_23942] = eta_p_24001;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_22677\n    #undef chunk_sizze_23945\n}\nFUTHARK_KERNEL_SIZED(compilerzisegred_small_23622_dim1, 1, 1)\nvoid compilerzisegred_small_23622(__global int *global_failure, int64_t mz2080U_19405, int64_t num_tblocks_22647, int64_t num_subhistos_23536, int64_t segment_sizze_nonzzero_23624, __global unsigned char *mem_22824, __global unsigned char *defunc_0_map_res_subhistos_mem_23537)\n{\n    #define seghist_tblock_sizze_22645 (compilerzisegred_small_23622ziseghist_tblock_sizze_22645)\n    \n    volatile __local unsigned char *red_arr_i32_mem_23631_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_23631_backing_0_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_22645 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22645, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23627;\n    int32_t tblock_sizze_23630;\n    int32_t wave_si", "zze_23629;\n    int32_t block_id_23628;\n    int32_t global_tid_23626;\n    int64_t flat_gtid_23622;\n    __local unsigned char *red_arr_i32_mem_23631;\n    int32_t phys_tblock_id_23633;\n    int32_t iterations_23634;\n    \n    local_tid_23627 = get_local_id(0);\n    tblock_sizze_23630 = get_local_size(0);\n    wave_sizze_23629 = LOCKSTEP_WIDTH;\n    block_id_23628 = get_tblock_id(0);\n    global_tid_23626 = block_id_23628 * tblock_sizze_23630 + local_tid_23627;\n    flat_gtid_23622 = sext_i32_i64(global_tid_23626);\n    red_arr_i32_mem_23631 = (__local unsigned char *) red_arr_i32_mem_23631_backing_0;\n    phys_tblock_id_23633 = get_tblock_id(0);\n    iterations_23634 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_19405, squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624))) - phys_tblock_id_23633, sext_i64_i32(num_tblocks_22647));\n    for (int32_t i_23635 = 0; i_23635 < iterations_23634; i_23635++) {\n        int32_t virt_tblock_id_23636;\n        int64_t slice_23637;\n        int64_t bucket_id_23620;\n        int64_t remnant_23638;\n        int64_t subhistogram_id_23621;\n        \n        virt_tblock_id_23636 = phys_tblock_id_23633 + i_23635 * sext_i64_i32(num_tblocks_22647);\n        slice_23637 = mz2080U_19405;\n        bucket_id_23620 = squot64(sext_i32_i64(local_tid_23627), segment_sizze_nonzzero_23624) + sext_i32_i64(virt_tblock_id_23636) * squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624);\n        remnant_23638 = squot64(sext_i32_i64(local_tid_23627), segment_sizze_nonzzero_23624) + sext_i32_i64(virt_tblock_id_23636) * squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624) - bucket_id_23620;\n        subhistogram_id_23621 = srem64(sext_i32_i64(local_tid_23627), num_subhistos_23536);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_23536) && (slt64(bucket_id_23620, mz2080U_19405) && slt64(sext_i32_i64(local_tid_23627), num_subhistos_23536 * squot64(seghist_tblock_sizze_22645, segment_sizze_nonz", "zero_23624)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_23639 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23537)[subhistogram_id_23621 * mz2080U_19405 + bucket_id_23620];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627)] = tmp_23639;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_23536)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_22653;\n                int32_t eta_p_22654;\n                int32_t eta_p_23640;\n                int32_t eta_p_23641;\n                bool ltid_in_bounds_23643 = slt64(sext_i32_i64(local_tid_23627), num_subhistos_23536 * squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624));\n                int32_t skip_threads_23644;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_23643) {\n                        eta_p_22654 = ((volatile __local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627)];\n                        if ((local_tid_23627 - squot32(local_tid_23627, 32) * 32) == 0) {\n                            eta_p_22653 = eta_p_22654;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23644 = 1;\n                    while (slt32(skip_threads_23644, 32)) {\n                        bool thread_active_23645 = sle32(skip_threads_23644, local_tid_23627 - squot32(local_tid_23627, 32) * 32) && ltid_in_bounds_23643;\n                        \n                        if (thread_active_23645) {\n                            // read operands\n                 ",
                                    "           {\n                                eta_p_22653 = ((volatile __local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627) - sext_i32_i64(skip_threads_23644)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_23646 = slt64(srem64(sext_i32_i64(local_tid_23627), num_subhistos_23536), sext_i32_i64(local_tid_23627) - sext_i32_i64(local_tid_23627 - skip_threads_23644));\n                            \n                            if (thread_active_23645 && inactive_23646) {\n                                eta_p_22653 = eta_p_22654;\n                            }\n                            if (thread_active_23645) {\n                                if (!inactive_23646) {\n                                    int32_t defunc_0_op_res_22655 = add32(eta_p_22653, eta_p_22654);\n                                    \n                                    eta_p_22653 = defunc_0_op_res_22655;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_23629, skip_threads_23644)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23645) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627)] = eta_p_22653;\n                                eta_p_22654 = eta_p_22653;\n                            }\n                        }\n                        if (sle32(wave_sizze_23629, skip_threads_23644)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23644 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to of", "fset 'i'\n                {\n                    if ((local_tid_23627 - squot32(local_tid_23627, 32) * 32) == 31 && ltid_in_bounds_23643) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(squot32(local_tid_23627, 32))] = eta_p_22653;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_23647;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_23627, 32) == 0 && ltid_in_bounds_23643) {\n                            eta_p_23641 = ((volatile __local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627)];\n                            if ((local_tid_23627 - squot32(local_tid_23627, 32) * 32) == 0) {\n                                eta_p_23640 = eta_p_23641;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_23647 = 1;\n                        while (slt32(skip_threads_23647, 32)) {\n                            bool thread_active_23648 = sle32(skip_threads_23647, local_tid_23627 - squot32(local_tid_23627, 32) * 32) && (squot32(local_tid_23627, 32) == 0 && ltid_in_bounds_23643);\n                            \n                            if (thread_active_23648) {\n                                // read operands\n                                {\n                                    eta_p_23640 = ((volatile __local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627) - sext_i32_i64(skip_threads_23647)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_23649 = ", "slt64(srem64(sext_i32_i64(local_tid_23627 * 32 + 32 - 1), num_subhistos_23536), sext_i32_i64(local_tid_23627 * 32 + 32 - 1) - sext_i32_i64((local_tid_23627 - skip_threads_23647) * 32 + 32 - 1));\n                                \n                                if (thread_active_23648 && inactive_23649) {\n                                    eta_p_23640 = eta_p_23641;\n                                }\n                                if (thread_active_23648) {\n                                    if (!inactive_23649) {\n                                        int32_t defunc_0_op_res_23642 = add32(eta_p_23640, eta_p_23641);\n                                        \n                                        eta_p_23640 = defunc_0_op_res_23642;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_23629, skip_threads_23647)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_23648) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627)] = eta_p_23640;\n                                    eta_p_23641 = eta_p_23640;\n                                }\n                            }\n                            if (sle32(wave_sizze_23629, skip_threads_23647)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_23647 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_23650 = squot32(local_tid_23627, 32) == 0 || !ltid_in_bounds_23643;\n                \n                // carry-in for every block except the first\n                {\n                    // read operand",
                                    "s\n                    {\n                        if (!no_carry_in_23650) {\n                            eta_p_22654 = eta_p_22653;\n                            eta_p_22653 = ((__local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(squot32(local_tid_23627, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_23651 = slt64(srem64(sext_i32_i64(local_tid_23627), num_subhistos_23536), sext_i32_i64(local_tid_23627) - sext_i32_i64(squot32(local_tid_23627, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_23650) {\n                            if (inactive_23651) {\n                                eta_p_22653 = eta_p_22654;\n                            }\n                        }\n                        if (!no_carry_in_23650) {\n                            if (!inactive_23651) {\n                                int32_t defunc_0_op_res_22655 = add32(eta_p_22653, eta_p_22654);\n                                \n                                eta_p_22653 = defunc_0_op_res_22655;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_23650) {\n                            ((__local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627)] = eta_p_22653;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_23627, 32) == 0 && ltid_in_bounds_23643) {\n                        ((__local int32_t *) red_arr_i32_mem_23631)[sext_i32_i64(local_tid_23627)] = eta_p_22654;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of ", "segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_23636) * squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624) + sext_i32_i64(local_tid_23627), mz2080U_19405) && slt64(sext_i32_i64(local_tid_23627), squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624))) {\n                int32_t tmp_23652 = ((__local int32_t *) red_arr_i32_mem_23631)[(sext_i32_i64(local_tid_23627) + (int64_t) 1) * segment_sizze_nonzzero_23624 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_22824)[sext_i32_i64(virt_tblock_id_23636) * squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624) + sext_i32_i64(local_tid_23627)] = tmp_23652;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_22645\n}\nFUTHARK_KERNEL_SIZED(compilerzisegred_small_23783_dim1, 1, 1)\nvoid compilerzisegred_small_23783(__global int *global_failure, int64_t mz2080U_19405, int64_t num_tblocks_22663, int64_t num_subhistos_23697, int64_t segment_sizze_nonzzero_23785, __global unsigned char *mem_22827, __global unsigned char *defunc_0_map_res_subhistos_mem_23698)\n{\n    #define seghist_tblock_sizze_22661 (compilerzisegred_small_23783ziseghist_tblock_sizze_22661)\n    \n    volatile __local unsigned char *red_arr_i32_mem_23792_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_23792_backing_0_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_22661 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22661, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23788;\n    int32_t tblock_sizze_23791;\n    int32_t wave_sizze_23790;\n    int32_t block_id_23789;\n    int32_t global_tid_23787;\n    int64_t flat_gtid_23783;\n    __local unsigned char *red_arr_i32_mem_23792;\n    int32_t phys_tblock_id_23794;\n    int32_t iterations_23795;\n    \n    local_tid_23788 = g", "et_local_id(0);\n    tblock_sizze_23791 = get_local_size(0);\n    wave_sizze_23790 = LOCKSTEP_WIDTH;\n    block_id_23789 = get_tblock_id(0);\n    global_tid_23787 = block_id_23789 * tblock_sizze_23791 + local_tid_23788;\n    flat_gtid_23783 = sext_i32_i64(global_tid_23787);\n    red_arr_i32_mem_23792 = (__local unsigned char *) red_arr_i32_mem_23792_backing_0;\n    phys_tblock_id_23794 = get_tblock_id(0);\n    iterations_23795 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_19405, squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785))) - phys_tblock_id_23794, sext_i64_i32(num_tblocks_22663));\n    for (int32_t i_23796 = 0; i_23796 < iterations_23795; i_23796++) {\n        int32_t virt_tblock_id_23797;\n        int64_t slice_23798;\n        int64_t bucket_id_23781;\n        int64_t remnant_23799;\n        int64_t subhistogram_id_23782;\n        \n        virt_tblock_id_23797 = phys_tblock_id_23794 + i_23796 * sext_i64_i32(num_tblocks_22663);\n        slice_23798 = mz2080U_19405;\n        bucket_id_23781 = squot64(sext_i32_i64(local_tid_23788), segment_sizze_nonzzero_23785) + sext_i32_i64(virt_tblock_id_23797) * squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785);\n        remnant_23799 = squot64(sext_i32_i64(local_tid_23788), segment_sizze_nonzzero_23785) + sext_i32_i64(virt_tblock_id_23797) * squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785) - bucket_id_23781;\n        subhistogram_id_23782 = srem64(sext_i32_i64(local_tid_23788), num_subhistos_23697);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_23697) && (slt64(bucket_id_23781, mz2080U_19405) && slt64(sext_i32_i64(local_tid_23788), num_subhistos_23697 * squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_23800 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23698)[subhistogram_id_23782 * mz2080U_19405 + bucket_id_23781];\n ",
                                    "                   \n                    ((__local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788)] = tmp_23800;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_23697)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_22669;\n                int32_t eta_p_22670;\n                int32_t eta_p_23801;\n                int32_t eta_p_23802;\n                bool ltid_in_bounds_23804 = slt64(sext_i32_i64(local_tid_23788), num_subhistos_23697 * squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785));\n                int32_t skip_threads_23805;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_23804) {\n                        eta_p_22670 = ((volatile __local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788)];\n                        if ((local_tid_23788 - squot32(local_tid_23788, 32) * 32) == 0) {\n                            eta_p_22669 = eta_p_22670;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23805 = 1;\n                    while (slt32(skip_threads_23805, 32)) {\n                        bool thread_active_23806 = sle32(skip_threads_23805, local_tid_23788 - squot32(local_tid_23788, 32) * 32) && ltid_in_bounds_23804;\n                        \n                        if (thread_active_23806) {\n                            // read operands\n                            {\n                                eta_p_22669 = ((volatile __local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788) - sext_i32_i64(skip_threads_23805)];\n                            }\n                        }\n     ", "                   // perform operation\n                        {\n                            bool inactive_23807 = slt64(srem64(sext_i32_i64(local_tid_23788), num_subhistos_23697), sext_i32_i64(local_tid_23788) - sext_i32_i64(local_tid_23788 - skip_threads_23805));\n                            \n                            if (thread_active_23806 && inactive_23807) {\n                                eta_p_22669 = eta_p_22670;\n                            }\n                            if (thread_active_23806) {\n                                if (!inactive_23807) {\n                                    int32_t defunc_0_op_res_22671 = add32(eta_p_22669, eta_p_22670);\n                                    \n                                    eta_p_22669 = defunc_0_op_res_22671;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_23790, skip_threads_23805)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23806) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788)] = eta_p_22669;\n                                eta_p_22670 = eta_p_22669;\n                            }\n                        }\n                        if (sle32(wave_sizze_23790, skip_threads_23805)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23805 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_23788 - squot32(local_tid_23788, 32) * 32) == 31 && ltid_in_bounds_23804) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(squot32(loca", "l_tid_23788, 32))] = eta_p_22669;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_23808;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_23788, 32) == 0 && ltid_in_bounds_23804) {\n                            eta_p_23802 = ((volatile __local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788)];\n                            if ((local_tid_23788 - squot32(local_tid_23788, 32) * 32) == 0) {\n                                eta_p_23801 = eta_p_23802;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_23808 = 1;\n                        while (slt32(skip_threads_23808, 32)) {\n                            bool thread_active_23809 = sle32(skip_threads_23808, local_tid_23788 - squot32(local_tid_23788, 32) * 32) && (squot32(local_tid_23788, 32) == 0 && ltid_in_bounds_23804);\n                            \n                            if (thread_active_23809) {\n                                // read operands\n                                {\n                                    eta_p_23801 = ((volatile __local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788) - sext_i32_i64(skip_threads_23808)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_23810 = slt64(srem64(sext_i32_i64(local_tid_23788 * 32 + 32 - 1), num_subhistos_23697), sext_i32_i64(local_tid_23788 * 32 + 32 - 1) - sext_i32_i64((local_tid_23788 - skip_threads_23808) * 32 + 32 - 1));\n                                \n            ",
                                    "                    if (thread_active_23809 && inactive_23810) {\n                                    eta_p_23801 = eta_p_23802;\n                                }\n                                if (thread_active_23809) {\n                                    if (!inactive_23810) {\n                                        int32_t defunc_0_op_res_23803 = add32(eta_p_23801, eta_p_23802);\n                                        \n                                        eta_p_23801 = defunc_0_op_res_23803;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_23790, skip_threads_23808)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_23809) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788)] = eta_p_23801;\n                                    eta_p_23802 = eta_p_23801;\n                                }\n                            }\n                            if (sle32(wave_sizze_23790, skip_threads_23808)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_23808 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_23811 = squot32(local_tid_23788, 32) == 0 || !ltid_in_bounds_23804;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_23811) {\n                            eta_p_22670 = eta_p_22669;\n                            eta_p_22669 = ((__local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(squot32(loca", "l_tid_23788, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_23812 = slt64(srem64(sext_i32_i64(local_tid_23788), num_subhistos_23697), sext_i32_i64(local_tid_23788) - sext_i32_i64(squot32(local_tid_23788, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_23811) {\n                            if (inactive_23812) {\n                                eta_p_22669 = eta_p_22670;\n                            }\n                        }\n                        if (!no_carry_in_23811) {\n                            if (!inactive_23812) {\n                                int32_t defunc_0_op_res_22671 = add32(eta_p_22669, eta_p_22670);\n                                \n                                eta_p_22669 = defunc_0_op_res_22671;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_23811) {\n                            ((__local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788)] = eta_p_22669;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_23788, 32) == 0 && ltid_in_bounds_23804) {\n                        ((__local int32_t *) red_arr_i32_mem_23792)[sext_i32_i64(local_tid_23788)] = eta_p_22670;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_23797) * squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785) + sext_i32_i64(local_tid_23788), mz2080U_19405) && slt64(sext_i32_i64(local_tid_23788), squot64(", "seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785))) {\n                int32_t tmp_23813 = ((__local int32_t *) red_arr_i32_mem_23792)[(sext_i32_i64(local_tid_23788) + (int64_t) 1) * segment_sizze_nonzzero_23785 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_22827)[sext_i32_i64(virt_tblock_id_23797) * squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785) + sext_i32_i64(local_tid_23788)] = tmp_23813;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_22661\n}\nFUTHARK_KERNEL_SIZED(compilerzisegred_small_23944_dim1, 1, 1)\nvoid compilerzisegred_small_23944(__global int *global_failure, int64_t mz2080U_19405, int64_t num_tblocks_22679, int64_t num_subhistos_23858, int64_t segment_sizze_nonzzero_23946, __global unsigned char *mem_22830, __global unsigned char *defunc_0_map_res_subhistos_mem_23859)\n{\n    #define seghist_tblock_sizze_22677 (compilerzisegred_small_23944ziseghist_tblock_sizze_22677)\n    \n    volatile __local unsigned char *red_arr_i32_mem_23953_backing_0 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_23953_backing_0_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_22677 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22677, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23949;\n    int32_t tblock_sizze_23952;\n    int32_t wave_sizze_23951;\n    int32_t block_id_23950;\n    int32_t global_tid_23948;\n    int64_t flat_gtid_23944;\n    __local unsigned char *red_arr_i32_mem_23953;\n    int32_t phys_tblock_id_23955;\n    int32_t iterations_23956;\n    \n    local_tid_23949 = get_local_id(0);\n    tblock_sizze_23952 = get_local_size(0);\n    wave_sizze_23951 = LOCKSTEP_WIDTH;\n    block_id_23950 = get_tblock_id(0);\n    global_tid_23948 = block_id_23950 * tblock_sizze_23952 + local_tid_23949;\n    flat_gtid_23944 = se",
                                    "xt_i32_i64(global_tid_23948);\n    red_arr_i32_mem_23953 = (__local unsigned char *) red_arr_i32_mem_23953_backing_0;\n    phys_tblock_id_23955 = get_tblock_id(0);\n    iterations_23956 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_19405, squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946))) - phys_tblock_id_23955, sext_i64_i32(num_tblocks_22679));\n    for (int32_t i_23957 = 0; i_23957 < iterations_23956; i_23957++) {\n        int32_t virt_tblock_id_23958;\n        int64_t slice_23959;\n        int64_t bucket_id_23942;\n        int64_t remnant_23960;\n        int64_t subhistogram_id_23943;\n        \n        virt_tblock_id_23958 = phys_tblock_id_23955 + i_23957 * sext_i64_i32(num_tblocks_22679);\n        slice_23959 = mz2080U_19405;\n        bucket_id_23942 = squot64(sext_i32_i64(local_tid_23949), segment_sizze_nonzzero_23946) + sext_i32_i64(virt_tblock_id_23958) * squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946);\n        remnant_23960 = squot64(sext_i32_i64(local_tid_23949), segment_sizze_nonzzero_23946) + sext_i32_i64(virt_tblock_id_23958) * squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946) - bucket_id_23942;\n        subhistogram_id_23943 = srem64(sext_i32_i64(local_tid_23949), num_subhistos_23858);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_23858) && (slt64(bucket_id_23942, mz2080U_19405) && slt64(sext_i32_i64(local_tid_23949), num_subhistos_23858 * squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_23961 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23859)[subhistogram_id_23943 * mz2080U_19405 + bucket_id_23942];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949)] = tmp_23961;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(", "local_tid_23949)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_23858)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_22685;\n                int32_t eta_p_22686;\n                int32_t eta_p_23962;\n                int32_t eta_p_23963;\n                bool ltid_in_bounds_23965 = slt64(sext_i32_i64(local_tid_23949), num_subhistos_23858 * squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946));\n                int32_t skip_threads_23966;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_23965) {\n                        eta_p_22686 = ((volatile __local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949)];\n                        if ((local_tid_23949 - squot32(local_tid_23949, 32) * 32) == 0) {\n                            eta_p_22685 = eta_p_22686;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23966 = 1;\n                    while (slt32(skip_threads_23966, 32)) {\n                        bool thread_active_23967 = sle32(skip_threads_23966, local_tid_23949 - squot32(local_tid_23949, 32) * 32) && ltid_in_bounds_23965;\n                        \n                        if (thread_active_23967) {\n                            // read operands\n                            {\n                                eta_p_22685 = ((volatile __local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949) - sext_i32_i64(skip_threads_23966)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_23968 = slt64(srem64(sext_i32_i64(local_tid_23949), num_subhistos_23858), sext_i32_i64(local_tid_23949) - sext_i32_i64(local_tid_239", "49 - skip_threads_23966));\n                            \n                            if (thread_active_23967 && inactive_23968) {\n                                eta_p_22685 = eta_p_22686;\n                            }\n                            if (thread_active_23967) {\n                                if (!inactive_23968) {\n                                    int32_t defunc_0_op_res_22687 = add32(eta_p_22685, eta_p_22686);\n                                    \n                                    eta_p_22685 = defunc_0_op_res_22687;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_23951, skip_threads_23966)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23967) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949)] = eta_p_22685;\n                                eta_p_22686 = eta_p_22685;\n                            }\n                        }\n                        if (sle32(wave_sizze_23951, skip_threads_23966)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23966 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_23949 - squot32(local_tid_23949, 32) * 32) == 31 && ltid_in_bounds_23965) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(squot32(local_tid_23949, 32))] = eta_p_22685;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n    ",
                                    "                int32_t skip_threads_23969;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_23949, 32) == 0 && ltid_in_bounds_23965) {\n                            eta_p_23963 = ((volatile __local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949)];\n                            if ((local_tid_23949 - squot32(local_tid_23949, 32) * 32) == 0) {\n                                eta_p_23962 = eta_p_23963;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_23969 = 1;\n                        while (slt32(skip_threads_23969, 32)) {\n                            bool thread_active_23970 = sle32(skip_threads_23969, local_tid_23949 - squot32(local_tid_23949, 32) * 32) && (squot32(local_tid_23949, 32) == 0 && ltid_in_bounds_23965);\n                            \n                            if (thread_active_23970) {\n                                // read operands\n                                {\n                                    eta_p_23962 = ((volatile __local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949) - sext_i32_i64(skip_threads_23969)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_23971 = slt64(srem64(sext_i32_i64(local_tid_23949 * 32 + 32 - 1), num_subhistos_23858), sext_i32_i64(local_tid_23949 * 32 + 32 - 1) - sext_i32_i64((local_tid_23949 - skip_threads_23969) * 32 + 32 - 1));\n                                \n                                if (thread_active_23970 && inactive_23971) {\n                                    eta_p_23962 = eta_p_23963;\n                                }\n                                if (thread_active_23970) {\n                   ", "                 if (!inactive_23971) {\n                                        int32_t defunc_0_op_res_23964 = add32(eta_p_23962, eta_p_23963);\n                                        \n                                        eta_p_23962 = defunc_0_op_res_23964;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_23951, skip_threads_23969)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_23970) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949)] = eta_p_23962;\n                                    eta_p_23963 = eta_p_23962;\n                                }\n                            }\n                            if (sle32(wave_sizze_23951, skip_threads_23969)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_23969 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_23972 = squot32(local_tid_23949, 32) == 0 || !ltid_in_bounds_23965;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_23972) {\n                            eta_p_22686 = eta_p_22685;\n                            eta_p_22685 = ((__local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(squot32(local_tid_23949, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_23973 = slt64(srem64(sext_i32_i64(local_tid_23949), num_s", "ubhistos_23858), sext_i32_i64(local_tid_23949) - sext_i32_i64(squot32(local_tid_23949, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_23972) {\n                            if (inactive_23973) {\n                                eta_p_22685 = eta_p_22686;\n                            }\n                        }\n                        if (!no_carry_in_23972) {\n                            if (!inactive_23973) {\n                                int32_t defunc_0_op_res_22687 = add32(eta_p_22685, eta_p_22686);\n                                \n                                eta_p_22685 = defunc_0_op_res_22687;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_23972) {\n                            ((__local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949)] = eta_p_22685;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_23949, 32) == 0 && ltid_in_bounds_23965) {\n                        ((__local int32_t *) red_arr_i32_mem_23953)[sext_i32_i64(local_tid_23949)] = eta_p_22686;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_23958) * squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946) + sext_i32_i64(local_tid_23949), mz2080U_19405) && slt64(sext_i32_i64(local_tid_23949), squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946))) {\n                int32_t tmp_23974 = ((__local int32_t *) red_arr_i32_mem_23953)[(sext_i32_i64(local_tid_23949) + (int64_t) 1) * segment_sizze_nonzzero_23946 - (int64_t) 1];\n     ",
                                    "           \n                ((__global int32_t *) mem_22830)[sext_i32_i64(virt_tblock_id_23958) * squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946) + sext_i32_i64(local_tid_23949)] = tmp_23974;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_22677\n}\nFUTHARK_KERNEL_SIZED(compilerzisegscan_22546_dim1, 1, 1)\nvoid compilerzisegscan_22546(__global int *global_failure, int64_t mz2080U_19405, int64_t num_tblocks_22543, int64_t num_virt_blocks_22911, int64_t num_virt_threads_22912, __global unsigned char *shp_mem_22767, __global unsigned char *mem_22773, __global unsigned char *status_flags_mem_22913, __global unsigned char *aggregates_mem_22935, __global unsigned char *incprefixes_mem_22937, __global unsigned char *global_dynid_mem_22939)\n{\n    #define segscan_tblock_sizze_22541 (compilerzisegscan_22546zisegscan_tblock_sizze_22541)\n    #define chunk_sizze_22910 (compilerzisegscan_22546zichunk_sizze_22910)\n    \n    volatile __local unsigned char *local_mem_22969_backing_0 = &shared_mem[0];\n    const int64_t local_mem_22969_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22541), chunk_sizze_22910 * segscan_tblock_sizze_22541 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22541), chunk_sizze_22910 * segscan_tblock_sizze_22541 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22962;\n    int32_t tblock_sizze_22965;\n    int32_t wave_sizze_22964;\n    int32_t block_id_22963;\n    int32_t global_tid_22961;\n    int64_t phys_tid_22546;\n    int32_t chunk_sizze_32b_22966;\n    int64_t byte_offsets_22967;\n    int64_t warp_byte_offset_22968;\n    __local unsigned char *local_mem_22969;\n    int64_t trans_arr_len_22970;\n    int64_t phys_block_id_22976;\n    int64_t vi", "rtloop_bound_22977;\n    \n    local_tid_22962 = get_local_id(0);\n    tblock_sizze_22965 = get_local_size(0);\n    wave_sizze_22964 = LOCKSTEP_WIDTH;\n    block_id_22963 = get_tblock_id(0);\n    global_tid_22961 = block_id_22963 * tblock_sizze_22965 + local_tid_22962;\n    phys_tid_22546 = sext_i32_i64(global_tid_22961);\n    chunk_sizze_32b_22966 = sext_i64_i32(chunk_sizze_22910);\n    byte_offsets_22967 = segscan_tblock_sizze_22541 * (int64_t) 8;\n    warp_byte_offset_22968 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_22969 = (__local unsigned char *) local_mem_22969_backing_0;\n    trans_arr_len_22970 = chunk_sizze_22910 * segscan_tblock_sizze_22541;\n    phys_block_id_22976 = get_tblock_id(0);\n    virtloop_bound_22977 = sdiv_up64(num_virt_blocks_22911 - phys_block_id_22976, num_tblocks_22543);\n    for (int64_t virtloop_i_22978 = 0; virtloop_i_22978 < virtloop_bound_22977; virtloop_i_22978++) {\n        int64_t dynamic_id_22979;\n        int64_t block_offset_22980;\n        int64_t sgm_idx_22981;\n        int32_t boundary_22982;\n        int32_t segsizze_compact_22983;\n        int64_t private_mem_22984[chunk_sizze_22910];\n        int64_t thd_offset_22986;\n        int64_t acc_23002;\n        int64_t prefix_23012;\n        bool block_new_sgm_23013;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_22962 == 0) {\n                dynamic_id_22979 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_22939)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_22969)[(int64_t) 0] = dynamic_id_22979;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_22979 == num_virt_blocks_22911 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_22939)[(int64_t) 0] = 0;\n            ", "        }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_22979 = ((__local int32_t *) local_mem_22969)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_22980 = dynamic_id_22979 * chunk_sizze_22910 * segscan_tblock_sizze_22541;\n        sgm_idx_22981 = smod64(block_offset_22980, mz2080U_19405);\n        boundary_22982 = sext_i64_i32(smin64(chunk_sizze_22910 * segscan_tblock_sizze_22541, mz2080U_19405 - sgm_idx_22981));\n        segsizze_compact_22983 = sext_i64_i32(smin64(chunk_sizze_22910 * segscan_tblock_sizze_22541, mz2080U_19405));\n        thd_offset_22986 = block_offset_22980 + sext_i32_i64(local_tid_22962);\n        // Load and map\n        {\n            for (int64_t i_22987 = 0; i_22987 < chunk_sizze_22910; i_22987++) {\n                int64_t virt_tid_22988 = thd_offset_22986 + i_22987 * segscan_tblock_sizze_22541;\n                int64_t slice_22989 = mz2080U_19405;\n                int64_t gtid_22545 = virt_tid_22988;\n                int64_t remnant_22990 = virt_tid_22988 - gtid_22545;\n                \n                if (slt64(virt_tid_22988, mz2080U_19405)) {\n                    int32_t eta_p_21458 = ((__global int32_t *) shp_mem_22767)[gtid_22545];\n                    int64_t i32_res_21459 = sext_i32_i64(eta_p_21458);\n                    \n                    private_mem_22984[i_22987] = i32_res_21459;\n                } else {\n                    private_mem_22984[i_22987] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_22991 = 0; i_22991 < chunk_sizze_22910; i_22991++) {\n                int64_t sharedIdx_22992 = sext_i32_i64(local_tid_22962) + i_22991 * segscan_tblock_sizze_22541;\n                int64_t tmp_22993 = private_mem_22984[i_22991];\n                \n                ((__local int64_t *) local_mem_22969)[sharedIdx_22992] = tmp_22993;\n            }\n            ba",
                                    "rrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_22994 = 0; i_22994 < chunk_sizze_22910; i_22994++) {\n                int64_t sharedIdx_22995 = sext_i32_i64(local_tid_22962) * chunk_sizze_22910 + i_22994;\n                int64_t tmp_22996 = ((__local int64_t *) local_mem_22969)[sharedIdx_22995];\n                \n                private_mem_22984[i_22994] = tmp_22996;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_22997 = 0; i_22997 < chunk_sizze_22910 - (int64_t) 1; i_22997++) {\n                int64_t eta_p_21341;\n                int64_t eta_p_21342;\n                \n                eta_p_21341 = private_mem_22984[i_22997];\n                eta_p_21342 = private_mem_22984[i_22997 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_21343 = add64(eta_p_21341, eta_p_21342);\n                \n                private_mem_22984[i_22997 + (int64_t) 1] = defunc_0_op_res_21343;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_22998 = private_mem_22984[chunk_sizze_22910 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)] = tmp_22998;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_22999;\n            int64_t eta_p_23000;\n            int64_t eta_p_23003;\n            int64_t eta_p_23004;\n            bool ltid_in_bounds_23006 = slt64(sext_i32_i64(local_tid_22962), num_virt_threads_22912);\n            int32_t skip_threads_23007;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23006) {\n                    eta_p_23000 = ((volatile __local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)];\n                    if ((local_tid_22962 - squot32(local_tid_22962, 32) * 32) == 0) {\n                        eta_p_22999 = eta_p_23000", ";\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23007 = 1;\n                while (slt32(skip_threads_23007, 32)) {\n                    bool thread_active_23008 = sle32(skip_threads_23007, local_tid_22962 - squot32(local_tid_22962, 32) * 32) && ltid_in_bounds_23006;\n                    \n                    if (thread_active_23008) {\n                        // read operands\n                        {\n                            eta_p_22999 = ((volatile __local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962) - sext_i32_i64(skip_threads_23007)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23008) {\n                            int64_t defunc_0_op_res_23001 = add64(eta_p_22999, eta_p_23000);\n                            \n                            eta_p_22999 = defunc_0_op_res_23001;\n                        }\n                    }\n                    if (sle32(wave_sizze_22964, skip_threads_23007)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23008) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)] = eta_p_22999;\n                            eta_p_23000 = eta_p_22999;\n                        }\n                    }\n                    if (sle32(wave_sizze_22964, skip_threads_23007)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23007 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_22962 - squot32(local_tid_22962, 32) * 32) == 31 && ltid_in_bounds_2", "3006) {\n                    ((volatile __local int64_t *) local_mem_22969)[sext_i32_i64(squot32(local_tid_22962, 32))] = eta_p_22999;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23009;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_22962, 32) == 0 && ltid_in_bounds_23006) {\n                        eta_p_23004 = ((volatile __local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)];\n                        if ((local_tid_22962 - squot32(local_tid_22962, 32) * 32) == 0) {\n                            eta_p_23003 = eta_p_23004;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23009 = 1;\n                    while (slt32(skip_threads_23009, 32)) {\n                        bool thread_active_23010 = sle32(skip_threads_23009, local_tid_22962 - squot32(local_tid_22962, 32) * 32) && (squot32(local_tid_22962, 32) == 0 && ltid_in_bounds_23006);\n                        \n                        if (thread_active_23010) {\n                            // read operands\n                            {\n                                eta_p_23003 = ((volatile __local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962) - sext_i32_i64(skip_threads_23009)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_23010) {\n                                int64_t defunc_0_op_res_23005 = add64(eta_p_23003, eta_p_23004);\n                                \n                                eta_p_23003 = defunc_0_op_res_23005;\n                            }\n                        }\n                ",
                                    "        if (sle32(wave_sizze_22964, skip_threads_23009)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23010) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)] = eta_p_23003;\n                                eta_p_23004 = eta_p_23003;\n                            }\n                        }\n                        if (sle32(wave_sizze_22964, skip_threads_23009)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23009 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23011 = squot32(local_tid_22962, 32) == 0 || !ltid_in_bounds_23006;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23011) {\n                        eta_p_23000 = eta_p_22999;\n                        eta_p_22999 = ((__local int64_t *) local_mem_22969)[sext_i32_i64(squot32(local_tid_22962, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23011) {\n                        int64_t defunc_0_op_res_23001 = add64(eta_p_22999, eta_p_23000);\n                        \n                        eta_p_22999 = defunc_0_op_res_23001;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_23011) {\n                        ((__local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)] = eta_p_22999;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first b", "lock\n            {\n                if (squot32(local_tid_22962, 32) == 0 && ltid_in_bounds_23006) {\n                    ((__local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)] = eta_p_23000;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_22962 == 0) {\n                acc_23002 = ((__local int64_t *) local_mem_22969)[segscan_tblock_sizze_22541 - (int64_t) 1];\n            } else {\n                acc_23002 = ((__local int64_t *) local_mem_22969)[sext_i32_i64(local_tid_22962) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23012 = (int64_t) 0;\n        block_new_sgm_23013 = sgm_idx_22981 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23013 && local_tid_22962 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_22937)[dynamic_id_22979] = acc_23002;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_22913)[dynamic_id_22979] = (int8_t) 2;\n                acc_23002 = (int64_t) 0;\n            }\n            if (!block_new_sgm_23013 && slt32(local_tid_22962, wave_sizze_22964)) {\n                if (local_tid_22962 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_22935)[dynamic_id_22979] = acc_23002;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_22913)[dynamic_id_22979] = (int8_t) 1;\n                    \n                    int8_t tmp_23014 = ((volatile __global int8_t *) status_flags_mem_22913)[dynamic_id_22979 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_22969)[(int64_t) 0] = tmp_23014;\n                }\n                mem_fence_local();\n                \n                int8_t status_23015 = ((__local int8_t *) local_mem_22969)[(int64_t) 0];\n                \n                if (status_", "23015 == (int8_t) 2) {\n                    if (local_tid_22962 == 0) {\n                        prefix_23012 = ((volatile __global int64_t *) incprefixes_mem_22937)[dynamic_id_22979 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23016 = sext_i64_i32(dynamic_id_22979 - sext_i32_i64(wave_sizze_22964));\n                    \n                    while (slt32(wave_sizze_22964 * -1, readOffset_23016)) {\n                        int32_t read_i_23017 = readOffset_23016 + local_tid_22962;\n                        int64_t aggr_23018 = (int64_t) 0;\n                        int8_t flag_23019 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23017)) {\n                            flag_23019 = ((volatile __global int8_t *) status_flags_mem_22913)[sext_i32_i64(read_i_23017)];\n                            if (flag_23019 == (int8_t) 2) {\n                                aggr_23018 = ((volatile __global int64_t *) incprefixes_mem_22937)[sext_i32_i64(read_i_23017)];\n                            } else if (flag_23019 == (int8_t) 1) {\n                                aggr_23018 = ((volatile __global int64_t *) aggregates_mem_22935)[sext_i32_i64(read_i_23017)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_22969)[(int64_t) 4 + sext_i32_i64(local_tid_22962)] = aggr_23018;\n                        ((__local int8_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)] = flag_23019;\n                        flag_23019 = ((__local int8_t *) local_mem_22969)[sext_i32_i64(wave_sizze_22964) - (int64_t) 1];\n                        if (slt8(flag_23019, (int8_t) 2)) {\n                            int8_t flg_x_23023;\n                            int8_t flg_y_23024;\n                            int64_t eta_p_23020;\n                            int64_t eta_p_23021;\n                            int32_t skip_threads_23025;\n                            \n                     ",
                                    "       // read input for in-block scan\n                            {\n                                flg_y_23024 = ((volatile __local int8_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)];\n                                eta_p_23021 = ((volatile __local int64_t *) local_mem_22969)[(int64_t) 4 + sext_i32_i64(local_tid_22962)];\n                                if ((local_tid_22962 - squot32(local_tid_22962, 32) * 32) == 0) {\n                                    eta_p_23020 = eta_p_23021;\n                                    flg_x_23023 = flg_y_23024;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23025 = 1;\n                                while (slt32(skip_threads_23025, 32)) {\n                                    if (sle32(skip_threads_23025, local_tid_22962 - squot32(local_tid_22962, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23023 = ((volatile __local int8_t *) local_mem_22969)[sext_i32_i64(local_tid_22962) - sext_i32_i64(skip_threads_23025)];\n                                            eta_p_23020 = ((volatile __local int64_t *) local_mem_22969)[(int64_t) 4 + (sext_i32_i64(local_tid_22962) - sext_i32_i64(skip_threads_23025))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23024 == (int8_t) 2 || flg_y_23024 == (int8_t) 0) {\n                                                flg_x_23023 = flg_y_23024;\n                                                eta_p_23020 = eta_p_23021;\n                                            } else {\n                                                int64_t defunc_0_op_res_23022 = add64(eta_p_23020, eta_p_23021);", "\n                                                \n                                                eta_p_23020 = defunc_0_op_res_23022;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_22969)[sext_i32_i64(local_tid_22962)] = flg_x_23023;\n                                            flg_y_23024 = flg_x_23023;\n                                            ((volatile __local int64_t *) local_mem_22969)[(int64_t) 4 + sext_i32_i64(local_tid_22962)] = eta_p_23020;\n                                            eta_p_23021 = eta_p_23020;\n                                        }\n                                    }\n                                    skip_threads_23025 *= 2;\n                                }\n                            }\n                        }\n                        flag_23019 = ((__local int8_t *) local_mem_22969)[sext_i32_i64(wave_sizze_22964) - (int64_t) 1];\n                        aggr_23018 = ((__local int64_t *) local_mem_22969)[(int64_t) 4 + (sext_i32_i64(wave_sizze_22964) - (int64_t) 1)];\n                        if (flag_23019 == (int8_t) 2) {\n                            readOffset_23016 = wave_sizze_22964 * -1;\n                        } else if (flag_23019 == (int8_t) 1) {\n                            readOffset_23016 -= wave_sizze_22964;\n                        }\n                        if (slt8((int8_t) 0, flag_23019)) {\n                            int64_t eta_p_23026 = aggr_23018;\n                            int64_t eta_p_23027 = prefix_23012;\n                            int64_t defunc_0_op_res_23028 = add64(eta_p_23026, eta_p_23027);\n                            \n                            prefix_23012 = defunc_0_op_res_23028;\n                        }\n                        mem_fence_local();\n                    }\n              ", "  }\n                if (local_tid_22962 == 0) {\n                    if (boundary_22982 == sext_i64_i32(segscan_tblock_sizze_22541 * chunk_sizze_22910)) {\n                        int64_t eta_p_23029 = prefix_23012;\n                        int64_t eta_p_23030 = acc_23002;\n                        int64_t defunc_0_op_res_23031 = add64(eta_p_23029, eta_p_23030);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_22937)[dynamic_id_22979] = defunc_0_op_res_23031;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_22913)[dynamic_id_22979] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_22969)[(int64_t) 4] = prefix_23012;\n                    acc_23002 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_22979 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23012 = ((__local int64_t *) local_mem_22969)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_23032;\n            int64_t eta_p_23033;\n            int64_t eta_p_23035 = prefix_23012;\n            int64_t eta_p_23036 = acc_23002;\n            \n            if (slt32(local_tid_22962 * chunk_sizze_32b_22966, boundary_22982) && !block_new_sgm_23013) {\n                int64_t defunc_0_op_res_23037 = add64(eta_p_23035, eta_p_23036);\n                \n                eta_p_23032 = defunc_0_op_res_23037;\n            } else {\n                eta_p_23032 = acc_23002;\n            }\n            \n            int32_t stopping_point_23038 = segsizze_compact_22983 - srem32(local_tid_22962 * chunk_sizze_32b_22966 - 1 + segsizze_compact_22983 - boundary_22982, segsizze_compact_22983);\n            \n            for (int64_t i_23039 = 0; i_23039 < chunk_sizze_22910; i_23039++) {\n                if (slt32(sext_i64_i32(i_23039), stopping_point",
                                    "_23038 - 1)) {\n                    eta_p_23033 = private_mem_22984[i_23039];\n                    \n                    int64_t defunc_0_op_res_23034 = add64(eta_p_23032, eta_p_23033);\n                    \n                    private_mem_22984[i_23039] = defunc_0_op_res_23034;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23040 = 0; i_23040 < chunk_sizze_22910; i_23040++) {\n                int64_t sharedIdx_23041 = sext_i32_i64(local_tid_22962) * chunk_sizze_22910 + i_23040;\n                int64_t tmp_23042 = private_mem_22984[i_23040];\n                \n                ((__local int64_t *) local_mem_22969)[sharedIdx_23041] = tmp_23042;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23043 = 0; i_23043 < chunk_sizze_22910; i_23043++) {\n                int64_t flat_idx_23044 = thd_offset_22986 + i_23043 * segscan_tblock_sizze_22541;\n                int64_t slice_23045 = mz2080U_19405;\n                int64_t gtid_22545 = flat_idx_23044;\n                int64_t remnant_23046 = flat_idx_23044 - gtid_22545;\n                \n                if (slt64(flat_idx_23044, mz2080U_19405)) {\n                    int64_t tmp_23047 = ((__local int64_t *) local_mem_22969)[flat_idx_23044 - block_offset_22980];\n                    \n                    ((__global int64_t *) mem_22773)[gtid_22545] = tmp_23047;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22541\n    #undef chunk_sizze_22910\n}\nFUTHARK_KERNEL_SIZED(compilerzisegscan_22562_dim1, 1, 1)\nvoid compilerzisegscan_22562(__global int *global_failure, int64_t nz2081U_19406, int64_t num_tblocks_22559, int64_t num_virt_blocks_23088, int64_t num_virt_threads_23089, __global unsigned char *mem_22774, __global unsigned char *mem_22781, __global unsigned char *status_flags_mem_23090, __glo", "bal unsigned char *aggregates_mem_23092, __global unsigned char *incprefixes_mem_23094, __global unsigned char *global_dynid_mem_23096)\n{\n    #define segscan_tblock_sizze_22557 (compilerzisegscan_22562zisegscan_tblock_sizze_22557)\n    #define chunk_sizze_23087 (compilerzisegscan_22562zichunk_sizze_23087)\n    \n    volatile __local unsigned char *local_mem_23106_backing_0 = &shared_mem[0];\n    const int64_t local_mem_23106_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22557), chunk_sizze_23087 * segscan_tblock_sizze_22557 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22557), chunk_sizze_23087 * segscan_tblock_sizze_22557 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23099;\n    int32_t tblock_sizze_23102;\n    int32_t wave_sizze_23101;\n    int32_t block_id_23100;\n    int32_t global_tid_23098;\n    int64_t phys_tid_22562;\n    int32_t chunk_sizze_32b_23103;\n    int64_t byte_offsets_23104;\n    int64_t warp_byte_offset_23105;\n    __local unsigned char *local_mem_23106;\n    int64_t trans_arr_len_23107;\n    int64_t phys_block_id_23113;\n    int64_t virtloop_bound_23114;\n    \n    local_tid_23099 = get_local_id(0);\n    tblock_sizze_23102 = get_local_size(0);\n    wave_sizze_23101 = LOCKSTEP_WIDTH;\n    block_id_23100 = get_tblock_id(0);\n    global_tid_23098 = block_id_23100 * tblock_sizze_23102 + local_tid_23099;\n    phys_tid_22562 = sext_i32_i64(global_tid_23098);\n    chunk_sizze_32b_23103 = sext_i64_i32(chunk_sizze_23087);\n    byte_offsets_23104 = segscan_tblock_sizze_22557 * (int64_t) 4;\n    warp_byte_offset_23105 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_23106 = (__local unsigned char *) local_mem_23106_backing_0;\n    trans_arr_len_23107 = chunk_sizze_23087 * segscan_tblock_sizze_22557;\n    phys_block_id_23113 = get_tblock_id(0);\n    virtloop_bound_23114 = sdiv_up", "64(num_virt_blocks_23088 - phys_block_id_23113, num_tblocks_22559);\n    for (int64_t virtloop_i_23115 = 0; virtloop_i_23115 < virtloop_bound_23114; virtloop_i_23115++) {\n        int64_t dynamic_id_23116;\n        int64_t block_offset_23117;\n        int64_t sgm_idx_23118;\n        int32_t boundary_23119;\n        int32_t segsizze_compact_23120;\n        int32_t private_mem_23121[chunk_sizze_23087];\n        int64_t thd_offset_23123;\n        int32_t acc_23139;\n        int32_t prefix_23149;\n        bool block_new_sgm_23150;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_23099 == 0) {\n                dynamic_id_23116 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_23096)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_23106)[(int64_t) 0] = dynamic_id_23116;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_23116 == num_virt_blocks_23088 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_23096)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_23116 = ((__local int32_t *) local_mem_23106)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_23117 = dynamic_id_23116 * chunk_sizze_23087 * segscan_tblock_sizze_22557;\n        sgm_idx_23118 = smod64(block_offset_23117, nz2081U_19406);\n        boundary_23119 = sext_i64_i32(smin64(chunk_sizze_23087 * segscan_tblock_sizze_22557, nz2081U_19406 - sgm_idx_23118));\n        segsizze_compact_23120 = sext_i64_i32(smin64(chunk_sizze_23087 * segscan_tblock_sizze_22557, nz2081U_19406));\n        thd_offset_23123 = block_offset_23117 + sext_i32_i64(local_tid_23099);\n        // Load and map\n        {\n            for (int64_t i_23124 = 0",
                                    "; i_23124 < chunk_sizze_23087; i_23124++) {\n                int64_t virt_tid_23125 = thd_offset_23123 + i_23124 * segscan_tblock_sizze_22557;\n                int64_t slice_23126 = nz2081U_19406;\n                int64_t gtid_22561 = virt_tid_23125;\n                int64_t remnant_23127 = virt_tid_23125 - gtid_22561;\n                \n                if (slt64(virt_tid_23125, nz2081U_19406)) {\n                    bool eta_p_21467 = ((__global bool *) mem_22774)[gtid_22561];\n                    int32_t bool_res_21468 = btoi_bool_i32(eta_p_21467);\n                    \n                    private_mem_23121[i_23124] = bool_res_21468;\n                } else {\n                    private_mem_23121[i_23124] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_23128 = 0; i_23128 < chunk_sizze_23087; i_23128++) {\n                int64_t sharedIdx_23129 = sext_i32_i64(local_tid_23099) + i_23128 * segscan_tblock_sizze_22557;\n                int32_t tmp_23130 = private_mem_23121[i_23128];\n                \n                ((__local int32_t *) local_mem_23106)[sharedIdx_23129] = tmp_23130;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23131 = 0; i_23131 < chunk_sizze_23087; i_23131++) {\n                int64_t sharedIdx_23132 = sext_i32_i64(local_tid_23099) * chunk_sizze_23087 + i_23131;\n                int32_t tmp_23133 = ((__local int32_t *) local_mem_23106)[sharedIdx_23132];\n                \n                private_mem_23121[i_23131] = tmp_23133;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_23134 = 0; i_23134 < chunk_sizze_23087 - (int64_t) 1; i_23134++) {\n                int32_t eta_p_21422;\n                int32_t eta_p_21423;\n                \n                eta_p_21422 = private_mem_23121[i_23134];\n                eta_p_21423 = private_mem_23121[i_23134 + ", "(int64_t) 1];\n                \n                int32_t defunc_0_op_res_21424 = add32(eta_p_21422, eta_p_21423);\n                \n                private_mem_23121[i_23134 + (int64_t) 1] = defunc_0_op_res_21424;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_23135 = private_mem_23121[chunk_sizze_23087 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)] = tmp_23135;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_23136;\n            int32_t eta_p_23137;\n            int32_t eta_p_23140;\n            int32_t eta_p_23141;\n            bool ltid_in_bounds_23143 = slt64(sext_i32_i64(local_tid_23099), num_virt_threads_23089);\n            int32_t skip_threads_23144;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23143) {\n                    eta_p_23137 = ((volatile __local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)];\n                    if ((local_tid_23099 - squot32(local_tid_23099, 32) * 32) == 0) {\n                        eta_p_23136 = eta_p_23137;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23144 = 1;\n                while (slt32(skip_threads_23144, 32)) {\n                    bool thread_active_23145 = sle32(skip_threads_23144, local_tid_23099 - squot32(local_tid_23099, 32) * 32) && ltid_in_bounds_23143;\n                    \n                    if (thread_active_23145) {\n                        // read operands\n                        {\n                            eta_p_23136 = ((volatile __local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099) - sext_i32_i64(skip_threads_23144)];\n                        }\n                    }\n                    // perform operation\n                    {\n ", "                       if (thread_active_23145) {\n                            int32_t defunc_0_op_res_23138 = add32(eta_p_23136, eta_p_23137);\n                            \n                            eta_p_23136 = defunc_0_op_res_23138;\n                        }\n                    }\n                    if (sle32(wave_sizze_23101, skip_threads_23144)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23145) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)] = eta_p_23136;\n                            eta_p_23137 = eta_p_23136;\n                        }\n                    }\n                    if (sle32(wave_sizze_23101, skip_threads_23144)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23144 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_23099 - squot32(local_tid_23099, 32) * 32) == 31 && ltid_in_bounds_23143) {\n                    ((volatile __local int32_t *) local_mem_23106)[sext_i32_i64(squot32(local_tid_23099, 32))] = eta_p_23136;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23146;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_23099, 32) == 0 && ltid_in_bounds_23143) {\n                        eta_p_23141 = ((volatile __local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)];\n                        if ((local_tid_23099 - squot32(local_tid_23099, 32) * 32) == 0) {\n                            eta_p_23140 = eta",
                                    "_p_23141;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23146 = 1;\n                    while (slt32(skip_threads_23146, 32)) {\n                        bool thread_active_23147 = sle32(skip_threads_23146, local_tid_23099 - squot32(local_tid_23099, 32) * 32) && (squot32(local_tid_23099, 32) == 0 && ltid_in_bounds_23143);\n                        \n                        if (thread_active_23147) {\n                            // read operands\n                            {\n                                eta_p_23140 = ((volatile __local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099) - sext_i32_i64(skip_threads_23146)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_23147) {\n                                int32_t defunc_0_op_res_23142 = add32(eta_p_23140, eta_p_23141);\n                                \n                                eta_p_23140 = defunc_0_op_res_23142;\n                            }\n                        }\n                        if (sle32(wave_sizze_23101, skip_threads_23146)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23147) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)] = eta_p_23140;\n                                eta_p_23141 = eta_p_23140;\n                            }\n                        }\n                        if (sle32(wave_sizze_23101, skip_threads_23146)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23146 *= 2;\n                    }\n                }\n            }\n          ", "  barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23148 = squot32(local_tid_23099, 32) == 0 || !ltid_in_bounds_23143;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23148) {\n                        eta_p_23137 = eta_p_23136;\n                        eta_p_23136 = ((__local int32_t *) local_mem_23106)[sext_i32_i64(squot32(local_tid_23099, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23148) {\n                        int32_t defunc_0_op_res_23138 = add32(eta_p_23136, eta_p_23137);\n                        \n                        eta_p_23136 = defunc_0_op_res_23138;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_23148) {\n                        ((__local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)] = eta_p_23136;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_23099, 32) == 0 && ltid_in_bounds_23143) {\n                    ((__local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)] = eta_p_23137;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_23099 == 0) {\n                acc_23139 = ((__local int32_t *) local_mem_23106)[segscan_tblock_sizze_22557 - (int64_t) 1];\n            } else {\n                acc_23139 = ((__local int32_t *) local_mem_23106)[sext_i32_i64(local_tid_23099) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23149 = 0;\n        block_new_sgm_23150 = sgm_idx_23118 == (int64_t) 0;\n        // Perform lookbac", "k\n        {\n            if (block_new_sgm_23150 && local_tid_23099 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_23094)[dynamic_id_23116] = acc_23139;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23090)[dynamic_id_23116] = (int8_t) 2;\n                acc_23139 = 0;\n            }\n            if (!block_new_sgm_23150 && slt32(local_tid_23099, wave_sizze_23101)) {\n                if (local_tid_23099 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_23092)[dynamic_id_23116] = acc_23139;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23090)[dynamic_id_23116] = (int8_t) 1;\n                    \n                    int8_t tmp_23151 = ((volatile __global int8_t *) status_flags_mem_23090)[dynamic_id_23116 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_23106)[(int64_t) 0] = tmp_23151;\n                }\n                mem_fence_local();\n                \n                int8_t status_23152 = ((__local int8_t *) local_mem_23106)[(int64_t) 0];\n                \n                if (status_23152 == (int8_t) 2) {\n                    if (local_tid_23099 == 0) {\n                        prefix_23149 = ((volatile __global int32_t *) incprefixes_mem_23094)[dynamic_id_23116 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23153 = sext_i64_i32(dynamic_id_23116 - sext_i32_i64(wave_sizze_23101));\n                    \n                    while (slt32(wave_sizze_23101 * -1, readOffset_23153)) {\n                        int32_t read_i_23154 = readOffset_23153 + local_tid_23099;\n                        int32_t aggr_23155 = 0;\n                        int8_t flag_23156 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23154)) {\n                            flag_23156 = ((volatile __global int8_t *) status_fl",
                                    "ags_mem_23090)[sext_i32_i64(read_i_23154)];\n                            if (flag_23156 == (int8_t) 2) {\n                                aggr_23155 = ((volatile __global int32_t *) incprefixes_mem_23094)[sext_i32_i64(read_i_23154)];\n                            } else if (flag_23156 == (int8_t) 1) {\n                                aggr_23155 = ((volatile __global int32_t *) aggregates_mem_23092)[sext_i32_i64(read_i_23154)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_23106)[(int64_t) 8 + sext_i32_i64(local_tid_23099)] = aggr_23155;\n                        ((__local int8_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)] = flag_23156;\n                        flag_23156 = ((__local int8_t *) local_mem_23106)[sext_i32_i64(wave_sizze_23101) - (int64_t) 1];\n                        if (slt8(flag_23156, (int8_t) 2)) {\n                            int8_t flg_x_23160;\n                            int8_t flg_y_23161;\n                            int32_t eta_p_23157;\n                            int32_t eta_p_23158;\n                            int32_t skip_threads_23162;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23161 = ((volatile __local int8_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)];\n                                eta_p_23158 = ((volatile __local int32_t *) local_mem_23106)[(int64_t) 8 + sext_i32_i64(local_tid_23099)];\n                                if ((local_tid_23099 - squot32(local_tid_23099, 32) * 32) == 0) {\n                                    eta_p_23157 = eta_p_23158;\n                                    flg_x_23160 = flg_y_23161;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23162 = 1;\n                            ", "    while (slt32(skip_threads_23162, 32)) {\n                                    if (sle32(skip_threads_23162, local_tid_23099 - squot32(local_tid_23099, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23160 = ((volatile __local int8_t *) local_mem_23106)[sext_i32_i64(local_tid_23099) - sext_i32_i64(skip_threads_23162)];\n                                            eta_p_23157 = ((volatile __local int32_t *) local_mem_23106)[(int64_t) 8 + (sext_i32_i64(local_tid_23099) - sext_i32_i64(skip_threads_23162))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23161 == (int8_t) 2 || flg_y_23161 == (int8_t) 0) {\n                                                flg_x_23160 = flg_y_23161;\n                                                eta_p_23157 = eta_p_23158;\n                                            } else {\n                                                int32_t defunc_0_op_res_23159 = add32(eta_p_23157, eta_p_23158);\n                                                \n                                                eta_p_23157 = defunc_0_op_res_23159;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_23106)[sext_i32_i64(local_tid_23099)] = flg_x_23160;\n                                            flg_y_23161 = flg_x_23160;\n                                            ((volatile __local int32_t *) local_mem_23106)[(int64_t) 8 + sext_i32_i64(local_tid_23099)] = eta_p_23157;\n                                            eta_p_23158 = eta_p_23157;\n                                        }\n                  ", "                  }\n                                    skip_threads_23162 *= 2;\n                                }\n                            }\n                        }\n                        flag_23156 = ((__local int8_t *) local_mem_23106)[sext_i32_i64(wave_sizze_23101) - (int64_t) 1];\n                        aggr_23155 = ((__local int32_t *) local_mem_23106)[(int64_t) 8 + (sext_i32_i64(wave_sizze_23101) - (int64_t) 1)];\n                        if (flag_23156 == (int8_t) 2) {\n                            readOffset_23153 = wave_sizze_23101 * -1;\n                        } else if (flag_23156 == (int8_t) 1) {\n                            readOffset_23153 -= wave_sizze_23101;\n                        }\n                        if (slt8((int8_t) 0, flag_23156)) {\n                            int32_t eta_p_23163 = aggr_23155;\n                            int32_t eta_p_23164 = prefix_23149;\n                            int32_t defunc_0_op_res_23165 = add32(eta_p_23163, eta_p_23164);\n                            \n                            prefix_23149 = defunc_0_op_res_23165;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_23099 == 0) {\n                    if (boundary_23119 == sext_i64_i32(segscan_tblock_sizze_22557 * chunk_sizze_23087)) {\n                        int32_t eta_p_23166 = prefix_23149;\n                        int32_t eta_p_23167 = acc_23139;\n                        int32_t defunc_0_op_res_23168 = add32(eta_p_23166, eta_p_23167);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_23094)[dynamic_id_23116] = defunc_0_op_res_23168;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23090)[dynamic_id_23116] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_23106)[(int64_t) 8] = prefix_23149;\n                    acc_23139 = 0;\n      ",
                                    "          }\n            }\n            if (!(dynamic_id_23116 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23149 = ((__local int32_t *) local_mem_23106)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_23169;\n            int32_t eta_p_23170;\n            int32_t eta_p_23172 = prefix_23149;\n            int32_t eta_p_23173 = acc_23139;\n            \n            if (slt32(local_tid_23099 * chunk_sizze_32b_23103, boundary_23119) && !block_new_sgm_23150) {\n                int32_t defunc_0_op_res_23174 = add32(eta_p_23172, eta_p_23173);\n                \n                eta_p_23169 = defunc_0_op_res_23174;\n            } else {\n                eta_p_23169 = acc_23139;\n            }\n            \n            int32_t stopping_point_23175 = segsizze_compact_23120 - srem32(local_tid_23099 * chunk_sizze_32b_23103 - 1 + segsizze_compact_23120 - boundary_23119, segsizze_compact_23120);\n            \n            for (int64_t i_23176 = 0; i_23176 < chunk_sizze_23087; i_23176++) {\n                if (slt32(sext_i64_i32(i_23176), stopping_point_23175 - 1)) {\n                    eta_p_23170 = private_mem_23121[i_23176];\n                    \n                    int32_t defunc_0_op_res_23171 = add32(eta_p_23169, eta_p_23170);\n                    \n                    private_mem_23121[i_23176] = defunc_0_op_res_23171;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23177 = 0; i_23177 < chunk_sizze_23087; i_23177++) {\n                int64_t sharedIdx_23178 = sext_i32_i64(local_tid_23099) * chunk_sizze_23087 + i_23177;\n                int32_t tmp_23179 = private_mem_23121[i_23177];\n                \n                ((__local int32_t *) local_mem_23106)[sharedIdx_23178] = tmp_23179;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n    ", "        for (int64_t i_23180 = 0; i_23180 < chunk_sizze_23087; i_23180++) {\n                int64_t flat_idx_23181 = thd_offset_23123 + i_23180 * segscan_tblock_sizze_22557;\n                int64_t slice_23182 = nz2081U_19406;\n                int64_t gtid_22561 = flat_idx_23181;\n                int64_t remnant_23183 = flat_idx_23181 - gtid_22561;\n                \n                if (slt64(flat_idx_23181, nz2081U_19406)) {\n                    int32_t tmp_23184 = ((__local int32_t *) local_mem_23106)[flat_idx_23181 - block_offset_23117];\n                    \n                    ((__global int32_t *) mem_22781)[gtid_22561] = tmp_23184;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22557\n    #undef chunk_sizze_23087\n}\nFUTHARK_KERNEL_SIZED(compilerzisegscan_22590_dim1, 1, 1)\nvoid compilerzisegscan_22590(__global int *global_failure, int64_t mz2080U_19405, int64_t num_tblocks_22587, int64_t num_virt_blocks_23212, int64_t num_virt_threads_23213, __global unsigned char *mem_param_22787, __global unsigned char *mem_22799, __global unsigned char *status_flags_mem_23214, __global unsigned char *aggregates_mem_23216, __global unsigned char *incprefixes_mem_23218, __global unsigned char *global_dynid_mem_23220)\n{\n    #define segscan_tblock_sizze_22585 (compilerzisegscan_22590zisegscan_tblock_sizze_22585)\n    #define chunk_sizze_23211 (compilerzisegscan_22590zichunk_sizze_23211)\n    \n    volatile __local unsigned char *local_mem_23230_backing_0 = &shared_mem[0];\n    const int64_t local_mem_23230_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22585), chunk_sizze_23211 * segscan_tblock_sizze_22585 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22585), chunk_sizze_23211 * segscan_tblock_sizze_22585 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n  ", "      return;\n    \n    int32_t local_tid_23223;\n    int32_t tblock_sizze_23226;\n    int32_t wave_sizze_23225;\n    int32_t block_id_23224;\n    int32_t global_tid_23222;\n    int64_t phys_tid_22590;\n    int32_t chunk_sizze_32b_23227;\n    int64_t byte_offsets_23228;\n    int64_t warp_byte_offset_23229;\n    __local unsigned char *local_mem_23230;\n    int64_t trans_arr_len_23231;\n    int64_t phys_block_id_23237;\n    int64_t virtloop_bound_23238;\n    \n    local_tid_23223 = get_local_id(0);\n    tblock_sizze_23226 = get_local_size(0);\n    wave_sizze_23225 = LOCKSTEP_WIDTH;\n    block_id_23224 = get_tblock_id(0);\n    global_tid_23222 = block_id_23224 * tblock_sizze_23226 + local_tid_23223;\n    phys_tid_22590 = sext_i32_i64(global_tid_23222);\n    chunk_sizze_32b_23227 = sext_i64_i32(chunk_sizze_23211);\n    byte_offsets_23228 = segscan_tblock_sizze_22585 * (int64_t) 4;\n    warp_byte_offset_23229 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_23230 = (__local unsigned char *) local_mem_23230_backing_0;\n    trans_arr_len_23231 = chunk_sizze_23211 * segscan_tblock_sizze_22585;\n    phys_block_id_23237 = get_tblock_id(0);\n    virtloop_bound_23238 = sdiv_up64(num_virt_blocks_23212 - phys_block_id_23237, num_tblocks_22587);\n    for (int64_t virtloop_i_23239 = 0; virtloop_i_23239 < virtloop_bound_23238; virtloop_i_23239++) {\n        int64_t dynamic_id_23240;\n        int64_t block_offset_23241;\n        int64_t sgm_idx_23242;\n        int32_t boundary_23243;\n        int32_t segsizze_compact_23244;\n        int32_t private_mem_23245[chunk_sizze_23211];\n        int64_t thd_offset_23247;\n        int32_t acc_23263;\n        int32_t prefix_23273;\n        bool block_new_sgm_23274;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_23223 == 0) {\n                dynamic_id_23240 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_23220)[(int64_t) 0], (int) 1);\n                // Set dynamic id f",
                                    "or this block\n                {\n                    ((__local int64_t *) local_mem_23230)[(int64_t) 0] = dynamic_id_23240;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_23240 == num_virt_blocks_23212 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_23220)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_23240 = ((__local int32_t *) local_mem_23230)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_23241 = dynamic_id_23240 * chunk_sizze_23211 * segscan_tblock_sizze_22585;\n        sgm_idx_23242 = smod64(block_offset_23241, mz2080U_19405);\n        boundary_23243 = sext_i64_i32(smin64(chunk_sizze_23211 * segscan_tblock_sizze_22585, mz2080U_19405 - sgm_idx_23242));\n        segsizze_compact_23244 = sext_i64_i32(smin64(chunk_sizze_23211 * segscan_tblock_sizze_22585, mz2080U_19405));\n        thd_offset_23247 = block_offset_23241 + sext_i32_i64(local_tid_23223);\n        // Load and map\n        {\n            for (int64_t i_23248 = 0; i_23248 < chunk_sizze_23211; i_23248++) {\n                int64_t virt_tid_23249 = thd_offset_23247 + i_23248 * segscan_tblock_sizze_22585;\n                int64_t slice_23250 = mz2080U_19405;\n                int64_t gtid_22589 = virt_tid_23249;\n                int64_t remnant_23251 = virt_tid_23249 - gtid_22589;\n                \n                if (slt64(virt_tid_23249, mz2080U_19405)) {\n                    int32_t x_21707 = ((__global int32_t *) mem_param_22787)[gtid_22589];\n                    \n                    private_mem_23245[i_23248] = x_21707;\n                } else {\n                    private_mem_23245[i_23248] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_23252 = 0; i_23252 < chu", "nk_sizze_23211; i_23252++) {\n                int64_t sharedIdx_23253 = sext_i32_i64(local_tid_23223) + i_23252 * segscan_tblock_sizze_22585;\n                int32_t tmp_23254 = private_mem_23245[i_23252];\n                \n                ((__local int32_t *) local_mem_23230)[sharedIdx_23253] = tmp_23254;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23255 = 0; i_23255 < chunk_sizze_23211; i_23255++) {\n                int64_t sharedIdx_23256 = sext_i32_i64(local_tid_23223) * chunk_sizze_23211 + i_23255;\n                int32_t tmp_23257 = ((__local int32_t *) local_mem_23230)[sharedIdx_23256];\n                \n                private_mem_23245[i_23255] = tmp_23257;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_23258 = 0; i_23258 < chunk_sizze_23211 - (int64_t) 1; i_23258++) {\n                int32_t eta_p_21704;\n                int32_t eta_p_21705;\n                \n                eta_p_21704 = private_mem_23245[i_23258];\n                eta_p_21705 = private_mem_23245[i_23258 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_21706 = add32(eta_p_21704, eta_p_21705);\n                \n                private_mem_23245[i_23258 + (int64_t) 1] = defunc_0_op_res_21706;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_23259 = private_mem_23245[chunk_sizze_23211 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)] = tmp_23259;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_23260;\n            int32_t eta_p_23261;\n            int32_t eta_p_23264;\n            int32_t eta_p_23265;\n            bool ltid_in_bounds_23267 = slt64(sext_i32_i64(local_tid_23223), num_virt_threads_23213);\n            int32_t skip_threads_23268;\n            \n            // r", "ead input for in-block scan\n            {\n                if (ltid_in_bounds_23267) {\n                    eta_p_23261 = ((volatile __local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)];\n                    if ((local_tid_23223 - squot32(local_tid_23223, 32) * 32) == 0) {\n                        eta_p_23260 = eta_p_23261;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23268 = 1;\n                while (slt32(skip_threads_23268, 32)) {\n                    bool thread_active_23269 = sle32(skip_threads_23268, local_tid_23223 - squot32(local_tid_23223, 32) * 32) && ltid_in_bounds_23267;\n                    \n                    if (thread_active_23269) {\n                        // read operands\n                        {\n                            eta_p_23260 = ((volatile __local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223) - sext_i32_i64(skip_threads_23268)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23269) {\n                            int32_t defunc_0_op_res_23262 = add32(eta_p_23260, eta_p_23261);\n                            \n                            eta_p_23260 = defunc_0_op_res_23262;\n                        }\n                    }\n                    if (sle32(wave_sizze_23225, skip_threads_23268)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23269) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)] = eta_p_23260;\n                            eta_p_23261 = eta_p_23260;\n                        }\n                    }\n                    if (sle32(wave_sizze_23225, skip_threads_23268)) {\n                        barrier(CLK_LOCAL_MEM_",
                                    "FENCE);\n                    }\n                    skip_threads_23268 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_23223 - squot32(local_tid_23223, 32) * 32) == 31 && ltid_in_bounds_23267) {\n                    ((volatile __local int32_t *) local_mem_23230)[sext_i32_i64(squot32(local_tid_23223, 32))] = eta_p_23260;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23270;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_23223, 32) == 0 && ltid_in_bounds_23267) {\n                        eta_p_23265 = ((volatile __local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)];\n                        if ((local_tid_23223 - squot32(local_tid_23223, 32) * 32) == 0) {\n                            eta_p_23264 = eta_p_23265;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23270 = 1;\n                    while (slt32(skip_threads_23270, 32)) {\n                        bool thread_active_23271 = sle32(skip_threads_23270, local_tid_23223 - squot32(local_tid_23223, 32) * 32) && (squot32(local_tid_23223, 32) == 0 && ltid_in_bounds_23267);\n                        \n                        if (thread_active_23271) {\n                            // read operands\n                            {\n                                eta_p_23264 = ((volatile __local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223) - sext_i32_i64(skip_threads_23270)];\n                            }\n                        }\n                        // perform operation\n                  ", "      {\n                            if (thread_active_23271) {\n                                int32_t defunc_0_op_res_23266 = add32(eta_p_23264, eta_p_23265);\n                                \n                                eta_p_23264 = defunc_0_op_res_23266;\n                            }\n                        }\n                        if (sle32(wave_sizze_23225, skip_threads_23270)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23271) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)] = eta_p_23264;\n                                eta_p_23265 = eta_p_23264;\n                            }\n                        }\n                        if (sle32(wave_sizze_23225, skip_threads_23270)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23270 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23272 = squot32(local_tid_23223, 32) == 0 || !ltid_in_bounds_23267;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23272) {\n                        eta_p_23261 = eta_p_23260;\n                        eta_p_23260 = ((__local int32_t *) local_mem_23230)[sext_i32_i64(squot32(local_tid_23223, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23272) {\n                        int32_t defunc_0_op_res_23262 = add32(eta_p_23260, eta_p_23261);\n                        \n                        eta_p_23260 = defunc_0_op_res_23262;\n                    }\n                }\n                // wr", "ite final result\n                {\n                    if (!no_carry_in_23272) {\n                        ((__local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)] = eta_p_23260;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_23223, 32) == 0 && ltid_in_bounds_23267) {\n                    ((__local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)] = eta_p_23261;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_23223 == 0) {\n                acc_23263 = ((__local int32_t *) local_mem_23230)[segscan_tblock_sizze_22585 - (int64_t) 1];\n            } else {\n                acc_23263 = ((__local int32_t *) local_mem_23230)[sext_i32_i64(local_tid_23223) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23273 = 0;\n        block_new_sgm_23274 = sgm_idx_23242 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23274 && local_tid_23223 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_23218)[dynamic_id_23240] = acc_23263;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23214)[dynamic_id_23240] = (int8_t) 2;\n                acc_23263 = 0;\n            }\n            if (!block_new_sgm_23274 && slt32(local_tid_23223, wave_sizze_23225)) {\n                if (local_tid_23223 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_23216)[dynamic_id_23240] = acc_23263;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23214)[dynamic_id_23240] = (int8_t) 1;\n                    \n                    int8_t tmp_23275 = ((volatile __global int8_t *) status_flags_mem_23214)[dynamic_id_23240 - (int64_t) 1];\n  ",
                                    "                  \n                    ((volatile __local int8_t *) local_mem_23230)[(int64_t) 0] = tmp_23275;\n                }\n                mem_fence_local();\n                \n                int8_t status_23276 = ((__local int8_t *) local_mem_23230)[(int64_t) 0];\n                \n                if (status_23276 == (int8_t) 2) {\n                    if (local_tid_23223 == 0) {\n                        prefix_23273 = ((volatile __global int32_t *) incprefixes_mem_23218)[dynamic_id_23240 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23277 = sext_i64_i32(dynamic_id_23240 - sext_i32_i64(wave_sizze_23225));\n                    \n                    while (slt32(wave_sizze_23225 * -1, readOffset_23277)) {\n                        int32_t read_i_23278 = readOffset_23277 + local_tid_23223;\n                        int32_t aggr_23279 = 0;\n                        int8_t flag_23280 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23278)) {\n                            flag_23280 = ((volatile __global int8_t *) status_flags_mem_23214)[sext_i32_i64(read_i_23278)];\n                            if (flag_23280 == (int8_t) 2) {\n                                aggr_23279 = ((volatile __global int32_t *) incprefixes_mem_23218)[sext_i32_i64(read_i_23278)];\n                            } else if (flag_23280 == (int8_t) 1) {\n                                aggr_23279 = ((volatile __global int32_t *) aggregates_mem_23216)[sext_i32_i64(read_i_23278)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_23230)[(int64_t) 8 + sext_i32_i64(local_tid_23223)] = aggr_23279;\n                        ((__local int8_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)] = flag_23280;\n                        flag_23280 = ((__local int8_t *) local_mem_23230)[sext_i32_i64(wave_sizze_23225) - (int64_t) 1];\n                        if (slt8(flag_23280, (int8_t) 2)", ") {\n                            int8_t flg_x_23284;\n                            int8_t flg_y_23285;\n                            int32_t eta_p_23281;\n                            int32_t eta_p_23282;\n                            int32_t skip_threads_23286;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23285 = ((volatile __local int8_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)];\n                                eta_p_23282 = ((volatile __local int32_t *) local_mem_23230)[(int64_t) 8 + sext_i32_i64(local_tid_23223)];\n                                if ((local_tid_23223 - squot32(local_tid_23223, 32) * 32) == 0) {\n                                    eta_p_23281 = eta_p_23282;\n                                    flg_x_23284 = flg_y_23285;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23286 = 1;\n                                while (slt32(skip_threads_23286, 32)) {\n                                    if (sle32(skip_threads_23286, local_tid_23223 - squot32(local_tid_23223, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23284 = ((volatile __local int8_t *) local_mem_23230)[sext_i32_i64(local_tid_23223) - sext_i32_i64(skip_threads_23286)];\n                                            eta_p_23281 = ((volatile __local int32_t *) local_mem_23230)[(int64_t) 8 + (sext_i32_i64(local_tid_23223) - sext_i32_i64(skip_threads_23286))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23285 == (int8_t) 2 || flg_y_23285 == (int8_t) 0) {\n           ", "                                     flg_x_23284 = flg_y_23285;\n                                                eta_p_23281 = eta_p_23282;\n                                            } else {\n                                                int32_t defunc_0_op_res_23283 = add32(eta_p_23281, eta_p_23282);\n                                                \n                                                eta_p_23281 = defunc_0_op_res_23283;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_23230)[sext_i32_i64(local_tid_23223)] = flg_x_23284;\n                                            flg_y_23285 = flg_x_23284;\n                                            ((volatile __local int32_t *) local_mem_23230)[(int64_t) 8 + sext_i32_i64(local_tid_23223)] = eta_p_23281;\n                                            eta_p_23282 = eta_p_23281;\n                                        }\n                                    }\n                                    skip_threads_23286 *= 2;\n                                }\n                            }\n                        }\n                        flag_23280 = ((__local int8_t *) local_mem_23230)[sext_i32_i64(wave_sizze_23225) - (int64_t) 1];\n                        aggr_23279 = ((__local int32_t *) local_mem_23230)[(int64_t) 8 + (sext_i32_i64(wave_sizze_23225) - (int64_t) 1)];\n                        if (flag_23280 == (int8_t) 2) {\n                            readOffset_23277 = wave_sizze_23225 * -1;\n                        } else if (flag_23280 == (int8_t) 1) {\n                            readOffset_23277 -= wave_sizze_23225;\n                        }\n                        if (slt8((int8_t) 0, flag_23280)) {\n                            int32_t eta_p_23287 = aggr_23279;\n                            int32_t eta_p_23288 = pre",
                                    "fix_23273;\n                            int32_t defunc_0_op_res_23289 = add32(eta_p_23287, eta_p_23288);\n                            \n                            prefix_23273 = defunc_0_op_res_23289;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_23223 == 0) {\n                    if (boundary_23243 == sext_i64_i32(segscan_tblock_sizze_22585 * chunk_sizze_23211)) {\n                        int32_t eta_p_23290 = prefix_23273;\n                        int32_t eta_p_23291 = acc_23263;\n                        int32_t defunc_0_op_res_23292 = add32(eta_p_23290, eta_p_23291);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_23218)[dynamic_id_23240] = defunc_0_op_res_23292;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23214)[dynamic_id_23240] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_23230)[(int64_t) 8] = prefix_23273;\n                    acc_23263 = 0;\n                }\n            }\n            if (!(dynamic_id_23240 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23273 = ((__local int32_t *) local_mem_23230)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_23293;\n            int32_t eta_p_23294;\n            int32_t eta_p_23296 = prefix_23273;\n            int32_t eta_p_23297 = acc_23263;\n            \n            if (slt32(local_tid_23223 * chunk_sizze_32b_23227, boundary_23243) && !block_new_sgm_23274) {\n                int32_t defunc_0_op_res_23298 = add32(eta_p_23296, eta_p_23297);\n                \n                eta_p_23293 = defunc_0_op_res_23298;\n            } else {\n                eta_p_23293 = acc_23263;\n            }\n            \n            int32_t stopping_point_23299 = segsiz", "ze_compact_23244 - srem32(local_tid_23223 * chunk_sizze_32b_23227 - 1 + segsizze_compact_23244 - boundary_23243, segsizze_compact_23244);\n            \n            for (int64_t i_23300 = 0; i_23300 < chunk_sizze_23211; i_23300++) {\n                if (slt32(sext_i64_i32(i_23300), stopping_point_23299 - 1)) {\n                    eta_p_23294 = private_mem_23245[i_23300];\n                    \n                    int32_t defunc_0_op_res_23295 = add32(eta_p_23293, eta_p_23294);\n                    \n                    private_mem_23245[i_23300] = defunc_0_op_res_23295;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23301 = 0; i_23301 < chunk_sizze_23211; i_23301++) {\n                int64_t sharedIdx_23302 = sext_i32_i64(local_tid_23223) * chunk_sizze_23211 + i_23301;\n                int32_t tmp_23303 = private_mem_23245[i_23301];\n                \n                ((__local int32_t *) local_mem_23230)[sharedIdx_23302] = tmp_23303;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23304 = 0; i_23304 < chunk_sizze_23211; i_23304++) {\n                int64_t flat_idx_23305 = thd_offset_23247 + i_23304 * segscan_tblock_sizze_22585;\n                int64_t slice_23306 = mz2080U_19405;\n                int64_t gtid_22589 = flat_idx_23305;\n                int64_t remnant_23307 = flat_idx_23305 - gtid_22589;\n                \n                if (slt64(flat_idx_23305, mz2080U_19405)) {\n                    int32_t tmp_23308 = ((__local int32_t *) local_mem_23230)[flat_idx_23305 - block_offset_23241];\n                    \n                    ((__global int32_t *) mem_22799)[gtid_22589] = tmp_23308;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22585\n    #undef chunk_sizze_23211\n}\nFUTHARK_KERNEL_SIZED(compilerzisegscan_22634_dim1, 1, 1)\nv", "oid compilerzisegscan_22634(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_19405, int64_t loop_dz2083Uz2082U_21002, int64_t num_tblocks_22631, int64_t num_virt_blocks_23324, int64_t num_virt_threads_23325, __global unsigned char *mem_param_22790, __global unsigned char *mem_param_22793, __global unsigned char *mem_22802, __global unsigned char *mem_22805, __global unsigned char *mem_22807, __global unsigned char *mem_22809, __global unsigned char *mem_22811, __global unsigned char *mem_22813, __global unsigned char *mem_22815, __global unsigned char *status_flags_mem_23326, __global unsigned char *aggregates_mem_23328, __global unsigned char *incprefixes_mem_23330, __global unsigned char *aggregates_mem_23332, __global unsigned char *incprefixes_mem_23334, __global unsigned char *aggregates_mem_23336, __global unsigned char *incprefixes_mem_23338, __global unsigned char *global_dynid_mem_23340)\n{\n    #define segscan_tblock_sizze_22629 (compilerzisegscan_22634zisegscan_tblock_sizze_22629)\n    #define chunk_sizze_23323 (compilerzisegscan_22634zichunk_sizze_23323)\n    \n    volatile __local unsigned char *local_mem_23354_backing_0 = &shared_mem[0];\n    const int64_t local_mem_23354_backing_0_offset = 0 + (smax64(smax64((int64_t) 800, sdiv_up64(sdiv_up64((int64_t) 8 * segscan_tblock_sizze_22629, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_22629, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_22629), smax64(smax64(chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8, chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8), chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 800, sdiv_up64(sdiv_up64((int64_t) 8 * segscan_tblock_sizze_22629, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_22629, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_22629), smax64(smax64(c",
                                    "hunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8, chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8), chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8)), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23343;\n    int32_t tblock_sizze_23346;\n    int32_t wave_sizze_23345;\n    int32_t block_id_23344;\n    int32_t global_tid_23342;\n    int64_t phys_tid_22634;\n    int32_t chunk_sizze_32b_23347;\n    int64_t byte_offsets_23348;\n    int64_t byte_offsets_23349;\n    int64_t byte_offsets_23350;\n    int64_t warp_byte_offset_23351;\n    int64_t warp_byte_offset_23352;\n    int64_t warp_byte_offset_23353;\n    __local unsigned char *local_mem_23354;\n    int64_t trans_arr_len_23355;\n    int64_t phys_block_id_23367;\n    int64_t virtloop_bound_23368;\n    \n    local_tid_23343 = get_local_id(0);\n    tblock_sizze_23346 = get_local_size(0);\n    wave_sizze_23345 = LOCKSTEP_WIDTH;\n    block_id_23344 = get_tblock_id(0);\n    global_tid_23342 = block_id_23344 * tblock_sizze_23346 + local_tid_23343;\n    phys_tid_22634 = sext_i32_i64(global_tid_23342);\n    chunk_sizze_32b_23347 = sext_i64_i32(chunk_sizze_23323);\n    byte_offsets_23348 = segscan_tblock_sizze_22629 * (int64_t) 8;\n    byte_offsets_23349 = sdiv_up64(byte_offsets_23348, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_22629 * (int64_t) 8;\n    byte_offsets_23350 = sdiv_up64(byte_offsets_23349, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_22629 * (int64_t) 8;\n    warp_byte_offset_23351 = (int64_t) 288;\n    warp_byte_offset_23352 = sdiv_up64(warp_byte_offset_23351, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    warp_byte_offset_23353 = sdiv_up64(warp_byte_offset_23352, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    ", "local_mem_23354 = (__local unsigned char *) local_mem_23354_backing_0;\n    trans_arr_len_23355 = chunk_sizze_23323 * segscan_tblock_sizze_22629;\n    phys_block_id_23367 = get_tblock_id(0);\n    virtloop_bound_23368 = sdiv_up64(num_virt_blocks_23324 - phys_block_id_23367, num_tblocks_22631);\n    for (int64_t virtloop_i_23369 = 0; virtloop_i_23369 < virtloop_bound_23368; virtloop_i_23369++) {\n        int64_t dynamic_id_23370;\n        int64_t block_offset_23371;\n        int64_t sgm_idx_23372;\n        int32_t boundary_23373;\n        int32_t segsizze_compact_23374;\n        int64_t private_mem_23375[chunk_sizze_23323];\n        int64_t private_mem_23377[chunk_sizze_23323];\n        int64_t private_mem_23379[chunk_sizze_23323];\n        int64_t thd_offset_23381;\n        int64_t acc_23417;\n        int64_t acc_23418;\n        int64_t acc_23419;\n        int64_t prefix_23435;\n        int64_t prefix_23436;\n        int64_t prefix_23437;\n        bool block_new_sgm_23438;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_23343 == 0) {\n                dynamic_id_23370 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_23340)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_23354)[(int64_t) 0] = dynamic_id_23370;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_23370 == num_virt_blocks_23324 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_23340)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_23370 = ((__local int32_t *) local_mem_23354)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_23371 = dynamic_id_23370 * chunk_sizze_23323 * segscan_tblock_sizze_22629;\n        sgm_idx", "_23372 = smod64(block_offset_23371, loop_dz2083Uz2082U_21002);\n        boundary_23373 = sext_i64_i32(smin64(chunk_sizze_23323 * segscan_tblock_sizze_22629, loop_dz2083Uz2082U_21002 - sgm_idx_23372));\n        segsizze_compact_23374 = sext_i64_i32(smin64(chunk_sizze_23323 * segscan_tblock_sizze_22629, loop_dz2083Uz2082U_21002));\n        thd_offset_23381 = block_offset_23371 + sext_i32_i64(local_tid_23343);\n        // Load and map\n        {\n            for (int64_t i_23382 = 0; i_23382 < chunk_sizze_23323; i_23382++) {\n                int64_t virt_tid_23383 = thd_offset_23381 + i_23382 * segscan_tblock_sizze_22629;\n                int64_t slice_23384 = loop_dz2083Uz2082U_21002;\n                int64_t gtid_22633 = virt_tid_23383;\n                int64_t remnant_23385 = virt_tid_23383 - gtid_22633;\n                \n                if (slt64(virt_tid_23383, loop_dz2083Uz2082U_21002)) {\n                    int32_t eta_p_21762 = ((__global int32_t *) mem_param_22790)[gtid_22633];\n                    int64_t ii_21767 = sext_i32_i64(eta_p_21762);\n                    bool x_21768 = sle64((int64_t) 0, ii_21767);\n                    bool y_21769 = slt64(ii_21767, mz2080U_19405);\n                    bool bounds_check_21770 = x_21768 && y_21769;\n                    bool index_certs_21771;\n                    \n                    if (!bounds_check_21770) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                                global_failure_args[0] = (int64_t) ii_21767;\n                                global_failure_args[1] = (int64_t) mz2080U_19405;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    float eta_p_21761 = ((__global float *) mem_param_22793)[gtid_22633];\n                    float pred_arg1_21772 = ((__g",
                                    "lobal float *) mem_22802)[ii_21767];\n                    bool defunc_0_pred_res_21773 = eta_p_21761 < pred_arg1_21772;\n                    int64_t defunc_0_f_res_21774 = btoi_bool_i64(defunc_0_pred_res_21773);\n                    bool defunc_0_pred_res_21783 = eta_p_21761 == pred_arg1_21772;\n                    int64_t defunc_0_f_res_21784 = btoi_bool_i64(defunc_0_pred_res_21783);\n                    bool defunc_0_pred_res_21794 = pred_arg1_21772 < eta_p_21761;\n                    int64_t defunc_0_f_res_21795 = btoi_bool_i64(defunc_0_pred_res_21794);\n                    \n                    ((__global int64_t *) mem_22811)[gtid_22633] = defunc_0_f_res_21795;\n                    ((__global int64_t *) mem_22813)[gtid_22633] = defunc_0_f_res_21784;\n                    ((__global int64_t *) mem_22815)[gtid_22633] = defunc_0_f_res_21774;\n                    private_mem_23375[i_23382] = defunc_0_f_res_21774;\n                    private_mem_23377[i_23382] = defunc_0_f_res_21784;\n                    private_mem_23379[i_23382] = defunc_0_f_res_21795;\n                } else {\n                    private_mem_23375[i_23382] = (int64_t) 0;\n                    private_mem_23377[i_23382] = (int64_t) 0;\n                    private_mem_23379[i_23382] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_23386 = 0; i_23386 < chunk_sizze_23323; i_23386++) {\n                int64_t sharedIdx_23387 = sext_i32_i64(local_tid_23343) + i_23386 * segscan_tblock_sizze_22629;\n                int64_t tmp_23388 = private_mem_23375[i_23386];\n                \n                ((__local int64_t *) local_mem_23354)[sharedIdx_23387] = tmp_23388;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23389 = 0; i_23389 < chunk_sizze_23323; i_23389++) {\n      ", "          int64_t sharedIdx_23390 = sext_i32_i64(local_tid_23343) * chunk_sizze_23323 + i_23389;\n                int64_t tmp_23391 = ((__local int64_t *) local_mem_23354)[sharedIdx_23390];\n                \n                private_mem_23375[i_23389] = tmp_23391;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23392 = 0; i_23392 < chunk_sizze_23323; i_23392++) {\n                int64_t sharedIdx_23393 = sext_i32_i64(local_tid_23343) + i_23392 * segscan_tblock_sizze_22629;\n                int64_t tmp_23394 = private_mem_23377[i_23392];\n                \n                ((__local int64_t *) local_mem_23354)[sharedIdx_23393] = tmp_23394;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23395 = 0; i_23395 < chunk_sizze_23323; i_23395++) {\n                int64_t sharedIdx_23396 = sext_i32_i64(local_tid_23343) * chunk_sizze_23323 + i_23395;\n                int64_t tmp_23397 = ((__local int64_t *) local_mem_23354)[sharedIdx_23396];\n                \n                private_mem_23377[i_23395] = tmp_23397;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23398 = 0; i_23398 < chunk_sizze_23323; i_23398++) {\n                int64_t sharedIdx_23399 = sext_i32_i64(local_tid_23343) + i_23398 * segscan_tblock_sizze_22629;\n                int64_t tmp_23400 = private_mem_23379[i_23398];\n                \n                ((__local int64_t *) local_mem_23354)[sharedIdx_23399] = tmp_23400;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23401 = 0; i_23401 < chunk_sizze_23323; i_23401++) {\n                int64_t sharedIdx_23402 = sext_i32_i64(local_tid_23343) * chunk_sizze_23323 + i_23401;\n                int64_t tmp_23403 = ((__local int64_t *) local_mem_23354)[sharedIdx_23402];\n                \n                private_mem_23379[i_23401] = tmp_23403;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n ", "           for (int64_t i_23404 = 0; i_23404 < chunk_sizze_23323 - (int64_t) 1; i_23404++) {\n                int64_t eta_p_21039;\n                int64_t eta_p_21040;\n                \n                eta_p_21039 = private_mem_23375[i_23404];\n                eta_p_21040 = private_mem_23375[i_23404 + (int64_t) 1];\n                \n                int64_t eta_p_21088;\n                int64_t eta_p_21089;\n                \n                eta_p_21088 = private_mem_23377[i_23404];\n                eta_p_21089 = private_mem_23377[i_23404 + (int64_t) 1];\n                \n                int64_t eta_p_21129;\n                int64_t eta_p_21130;\n                \n                eta_p_21129 = private_mem_23379[i_23404];\n                eta_p_21130 = private_mem_23379[i_23404 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_21041 = add64(eta_p_21039, eta_p_21040);\n                int64_t defunc_0_op_res_21090 = add64(eta_p_21088, eta_p_21089);\n                int64_t defunc_0_op_res_21131 = add64(eta_p_21129, eta_p_21130);\n                \n                private_mem_23375[i_23404 + (int64_t) 1] = defunc_0_op_res_21041;\n                private_mem_23377[i_23404 + (int64_t) 1] = defunc_0_op_res_21090;\n                private_mem_23379[i_23404 + (int64_t) 1] = defunc_0_op_res_21131;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_23405 = private_mem_23375[chunk_sizze_23323 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)] = tmp_23405;\n            \n            int64_t tmp_23406 = private_mem_23377[chunk_sizze_23323 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = tmp_23406;\n            \n            int64_t tmp_23407 = private_mem_23379[chunk_sizze_23323 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_23354)[squot64(byt",
                                    "e_offsets_23349, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = tmp_23407;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_23408;\n            int64_t eta_p_23409;\n            int64_t eta_p_23410;\n            int64_t eta_p_23411;\n            int64_t eta_p_23412;\n            int64_t eta_p_23413;\n            int64_t eta_p_23420;\n            int64_t eta_p_23421;\n            int64_t eta_p_23422;\n            int64_t eta_p_23423;\n            int64_t eta_p_23424;\n            int64_t eta_p_23425;\n            bool ltid_in_bounds_23429 = slt64(sext_i32_i64(local_tid_23343), num_virt_threads_23325);\n            int32_t skip_threads_23430;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23429) {\n                    eta_p_23411 = ((volatile __local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)];\n                    eta_p_23412 = ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + sext_i32_i64(local_tid_23343)];\n                    eta_p_23413 = ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + sext_i32_i64(local_tid_23343)];\n                    if ((local_tid_23343 - squot32(local_tid_23343, 32) * 32) == 0) {\n                        eta_p_23408 = eta_p_23411;\n                        eta_p_23409 = eta_p_23412;\n                        eta_p_23410 = eta_p_23413;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23430 = 1;\n                while (slt32(skip_threads_23430, 32)) {\n                    bool thread_active_23431 = sle32(skip_threads_23430, local_tid_23343 - squot32(local_tid_23343, 32) * 32) && ltid_in_bounds_23429;\n                    \n                    if (thread_active_23431) {\n                        // read operands\n                    ", "    {\n                            eta_p_23408 = ((volatile __local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23430)];\n                            eta_p_23409 = ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + (sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23430))];\n                            eta_p_23410 = ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + (sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23430))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23431) {\n                            int64_t defunc_0_op_res_23414 = add64(eta_p_23408, eta_p_23411);\n                            int64_t defunc_0_op_res_23415 = add64(eta_p_23409, eta_p_23412);\n                            int64_t defunc_0_op_res_23416 = add64(eta_p_23410, eta_p_23413);\n                            \n                            eta_p_23408 = defunc_0_op_res_23414;\n                            eta_p_23409 = defunc_0_op_res_23415;\n                            eta_p_23410 = defunc_0_op_res_23416;\n                        }\n                    }\n                    if (sle32(wave_sizze_23345, skip_threads_23430)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23431) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)] = eta_p_23408;\n                            eta_p_23411 = eta_p_23408;\n                            ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23409;\n                            eta_p_23412 = eta_p_23409;\n                            ((volatile __local int64_t *) local_mem_", "23354)[squot64(byte_offsets_23349, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23410;\n                            eta_p_23413 = eta_p_23410;\n                        }\n                    }\n                    if (sle32(wave_sizze_23345, skip_threads_23430)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23430 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_23343 - squot32(local_tid_23343, 32) * 32) == 31 && ltid_in_bounds_23429) {\n                    ((volatile __local int64_t *) local_mem_23354)[sext_i32_i64(squot32(local_tid_23343, 32))] = eta_p_23408;\n                    ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + sext_i32_i64(squot32(local_tid_23343, 32))] = eta_p_23409;\n                    ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + sext_i32_i64(squot32(local_tid_23343, 32))] = eta_p_23410;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23432;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_23343, 32) == 0 && ltid_in_bounds_23429) {\n                        eta_p_23423 = ((volatile __local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)];\n                        eta_p_23424 = ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + sext_i32_i64(local_tid_23343)];\n                        eta_p_23425 = ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + sext_i32_i64(local_tid_23343)];\n                        if ((local_tid_23343 - ",
                                    "squot32(local_tid_23343, 32) * 32) == 0) {\n                            eta_p_23420 = eta_p_23423;\n                            eta_p_23421 = eta_p_23424;\n                            eta_p_23422 = eta_p_23425;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23432 = 1;\n                    while (slt32(skip_threads_23432, 32)) {\n                        bool thread_active_23433 = sle32(skip_threads_23432, local_tid_23343 - squot32(local_tid_23343, 32) * 32) && (squot32(local_tid_23343, 32) == 0 && ltid_in_bounds_23429);\n                        \n                        if (thread_active_23433) {\n                            // read operands\n                            {\n                                eta_p_23420 = ((volatile __local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23432)];\n                                eta_p_23421 = ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + (sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23432))];\n                                eta_p_23422 = ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + (sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23432))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_23433) {\n                                int64_t defunc_0_op_res_23426 = add64(eta_p_23420, eta_p_23423);\n                                int64_t defunc_0_op_res_23427 = add64(eta_p_23421, eta_p_23424);\n                                int64_t defunc_0_op_res_23428 = add64(eta_p_23422, eta_p_23425);\n                                \n                                eta_p_23420 = defunc_0_op_res_23426;\n                                eta_p_23421 = defu", "nc_0_op_res_23427;\n                                eta_p_23422 = defunc_0_op_res_23428;\n                            }\n                        }\n                        if (sle32(wave_sizze_23345, skip_threads_23432)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23433) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)] = eta_p_23420;\n                                eta_p_23423 = eta_p_23420;\n                                ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23421;\n                                eta_p_23424 = eta_p_23421;\n                                ((volatile __local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23422;\n                                eta_p_23425 = eta_p_23422;\n                            }\n                        }\n                        if (sle32(wave_sizze_23345, skip_threads_23432)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23432 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23434 = squot32(local_tid_23343, 32) == 0 || !ltid_in_bounds_23429;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23434) {\n                        eta_p_23411 = eta_p_23408;\n                        eta_p_23412 = eta_p_23409;\n                        eta_p_23413 = eta_p_23410;\n                        eta_p_23408 = ((__local int64_t *) local_mem_23354)[sext_i32_i64(squot32(local_tid_23343, 32)) - (int64_t)", " 1];\n                        eta_p_23409 = ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_23343, 32)) - (int64_t) 1)];\n                        eta_p_23410 = ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_23343, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23434) {\n                        int64_t defunc_0_op_res_23414 = add64(eta_p_23408, eta_p_23411);\n                        int64_t defunc_0_op_res_23415 = add64(eta_p_23409, eta_p_23412);\n                        int64_t defunc_0_op_res_23416 = add64(eta_p_23410, eta_p_23413);\n                        \n                        eta_p_23408 = defunc_0_op_res_23414;\n                        eta_p_23409 = defunc_0_op_res_23415;\n                        eta_p_23410 = defunc_0_op_res_23416;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_23434) {\n                        ((__local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)] = eta_p_23408;\n                        ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23409;\n                        ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23410;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_23343, 32) == 0 && ltid_in_bounds_23429) {\n                    ((__local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)] = eta_p_23411;\n                    ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + sext_i32_i64(loca",
                                    "l_tid_23343)] = eta_p_23412;\n                    ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23413;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_23343 == 0) {\n                acc_23417 = ((__local int64_t *) local_mem_23354)[segscan_tblock_sizze_22629 - (int64_t) 1];\n                acc_23418 = ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + (segscan_tblock_sizze_22629 - (int64_t) 1)];\n                acc_23419 = ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + (segscan_tblock_sizze_22629 - (int64_t) 1)];\n            } else {\n                acc_23417 = ((__local int64_t *) local_mem_23354)[sext_i32_i64(local_tid_23343) - (int64_t) 1];\n                acc_23418 = ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23348, (int64_t) 8) + (sext_i32_i64(local_tid_23343) - (int64_t) 1)];\n                acc_23419 = ((__local int64_t *) local_mem_23354)[squot64(byte_offsets_23349, (int64_t) 8) + (sext_i32_i64(local_tid_23343) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23435 = (int64_t) 0;\n        prefix_23436 = (int64_t) 0;\n        prefix_23437 = (int64_t) 0;\n        block_new_sgm_23438 = sgm_idx_23372 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23438 && local_tid_23343 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_23330)[dynamic_id_23370] = acc_23417;\n                ((volatile __global int64_t *) incprefixes_mem_23334)[dynamic_id_23370] = acc_23418;\n                ((volatile __global int64_t *) incprefixes_mem_23338)[dynamic_id_23370] = acc_23419;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23326)[dynamic_id_23370] = (int8_t) 2;\n                acc_23417 = ", "(int64_t) 0;\n                acc_23418 = (int64_t) 0;\n                acc_23419 = (int64_t) 0;\n            }\n            if (!block_new_sgm_23438 && slt32(local_tid_23343, wave_sizze_23345)) {\n                if (local_tid_23343 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_23328)[dynamic_id_23370] = acc_23417;\n                    ((volatile __global int64_t *) aggregates_mem_23332)[dynamic_id_23370] = acc_23418;\n                    ((volatile __global int64_t *) aggregates_mem_23336)[dynamic_id_23370] = acc_23419;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23326)[dynamic_id_23370] = (int8_t) 1;\n                    \n                    int8_t tmp_23439 = ((volatile __global int8_t *) status_flags_mem_23326)[dynamic_id_23370 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_23354)[(int64_t) 0] = tmp_23439;\n                }\n                mem_fence_local();\n                \n                int8_t status_23440 = ((__local int8_t *) local_mem_23354)[(int64_t) 0];\n                \n                if (status_23440 == (int8_t) 2) {\n                    if (local_tid_23343 == 0) {\n                        prefix_23435 = ((volatile __global int64_t *) incprefixes_mem_23330)[dynamic_id_23370 - (int64_t) 1];\n                        prefix_23436 = ((volatile __global int64_t *) incprefixes_mem_23334)[dynamic_id_23370 - (int64_t) 1];\n                        prefix_23437 = ((volatile __global int64_t *) incprefixes_mem_23338)[dynamic_id_23370 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23441 = sext_i64_i32(dynamic_id_23370 - sext_i32_i64(wave_sizze_23345));\n                    \n                    while (slt32(wave_sizze_23345 * -1, readOffset_23441)) {\n                        int32_t read_i_23442 = readOffset_23441 + local_tid_23343;\n                        int64_t aggr_23443 = (int64_t", ") 0;\n                        int64_t aggr_23444 = (int64_t) 0;\n                        int64_t aggr_23445 = (int64_t) 0;\n                        int8_t flag_23446 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23442)) {\n                            flag_23446 = ((volatile __global int8_t *) status_flags_mem_23326)[sext_i32_i64(read_i_23442)];\n                            if (flag_23446 == (int8_t) 2) {\n                                aggr_23443 = ((volatile __global int64_t *) incprefixes_mem_23330)[sext_i32_i64(read_i_23442)];\n                                aggr_23444 = ((volatile __global int64_t *) incprefixes_mem_23334)[sext_i32_i64(read_i_23442)];\n                                aggr_23445 = ((volatile __global int64_t *) incprefixes_mem_23338)[sext_i32_i64(read_i_23442)];\n                            } else if (flag_23446 == (int8_t) 1) {\n                                aggr_23443 = ((volatile __global int64_t *) aggregates_mem_23328)[sext_i32_i64(read_i_23442)];\n                                aggr_23444 = ((volatile __global int64_t *) aggregates_mem_23332)[sext_i32_i64(read_i_23442)];\n                                aggr_23445 = ((volatile __global int64_t *) aggregates_mem_23336)[sext_i32_i64(read_i_23442)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_23354)[(int64_t) 4 + sext_i32_i64(local_tid_23343)] = aggr_23443;\n                        ((__local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23351, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = aggr_23444;\n                        ((__local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23352, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = aggr_23445;\n                        ((__local int8_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)] = flag_23446;\n                        flag_23446 = ((__local int8_t *) local_mem_23354)[sext_i32_i64(wave_sizze_23345) - (int64_t) 1];\n                ",
                                    "        if (slt8(flag_23446, (int8_t) 2)) {\n                            int8_t flg_x_23456;\n                            int8_t flg_y_23457;\n                            int64_t eta_p_23447;\n                            int64_t eta_p_23448;\n                            int64_t eta_p_23449;\n                            int64_t eta_p_23450;\n                            int64_t eta_p_23451;\n                            int64_t eta_p_23452;\n                            int32_t skip_threads_23458;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23457 = ((volatile __local int8_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)];\n                                eta_p_23450 = ((volatile __local int64_t *) local_mem_23354)[(int64_t) 4 + sext_i32_i64(local_tid_23343)];\n                                eta_p_23451 = ((volatile __local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23351, (int64_t) 8) + sext_i32_i64(local_tid_23343)];\n                                eta_p_23452 = ((volatile __local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23352, (int64_t) 8) + sext_i32_i64(local_tid_23343)];\n                                if ((local_tid_23343 - squot32(local_tid_23343, 32) * 32) == 0) {\n                                    eta_p_23447 = eta_p_23450;\n                                    eta_p_23448 = eta_p_23451;\n                                    eta_p_23449 = eta_p_23452;\n                                    flg_x_23456 = flg_y_23457;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23458 = 1;\n                                while (slt32(skip_threads_23458, 32)) {\n                                    if (sle32(skip_threads_23458, local_tid_23343 - squot32(local_tid_23343, 32) * 32)) {\n              ", "                          // read operands\n                                        {\n                                            flg_x_23456 = ((volatile __local int8_t *) local_mem_23354)[sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23458)];\n                                            eta_p_23447 = ((volatile __local int64_t *) local_mem_23354)[(int64_t) 4 + (sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23458))];\n                                            eta_p_23448 = ((volatile __local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23351, (int64_t) 8) + (sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23458))];\n                                            eta_p_23449 = ((volatile __local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23352, (int64_t) 8) + (sext_i32_i64(local_tid_23343) - sext_i32_i64(skip_threads_23458))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23457 == (int8_t) 2 || flg_y_23457 == (int8_t) 0) {\n                                                flg_x_23456 = flg_y_23457;\n                                                eta_p_23447 = eta_p_23450;\n                                                eta_p_23448 = eta_p_23451;\n                                                eta_p_23449 = eta_p_23452;\n                                            } else {\n                                                int64_t defunc_0_op_res_23453 = add64(eta_p_23447, eta_p_23450);\n                                                int64_t defunc_0_op_res_23454 = add64(eta_p_23448, eta_p_23451);\n                                                int64_t defunc_0_op_res_23455 = add64(eta_p_23449, eta_p_23452);\n                                                \n                                                eta_p_23447 = defunc_0_op_res_23453;\n                                     ", "           eta_p_23448 = defunc_0_op_res_23454;\n                                                eta_p_23449 = defunc_0_op_res_23455;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_23354)[sext_i32_i64(local_tid_23343)] = flg_x_23456;\n                                            flg_y_23457 = flg_x_23456;\n                                            ((volatile __local int64_t *) local_mem_23354)[(int64_t) 4 + sext_i32_i64(local_tid_23343)] = eta_p_23447;\n                                            eta_p_23450 = eta_p_23447;\n                                            ((volatile __local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23351, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23448;\n                                            eta_p_23451 = eta_p_23448;\n                                            ((volatile __local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23352, (int64_t) 8) + sext_i32_i64(local_tid_23343)] = eta_p_23449;\n                                            eta_p_23452 = eta_p_23449;\n                                        }\n                                    }\n                                    skip_threads_23458 *= 2;\n                                }\n                            }\n                        }\n                        flag_23446 = ((__local int8_t *) local_mem_23354)[sext_i32_i64(wave_sizze_23345) - (int64_t) 1];\n                        aggr_23443 = ((__local int64_t *) local_mem_23354)[(int64_t) 4 + (sext_i32_i64(wave_sizze_23345) - (int64_t) 1)];\n                        aggr_23444 = ((__local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23351, (int64_t) 8) + (sext_i32_i64(wave_sizze_23345) - (int64_t) 1)];\n                        aggr_23445 = ((__local int64_t *) local_mem_23354)[squot6",
                                    "4(warp_byte_offset_23352, (int64_t) 8) + (sext_i32_i64(wave_sizze_23345) - (int64_t) 1)];\n                        if (flag_23446 == (int8_t) 2) {\n                            readOffset_23441 = wave_sizze_23345 * -1;\n                        } else if (flag_23446 == (int8_t) 1) {\n                            readOffset_23441 -= wave_sizze_23345;\n                        }\n                        if (slt8((int8_t) 0, flag_23446)) {\n                            int64_t eta_p_23459 = aggr_23443;\n                            int64_t eta_p_23460 = aggr_23444;\n                            int64_t eta_p_23461 = aggr_23445;\n                            int64_t eta_p_23462 = prefix_23435;\n                            int64_t eta_p_23463 = prefix_23436;\n                            int64_t eta_p_23464 = prefix_23437;\n                            int64_t defunc_0_op_res_23465 = add64(eta_p_23459, eta_p_23462);\n                            int64_t defunc_0_op_res_23466 = add64(eta_p_23460, eta_p_23463);\n                            int64_t defunc_0_op_res_23467 = add64(eta_p_23461, eta_p_23464);\n                            \n                            prefix_23435 = defunc_0_op_res_23465;\n                            prefix_23436 = defunc_0_op_res_23466;\n                            prefix_23437 = defunc_0_op_res_23467;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_23343 == 0) {\n                    if (boundary_23373 == sext_i64_i32(segscan_tblock_sizze_22629 * chunk_sizze_23323)) {\n                        int64_t eta_p_23468 = prefix_23435;\n                        int64_t eta_p_23469 = prefix_23436;\n                        int64_t eta_p_23470 = prefix_23437;\n                        int64_t eta_p_23471 = acc_23417;\n                        int64_t eta_p_23472 = acc_23418;\n                        int64_t eta_p_23473 = acc_23419;\n                        int64_t defunc_0_op_res_23474 = add64(eta_p_23468, ", "eta_p_23471);\n                        int64_t defunc_0_op_res_23475 = add64(eta_p_23469, eta_p_23472);\n                        int64_t defunc_0_op_res_23476 = add64(eta_p_23470, eta_p_23473);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_23330)[dynamic_id_23370] = defunc_0_op_res_23474;\n                        ((volatile __global int64_t *) incprefixes_mem_23334)[dynamic_id_23370] = defunc_0_op_res_23475;\n                        ((volatile __global int64_t *) incprefixes_mem_23338)[dynamic_id_23370] = defunc_0_op_res_23476;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23326)[dynamic_id_23370] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_23354)[(int64_t) 4] = prefix_23435;\n                    ((__local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23351, (int64_t) 8)] = prefix_23436;\n                    ((__local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23352, (int64_t) 8)] = prefix_23437;\n                    acc_23417 = (int64_t) 0;\n                    acc_23418 = (int64_t) 0;\n                    acc_23419 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_23370 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23435 = ((__local int64_t *) local_mem_23354)[(int64_t) 4];\n                prefix_23436 = ((__local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23351, (int64_t) 8)];\n                prefix_23437 = ((__local int64_t *) local_mem_23354)[squot64(warp_byte_offset_23352, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_23477;\n            int64_t eta_p_23480;\n            int64_t eta_p_23486 = prefix_23435;\n            int64_t eta_p_23489 = acc_23417;\n            int64_t eta_p_23478;\n            int64_t eta_p_23481;\n", "            int64_t eta_p_23487 = prefix_23436;\n            int64_t eta_p_23490 = acc_23418;\n            int64_t eta_p_23479;\n            int64_t eta_p_23482;\n            int64_t eta_p_23488 = prefix_23437;\n            int64_t eta_p_23491 = acc_23419;\n            \n            if (slt32(local_tid_23343 * chunk_sizze_32b_23347, boundary_23373) && !block_new_sgm_23438) {\n                int64_t defunc_0_op_res_23492 = add64(eta_p_23486, eta_p_23489);\n                int64_t defunc_0_op_res_23493 = add64(eta_p_23487, eta_p_23490);\n                int64_t defunc_0_op_res_23494 = add64(eta_p_23488, eta_p_23491);\n                \n                eta_p_23477 = defunc_0_op_res_23492;\n                eta_p_23478 = defunc_0_op_res_23493;\n                eta_p_23479 = defunc_0_op_res_23494;\n            } else {\n                eta_p_23477 = acc_23417;\n                eta_p_23478 = acc_23418;\n                eta_p_23479 = acc_23419;\n            }\n            \n            int32_t stopping_point_23495 = segsizze_compact_23374 - srem32(local_tid_23343 * chunk_sizze_32b_23347 - 1 + segsizze_compact_23374 - boundary_23373, segsizze_compact_23374);\n            \n            for (int64_t i_23496 = 0; i_23496 < chunk_sizze_23323; i_23496++) {\n                if (slt32(sext_i64_i32(i_23496), stopping_point_23495 - 1)) {\n                    eta_p_23480 = private_mem_23375[i_23496];\n                    eta_p_23481 = private_mem_23377[i_23496];\n                    eta_p_23482 = private_mem_23379[i_23496];\n                    \n                    int64_t defunc_0_op_res_23483 = add64(eta_p_23477, eta_p_23480);\n                    int64_t defunc_0_op_res_23484 = add64(eta_p_23478, eta_p_23481);\n                    int64_t defunc_0_op_res_23485 = add64(eta_p_23479, eta_p_23482);\n                    \n                    private_mem_23375[i_23496] = defunc_0_op_res_23483;\n                    private_mem_23377[i_23496] = defunc_0_op_res_23484;\n                    private_mem_23379[i_23496] = defun",
                                    "c_0_op_res_23485;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23497 = 0; i_23497 < chunk_sizze_23323; i_23497++) {\n                int64_t sharedIdx_23498 = sext_i32_i64(local_tid_23343) * chunk_sizze_23323 + i_23497;\n                int64_t tmp_23499 = private_mem_23375[i_23497];\n                \n                ((__local int64_t *) local_mem_23354)[sharedIdx_23498] = tmp_23499;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23500 = 0; i_23500 < chunk_sizze_23323; i_23500++) {\n                int64_t flat_idx_23501 = thd_offset_23381 + i_23500 * segscan_tblock_sizze_22629;\n                int64_t slice_23502 = loop_dz2083Uz2082U_21002;\n                int64_t gtid_22633 = flat_idx_23501;\n                int64_t remnant_23503 = flat_idx_23501 - gtid_22633;\n                \n                if (slt64(flat_idx_23501, loop_dz2083Uz2082U_21002)) {\n                    int64_t tmp_23504 = ((__local int64_t *) local_mem_23354)[flat_idx_23501 - block_offset_23371];\n                    \n                    ((__global int64_t *) mem_22805)[gtid_22633] = tmp_23504;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23505 = 0; i_23505 < chunk_sizze_23323; i_23505++) {\n                int64_t sharedIdx_23506 = sext_i32_i64(local_tid_23343) * chunk_sizze_23323 + i_23505;\n                int64_t tmp_23507 = private_mem_23377[i_23505];\n                \n                ((__local int64_t *) local_mem_23354)[sharedIdx_23506] = tmp_23507;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23508 = 0; i_23508 < chunk_sizze_23323; i_23508++) {\n                int64_t flat_idx_23509 = thd_offset_23381 + i_23508 * segscan_tblock_sizze_22629;\n                int64_t slice_23510 = loop_dz2083Uz2082U_21002;\n                int64_t gtid_22633 = flat_idx_23509;\n  ", "              int64_t remnant_23511 = flat_idx_23509 - gtid_22633;\n                \n                if (slt64(flat_idx_23509, loop_dz2083Uz2082U_21002)) {\n                    int64_t tmp_23512 = ((__local int64_t *) local_mem_23354)[flat_idx_23509 - block_offset_23371];\n                    \n                    ((__global int64_t *) mem_22807)[gtid_22633] = tmp_23512;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23513 = 0; i_23513 < chunk_sizze_23323; i_23513++) {\n                int64_t sharedIdx_23514 = sext_i32_i64(local_tid_23343) * chunk_sizze_23323 + i_23513;\n                int64_t tmp_23515 = private_mem_23379[i_23513];\n                \n                ((__local int64_t *) local_mem_23354)[sharedIdx_23514] = tmp_23515;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23516 = 0; i_23516 < chunk_sizze_23323; i_23516++) {\n                int64_t flat_idx_23517 = thd_offset_23381 + i_23516 * segscan_tblock_sizze_22629;\n                int64_t slice_23518 = loop_dz2083Uz2082U_21002;\n                int64_t gtid_22633 = flat_idx_23517;\n                int64_t remnant_23519 = flat_idx_23517 - gtid_22633;\n                \n                if (slt64(flat_idx_23517, loop_dz2083Uz2082U_21002)) {\n                    int64_t tmp_23520 = ((__local int64_t *) local_mem_23354)[flat_idx_23517 - block_offset_23371];\n                    \n                    ((__global int64_t *) mem_22809)[gtid_22633] = tmp_23520;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22629\n    #undef chunk_sizze_23323\n}\nFUTHARK_KERNEL_SIZED(compilerzisegscan_22755_dim1, 1, 1)\nvoid compilerzisegscan_22755(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_19405, int64_t loop_dz2083Uz2082U_21002, int64_t num_tblocks_22752, int64_t num_virt_blocks_24033, in", "t64_t num_virt_threads_24034, __global unsigned char *mem_param_22790, __global unsigned char *mem_param_22793, __global unsigned char *mem_22802, __global unsigned char *mem_22840, __global unsigned char *mem_22843, __global unsigned char *mem_22845, __global unsigned char *status_flags_mem_24035, __global unsigned char *aggregates_mem_24037, __global unsigned char *incprefixes_mem_24039, __global unsigned char *global_dynid_mem_24041)\n{\n    #define segscan_tblock_sizze_22750 (compilerzisegscan_22755zisegscan_tblock_sizze_22750)\n    #define chunk_sizze_24032 (compilerzisegscan_22755zichunk_sizze_24032)\n    \n    volatile __local unsigned char *local_mem_24051_backing_0 = &shared_mem[0];\n    const int64_t local_mem_24051_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22750), chunk_sizze_24032 * segscan_tblock_sizze_22750 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22750), chunk_sizze_24032 * segscan_tblock_sizze_22750 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24044;\n    int32_t tblock_sizze_24047;\n    int32_t wave_sizze_24046;\n    int32_t block_id_24045;\n    int32_t global_tid_24043;\n    int64_t phys_tid_22755;\n    int32_t chunk_sizze_32b_24048;\n    int64_t byte_offsets_24049;\n    int64_t warp_byte_offset_24050;\n    __local unsigned char *local_mem_24051;\n    int64_t trans_arr_len_24052;\n    int64_t phys_block_id_24058;\n    int64_t virtloop_bound_24059;\n    \n    local_tid_24044 = get_local_id(0);\n    tblock_sizze_24047 = get_local_size(0);\n    wave_sizze_24046 = LOCKSTEP_WIDTH;\n    block_id_24045 = get_tblock_id(0);\n    global_tid_24043 = block_id_24045 * tblock_sizze_24047 + local_tid_24044;\n    phys_tid_",
                                    "22755 = sext_i32_i64(global_tid_24043);\n    chunk_sizze_32b_24048 = sext_i64_i32(chunk_sizze_24032);\n    byte_offsets_24049 = segscan_tblock_sizze_22750 * (int64_t) 8;\n    warp_byte_offset_24050 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_24051 = (__local unsigned char *) local_mem_24051_backing_0;\n    trans_arr_len_24052 = chunk_sizze_24032 * segscan_tblock_sizze_22750;\n    phys_block_id_24058 = get_tblock_id(0);\n    virtloop_bound_24059 = sdiv_up64(num_virt_blocks_24033 - phys_block_id_24058, num_tblocks_22752);\n    for (int64_t virtloop_i_24060 = 0; virtloop_i_24060 < virtloop_bound_24059; virtloop_i_24060++) {\n        int64_t dynamic_id_24061;\n        int64_t block_offset_24062;\n        int64_t sgm_idx_24063;\n        int32_t boundary_24064;\n        int32_t segsizze_compact_24065;\n        int64_t private_mem_24066[chunk_sizze_24032];\n        int64_t thd_offset_24068;\n        int64_t acc_24084;\n        int64_t prefix_24094;\n        bool block_new_sgm_24095;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_24044 == 0) {\n                dynamic_id_24061 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_24041)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_24051)[(int64_t) 0] = dynamic_id_24061;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_24061 == num_virt_blocks_24033 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_24041)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_24061 = ((__local int32_t *) local_mem_24051)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_24062 = dynamic_id_24061 * chunk_sizze_24032 * se", "gscan_tblock_sizze_22750;\n        sgm_idx_24063 = smod64(block_offset_24062, loop_dz2083Uz2082U_21002);\n        boundary_24064 = sext_i64_i32(smin64(chunk_sizze_24032 * segscan_tblock_sizze_22750, loop_dz2083Uz2082U_21002 - sgm_idx_24063));\n        segsizze_compact_24065 = sext_i64_i32(smin64(chunk_sizze_24032 * segscan_tblock_sizze_22750, loop_dz2083Uz2082U_21002));\n        thd_offset_24068 = block_offset_24062 + sext_i32_i64(local_tid_24044);\n        // Load and map\n        {\n            for (int64_t i_24069 = 0; i_24069 < chunk_sizze_24032; i_24069++) {\n                int64_t virt_tid_24070 = thd_offset_24068 + i_24069 * segscan_tblock_sizze_22750;\n                int64_t slice_24071 = loop_dz2083Uz2082U_21002;\n                int64_t gtid_22754 = virt_tid_24070;\n                int64_t remnant_24072 = virt_tid_24070 - gtid_22754;\n                \n                if (slt64(virt_tid_24070, loop_dz2083Uz2082U_21002)) {\n                    int32_t eta_p_21483 = ((__global int32_t *) mem_param_22790)[gtid_22754];\n                    int64_t ii_21484 = sext_i32_i64(eta_p_21483);\n                    bool x_21485 = sle64((int64_t) 0, ii_21484);\n                    bool y_21486 = slt64(ii_21484, mz2080U_19405);\n                    bool bounds_check_21487 = x_21485 && y_21486;\n                    bool index_certs_21488;\n                    \n                    if (!bounds_check_21487) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                                global_failure_args[0] = (int64_t) ii_21484;\n                                global_failure_args[1] = (int64_t) mz2080U_19405;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int32_t zeze_lhs_21489 = ((__global int32_t *) mem_22840)[ii_21484];\n         ", "           bool cond_21490 = zeze_lhs_21489 == -1;\n                    bool lifted_lambda_res_21491;\n                    \n                    if (cond_21490) {\n                        lifted_lambda_res_21491 = 0;\n                    } else {\n                        float eta_p_21482 = ((__global float *) mem_param_22793)[gtid_22754];\n                        bool cond_21492 = zeze_lhs_21489 == 0;\n                        bool lifted_lambda_res_f_res_21493;\n                        \n                        if (cond_21492) {\n                            float zl_rhs_21910 = ((__global float *) mem_22802)[ii_21484];\n                            bool lifted_lambda_res_f_res_t_res_21911 = eta_p_21482 < zl_rhs_21910;\n                            \n                            lifted_lambda_res_f_res_21493 = lifted_lambda_res_f_res_t_res_21911;\n                        } else {\n                            bool cond_21496 = zeze_lhs_21489 == 1;\n                            bool lifted_lambda_res_f_res_f_res_21497;\n                            \n                            if (cond_21496) {\n                                lifted_lambda_res_f_res_f_res_21497 = 0;\n                            } else {\n                                float zg_rhs_21498 = ((__global float *) mem_22802)[ii_21484];\n                                bool lifted_lambda_res_f_res_f_res_f_res_21499 = zg_rhs_21498 < eta_p_21482;\n                                \n                                lifted_lambda_res_f_res_f_res_21497 = lifted_lambda_res_f_res_f_res_f_res_21499;\n                            }\n                            lifted_lambda_res_f_res_21493 = lifted_lambda_res_f_res_f_res_21497;\n                        }\n                        lifted_lambda_res_21491 = lifted_lambda_res_f_res_21493;\n                    }\n                    \n                    int64_t defunc_0_f_res_21500 = btoi_bool_i64(lifted_lambda_res_21491);\n                    \n                    ((__global int64_t *) mem_22845)[gtid_22754]",
                                    " = defunc_0_f_res_21500;\n                    private_mem_24066[i_24069] = defunc_0_f_res_21500;\n                } else {\n                    private_mem_24066[i_24069] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_24073 = 0; i_24073 < chunk_sizze_24032; i_24073++) {\n                int64_t sharedIdx_24074 = sext_i32_i64(local_tid_24044) + i_24073 * segscan_tblock_sizze_22750;\n                int64_t tmp_24075 = private_mem_24066[i_24073];\n                \n                ((__local int64_t *) local_mem_24051)[sharedIdx_24074] = tmp_24075;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_24076 = 0; i_24076 < chunk_sizze_24032; i_24076++) {\n                int64_t sharedIdx_24077 = sext_i32_i64(local_tid_24044) * chunk_sizze_24032 + i_24076;\n                int64_t tmp_24078 = ((__local int64_t *) local_mem_24051)[sharedIdx_24077];\n                \n                private_mem_24066[i_24076] = tmp_24078;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_24079 = 0; i_24079 < chunk_sizze_24032 - (int64_t) 1; i_24079++) {\n                int64_t eta_p_21243;\n                int64_t eta_p_21244;\n                \n                eta_p_21243 = private_mem_24066[i_24079];\n                eta_p_21244 = private_mem_24066[i_24079 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_21245 = add64(eta_p_21243, eta_p_21244);\n                \n                private_mem_24066[i_24079 + (int64_t) 1] = defunc_0_op_res_21245;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_24080 = private_mem_24066[chunk_sizze_24032 - (int64_t) 1];\n            \n            ((__local int64_t *) l", "ocal_mem_24051)[sext_i32_i64(local_tid_24044)] = tmp_24080;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_24081;\n            int64_t eta_p_24082;\n            int64_t eta_p_24085;\n            int64_t eta_p_24086;\n            bool ltid_in_bounds_24088 = slt64(sext_i32_i64(local_tid_24044), num_virt_threads_24034);\n            int32_t skip_threads_24089;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_24088) {\n                    eta_p_24082 = ((volatile __local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)];\n                    if ((local_tid_24044 - squot32(local_tid_24044, 32) * 32) == 0) {\n                        eta_p_24081 = eta_p_24082;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_24089 = 1;\n                while (slt32(skip_threads_24089, 32)) {\n                    bool thread_active_24090 = sle32(skip_threads_24089, local_tid_24044 - squot32(local_tid_24044, 32) * 32) && ltid_in_bounds_24088;\n                    \n                    if (thread_active_24090) {\n                        // read operands\n                        {\n                            eta_p_24081 = ((volatile __local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044) - sext_i32_i64(skip_threads_24089)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_24090) {\n                            int64_t defunc_0_op_res_24083 = add64(eta_p_24081, eta_p_24082);\n                            \n                            eta_p_24081 = defunc_0_op_res_24083;\n                        }\n                    }\n                    if (sle32(wave_sizze_24046, skip_threads_24089)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n          ", "          }\n                    if (thread_active_24090) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)] = eta_p_24081;\n                            eta_p_24082 = eta_p_24081;\n                        }\n                    }\n                    if (sle32(wave_sizze_24046, skip_threads_24089)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_24089 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_24044 - squot32(local_tid_24044, 32) * 32) == 31 && ltid_in_bounds_24088) {\n                    ((volatile __local int64_t *) local_mem_24051)[sext_i32_i64(squot32(local_tid_24044, 32))] = eta_p_24081;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_24091;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_24044, 32) == 0 && ltid_in_bounds_24088) {\n                        eta_p_24086 = ((volatile __local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)];\n                        if ((local_tid_24044 - squot32(local_tid_24044, 32) * 32) == 0) {\n                            eta_p_24085 = eta_p_24086;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_24091 = 1;\n                    while (slt32(skip_threads_24091, 32)) {\n                        bool thread_active_24092 = sle32(skip_threads_24091, local_tid_24044 - squot32(local_tid_24044, 32) * 32) && (squot32(local_tid_24044,",
                                    " 32) == 0 && ltid_in_bounds_24088);\n                        \n                        if (thread_active_24092) {\n                            // read operands\n                            {\n                                eta_p_24085 = ((volatile __local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044) - sext_i32_i64(skip_threads_24091)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_24092) {\n                                int64_t defunc_0_op_res_24087 = add64(eta_p_24085, eta_p_24086);\n                                \n                                eta_p_24085 = defunc_0_op_res_24087;\n                            }\n                        }\n                        if (sle32(wave_sizze_24046, skip_threads_24091)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_24092) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)] = eta_p_24085;\n                                eta_p_24086 = eta_p_24085;\n                            }\n                        }\n                        if (sle32(wave_sizze_24046, skip_threads_24091)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_24091 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_24093 = squot32(local_tid_24044, 32) == 0 || !ltid_in_bounds_24088;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_24093) {\n                        eta_p_24082 = eta_p_24081;\n                        eta_p_24081 = ((__loca", "l int64_t *) local_mem_24051)[sext_i32_i64(squot32(local_tid_24044, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_24093) {\n                        int64_t defunc_0_op_res_24083 = add64(eta_p_24081, eta_p_24082);\n                        \n                        eta_p_24081 = defunc_0_op_res_24083;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_24093) {\n                        ((__local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)] = eta_p_24081;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_24044, 32) == 0 && ltid_in_bounds_24088) {\n                    ((__local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)] = eta_p_24082;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_24044 == 0) {\n                acc_24084 = ((__local int64_t *) local_mem_24051)[segscan_tblock_sizze_22750 - (int64_t) 1];\n            } else {\n                acc_24084 = ((__local int64_t *) local_mem_24051)[sext_i32_i64(local_tid_24044) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_24094 = (int64_t) 0;\n        block_new_sgm_24095 = sgm_idx_24063 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_24095 && local_tid_24044 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_24039)[dynamic_id_24061] = acc_24084;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_24035)[dynamic_id_24061] = (int8_t) 2;\n                acc_24084 = (int64_t) 0;\n            }\n            if (!block_new_sgm_24095 && s", "lt32(local_tid_24044, wave_sizze_24046)) {\n                if (local_tid_24044 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_24037)[dynamic_id_24061] = acc_24084;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_24035)[dynamic_id_24061] = (int8_t) 1;\n                    \n                    int8_t tmp_24096 = ((volatile __global int8_t *) status_flags_mem_24035)[dynamic_id_24061 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_24051)[(int64_t) 0] = tmp_24096;\n                }\n                mem_fence_local();\n                \n                int8_t status_24097 = ((__local int8_t *) local_mem_24051)[(int64_t) 0];\n                \n                if (status_24097 == (int8_t) 2) {\n                    if (local_tid_24044 == 0) {\n                        prefix_24094 = ((volatile __global int64_t *) incprefixes_mem_24039)[dynamic_id_24061 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_24098 = sext_i64_i32(dynamic_id_24061 - sext_i32_i64(wave_sizze_24046));\n                    \n                    while (slt32(wave_sizze_24046 * -1, readOffset_24098)) {\n                        int32_t read_i_24099 = readOffset_24098 + local_tid_24044;\n                        int64_t aggr_24100 = (int64_t) 0;\n                        int8_t flag_24101 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_24099)) {\n                            flag_24101 = ((volatile __global int8_t *) status_flags_mem_24035)[sext_i32_i64(read_i_24099)];\n                            if (flag_24101 == (int8_t) 2) {\n                                aggr_24100 = ((volatile __global int64_t *) incprefixes_mem_24039)[sext_i32_i64(read_i_24099)];\n                            } else if (flag_24101 == (int8_t) 1) {\n                                aggr_24100 = ((volatile __global int64_t *) aggregates_mem_",
                                    "24037)[sext_i32_i64(read_i_24099)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_24051)[(int64_t) 4 + sext_i32_i64(local_tid_24044)] = aggr_24100;\n                        ((__local int8_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)] = flag_24101;\n                        flag_24101 = ((__local int8_t *) local_mem_24051)[sext_i32_i64(wave_sizze_24046) - (int64_t) 1];\n                        if (slt8(flag_24101, (int8_t) 2)) {\n                            int8_t flg_x_24105;\n                            int8_t flg_y_24106;\n                            int64_t eta_p_24102;\n                            int64_t eta_p_24103;\n                            int32_t skip_threads_24107;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_24106 = ((volatile __local int8_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)];\n                                eta_p_24103 = ((volatile __local int64_t *) local_mem_24051)[(int64_t) 4 + sext_i32_i64(local_tid_24044)];\n                                if ((local_tid_24044 - squot32(local_tid_24044, 32) * 32) == 0) {\n                                    eta_p_24102 = eta_p_24103;\n                                    flg_x_24105 = flg_y_24106;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_24107 = 1;\n                                while (slt32(skip_threads_24107, 32)) {\n                                    if (sle32(skip_threads_24107, local_tid_24044 - squot32(local_tid_24044, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_24105 = ((volatile __local int8_t *) local_mem_24051)[sext_i32_i64(local_ti", "d_24044) - sext_i32_i64(skip_threads_24107)];\n                                            eta_p_24102 = ((volatile __local int64_t *) local_mem_24051)[(int64_t) 4 + (sext_i32_i64(local_tid_24044) - sext_i32_i64(skip_threads_24107))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_24106 == (int8_t) 2 || flg_y_24106 == (int8_t) 0) {\n                                                flg_x_24105 = flg_y_24106;\n                                                eta_p_24102 = eta_p_24103;\n                                            } else {\n                                                int64_t defunc_0_op_res_24104 = add64(eta_p_24102, eta_p_24103);\n                                                \n                                                eta_p_24102 = defunc_0_op_res_24104;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_24051)[sext_i32_i64(local_tid_24044)] = flg_x_24105;\n                                            flg_y_24106 = flg_x_24105;\n                                            ((volatile __local int64_t *) local_mem_24051)[(int64_t) 4 + sext_i32_i64(local_tid_24044)] = eta_p_24102;\n                                            eta_p_24103 = eta_p_24102;\n                                        }\n                                    }\n                                    skip_threads_24107 *= 2;\n                                }\n                            }\n                        }\n                        flag_24101 = ((__local int8_t *) local_mem_24051)[sext_i32_i64(wave_sizze_24046) - (int64_t) 1];\n                        aggr_24100 = ((__local int64_t *) local_mem_24051)[(int64_t) 4 + (sext_i32", "_i64(wave_sizze_24046) - (int64_t) 1)];\n                        if (flag_24101 == (int8_t) 2) {\n                            readOffset_24098 = wave_sizze_24046 * -1;\n                        } else if (flag_24101 == (int8_t) 1) {\n                            readOffset_24098 -= wave_sizze_24046;\n                        }\n                        if (slt8((int8_t) 0, flag_24101)) {\n                            int64_t eta_p_24108 = aggr_24100;\n                            int64_t eta_p_24109 = prefix_24094;\n                            int64_t defunc_0_op_res_24110 = add64(eta_p_24108, eta_p_24109);\n                            \n                            prefix_24094 = defunc_0_op_res_24110;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_24044 == 0) {\n                    if (boundary_24064 == sext_i64_i32(segscan_tblock_sizze_22750 * chunk_sizze_24032)) {\n                        int64_t eta_p_24111 = prefix_24094;\n                        int64_t eta_p_24112 = acc_24084;\n                        int64_t defunc_0_op_res_24113 = add64(eta_p_24111, eta_p_24112);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_24039)[dynamic_id_24061] = defunc_0_op_res_24113;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_24035)[dynamic_id_24061] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_24051)[(int64_t) 4] = prefix_24094;\n                    acc_24084 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_24061 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_24094 = ((__local int64_t *) local_mem_24051)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_24114;\n            int64_t eta_p_24",
                                    "115;\n            int64_t eta_p_24117 = prefix_24094;\n            int64_t eta_p_24118 = acc_24084;\n            \n            if (slt32(local_tid_24044 * chunk_sizze_32b_24048, boundary_24064) && !block_new_sgm_24095) {\n                int64_t defunc_0_op_res_24119 = add64(eta_p_24117, eta_p_24118);\n                \n                eta_p_24114 = defunc_0_op_res_24119;\n            } else {\n                eta_p_24114 = acc_24084;\n            }\n            \n            int32_t stopping_point_24120 = segsizze_compact_24065 - srem32(local_tid_24044 * chunk_sizze_32b_24048 - 1 + segsizze_compact_24065 - boundary_24064, segsizze_compact_24065);\n            \n            for (int64_t i_24121 = 0; i_24121 < chunk_sizze_24032; i_24121++) {\n                if (slt32(sext_i64_i32(i_24121), stopping_point_24120 - 1)) {\n                    eta_p_24115 = private_mem_24066[i_24121];\n                    \n                    int64_t defunc_0_op_res_24116 = add64(eta_p_24114, eta_p_24115);\n                    \n                    private_mem_24066[i_24121] = defunc_0_op_res_24116;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_24122 = 0; i_24122 < chunk_sizze_24032; i_24122++) {\n                int64_t sharedIdx_24123 = sext_i32_i64(local_tid_24044) * chunk_sizze_24032 + i_24122;\n                int64_t tmp_24124 = private_mem_24066[i_24122];\n                \n                ((__local int64_t *) local_mem_24051)[sharedIdx_24123] = tmp_24124;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_24125 = 0; i_24125 < chunk_sizze_24032; i_24125++) {\n                int64_t flat_idx_24126 = thd_offset_24068 + i_24125 * segscan_tblock_sizze_22750;\n                int64_t slice_24127 = loop_dz2083Uz2082U_21002;\n                int64_t gtid_22754 = flat_idx_24126;\n                int64_t remnant_24128 = flat_idx_24126 - gtid_22754;\n                \n   ", "             if (slt64(flat_idx_24126, loop_dz2083Uz2082U_21002)) {\n                    int64_t tmp_24129 = ((__local int64_t *) local_mem_24051)[flat_idx_24126 - block_offset_24062];\n                    \n                    ((__global int64_t *) mem_22843)[gtid_22754] = tmp_24129;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22750\n    #undef chunk_sizze_24032\n}\nFUTHARK_KERNEL_SIZED(humanziseghist_global_22065_dim1, 1, 1)\nvoid humanziseghist_global_22065(__global int *global_failure, int64_t mz2080U_14093, int64_t loop_dz2087U_20987, int64_t num_tblocks_22060, int64_t num_subhistos_23079, int32_t chk_i_23160, int64_t hist_H_chk_23161, __global unsigned char *mem_param_22780, __global unsigned char *mem_22795, __global unsigned char *mem_22797, __global unsigned char *zzip_copy_subhistos_mem_23080, __global unsigned char *zzip_copy_subhistos_mem_23082)\n{\n    #define seghist_tblock_sizze_22058 (humanziseghist_global_22065ziseghist_tblock_sizze_22058)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23163;\n    int32_t tblock_sizze_23166;\n    int32_t wave_sizze_23165;\n    int32_t block_id_23164;\n    int32_t global_tid_23162;\n    int64_t phys_tid_22065;\n    int32_t subhisto_ind_23167;\n    int64_t num_chunks_23168;\n    \n    local_tid_23163 = get_local_id(0);\n    tblock_sizze_23166 = get_local_size(0);\n    wave_sizze_23165 = LOCKSTEP_WIDTH;\n    block_id_23164 = get_tblock_id(0);\n    global_tid_23162 = block_id_23164 * tblock_sizze_23166 + local_tid_23163;\n    phys_tid_22065 = sext_i32_i64(global_tid_23162);\n    subhisto_ind_23167 = squot32(global_tid_23162, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_22058 * num_tblocks_22060), sext_i64_i32(num_subhistos_23079)));\n    num_chunks_23168 = sdiv_up64(loop_dz2087U_20987, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22058 * num_tblocks_22060)));\n    for (int64_t chunk_i_23169 = 0; chunk_i_23169 < num", "_chunks_23168; chunk_i_23169++) {\n        int64_t i_23170 = chunk_i_23169 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22058 * num_tblocks_22060)) + sext_i32_i64(global_tid_23162);\n        \n        if (slt64(i_23170, loop_dz2087U_20987)) {\n            int64_t slice_23171;\n            int64_t gtid_22064;\n            int64_t remnant_23172;\n            \n            slice_23171 = loop_dz2087U_20987;\n            gtid_22064 = i_23170;\n            remnant_23172 = i_23170 - gtid_22064;\n            if (slt64(i_23170, loop_dz2087U_20987)) {\n                int32_t eta_p_22072;\n                int32_t img_p_22073;\n                int32_t img_p_22074;\n                int64_t i32_res_22075;\n                \n                eta_p_22072 = ((__global int32_t *) mem_param_22780)[gtid_22064];\n                img_p_22073 = ((__global int32_t *) mem_22797)[gtid_22064];\n                img_p_22074 = ((__global int32_t *) mem_22795)[gtid_22064];\n                i32_res_22075 = sext_i32_i64(eta_p_22072);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_23160) * hist_H_chk_23161, i32_res_22075) && (slt64(i32_res_22075, sext_i32_i64(chk_i_23160) * hist_H_chk_23161 + hist_H_chk_23161) && (sle64((int64_t) 0, i32_res_22075) && slt64(i32_res_22075, mz2080U_14093)))) {\n                        int32_t eta_p_22066;\n                        int32_t eta_p_22067;\n                        int32_t eta_p_22068;\n                        int32_t eta_p_22069;\n                        \n                        eta_p_22068 = img_p_22073;\n                        eta_p_22069 = img_p_22074;\n                        \n                        int32_t old_23173;\n                        \n                        old_23173 = atomic_add_i32_global(&((volatile __global int *) zzip_copy_subhistos_mem_23080)[sext_i32_i64(subhisto_ind_23167) * mz2080U_14093 + i32_res_22075], (int) eta_p_22068);\n            ",
                                    "            \n                        int32_t old_23174;\n                        \n                        old_23174 = atomic_add_i32_global(&((volatile __global int *) zzip_copy_subhistos_mem_23082)[sext_i32_i64(subhisto_ind_23167) * mz2080U_14093 + i32_res_22075], (int) eta_p_22069);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_22058\n}\nFUTHARK_KERNEL_SIZED(humanziseghist_local_22065_dim1, 1, 1)\nvoid humanziseghist_local_22065(__global int *global_failure, int64_t mz2080U_14093, int64_t loop_dz2087U_20987, int64_t num_subhistos_23079, int64_t num_tblocks_23092, int32_t hist_M_23098, int32_t chk_i_23102, int64_t num_segments_23103, int64_t hist_H_chk_23104, int64_t histo_sizze_23105, int32_t init_per_thread_23106, __global unsigned char *mem_param_22780, __global unsigned char *mem_22795, __global unsigned char *mem_22797, __global unsigned char *zzip_copy_subhistos_mem_23080, __global unsigned char *zzip_copy_subhistos_mem_23082)\n{\n    #define max_tblock_sizze_23091 (humanziseghist_local_22065zimax_tblock_sizze_23091)\n    \n    volatile __local unsigned char *subhistogram_local_mem_23122_backing_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_23122_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_23098 * hist_H_chk_23104) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23098 * hist_H_chk_23104), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_23120_backing_0 = &shared_mem[subhistogram_local_mem_23122_backing_1_offset];\n    const int64_t subhistogram_local_mem_23120_backing_0_offset = subhistogram_local_mem_23122_backing_1_offset + ((int64_t) 4 * (hist_M_23098 * hist_H_chk_23104) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23098 * hist_H_chk_23104), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23108;\n    int32_t tblock_sizze_23111;\n    int32_t wave_sizze_23110;\n  ", "  int32_t block_id_23109;\n    int32_t global_tid_23107;\n    int64_t phys_tid_22065;\n    int32_t phys_tblock_id_23112;\n    int32_t iterations_23113;\n    \n    local_tid_23108 = get_local_id(0);\n    tblock_sizze_23111 = get_local_size(0);\n    wave_sizze_23110 = LOCKSTEP_WIDTH;\n    block_id_23109 = get_tblock_id(0);\n    global_tid_23107 = block_id_23109 * tblock_sizze_23111 + local_tid_23108;\n    phys_tid_22065 = sext_i32_i64(global_tid_23107);\n    phys_tblock_id_23112 = get_tblock_id(0);\n    iterations_23113 = sdiv_up32(sext_i64_i32(num_tblocks_23092 * num_segments_23103) - phys_tblock_id_23112, sext_i64_i32(num_tblocks_23092));\n    for (int32_t i_23114 = 0; i_23114 < iterations_23113; i_23114++) {\n        int32_t virt_tblock_id_23115;\n        int32_t flat_segment_id_23116;\n        int32_t gid_in_segment_23117;\n        int32_t pgtid_in_segment_23118;\n        int32_t threads_per_segment_23119;\n        __local unsigned char *subhistogram_local_mem_23120;\n        __local unsigned char *subhistogram_local_mem_23122;\n        int32_t thread_local_subhisto_i_23124;\n        int64_t num_chunks_23137;\n        \n        virt_tblock_id_23115 = phys_tblock_id_23112 + i_23114 * sext_i64_i32(num_tblocks_23092);\n        flat_segment_id_23116 = squot32(virt_tblock_id_23115, sext_i64_i32(num_tblocks_23092));\n        gid_in_segment_23117 = srem32(virt_tblock_id_23115, sext_i64_i32(num_tblocks_23092));\n        pgtid_in_segment_23118 = gid_in_segment_23117 * sext_i64_i32(max_tblock_sizze_23091) + local_tid_23108;\n        threads_per_segment_23119 = sext_i64_i32(num_tblocks_23092 * max_tblock_sizze_23091);\n        subhistogram_local_mem_23120 = (__local unsigned char *) subhistogram_local_mem_23120_backing_0;\n        subhistogram_local_mem_23122 = (__local unsigned char *) subhistogram_local_mem_23122_backing_1;\n        thread_local_subhisto_i_23124 = srem32(local_tid_23108, hist_M_23098);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_23125 = 0;", " local_i_23125 < init_per_thread_23106; local_i_23125++) {\n                int32_t j_23126 = local_i_23125 * sext_i64_i32(max_tblock_sizze_23091) + local_tid_23108;\n                int32_t j_offset_23127 = hist_M_23098 * sext_i64_i32(histo_sizze_23105) * gid_in_segment_23117 + j_23126;\n                int32_t local_subhisto_i_23128 = squot32(j_23126, sext_i64_i32(histo_sizze_23105));\n                int32_t global_subhisto_i_23129 = squot32(j_offset_23127, sext_i64_i32(histo_sizze_23105));\n                \n                if (slt32(j_23126, hist_M_23098 * sext_i64_i32(histo_sizze_23105))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_23129 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23079)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23126, sext_i64_i32(histo_sizze_23105))) + sext_i32_i64(chk_i_23102) * hist_H_chk_23104) && slt64(sext_i32_i64(srem32(j_23126, sext_i64_i32(histo_sizze_23105))) + sext_i32_i64(chk_i_23102) * hist_H_chk_23104, mz2080U_14093)))) {\n                            int32_t tmp_23130 = ((__global int32_t *) zzip_copy_subhistos_mem_23080)[sext_i32_i64(srem32(j_23126, sext_i64_i32(histo_sizze_23105))) + sext_i32_i64(chk_i_23102) * hist_H_chk_23104];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23120)[sext_i32_i64(local_subhisto_i_23128) * hist_H_chk_23104 + sext_i32_i64(srem32(j_23126, sext_i64_i32(histo_sizze_23105)))] = tmp_23130;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_23120)[sext_i32_i64(local_subhisto_i_23128) * hist_H_chk_23104 + sext_i32_i64(srem32(j_23126, sext_i64_i32(histo_sizze_23105)))] = 0;\n                        }\n                    }\n                }\n            }\n            for (int32_t local_i_23131 = 0; local_i_23131 < init_per_thread_23106; loca",
                                    "l_i_23131++) {\n                int32_t j_23132 = local_i_23131 * sext_i64_i32(max_tblock_sizze_23091) + local_tid_23108;\n                int32_t j_offset_23133 = hist_M_23098 * sext_i64_i32(histo_sizze_23105) * gid_in_segment_23117 + j_23132;\n                int32_t local_subhisto_i_23134 = squot32(j_23132, sext_i64_i32(histo_sizze_23105));\n                int32_t global_subhisto_i_23135 = squot32(j_offset_23133, sext_i64_i32(histo_sizze_23105));\n                \n                if (slt32(j_23132, hist_M_23098 * sext_i64_i32(histo_sizze_23105))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_23135 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23079)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23132, sext_i64_i32(histo_sizze_23105))) + sext_i32_i64(chk_i_23102) * hist_H_chk_23104) && slt64(sext_i32_i64(srem32(j_23132, sext_i64_i32(histo_sizze_23105))) + sext_i32_i64(chk_i_23102) * hist_H_chk_23104, mz2080U_14093)))) {\n                            int32_t tmp_23136 = ((__global int32_t *) zzip_copy_subhistos_mem_23082)[sext_i32_i64(srem32(j_23132, sext_i64_i32(histo_sizze_23105))) + sext_i32_i64(chk_i_23102) * hist_H_chk_23104];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23122)[sext_i32_i64(local_subhisto_i_23134) * hist_H_chk_23104 + sext_i32_i64(srem32(j_23132, sext_i64_i32(histo_sizze_23105)))] = tmp_23136;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_23122)[sext_i32_i64(local_subhisto_i_23134) * hist_H_chk_23104 + sext_i32_i64(srem32(j_23132, sext_i64_i32(histo_sizze_23105)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_23137 = sdiv_up64(loop_dz2087U_20987, sext_i32_i64(threads_per_s", "egment_23119));\n        for (int64_t chunk_i_23138 = 0; chunk_i_23138 < num_chunks_23137; chunk_i_23138++) {\n            int64_t i_23139 = chunk_i_23138 * sext_i32_i64(threads_per_segment_23119) + sext_i32_i64(pgtid_in_segment_23118);\n            \n            if (slt64(i_23139, loop_dz2087U_20987)) {\n                int64_t gtid_22064;\n                int32_t eta_p_22072;\n                int32_t img_p_22073;\n                int32_t img_p_22074;\n                int64_t i32_res_22075;\n                \n                gtid_22064 = i_23139;\n                eta_p_22072 = ((__global int32_t *) mem_param_22780)[gtid_22064];\n                img_p_22073 = ((__global int32_t *) mem_22797)[gtid_22064];\n                img_p_22074 = ((__global int32_t *) mem_22795)[gtid_22064];\n                i32_res_22075 = sext_i32_i64(eta_p_22072);\n                if (chk_i_23102 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, i32_res_22075) && slt64(i32_res_22075, mz2080U_14093)) && (sle64(sext_i32_i64(chk_i_23102) * hist_H_chk_23104, i32_res_22075) && slt64(i32_res_22075, sext_i32_i64(chk_i_23102) * hist_H_chk_23104 + hist_H_chk_23104))) {\n                        int32_t eta_p_22066;\n                        int32_t eta_p_22067;\n                        int32_t eta_p_22068;\n                        int32_t eta_p_22069;\n                        \n                        eta_p_22068 = img_p_22073;\n                        eta_p_22069 = img_p_22074;\n                        \n                        int32_t old_23140;\n                        \n                        old_23140 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23120)[sext_i32_i64(thread_local_subhisto_i_23124) * hist_H_chk_23104 + (i32_res_22075 - sext_i32_i64(chk_i_23102) * hist_H_chk_23104)], (int) eta_p_22068);\n                        \n                        i", "nt32_t old_23141;\n                        \n                        old_23141 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23122)[sext_i32_i64(thread_local_subhisto_i_23124) * hist_H_chk_23104 + (i32_res_22075 - sext_i32_i64(chk_i_23102) * hist_H_chk_23104)], (int) eta_p_22069);\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_23142 = smin64(hist_H_chk_23104, mz2080U_14093 - sext_i32_i64(chk_i_23102) * hist_H_chk_23104);\n            int32_t histo_sizze_23143 = sext_i64_i32(trunc_H_23142);\n            \n            for (int32_t local_i_23144 = 0; local_i_23144 < init_per_thread_23106; local_i_23144++) {\n                int32_t j_23145 = local_i_23144 * sext_i64_i32(max_tblock_sizze_23091) + local_tid_23108;\n                \n                if (slt32(j_23145, histo_sizze_23143)) {\n                    int32_t eta_p_22066;\n                    int32_t eta_p_22067;\n                    int32_t eta_p_22068;\n                    int32_t eta_p_22069;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_22066 = ((__local int32_t *) subhistogram_local_mem_23120)[sext_i32_i64(j_23145)];\n                        eta_p_22067 = ((__local int32_t *) subhistogram_local_mem_23122)[sext_i32_i64(j_23145)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_23146 = 0; subhisto_id_23146 < hist_M_23098 - 1; subhisto_id_23146++) {\n                            eta_p_22068 = ((__local int32_t *) subhistogram_local_mem_23120)[(sext_i32_i64(subhisto_id_23146) + (int64_t) 1) * hist_H_chk_23104 + sext_i32_i64(j_23145)];\n                            eta_p_22069 = ((__local int32_t *) subhi",
                                    "stogram_local_mem_23122)[(sext_i32_i64(subhisto_id_23146) + (int64_t) 1) * hist_H_chk_23104 + sext_i32_i64(j_23145)];\n                            \n                            int32_t tmp_22070 = add32(eta_p_22066, eta_p_22068);\n                            int32_t tmp_22071 = add32(eta_p_22067, eta_p_22069);\n                            \n                            eta_p_22066 = tmp_22070;\n                            eta_p_22067 = tmp_22071;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) zzip_copy_subhistos_mem_23080)[srem64(sext_i32_i64(virt_tblock_id_23115), num_tblocks_23092) * mz2080U_14093 + (sext_i32_i64(j_23145) + sext_i32_i64(chk_i_23102) * hist_H_chk_23104)] = eta_p_22066;\n                        ((__global int32_t *) zzip_copy_subhistos_mem_23082)[srem64(sext_i32_i64(virt_tblock_id_23115), num_tblocks_23092) * mz2080U_14093 + (sext_i32_i64(j_23145) + sext_i32_i64(chk_i_23102) * hist_H_chk_23104)] = eta_p_22067;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_23091\n}\nFUTHARK_KERNEL_SIZED(humanzisegmap_22004_dim1, 1, 1)\nvoid humanzisegmap_22004(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_14093, int64_t loop_dz2087U_20987, __global unsigned char *mem_param_22777, __global unsigned char *mem_param_22783, __global unsigned char *mem_22789, __global unsigned char *mem_22792)\n{\n    #define segmap_tblock_sizze_22000 (humanzisegmap_22004zisegmap_tblock_sizze_22000)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23062;\n    int32_t tblock_sizze_23065;\n    int32_t wave_sizze_23064;\n    int32_t block_id_23063;\n    int32_t global_tid_23061;\n    int64_t phys_tid_22004;\n    int64_t global_tid_23066;\n    int64_t slic", "e_23067;\n    int64_t gtid_22003;\n    int64_t remnant_23068;\n    \n    local_tid_23062 = get_local_id(0);\n    tblock_sizze_23065 = get_local_size(0);\n    wave_sizze_23064 = LOCKSTEP_WIDTH;\n    block_id_23063 = get_tblock_id(0);\n    global_tid_23061 = block_id_23063 * tblock_sizze_23065 + local_tid_23062;\n    phys_tid_22004 = sext_i32_i64(global_tid_23061);\n    global_tid_23066 = sext_i32_i64(block_id_23063) * segmap_tblock_sizze_22000 + sext_i32_i64(local_tid_23062);\n    slice_23067 = mz2080U_14093;\n    gtid_22003 = global_tid_23066;\n    remnant_23068 = global_tid_23066 - gtid_22003;\n    if (slt64(gtid_22003, mz2080U_14093)) {\n        int32_t eta_p_22006;\n        bool cond_22008;\n        float lifted_lambda_res_22009;\n        \n        eta_p_22006 = ((__global int32_t *) mem_param_22777)[gtid_22003];\n        cond_22008 = slt32(0, eta_p_22006);\n        if (cond_22008) {\n            int32_t eta_p_22005;\n            int32_t tmp_22010;\n            int64_t tmp_22011;\n            bool x_22012;\n            bool y_22013;\n            bool bounds_check_22014;\n            bool index_certs_22015;\n            float lifted_lambda_res_t_res_22016;\n            \n            eta_p_22005 = ((__global int32_t *) mem_22789)[gtid_22003];\n            tmp_22010 = sub32(eta_p_22005, 1);\n            tmp_22011 = sext_i32_i64(tmp_22010);\n            x_22012 = sle64((int64_t) 0, tmp_22011);\n            y_22013 = slt64(tmp_22011, loop_dz2087U_20987);\n            bounds_check_22014 = x_22012 && y_22013;\n            if (!bounds_check_22014) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_22011;\n                        global_failure_args[1] = (int64_t) loop_dz2087U_20987;\n                        ;\n                    }\n                    return;\n                }\n            }\n            lifted_lambda_res_t_res_22016 = ((__global float *) mem_param_22783)[tmp_22011];\n            lift", "ed_lambda_res_22009 = lifted_lambda_res_t_res_22016;\n        } else {\n            lifted_lambda_res_22009 = 0.0F;\n        }\n        ((__global float *) mem_22792)[gtid_22003] = lifted_lambda_res_22009;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22000\n}\nFUTHARK_KERNEL_SIZED(humanzisegmap_22043_dim1, 1, 1)\nvoid humanzisegmap_22043(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_14093, int64_t loop_dz2087U_20987, __global unsigned char *mem_param_22780, __global unsigned char *mem_param_22783, __global unsigned char *mem_22792, __global unsigned char *mem_22795, __global unsigned char *mem_22797)\n{\n    #define segmap_tblock_sizze_22038 (humanzisegmap_22043zisegmap_tblock_sizze_22038)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23071;\n    int32_t tblock_sizze_23074;\n    int32_t wave_sizze_23073;\n    int32_t block_id_23072;\n    int32_t global_tid_23070;\n    int64_t phys_tid_22043;\n    int64_t global_tid_23075;\n    int64_t slice_23076;\n    int64_t gtid_22042;\n    int64_t remnant_23077;\n    \n    local_tid_23071 = get_local_id(0);\n    tblock_sizze_23074 = get_local_size(0);\n    wave_sizze_23073 = LOCKSTEP_WIDTH;\n    block_id_23072 = get_tblock_id(0);\n    global_tid_23070 = block_id_23072 * tblock_sizze_23074 + local_tid_23071;\n    phys_tid_22043 = sext_i32_i64(global_tid_23070);\n    global_tid_23075 = sext_i32_i64(block_id_23072) * segmap_tblock_sizze_22038 + sext_i32_i64(local_tid_23071);\n    slice_23076 = loop_dz2087U_20987;\n    gtid_22042 = global_tid_23075;\n    remnant_23077 = global_tid_23075 - gtid_22042;\n    if (slt64(gtid_22042, loop_dz2087U_20987)) {\n        int32_t eta_p_22045;\n        int64_t ii_22046;\n        bool x_22047;\n        bool y_22048;\n        bool bounds_check_22049;\n        bool index_certs_22050;\n        float eta_p_22044;\n        float zl_rhs_22051;\n        bool bool_arg0_22052;\n        int32_t bool_res_22053;\n        bool bool_arg0_2205",
                                    "4;\n        int32_t bool_res_22055;\n        \n        eta_p_22045 = ((__global int32_t *) mem_param_22780)[gtid_22042];\n        ii_22046 = sext_i32_i64(eta_p_22045);\n        x_22047 = sle64((int64_t) 0, ii_22046);\n        y_22048 = slt64(ii_22046, mz2080U_14093);\n        bounds_check_22049 = x_22047 && y_22048;\n        if (!bounds_check_22049) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                    global_failure_args[0] = (int64_t) ii_22046;\n                    global_failure_args[1] = (int64_t) mz2080U_14093;\n                    ;\n                }\n                return;\n            }\n        }\n        eta_p_22044 = ((__global float *) mem_param_22783)[gtid_22042];\n        zl_rhs_22051 = ((__global float *) mem_22792)[ii_22046];\n        bool_arg0_22052 = eta_p_22044 < zl_rhs_22051;\n        bool_res_22053 = btoi_bool_i32(bool_arg0_22052);\n        bool_arg0_22054 = eta_p_22044 == zl_rhs_22051;\n        bool_res_22055 = btoi_bool_i32(bool_arg0_22054);\n        ((__global int32_t *) mem_22795)[gtid_22042] = bool_res_22055;\n        ((__global int32_t *) mem_22797)[gtid_22042] = bool_res_22053;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22038\n}\nFUTHARK_KERNEL_SIZED(humanzisegmap_22117_dim1, 1, 1)\nvoid humanzisegmap_22117(__global int *global_failure, int64_t mz2080U_14093, __global unsigned char *mem_param_22774, __global unsigned char *mem_param_22777, __global unsigned char *mem_param_22786, __global unsigned char *mem_22792, __global unsigned char *mem_22799, __global unsigned char *mem_22801, __global unsigned char *mem_22805, __global unsigned char *mem_22807, __global unsigned char *mem_22809, __global unsigned char *mem_22811)\n{\n    #define segmap_tblock_sizze_22110 (humanzisegmap_22117zisegmap_tblock_sizze_22110)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23268;\n    int32_t tblock_sizze_23271;\n    int32_t wave_sizze_23270;\n    int32_t block_id_23269;\n    in", "t32_t global_tid_23267;\n    int64_t phys_tid_22117;\n    int64_t global_tid_23272;\n    int64_t slice_23273;\n    int64_t gtid_22116;\n    int64_t remnant_23274;\n    \n    local_tid_23268 = get_local_id(0);\n    tblock_sizze_23271 = get_local_size(0);\n    wave_sizze_23270 = LOCKSTEP_WIDTH;\n    block_id_23269 = get_tblock_id(0);\n    global_tid_23267 = block_id_23269 * tblock_sizze_23271 + local_tid_23268;\n    phys_tid_22117 = sext_i32_i64(global_tid_23267);\n    global_tid_23272 = sext_i32_i64(block_id_23269) * segmap_tblock_sizze_22110 + sext_i32_i64(local_tid_23268);\n    slice_23273 = mz2080U_14093;\n    gtid_22116 = global_tid_23272;\n    remnant_23274 = global_tid_23272 - gtid_22116;\n    if (slt64(gtid_22116, mz2080U_14093)) {\n        int32_t eta_p_22118;\n        int32_t eta_p_22119;\n        bool cond_22124;\n        int32_t lifted_lambda_res_22125;\n        int32_t lifted_lambda_res_22126;\n        int32_t lifted_lambda_res_22127;\n        bool cond_22141;\n        float lifted_lambda_res_22142;\n        \n        eta_p_22118 = ((__global int32_t *) mem_param_22774)[gtid_22116];\n        eta_p_22119 = ((__global int32_t *) mem_param_22777)[gtid_22116];\n        cond_22124 = eta_p_22119 == 0;\n        if (cond_22124) {\n            lifted_lambda_res_22125 = -1;\n            lifted_lambda_res_22126 = 0;\n            lifted_lambda_res_22127 = eta_p_22118;\n        } else {\n            int32_t eta_p_22120;\n            bool cond_22128;\n            int32_t lifted_lambda_res_f_res_22129;\n            int32_t lifted_lambda_res_f_res_22130;\n            int32_t lifted_lambda_res_f_res_22131;\n            \n            eta_p_22120 = ((__global int32_t *) mem_22801)[gtid_22116];\n            cond_22128 = sle32(eta_p_22118, eta_p_22120);\n            if (cond_22128) {\n                lifted_lambda_res_f_res_22129 = 0;\n                lifted_lambda_res_f_res_22130 = eta_p_22120;\n                lifted_lambda_res_f_res_22131 = eta_p_22118;\n            } else {\n                int32_t eta_p_22121;\n       ", "         int32_t zlze_rhs_22132;\n                bool cond_22133;\n                int32_t lifted_lambda_res_f_res_f_res_22134;\n                int32_t lifted_lambda_res_f_res_f_res_22135;\n                int32_t lifted_lambda_res_f_res_f_res_22136;\n                \n                eta_p_22121 = ((__global int32_t *) mem_22799)[gtid_22116];\n                zlze_rhs_22132 = add32(eta_p_22120, eta_p_22121);\n                cond_22133 = sle32(eta_p_22118, zlze_rhs_22132);\n                if (cond_22133) {\n                    lifted_lambda_res_f_res_f_res_22134 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_22134 = 2;\n                }\n                if (cond_22133) {\n                    lifted_lambda_res_f_res_f_res_22135 = 0;\n                    lifted_lambda_res_f_res_f_res_22136 = -1;\n                } else {\n                    int32_t zm_lhs_22137;\n                    int32_t tmp_22138;\n                    int32_t zm_lhs_22139;\n                    int32_t tmp_22140;\n                    \n                    zm_lhs_22137 = sub32(eta_p_22119, eta_p_22120);\n                    tmp_22138 = sub32(zm_lhs_22137, eta_p_22121);\n                    zm_lhs_22139 = sub32(eta_p_22118, eta_p_22120);\n                    tmp_22140 = sub32(zm_lhs_22139, eta_p_22121);\n                    lifted_lambda_res_f_res_f_res_22135 = tmp_22138;\n                    lifted_lambda_res_f_res_f_res_22136 = tmp_22140;\n                }\n                lifted_lambda_res_f_res_22129 = lifted_lambda_res_f_res_f_res_22134;\n                lifted_lambda_res_f_res_22130 = lifted_lambda_res_f_res_f_res_22135;\n                lifted_lambda_res_f_res_22131 = lifted_lambda_res_f_res_f_res_22136;\n            }\n            lifted_lambda_res_22125 = lifted_lambda_res_f_res_22129;\n            lifted_lambda_res_22126 = lifted_lambda_res_f_res_22130;\n            lifted_lambda_res_22127 = lifted_lambda_res_f_res_22131;\n        }\n        cond_22141 = lifted_lambda_res_22125 == 1;\n  ",
                                    "      if (cond_22141) {\n            float eta_p_22123 = ((__global float *) mem_22792)[gtid_22116];\n            \n            lifted_lambda_res_22142 = eta_p_22123;\n        } else {\n            float eta_p_22122 = ((__global float *) mem_param_22786)[gtid_22116];\n            \n            lifted_lambda_res_22142 = eta_p_22122;\n        }\n        ((__global float *) mem_22805)[gtid_22116] = lifted_lambda_res_22142;\n        ((__global int32_t *) mem_22807)[gtid_22116] = lifted_lambda_res_22125;\n        ((__global int32_t *) mem_22809)[gtid_22116] = lifted_lambda_res_22126;\n        ((__global int32_t *) mem_22811)[gtid_22116] = lifted_lambda_res_22127;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22110\n}\nFUTHARK_KERNEL_SIZED(humanzisegmap_22152_dim1, 1, 1)\nvoid humanzisegmap_22152(__global int *global_failure, int64_t loop_dz2087U_20987, int64_t m_21120, int64_t num_tblocks_22157, int32_t virt_num_tblocks_23379, __global unsigned char *mem_param_22780, __global unsigned char *mem_param_22783, __global unsigned char *mem_22814, __global unsigned char *mem_22816, __global unsigned char *mem_22818, __global unsigned char *mem_22820)\n{\n    #define segmap_tblock_sizze_22155 (humanzisegmap_22152zisegmap_tblock_sizze_22155)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23381;\n    int32_t tblock_sizze_23384;\n    int32_t wave_sizze_23383;\n    int32_t block_id_23382;\n    int32_t global_tid_23380;\n    int64_t phys_tid_22152;\n    int32_t phys_tblock_id_23385;\n    int32_t iterations_23386;\n    \n    local_tid_23381 = get_local_id(0);\n    tblock_sizze_23384 = get_local_size(0);\n    wave_sizze_23383 = LOCKSTEP_WIDTH;\n    block_id_23382 = get_tblock_id(0);\n    global_tid_23380 = block_id_23382 * tblock_sizze_23384 + local_tid_23381;\n    phys_tid_22152 = sext_i32_i64(global_tid_23380);\n    phys_tblock_id_23385 = get_tblock_id(0);\n    iterations_23386 = sdiv_up32(virt_num_tblocks_23379 - phys_tblock_id_23385, sext_i64_i32(num_tblocks_22157));\n ", "   for (int32_t i_23387 = 0; i_23387 < iterations_23386; i_23387++) {\n        int32_t virt_tblock_id_23388;\n        int64_t global_tid_23389;\n        int64_t slice_23390;\n        int64_t write_i_22151;\n        int64_t remnant_23391;\n        \n        virt_tblock_id_23388 = phys_tblock_id_23385 + i_23387 * sext_i64_i32(num_tblocks_22157);\n        global_tid_23389 = sext_i32_i64(virt_tblock_id_23388) * segmap_tblock_sizze_22155 + sext_i32_i64(local_tid_23381);\n        slice_23390 = loop_dz2087U_20987;\n        write_i_22151 = global_tid_23389;\n        remnant_23391 = global_tid_23389 - write_i_22151;\n        if (slt64(write_i_22151, loop_dz2087U_20987)) {\n            int64_t eta_p_21359;\n            float write_value_21361;\n            int32_t write_value_21362;\n            bool cond_21363;\n            int64_t lifted_lambda_res_21364;\n            \n            eta_p_21359 = ((__global int64_t *) mem_22816)[write_i_22151];\n            write_value_21361 = ((__global float *) mem_param_22783)[write_i_22151];\n            write_value_21362 = ((__global int32_t *) mem_param_22780)[write_i_22151];\n            cond_21363 = eta_p_21359 == (int64_t) 1;\n            if (cond_21363) {\n                int64_t eta_p_21360;\n                int64_t lifted_lambda_res_t_res_21609;\n                \n                eta_p_21360 = ((__global int64_t *) mem_22814)[write_i_22151];\n                lifted_lambda_res_t_res_21609 = sub64(eta_p_21360, (int64_t) 1);\n                lifted_lambda_res_21364 = lifted_lambda_res_t_res_21609;\n            } else {\n                lifted_lambda_res_21364 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21364) && slt64(lifted_lambda_res_21364, m_21120)) {\n                ((__global float *) mem_22820)[lifted_lambda_res_21364] = write_value_21361;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21364) && slt64(lifted_lambda_res_21364, m_21120)) {\n                ((__global int32_t *) mem_22818)[lifted_lambda", "_res_21364] = write_value_21362;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22155\n}\nFUTHARK_KERNEL_SIZED(humanzisegred_large_23177_dim1, 1, 1)\nvoid humanzisegred_large_23177(__global int *global_failure, int64_t mz2080U_14093, int64_t num_tblocks_22060, int64_t num_subhistos_23079, int64_t blocks_per_segment_23215, int64_t q_23216, int64_t num_virtblocks_23217, int64_t threads_per_segment_23218, __global unsigned char *mem_22799, __global unsigned char *mem_22801, __global unsigned char *zzip_copy_subhistos_mem_23080, __global unsigned char *zzip_copy_subhistos_mem_23082, __global unsigned char *segred_tmp_mem_23219, __global unsigned char *segred_tmp_mem_23221, __global unsigned char *counters_mem_23223)\n{\n    #define seghist_tblock_sizze_22058 (humanzisegred_large_23177ziseghist_tblock_sizze_22058)\n    #define chunk_sizze_23178 (humanzisegred_large_23177zichunk_sizze_23178)\n    \n    volatile __local unsigned char *sync_arr_mem_23234_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_23234_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_23232_backing_1 = &shared_mem[sync_arr_mem_23234_backing_2_offset];\n    const int64_t red_arr_i32_mem_23232_backing_1_offset = sync_arr_mem_23234_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_22058 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22058, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_23230_backing_0 = &shared_mem[red_arr_i32_mem_23232_backing_1_offset];\n    const int64_t red_arr_i32_mem_23230_backing_0_offset = red_arr_i32_mem_23232_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22058 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22058, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23226;\n    int32_t tblock_sizze_23229;\n    int32_",
                                    "t wave_sizze_23228;\n    int32_t block_id_23227;\n    int32_t global_tid_23225;\n    int64_t flat_gtid_23177;\n    __local unsigned char *red_arr_i32_mem_23230;\n    __local unsigned char *red_arr_i32_mem_23232;\n    __local unsigned char *sync_arr_mem_23234;\n    int32_t phys_tblock_id_23236;\n    int32_t iterations_23237;\n    \n    local_tid_23226 = get_local_id(0);\n    tblock_sizze_23229 = get_local_size(0);\n    wave_sizze_23228 = LOCKSTEP_WIDTH;\n    block_id_23227 = get_tblock_id(0);\n    global_tid_23225 = block_id_23227 * tblock_sizze_23229 + local_tid_23226;\n    flat_gtid_23177 = sext_i32_i64(global_tid_23225);\n    red_arr_i32_mem_23230 = (__local unsigned char *) red_arr_i32_mem_23230_backing_0;\n    red_arr_i32_mem_23232 = (__local unsigned char *) red_arr_i32_mem_23232_backing_1;\n    sync_arr_mem_23234 = (__local unsigned char *) sync_arr_mem_23234_backing_2;\n    phys_tblock_id_23236 = get_tblock_id(0);\n    iterations_23237 = sdiv_up32(sext_i64_i32(num_virtblocks_23217) - phys_tblock_id_23236, sext_i64_i32(num_tblocks_22060));\n    for (int32_t i_23238 = 0; i_23238 < iterations_23237; i_23238++) {\n        int32_t virt_tblock_id_23239;\n        int64_t flat_segment_id_23240;\n        int64_t global_tid_23241;\n        int64_t slice_23242;\n        int64_t bucket_id_23175;\n        int64_t remnant_23243;\n        int64_t subhistogram_id_23176;\n        int32_t eta_p_block_res_acc_23244;\n        int32_t eta_p_block_res_acc_23245;\n        int32_t eta_p_22066;\n        int32_t eta_p_22067;\n        int32_t eta_p_22068;\n        int32_t eta_p_22069;\n        int64_t tblock_id_in_segment_23252;\n        int64_t block_base_offset_23253;\n        int32_t offset_23256;\n        int32_t skip_waves_23257;\n        int32_t eta_p_23246;\n        int32_t eta_p_23247;\n        int32_t eta_p_23248;\n        int32_t eta_p_23249;\n        \n        virt_tblock_id_23239 = phys_tblock_id_23236 + i_23238 * sext_i64_i32(num_tblocks_22060);\n        flat_segment_id_23240 = squot64(sext_i32_i64(virt_tblock_id_232", "39), blocks_per_segment_23215);\n        global_tid_23241 = srem64(sext_i32_i64(virt_tblock_id_23239) * seghist_tblock_sizze_22058 + sext_i32_i64(local_tid_23226), threads_per_segment_23218);\n        slice_23242 = mz2080U_14093;\n        bucket_id_23175 = flat_segment_id_23240;\n        remnant_23243 = flat_segment_id_23240 - bucket_id_23175;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_23244 = 0;\n            eta_p_block_res_acc_23245 = 0;\n        }\n        tblock_id_in_segment_23252 = squot64(global_tid_23241, seghist_tblock_sizze_22058);\n        block_base_offset_23253 = tblock_id_in_segment_23252 * q_23216 * seghist_tblock_sizze_22058;\n        for (int64_t i_23254 = 0; i_23254 < q_23216; i_23254++) {\n            int64_t block_offset_23255 = block_base_offset_23253 + i_23254 * seghist_tblock_sizze_22058;\n            \n            subhistogram_id_23176 = global_tid_23241 + threads_per_segment_23218 * i_23254;\n            if (slt64(subhistogram_id_23176, num_subhistos_23079)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_22066 = eta_p_block_res_acc_23244;\n                        eta_p_22067 = eta_p_block_res_acc_23245;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_22068 = ((__global int32_t *) zzip_copy_subhistos_mem_23080)[subhistogram_id_23176 * mz2080U_14093 + bucket_id_23175];\n                        eta_p_22069 = ((__global int32_t *) zzip_copy_subhistos_mem_23082)[subhistogram_id_23176 * mz2080U_14093 + bucket_id_23175];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_22070 = add32(eta_p_22066, eta_p_22068);\n                        int32_t tmp_22071 = add32(eta_p_22067, eta_p_22069);\n                        \n                        // store in accu", "mulator(s)\n                        {\n                            eta_p_block_res_acc_23244 = tmp_22070;\n                            eta_p_block_res_acc_23245 = tmp_22071;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226)] = eta_p_block_res_acc_23244;\n            ((__local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226)] = eta_p_block_res_acc_23245;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_23257 = 1;\n        offset_23256 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_23226, sext_i64_i32(seghist_tblock_sizze_22058))) {\n                eta_p_23246 = ((__local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226 + offset_23256)];\n                eta_p_23247 = ((__local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226 + offset_23256)];\n            }\n        }\n        offset_23256 = 1;\n        while (slt32(offset_23256, wave_sizze_23228)) {\n            if (slt32(local_tid_23226 + offset_23256, sext_i64_i32(seghist_tblock_sizze_22058)) && ((local_tid_23226 - squot32(local_tid_23226, wave_sizze_23228) * wave_sizze_23228) & (2 * offset_23256 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_23248 = ((volatile __local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226 + offset_23256)];\n                    eta_p_23249 = ((volatile __local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226 + offset_23256)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_23250 = add32(eta_p_23246, eta_p_23248);\n                    int32_t tmp_23251 = add32(eta_p_23247, eta_p_23249);\n           ",
                                    "         \n                    eta_p_23246 = tmp_23250;\n                    eta_p_23247 = tmp_23251;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226)] = eta_p_23246;\n                    ((volatile __local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226)] = eta_p_23247;\n                }\n            }\n            offset_23256 *= 2;\n        }\n        while (slt32(skip_waves_23257, squot32(sext_i64_i32(seghist_tblock_sizze_22058) + wave_sizze_23228 - 1, wave_sizze_23228))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23256 = skip_waves_23257 * wave_sizze_23228;\n            if (slt32(local_tid_23226 + offset_23256, sext_i64_i32(seghist_tblock_sizze_22058)) && ((local_tid_23226 - squot32(local_tid_23226, wave_sizze_23228) * wave_sizze_23228) == 0 && (squot32(local_tid_23226, wave_sizze_23228) & (2 * skip_waves_23257 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_23248 = ((__local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226 + offset_23256)];\n                    eta_p_23249 = ((__local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226 + offset_23256)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_23250 = add32(eta_p_23246, eta_p_23248);\n                    int32_t tmp_23251 = add32(eta_p_23247, eta_p_23249);\n                    \n                    eta_p_23246 = tmp_23250;\n                    eta_p_23247 = tmp_23251;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226)] = eta_p_23246;\n                    ((__local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226)] = eta_p_23247;\n                }\n            }\n            skip_w", "aves_23257 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_23226) == (int64_t) 0) {\n                eta_p_block_res_acc_23244 = eta_p_23246;\n                eta_p_block_res_acc_23245 = eta_p_23247;\n            } else {\n                eta_p_block_res_acc_23244 = 0;\n                eta_p_block_res_acc_23245 = 0;\n            }\n        }\n        if (blocks_per_segment_23215 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_23226 == 0) {\n                    ((__global int32_t *) mem_22801)[bucket_id_23175] = eta_p_block_res_acc_23244;\n                    ((__global int32_t *) mem_22799)[bucket_id_23175] = eta_p_block_res_acc_23245;\n                }\n            }\n        } else {\n            int32_t old_counter_23258;\n            bool is_last_block_23259;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_23226 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_23219)[sext_i32_i64(virt_tblock_id_23239)] = eta_p_block_res_acc_23244;\n                    mem_fence_global();\n                    ((__global int32_t *) segred_tmp_mem_23221)[sext_i32_i64(virt_tblock_id_23239)] = eta_p_block_res_acc_23245;\n                    mem_fence_global();\n                    old_counter_23258 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23223)[srem64(flat_segment_id_23240, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_23234)[(int64_t) 0] = old_counter_23258 == sext_i64_i32(blocks_per_segment_23215 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_23259 = ((__local bool *) sync_arr_mem_23234)[(int64_t) 0];\n            if (is_las", "t_block_23259) {\n                if (local_tid_23226 == 0) {\n                    old_counter_23258 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23223)[srem64(flat_segment_id_23240, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_23215));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_23260 = sdiv_up64(blocks_per_segment_23215, seghist_tblock_sizze_22058);\n                    \n                    eta_p_22066 = 0;\n                    eta_p_22067 = 0;\n                    for (int64_t i_23261 = 0; i_23261 < read_per_thread_23260; i_23261++) {\n                        int64_t block_res_id_23262 = sext_i32_i64(local_tid_23226) * read_per_thread_23260 + i_23261;\n                        int64_t index_of_block_res_23263 = flat_segment_id_23240 * blocks_per_segment_23215 + block_res_id_23262;\n                        \n                        if (slt64(block_res_id_23262, blocks_per_segment_23215)) {\n                            eta_p_22068 = ((__global int32_t *) segred_tmp_mem_23219)[index_of_block_res_23263];\n                            eta_p_22069 = ((__global int32_t *) segred_tmp_mem_23221)[index_of_block_res_23263];\n                            \n                            int32_t tmp_22070 = add32(eta_p_22066, eta_p_22068);\n                            int32_t tmp_22071 = add32(eta_p_22067, eta_p_22069);\n                            \n                            eta_p_22066 = tmp_22070;\n                            eta_p_22067 = tmp_22071;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226)] = eta_p_22066;\n                ((__local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226)] = eta_p_22067;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offs",
                                    "et_23264;\n                    int32_t skip_waves_23265 = 1;\n                    int32_t eta_p_23246;\n                    int32_t eta_p_23247;\n                    int32_t eta_p_23248;\n                    int32_t eta_p_23249;\n                    \n                    offset_23264 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_23226, sext_i64_i32(seghist_tblock_sizze_22058))) {\n                            eta_p_23246 = ((__local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226 + offset_23264)];\n                            eta_p_23247 = ((__local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226 + offset_23264)];\n                        }\n                    }\n                    offset_23264 = 1;\n                    while (slt32(offset_23264, wave_sizze_23228)) {\n                        if (slt32(local_tid_23226 + offset_23264, sext_i64_i32(seghist_tblock_sizze_22058)) && ((local_tid_23226 - squot32(local_tid_23226, wave_sizze_23228) * wave_sizze_23228) & (2 * offset_23264 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_23248 = ((volatile __local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226 + offset_23264)];\n                                eta_p_23249 = ((volatile __local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226 + offset_23264)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_23250 = add32(eta_p_23246, eta_p_23248);\n                                int32_t tmp_23251 = add32(eta_p_23247, eta_p_23249);\n                                \n                                eta_p_23246 = tmp_23250;\n                                eta_p_23247 = tmp_23251;\n                            }\n                            // write result o", "f operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226)] = eta_p_23246;\n                                ((volatile __local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226)] = eta_p_23247;\n                            }\n                        }\n                        offset_23264 *= 2;\n                    }\n                    while (slt32(skip_waves_23265, squot32(sext_i64_i32(seghist_tblock_sizze_22058) + wave_sizze_23228 - 1, wave_sizze_23228))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_23264 = skip_waves_23265 * wave_sizze_23228;\n                        if (slt32(local_tid_23226 + offset_23264, sext_i64_i32(seghist_tblock_sizze_22058)) && ((local_tid_23226 - squot32(local_tid_23226, wave_sizze_23228) * wave_sizze_23228) == 0 && (squot32(local_tid_23226, wave_sizze_23228) & (2 * skip_waves_23265 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_23248 = ((__local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226 + offset_23264)];\n                                eta_p_23249 = ((__local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226 + offset_23264)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_23250 = add32(eta_p_23246, eta_p_23248);\n                                int32_t tmp_23251 = add32(eta_p_23247, eta_p_23249);\n                                \n                                eta_p_23246 = tmp_23250;\n                                eta_p_23247 = tmp_23251;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_23230)[sext_i32_i64(local_tid_23226)] = ", "eta_p_23246;\n                                ((__local int32_t *) red_arr_i32_mem_23232)[sext_i32_i64(local_tid_23226)] = eta_p_23247;\n                            }\n                        }\n                        skip_waves_23265 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_23226 == 0) {\n                            ((__global int32_t *) mem_22801)[bucket_id_23175] = eta_p_23246;\n                            ((__global int32_t *) mem_22799)[bucket_id_23175] = eta_p_23247;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_22058\n    #undef chunk_sizze_23178\n}\nFUTHARK_KERNEL_SIZED(humanzisegred_small_23177_dim1, 1, 1)\nvoid humanzisegred_small_23177(__global int *global_failure, int64_t mz2080U_14093, int64_t num_tblocks_22060, int64_t num_subhistos_23079, int64_t segment_sizze_nonzzero_23179, __global unsigned char *mem_22799, __global unsigned char *mem_22801, __global unsigned char *zzip_copy_subhistos_mem_23080, __global unsigned char *zzip_copy_subhistos_mem_23082)\n{\n    #define seghist_tblock_sizze_22058 (humanzisegred_small_23177ziseghist_tblock_sizze_22058)\n    \n    volatile __local unsigned char *red_arr_i32_mem_23188_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_23188_backing_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_22058 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22058, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_23186_backing_0 = &shared_mem[red_arr_i32_mem_23188_backing_1_offset];\n    const int64_t red_arr_i32_mem_23186_backing_0_offset = red_arr_i32_mem_23188_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22058 + srem64((int64_t) 8 - srem64((int64",
                                    "_t) 4 * seghist_tblock_sizze_22058, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23182;\n    int32_t tblock_sizze_23185;\n    int32_t wave_sizze_23184;\n    int32_t block_id_23183;\n    int32_t global_tid_23181;\n    int64_t flat_gtid_23177;\n    __local unsigned char *red_arr_i32_mem_23186;\n    __local unsigned char *red_arr_i32_mem_23188;\n    int32_t phys_tblock_id_23190;\n    int32_t iterations_23191;\n    \n    local_tid_23182 = get_local_id(0);\n    tblock_sizze_23185 = get_local_size(0);\n    wave_sizze_23184 = LOCKSTEP_WIDTH;\n    block_id_23183 = get_tblock_id(0);\n    global_tid_23181 = block_id_23183 * tblock_sizze_23185 + local_tid_23182;\n    flat_gtid_23177 = sext_i32_i64(global_tid_23181);\n    red_arr_i32_mem_23186 = (__local unsigned char *) red_arr_i32_mem_23186_backing_0;\n    red_arr_i32_mem_23188 = (__local unsigned char *) red_arr_i32_mem_23188_backing_1;\n    phys_tblock_id_23190 = get_tblock_id(0);\n    iterations_23191 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_14093, squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179))) - phys_tblock_id_23190, sext_i64_i32(num_tblocks_22060));\n    for (int32_t i_23192 = 0; i_23192 < iterations_23191; i_23192++) {\n        int32_t virt_tblock_id_23193;\n        int64_t slice_23194;\n        int64_t bucket_id_23175;\n        int64_t remnant_23195;\n        int64_t subhistogram_id_23176;\n        \n        virt_tblock_id_23193 = phys_tblock_id_23190 + i_23192 * sext_i64_i32(num_tblocks_22060);\n        slice_23194 = mz2080U_14093;\n        bucket_id_23175 = squot64(sext_i32_i64(local_tid_23182), segment_sizze_nonzzero_23179) + sext_i32_i64(virt_tblock_id_23193) * squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179);\n        remnant_23195 = squot64(sext_i32_i64(local_tid_23182), segment_sizze_nonzzero_23179) + sext_i32_i64(virt_tblock_id_23193) * squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179) - bucket_id_23175;\n        subhistogram_", "id_23176 = srem64(sext_i32_i64(local_tid_23182), num_subhistos_23079);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_23079) && (slt64(bucket_id_23175, mz2080U_14093) && slt64(sext_i32_i64(local_tid_23182), num_subhistos_23079 * squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_23196 = ((__global int32_t *) zzip_copy_subhistos_mem_23080)[subhistogram_id_23176 * mz2080U_14093 + bucket_id_23175];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182)] = tmp_23196;\n                    \n                    int32_t tmp_23197 = ((__global int32_t *) zzip_copy_subhistos_mem_23082)[subhistogram_id_23176 * mz2080U_14093 + bucket_id_23175];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182)] = tmp_23197;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_23079)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_22066;\n                int32_t eta_p_22067;\n                int32_t eta_p_22068;\n                int32_t eta_p_22069;\n                int32_t eta_p_23198;\n                int32_t eta_p_23199;\n                int32_t eta_p_23200;\n                int32_t eta_p_23201;\n                bool ltid_in_bounds_23204 = slt64(sext_i32_i64(local_tid_23182), num_subhistos_23079 * squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179));\n                int32_t skip_threads_23205;\n                \n                // read input for in-block scan\n   ", "             {\n                    if (ltid_in_bounds_23204) {\n                        eta_p_22068 = ((volatile __local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182)];\n                        eta_p_22069 = ((volatile __local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182)];\n                        if ((local_tid_23182 - squot32(local_tid_23182, 32) * 32) == 0) {\n                            eta_p_22066 = eta_p_22068;\n                            eta_p_22067 = eta_p_22069;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23205 = 1;\n                    while (slt32(skip_threads_23205, 32)) {\n                        bool thread_active_23206 = sle32(skip_threads_23205, local_tid_23182 - squot32(local_tid_23182, 32) * 32) && ltid_in_bounds_23204;\n                        \n                        if (thread_active_23206) {\n                            // read operands\n                            {\n                                eta_p_22066 = ((volatile __local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182) - sext_i32_i64(skip_threads_23205)];\n                                eta_p_22067 = ((volatile __local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182) - sext_i32_i64(skip_threads_23205)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_23207 = slt64(srem64(sext_i32_i64(local_tid_23182), num_subhistos_23079), sext_i32_i64(local_tid_23182) - sext_i32_i64(local_tid_23182 - skip_threads_23205));\n                            \n                            if (thread_active_23206 && inactive_23207) {\n                                eta_p_22066 = eta_p_22068;\n                                eta_p_22067 = eta_p_22069;\n                            }\n                       ",
                                    "     if (thread_active_23206) {\n                                if (!inactive_23207) {\n                                    int32_t tmp_22070 = add32(eta_p_22066, eta_p_22068);\n                                    int32_t tmp_22071 = add32(eta_p_22067, eta_p_22069);\n                                    \n                                    eta_p_22066 = tmp_22070;\n                                    eta_p_22067 = tmp_22071;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_23184, skip_threads_23205)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23206) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182)] = eta_p_22066;\n                                eta_p_22068 = eta_p_22066;\n                                ((volatile __local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182)] = eta_p_22067;\n                                eta_p_22069 = eta_p_22067;\n                            }\n                        }\n                        if (sle32(wave_sizze_23184, skip_threads_23205)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23205 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_23182 - squot32(local_tid_23182, 32) * 32) == 31 && ltid_in_bounds_23204) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(squot32(local_tid_23182, 32))] = eta_p_22066;\n                        ((volatile __local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(squot32(local_tid_23182, 32))] = eta_p_22", "067;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_23208;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_23182, 32) == 0 && ltid_in_bounds_23204) {\n                            eta_p_23200 = ((volatile __local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182)];\n                            eta_p_23201 = ((volatile __local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182)];\n                            if ((local_tid_23182 - squot32(local_tid_23182, 32) * 32) == 0) {\n                                eta_p_23198 = eta_p_23200;\n                                eta_p_23199 = eta_p_23201;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_23208 = 1;\n                        while (slt32(skip_threads_23208, 32)) {\n                            bool thread_active_23209 = sle32(skip_threads_23208, local_tid_23182 - squot32(local_tid_23182, 32) * 32) && (squot32(local_tid_23182, 32) == 0 && ltid_in_bounds_23204);\n                            \n                            if (thread_active_23209) {\n                                // read operands\n                                {\n                                    eta_p_23198 = ((volatile __local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182) - sext_i32_i64(skip_threads_23208)];\n                                    eta_p_23199 = ((volatile __local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182) - sext_i32_i64(skip_threads_23208)];\n                                }\n                            }\n                            // perform operati", "on\n                            {\n                                bool inactive_23210 = slt64(srem64(sext_i32_i64(local_tid_23182 * 32 + 32 - 1), num_subhistos_23079), sext_i32_i64(local_tid_23182 * 32 + 32 - 1) - sext_i32_i64((local_tid_23182 - skip_threads_23208) * 32 + 32 - 1));\n                                \n                                if (thread_active_23209 && inactive_23210) {\n                                    eta_p_23198 = eta_p_23200;\n                                    eta_p_23199 = eta_p_23201;\n                                }\n                                if (thread_active_23209) {\n                                    if (!inactive_23210) {\n                                        int32_t tmp_23202 = add32(eta_p_23198, eta_p_23200);\n                                        int32_t tmp_23203 = add32(eta_p_23199, eta_p_23201);\n                                        \n                                        eta_p_23198 = tmp_23202;\n                                        eta_p_23199 = tmp_23203;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_23184, skip_threads_23208)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_23209) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182)] = eta_p_23198;\n                                    eta_p_23200 = eta_p_23198;\n                                    ((volatile __local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182)] = eta_p_23199;\n                                    eta_p_23201 = eta_p_23199;\n                                }\n                            }\n                            if (sle32(wave_sizze_23184, skip_threads_23208)) {\n                        ",
                                    "        barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_23208 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_23211 = squot32(local_tid_23182, 32) == 0 || !ltid_in_bounds_23204;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_23211) {\n                            eta_p_22068 = eta_p_22066;\n                            eta_p_22069 = eta_p_22067;\n                            eta_p_22066 = ((__local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(squot32(local_tid_23182, 32)) - (int64_t) 1];\n                            eta_p_22067 = ((__local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(squot32(local_tid_23182, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_23212 = slt64(srem64(sext_i32_i64(local_tid_23182), num_subhistos_23079), sext_i32_i64(local_tid_23182) - sext_i32_i64(squot32(local_tid_23182, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_23211) {\n                            if (inactive_23212) {\n                                eta_p_22066 = eta_p_22068;\n                                eta_p_22067 = eta_p_22069;\n                            }\n                        }\n                        if (!no_carry_in_23211) {\n                            if (!inactive_23212) {\n                                int32_t tmp_22070 = add32(eta_p_22066, eta_p_22068);\n                                int32_t tmp_22071 = add32(eta_p_22067, eta_p_22069);\n                                \n                                eta_p_22066 = tmp_22070;\n                                eta_p_22067 = tmp_22071;\n                  ", "          }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_23211) {\n                            ((__local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182)] = eta_p_22066;\n                            ((__local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182)] = eta_p_22067;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_23182, 32) == 0 && ltid_in_bounds_23204) {\n                        ((__local int32_t *) red_arr_i32_mem_23186)[sext_i32_i64(local_tid_23182)] = eta_p_22068;\n                        ((__local int32_t *) red_arr_i32_mem_23188)[sext_i32_i64(local_tid_23182)] = eta_p_22069;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_23193) * squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179) + sext_i32_i64(local_tid_23182), mz2080U_14093) && slt64(sext_i32_i64(local_tid_23182), squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179))) {\n                int32_t tmp_23213 = ((__local int32_t *) red_arr_i32_mem_23186)[(sext_i32_i64(local_tid_23182) + (int64_t) 1) * segment_sizze_nonzzero_23179 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_22801)[sext_i32_i64(virt_tblock_id_23193) * squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179) + sext_i32_i64(local_tid_23182)] = tmp_23213;\n                \n                int32_t tmp_23214 = ((__local int32_t *) red_arr_i32_mem_23188)[(sext_i32_i64(local_tid_23182) + (int64_t) 1) * segment_sizze_nonzzero_23179 - (int64_t) 1];\n                \n            ", "    ((__global int32_t *) mem_22799)[sext_i32_i64(virt_tblock_id_23193) * squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179) + sext_i32_i64(local_tid_23182)] = tmp_23214;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_22058\n}\nFUTHARK_KERNEL_SIZED(humanzisegscan_21978_dim1, 1, 1)\nvoid humanzisegscan_21978(__global int *global_failure, int64_t mz2080U_14093, int64_t num_tblocks_21975, int64_t num_virt_blocks_22923, int64_t num_virt_threads_22924, __global unsigned char *mem_param_22777, __global unsigned char *mem_22789, __global unsigned char *status_flags_mem_22925, __global unsigned char *aggregates_mem_22947, __global unsigned char *incprefixes_mem_22949, __global unsigned char *global_dynid_mem_22951)\n{\n    #define segscan_tblock_sizze_21973 (humanzisegscan_21978zisegscan_tblock_sizze_21973)\n    #define chunk_sizze_22922 (humanzisegscan_21978zichunk_sizze_22922)\n    \n    volatile __local unsigned char *local_mem_22981_backing_0 = &shared_mem[0];\n    const int64_t local_mem_22981_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_21973), chunk_sizze_22922 * segscan_tblock_sizze_21973 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_21973), chunk_sizze_22922 * segscan_tblock_sizze_21973 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22974;\n    int32_t tblock_sizze_22977;\n    int32_t wave_sizze_22976;\n    int32_t block_id_22975;\n    int32_t global_tid_22973;\n    int64_t phys_tid_21978;\n    int32_t chunk_sizze_32b_22978;\n    int64_t byte_offsets_22979;\n    int64_t warp_byte_offset_22980;\n    __local unsigned char *local_mem_22981;\n    int64_t trans_arr_len_22982;\n    int64_t phys_block_id_22988;\n    int64_t virtloop_bound_22989;\n    \n    local",
                                    "_tid_22974 = get_local_id(0);\n    tblock_sizze_22977 = get_local_size(0);\n    wave_sizze_22976 = LOCKSTEP_WIDTH;\n    block_id_22975 = get_tblock_id(0);\n    global_tid_22973 = block_id_22975 * tblock_sizze_22977 + local_tid_22974;\n    phys_tid_21978 = sext_i32_i64(global_tid_22973);\n    chunk_sizze_32b_22978 = sext_i64_i32(chunk_sizze_22922);\n    byte_offsets_22979 = segscan_tblock_sizze_21973 * (int64_t) 4;\n    warp_byte_offset_22980 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_22981 = (__local unsigned char *) local_mem_22981_backing_0;\n    trans_arr_len_22982 = chunk_sizze_22922 * segscan_tblock_sizze_21973;\n    phys_block_id_22988 = get_tblock_id(0);\n    virtloop_bound_22989 = sdiv_up64(num_virt_blocks_22923 - phys_block_id_22988, num_tblocks_21975);\n    for (int64_t virtloop_i_22990 = 0; virtloop_i_22990 < virtloop_bound_22989; virtloop_i_22990++) {\n        int64_t dynamic_id_22991;\n        int64_t block_offset_22992;\n        int64_t sgm_idx_22993;\n        int32_t boundary_22994;\n        int32_t segsizze_compact_22995;\n        int32_t private_mem_22996[chunk_sizze_22922];\n        int64_t thd_offset_22998;\n        int32_t acc_23014;\n        int32_t prefix_23024;\n        bool block_new_sgm_23025;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_22974 == 0) {\n                dynamic_id_22991 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_22951)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_22981)[(int64_t) 0] = dynamic_id_22991;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_22991 == num_virt_blocks_22923 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_22951)[(int64_t) 0] = 0;\n                    }\n                }\n      ", "      }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_22991 = ((__local int32_t *) local_mem_22981)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_22992 = dynamic_id_22991 * chunk_sizze_22922 * segscan_tblock_sizze_21973;\n        sgm_idx_22993 = smod64(block_offset_22992, mz2080U_14093);\n        boundary_22994 = sext_i64_i32(smin64(chunk_sizze_22922 * segscan_tblock_sizze_21973, mz2080U_14093 - sgm_idx_22993));\n        segsizze_compact_22995 = sext_i64_i32(smin64(chunk_sizze_22922 * segscan_tblock_sizze_21973, mz2080U_14093));\n        thd_offset_22998 = block_offset_22992 + sext_i32_i64(local_tid_22974);\n        // Load and map\n        {\n            for (int64_t i_22999 = 0; i_22999 < chunk_sizze_22922; i_22999++) {\n                int64_t virt_tid_23000 = thd_offset_22998 + i_22999 * segscan_tblock_sizze_21973;\n                int64_t slice_23001 = mz2080U_14093;\n                int64_t gtid_21977 = virt_tid_23000;\n                int64_t remnant_23002 = virt_tid_23000 - gtid_21977;\n                \n                if (slt64(virt_tid_23000, mz2080U_14093)) {\n                    int32_t x_21495 = ((__global int32_t *) mem_param_22777)[gtid_21977];\n                    \n                    private_mem_22996[i_22999] = x_21495;\n                } else {\n                    private_mem_22996[i_22999] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_23003 = 0; i_23003 < chunk_sizze_22922; i_23003++) {\n                int64_t sharedIdx_23004 = sext_i32_i64(local_tid_22974) + i_23003 * segscan_tblock_sizze_21973;\n                int32_t tmp_23005 = private_mem_22996[i_23003];\n                \n                ((__local int32_t *) local_mem_22981)[sharedIdx_23004] = tmp_23005;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23006 = 0; i_23006 < chunk_sizze_22922; i_23006++) {\n               ", " int64_t sharedIdx_23007 = sext_i32_i64(local_tid_22974) * chunk_sizze_22922 + i_23006;\n                int32_t tmp_23008 = ((__local int32_t *) local_mem_22981)[sharedIdx_23007];\n                \n                private_mem_22996[i_23006] = tmp_23008;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_23009 = 0; i_23009 < chunk_sizze_22922 - (int64_t) 1; i_23009++) {\n                int32_t eta_p_21492;\n                int32_t eta_p_21493;\n                \n                eta_p_21492 = private_mem_22996[i_23009];\n                eta_p_21493 = private_mem_22996[i_23009 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_21494 = add32(eta_p_21492, eta_p_21493);\n                \n                private_mem_22996[i_23009 + (int64_t) 1] = defunc_0_op_res_21494;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_23010 = private_mem_22996[chunk_sizze_22922 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)] = tmp_23010;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_23011;\n            int32_t eta_p_23012;\n            int32_t eta_p_23015;\n            int32_t eta_p_23016;\n            bool ltid_in_bounds_23018 = slt64(sext_i32_i64(local_tid_22974), num_virt_threads_22924);\n            int32_t skip_threads_23019;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23018) {\n                    eta_p_23012 = ((volatile __local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)];\n                    if ((local_tid_22974 - squot32(local_tid_22974, 32) * 32) == 0) {\n                        eta_p_23011 = eta_p_23012;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n       ",
                                    "     {\n                skip_threads_23019 = 1;\n                while (slt32(skip_threads_23019, 32)) {\n                    bool thread_active_23020 = sle32(skip_threads_23019, local_tid_22974 - squot32(local_tid_22974, 32) * 32) && ltid_in_bounds_23018;\n                    \n                    if (thread_active_23020) {\n                        // read operands\n                        {\n                            eta_p_23011 = ((volatile __local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974) - sext_i32_i64(skip_threads_23019)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23020) {\n                            int32_t defunc_0_op_res_23013 = add32(eta_p_23011, eta_p_23012);\n                            \n                            eta_p_23011 = defunc_0_op_res_23013;\n                        }\n                    }\n                    if (sle32(wave_sizze_22976, skip_threads_23019)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23020) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)] = eta_p_23011;\n                            eta_p_23012 = eta_p_23011;\n                        }\n                    }\n                    if (sle32(wave_sizze_22976, skip_threads_23019)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23019 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_22974 - squot32(local_tid_22974, 32) * 32) == 31 && ltid_in_bounds_23018) {\n                    ((volatile __local int32_t *) local_mem_22981)[sext_i32_i64(squot32(local_tid_22974, 32))] = et", "a_p_23011;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23021;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_22974, 32) == 0 && ltid_in_bounds_23018) {\n                        eta_p_23016 = ((volatile __local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)];\n                        if ((local_tid_22974 - squot32(local_tid_22974, 32) * 32) == 0) {\n                            eta_p_23015 = eta_p_23016;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23021 = 1;\n                    while (slt32(skip_threads_23021, 32)) {\n                        bool thread_active_23022 = sle32(skip_threads_23021, local_tid_22974 - squot32(local_tid_22974, 32) * 32) && (squot32(local_tid_22974, 32) == 0 && ltid_in_bounds_23018);\n                        \n                        if (thread_active_23022) {\n                            // read operands\n                            {\n                                eta_p_23015 = ((volatile __local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974) - sext_i32_i64(skip_threads_23021)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_23022) {\n                                int32_t defunc_0_op_res_23017 = add32(eta_p_23015, eta_p_23016);\n                                \n                                eta_p_23015 = defunc_0_op_res_23017;\n                            }\n                        }\n                        if (sle32(wave_sizze_22976, skip_threads_23021)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n      ", "                  }\n                        if (thread_active_23022) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)] = eta_p_23015;\n                                eta_p_23016 = eta_p_23015;\n                            }\n                        }\n                        if (sle32(wave_sizze_22976, skip_threads_23021)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23021 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23023 = squot32(local_tid_22974, 32) == 0 || !ltid_in_bounds_23018;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23023) {\n                        eta_p_23012 = eta_p_23011;\n                        eta_p_23011 = ((__local int32_t *) local_mem_22981)[sext_i32_i64(squot32(local_tid_22974, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23023) {\n                        int32_t defunc_0_op_res_23013 = add32(eta_p_23011, eta_p_23012);\n                        \n                        eta_p_23011 = defunc_0_op_res_23013;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_23023) {\n                        ((__local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)] = eta_p_23011;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_22974, 32) == 0 && ltid_in_bounds_23018) {\n                    ((_",
                                    "_local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)] = eta_p_23012;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_22974 == 0) {\n                acc_23014 = ((__local int32_t *) local_mem_22981)[segscan_tblock_sizze_21973 - (int64_t) 1];\n            } else {\n                acc_23014 = ((__local int32_t *) local_mem_22981)[sext_i32_i64(local_tid_22974) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23024 = 0;\n        block_new_sgm_23025 = sgm_idx_22993 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23025 && local_tid_22974 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_22949)[dynamic_id_22991] = acc_23014;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_22925)[dynamic_id_22991] = (int8_t) 2;\n                acc_23014 = 0;\n            }\n            if (!block_new_sgm_23025 && slt32(local_tid_22974, wave_sizze_22976)) {\n                if (local_tid_22974 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_22947)[dynamic_id_22991] = acc_23014;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_22925)[dynamic_id_22991] = (int8_t) 1;\n                    \n                    int8_t tmp_23026 = ((volatile __global int8_t *) status_flags_mem_22925)[dynamic_id_22991 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_22981)[(int64_t) 0] = tmp_23026;\n                }\n                mem_fence_local();\n                \n                int8_t status_23027 = ((__local int8_t *) local_mem_22981)[(int64_t) 0];\n                \n                if (status_23027 == (int8_t) 2) {\n                    if (local_tid_22974 == 0) {\n                        prefix_23024 = ((volatile __global int32_t *) in", "cprefixes_mem_22949)[dynamic_id_22991 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23028 = sext_i64_i32(dynamic_id_22991 - sext_i32_i64(wave_sizze_22976));\n                    \n                    while (slt32(wave_sizze_22976 * -1, readOffset_23028)) {\n                        int32_t read_i_23029 = readOffset_23028 + local_tid_22974;\n                        int32_t aggr_23030 = 0;\n                        int8_t flag_23031 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23029)) {\n                            flag_23031 = ((volatile __global int8_t *) status_flags_mem_22925)[sext_i32_i64(read_i_23029)];\n                            if (flag_23031 == (int8_t) 2) {\n                                aggr_23030 = ((volatile __global int32_t *) incprefixes_mem_22949)[sext_i32_i64(read_i_23029)];\n                            } else if (flag_23031 == (int8_t) 1) {\n                                aggr_23030 = ((volatile __global int32_t *) aggregates_mem_22947)[sext_i32_i64(read_i_23029)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_22981)[(int64_t) 8 + sext_i32_i64(local_tid_22974)] = aggr_23030;\n                        ((__local int8_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)] = flag_23031;\n                        flag_23031 = ((__local int8_t *) local_mem_22981)[sext_i32_i64(wave_sizze_22976) - (int64_t) 1];\n                        if (slt8(flag_23031, (int8_t) 2)) {\n                            int8_t flg_x_23035;\n                            int8_t flg_y_23036;\n                            int32_t eta_p_23032;\n                            int32_t eta_p_23033;\n                            int32_t skip_threads_23037;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23036 = ((volatile __local int8_t *) local_mem", "_22981)[sext_i32_i64(local_tid_22974)];\n                                eta_p_23033 = ((volatile __local int32_t *) local_mem_22981)[(int64_t) 8 + sext_i32_i64(local_tid_22974)];\n                                if ((local_tid_22974 - squot32(local_tid_22974, 32) * 32) == 0) {\n                                    eta_p_23032 = eta_p_23033;\n                                    flg_x_23035 = flg_y_23036;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23037 = 1;\n                                while (slt32(skip_threads_23037, 32)) {\n                                    if (sle32(skip_threads_23037, local_tid_22974 - squot32(local_tid_22974, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23035 = ((volatile __local int8_t *) local_mem_22981)[sext_i32_i64(local_tid_22974) - sext_i32_i64(skip_threads_23037)];\n                                            eta_p_23032 = ((volatile __local int32_t *) local_mem_22981)[(int64_t) 8 + (sext_i32_i64(local_tid_22974) - sext_i32_i64(skip_threads_23037))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23036 == (int8_t) 2 || flg_y_23036 == (int8_t) 0) {\n                                                flg_x_23035 = flg_y_23036;\n                                                eta_p_23032 = eta_p_23033;\n                                            } else {\n                                                int32_t defunc_0_op_res_23034 = add32(eta_p_23032, eta_p_23033);\n                                                \n                                                eta_p_23032 = defunc_0_op_res_23034;\n                  ",
                                    "                          }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_22981)[sext_i32_i64(local_tid_22974)] = flg_x_23035;\n                                            flg_y_23036 = flg_x_23035;\n                                            ((volatile __local int32_t *) local_mem_22981)[(int64_t) 8 + sext_i32_i64(local_tid_22974)] = eta_p_23032;\n                                            eta_p_23033 = eta_p_23032;\n                                        }\n                                    }\n                                    skip_threads_23037 *= 2;\n                                }\n                            }\n                        }\n                        flag_23031 = ((__local int8_t *) local_mem_22981)[sext_i32_i64(wave_sizze_22976) - (int64_t) 1];\n                        aggr_23030 = ((__local int32_t *) local_mem_22981)[(int64_t) 8 + (sext_i32_i64(wave_sizze_22976) - (int64_t) 1)];\n                        if (flag_23031 == (int8_t) 2) {\n                            readOffset_23028 = wave_sizze_22976 * -1;\n                        } else if (flag_23031 == (int8_t) 1) {\n                            readOffset_23028 -= wave_sizze_22976;\n                        }\n                        if (slt8((int8_t) 0, flag_23031)) {\n                            int32_t eta_p_23038 = aggr_23030;\n                            int32_t eta_p_23039 = prefix_23024;\n                            int32_t defunc_0_op_res_23040 = add32(eta_p_23038, eta_p_23039);\n                            \n                            prefix_23024 = defunc_0_op_res_23040;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_22974 == 0) {\n                    if (boundary_22994 == sext_i64_i32(segscan_tblock_sizze_21973 * chunk_sizze_22922)) {", "\n                        int32_t eta_p_23041 = prefix_23024;\n                        int32_t eta_p_23042 = acc_23014;\n                        int32_t defunc_0_op_res_23043 = add32(eta_p_23041, eta_p_23042);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_22949)[dynamic_id_22991] = defunc_0_op_res_23043;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_22925)[dynamic_id_22991] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_22981)[(int64_t) 8] = prefix_23024;\n                    acc_23014 = 0;\n                }\n            }\n            if (!(dynamic_id_22991 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23024 = ((__local int32_t *) local_mem_22981)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_23044;\n            int32_t eta_p_23045;\n            int32_t eta_p_23047 = prefix_23024;\n            int32_t eta_p_23048 = acc_23014;\n            \n            if (slt32(local_tid_22974 * chunk_sizze_32b_22978, boundary_22994) && !block_new_sgm_23025) {\n                int32_t defunc_0_op_res_23049 = add32(eta_p_23047, eta_p_23048);\n                \n                eta_p_23044 = defunc_0_op_res_23049;\n            } else {\n                eta_p_23044 = acc_23014;\n            }\n            \n            int32_t stopping_point_23050 = segsizze_compact_22995 - srem32(local_tid_22974 * chunk_sizze_32b_22978 - 1 + segsizze_compact_22995 - boundary_22994, segsizze_compact_22995);\n            \n            for (int64_t i_23051 = 0; i_23051 < chunk_sizze_22922; i_23051++) {\n                if (slt32(sext_i64_i32(i_23051), stopping_point_23050 - 1)) {\n                    eta_p_23045 = private_mem_22996[i_23051];\n                    \n                    int32_t defunc_0_op_res_23046 = add32(eta_p_2", "3044, eta_p_23045);\n                    \n                    private_mem_22996[i_23051] = defunc_0_op_res_23046;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23052 = 0; i_23052 < chunk_sizze_22922; i_23052++) {\n                int64_t sharedIdx_23053 = sext_i32_i64(local_tid_22974) * chunk_sizze_22922 + i_23052;\n                int32_t tmp_23054 = private_mem_22996[i_23052];\n                \n                ((__local int32_t *) local_mem_22981)[sharedIdx_23053] = tmp_23054;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23055 = 0; i_23055 < chunk_sizze_22922; i_23055++) {\n                int64_t flat_idx_23056 = thd_offset_22998 + i_23055 * segscan_tblock_sizze_21973;\n                int64_t slice_23057 = mz2080U_14093;\n                int64_t gtid_21977 = flat_idx_23056;\n                int64_t remnant_23058 = flat_idx_23056 - gtid_21977;\n                \n                if (slt64(flat_idx_23056, mz2080U_14093)) {\n                    int32_t tmp_23059 = ((__local int32_t *) local_mem_22981)[flat_idx_23056 - block_offset_22992];\n                    \n                    ((__global int32_t *) mem_22789)[gtid_21977] = tmp_23059;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_21973\n    #undef chunk_sizze_22922\n}\nFUTHARK_KERNEL_SIZED(humanzisegscan_22150_dim1, 1, 1)\nvoid humanzisegscan_22150(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_14093, int64_t loop_dz2087U_20987, int64_t num_tblocks_22147, int64_t num_virt_blocks_23281, int64_t num_virt_threads_23282, __global unsigned char *mem_param_22780, __global unsigned char *mem_22795, __global unsigned char *mem_22797, __global unsigned char *mem_22807, __global unsigned char *mem_22814, __global unsigned ",
                                    "char *mem_22816, __global unsigned char *status_flags_mem_23283, __global unsigned char *aggregates_mem_23285, __global unsigned char *incprefixes_mem_23287, __global unsigned char *global_dynid_mem_23289)\n{\n    #define segscan_tblock_sizze_22145 (humanzisegscan_22150zisegscan_tblock_sizze_22145)\n    #define chunk_sizze_23280 (humanzisegscan_22150zichunk_sizze_23280)\n    \n    volatile __local unsigned char *local_mem_23299_backing_0 = &shared_mem[0];\n    const int64_t local_mem_23299_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22145), chunk_sizze_23280 * segscan_tblock_sizze_22145 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22145), chunk_sizze_23280 * segscan_tblock_sizze_22145 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23292;\n    int32_t tblock_sizze_23295;\n    int32_t wave_sizze_23294;\n    int32_t block_id_23293;\n    int32_t global_tid_23291;\n    int64_t phys_tid_22150;\n    int32_t chunk_sizze_32b_23296;\n    int64_t byte_offsets_23297;\n    int64_t warp_byte_offset_23298;\n    __local unsigned char *local_mem_23299;\n    int64_t trans_arr_len_23300;\n    int64_t phys_block_id_23306;\n    int64_t virtloop_bound_23307;\n    \n    local_tid_23292 = get_local_id(0);\n    tblock_sizze_23295 = get_local_size(0);\n    wave_sizze_23294 = LOCKSTEP_WIDTH;\n    block_id_23293 = get_tblock_id(0);\n    global_tid_23291 = block_id_23293 * tblock_sizze_23295 + local_tid_23292;\n    phys_tid_22150 = sext_i32_i64(global_tid_23291);\n    chunk_sizze_32b_23296 = sext_i64_i32(chunk_sizze_23280);\n    byte_offsets_23297 = segscan_tblock_sizze_22145 * (int64_t) 8;\n    warp_byte_offset_23298 = (int64_t) 288;\n    // Allocate reusable shar", "ed memory\n    { }\n    local_mem_23299 = (__local unsigned char *) local_mem_23299_backing_0;\n    trans_arr_len_23300 = chunk_sizze_23280 * segscan_tblock_sizze_22145;\n    phys_block_id_23306 = get_tblock_id(0);\n    virtloop_bound_23307 = sdiv_up64(num_virt_blocks_23281 - phys_block_id_23306, num_tblocks_22147);\n    for (int64_t virtloop_i_23308 = 0; virtloop_i_23308 < virtloop_bound_23307; virtloop_i_23308++) {\n        int64_t dynamic_id_23309;\n        int64_t block_offset_23310;\n        int64_t sgm_idx_23311;\n        int32_t boundary_23312;\n        int32_t segsizze_compact_23313;\n        int64_t private_mem_23314[chunk_sizze_23280];\n        int64_t thd_offset_23316;\n        int64_t acc_23332;\n        int64_t prefix_23342;\n        bool block_new_sgm_23343;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_23292 == 0) {\n                dynamic_id_23309 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_23289)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_23299)[(int64_t) 0] = dynamic_id_23309;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_23309 == num_virt_blocks_23281 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_23289)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_23309 = ((__local int32_t *) local_mem_23299)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_23310 = dynamic_id_23309 * chunk_sizze_23280 * segscan_tblock_sizze_22145;\n        sgm_idx_23311 = smod64(block_offset_23310, loop_dz2087U_20987);\n        boundary_23312 = sext_i64_i32(smin64(chunk_sizze_23280 * segscan_tblock_sizze_22145, loop_dz2087U_20987 - sgm_idx_23311));\n        segs", "izze_compact_23313 = sext_i64_i32(smin64(chunk_sizze_23280 * segscan_tblock_sizze_22145, loop_dz2087U_20987));\n        thd_offset_23316 = block_offset_23310 + sext_i32_i64(local_tid_23292);\n        // Load and map\n        {\n            for (int64_t i_23317 = 0; i_23317 < chunk_sizze_23280; i_23317++) {\n                int64_t virt_tid_23318 = thd_offset_23316 + i_23317 * segscan_tblock_sizze_22145;\n                int64_t slice_23319 = loop_dz2087U_20987;\n                int64_t gtid_22149 = virt_tid_23318;\n                int64_t remnant_23320 = virt_tid_23318 - gtid_22149;\n                \n                if (slt64(virt_tid_23318, loop_dz2087U_20987)) {\n                    int32_t eta_p_21390 = ((__global int32_t *) mem_param_22780)[gtid_22149];\n                    int64_t ii_21393 = sext_i32_i64(eta_p_21390);\n                    bool x_21394 = sle64((int64_t) 0, ii_21393);\n                    bool y_21395 = slt64(ii_21393, mz2080U_14093);\n                    bool bounds_check_21396 = x_21394 && y_21395;\n                    bool index_certs_21397;\n                    \n                    if (!bounds_check_21396) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                                global_failure_args[0] = (int64_t) ii_21393;\n                                global_failure_args[1] = (int64_t) mz2080U_14093;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int32_t eta_p_21391 = ((__global int32_t *) mem_22797)[gtid_22149];\n                    int32_t eta_p_21392 = ((__global int32_t *) mem_22795)[gtid_22149];\n                    int32_t lifted_lambda_res_21398 = ((__global int32_t *) mem_22807)[ii_21393];\n                    bool cond_21400 = lifted_lambda_res_21398 == 0;\n                    bool co",
                                    "nd_t_res_21401 = eta_p_21391 == 1;\n                    bool x_21402 = cond_21400 && cond_t_res_21401;\n                    bool cond_21403 = lifted_lambda_res_21398 == 2;\n                    bool cond_t_res_21404 = eta_p_21391 == 0;\n                    bool x_21405 = cond_21403 && cond_t_res_21404;\n                    bool lifted_lambda_res_f_res_t_res_21406 = eta_p_21392 == 0;\n                    bool x_21407 = x_21405 && lifted_lambda_res_f_res_t_res_21406;\n                    bool x_21408 = !x_21402;\n                    bool y_21409 = x_21407 && x_21408;\n                    bool lifted_lambda_res_21410 = x_21402 || y_21409;\n                    int64_t defunc_0_f_res_21412 = btoi_bool_i64(lifted_lambda_res_21410);\n                    \n                    ((__global int64_t *) mem_22816)[gtid_22149] = defunc_0_f_res_21412;\n                    private_mem_23314[i_23317] = defunc_0_f_res_21412;\n                } else {\n                    private_mem_23314[i_23317] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_23321 = 0; i_23321 < chunk_sizze_23280; i_23321++) {\n                int64_t sharedIdx_23322 = sext_i32_i64(local_tid_23292) + i_23321 * segscan_tblock_sizze_22145;\n                int64_t tmp_23323 = private_mem_23314[i_23321];\n                \n                ((__local int64_t *) local_mem_23299)[sharedIdx_23322] = tmp_23323;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23324 = 0; i_23324 < chunk_sizze_23280; i_23324++) {\n                int64_t sharedIdx_23325 = sext_i32_i64(local_tid_23292) * chunk_sizze_23280 + i_23324;\n                int64_t tmp_23326 = ((__local int64_t *) local_mem_23299)[sharedIdx_23325];\n                \n                private_mem_23314[i_23324] = tmp_23326;\n            }\n", "            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_23327 = 0; i_23327 < chunk_sizze_23280 - (int64_t) 1; i_23327++) {\n                int64_t eta_p_21106;\n                int64_t eta_p_21107;\n                \n                eta_p_21106 = private_mem_23314[i_23327];\n                eta_p_21107 = private_mem_23314[i_23327 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_21108 = add64(eta_p_21106, eta_p_21107);\n                \n                private_mem_23314[i_23327 + (int64_t) 1] = defunc_0_op_res_21108;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_23328 = private_mem_23314[chunk_sizze_23280 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)] = tmp_23328;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_23329;\n            int64_t eta_p_23330;\n            int64_t eta_p_23333;\n            int64_t eta_p_23334;\n            bool ltid_in_bounds_23336 = slt64(sext_i32_i64(local_tid_23292), num_virt_threads_23282);\n            int32_t skip_threads_23337;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23336) {\n                    eta_p_23330 = ((volatile __local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)];\n                    if ((local_tid_23292 - squot32(local_tid_23292, 32) * 32) == 0) {\n                        eta_p_23329 = eta_p_23330;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23337 = 1;\n                while (slt32(skip_threads_23337, 32)) {\n                    bool thread_active_23338 = sle32(skip_threads_23337, local_tid_23292 - squot32(local_tid_23292, 32) * 32) && ltid_in_bounds_23336;\n             ", "       \n                    if (thread_active_23338) {\n                        // read operands\n                        {\n                            eta_p_23329 = ((volatile __local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292) - sext_i32_i64(skip_threads_23337)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23338) {\n                            int64_t defunc_0_op_res_23331 = add64(eta_p_23329, eta_p_23330);\n                            \n                            eta_p_23329 = defunc_0_op_res_23331;\n                        }\n                    }\n                    if (sle32(wave_sizze_23294, skip_threads_23337)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23338) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)] = eta_p_23329;\n                            eta_p_23330 = eta_p_23329;\n                        }\n                    }\n                    if (sle32(wave_sizze_23294, skip_threads_23337)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23337 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_23292 - squot32(local_tid_23292, 32) * 32) == 31 && ltid_in_bounds_23336) {\n                    ((volatile __local int64_t *) local_mem_23299)[sext_i32_i64(squot32(local_tid_23292, 32))] = eta_p_23329;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23339;\n                \n             ",
                                    "   // read input for in-block scan\n                {\n                    if (squot32(local_tid_23292, 32) == 0 && ltid_in_bounds_23336) {\n                        eta_p_23334 = ((volatile __local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)];\n                        if ((local_tid_23292 - squot32(local_tid_23292, 32) * 32) == 0) {\n                            eta_p_23333 = eta_p_23334;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23339 = 1;\n                    while (slt32(skip_threads_23339, 32)) {\n                        bool thread_active_23340 = sle32(skip_threads_23339, local_tid_23292 - squot32(local_tid_23292, 32) * 32) && (squot32(local_tid_23292, 32) == 0 && ltid_in_bounds_23336);\n                        \n                        if (thread_active_23340) {\n                            // read operands\n                            {\n                                eta_p_23333 = ((volatile __local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292) - sext_i32_i64(skip_threads_23339)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_23340) {\n                                int64_t defunc_0_op_res_23335 = add64(eta_p_23333, eta_p_23334);\n                                \n                                eta_p_23333 = defunc_0_op_res_23335;\n                            }\n                        }\n                        if (sle32(wave_sizze_23294, skip_threads_23339)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23340) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)] = eta_p_2333", "3;\n                                eta_p_23334 = eta_p_23333;\n                            }\n                        }\n                        if (sle32(wave_sizze_23294, skip_threads_23339)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23339 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23341 = squot32(local_tid_23292, 32) == 0 || !ltid_in_bounds_23336;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23341) {\n                        eta_p_23330 = eta_p_23329;\n                        eta_p_23329 = ((__local int64_t *) local_mem_23299)[sext_i32_i64(squot32(local_tid_23292, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23341) {\n                        int64_t defunc_0_op_res_23331 = add64(eta_p_23329, eta_p_23330);\n                        \n                        eta_p_23329 = defunc_0_op_res_23331;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_23341) {\n                        ((__local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)] = eta_p_23329;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_23292, 32) == 0 && ltid_in_bounds_23336) {\n                    ((__local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)] = eta_p_23330;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_23292 == 0) {\n                acc_23332 = ((", "__local int64_t *) local_mem_23299)[segscan_tblock_sizze_22145 - (int64_t) 1];\n            } else {\n                acc_23332 = ((__local int64_t *) local_mem_23299)[sext_i32_i64(local_tid_23292) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23342 = (int64_t) 0;\n        block_new_sgm_23343 = sgm_idx_23311 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23343 && local_tid_23292 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_23287)[dynamic_id_23309] = acc_23332;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23283)[dynamic_id_23309] = (int8_t) 2;\n                acc_23332 = (int64_t) 0;\n            }\n            if (!block_new_sgm_23343 && slt32(local_tid_23292, wave_sizze_23294)) {\n                if (local_tid_23292 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_23285)[dynamic_id_23309] = acc_23332;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23283)[dynamic_id_23309] = (int8_t) 1;\n                    \n                    int8_t tmp_23344 = ((volatile __global int8_t *) status_flags_mem_23283)[dynamic_id_23309 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_23299)[(int64_t) 0] = tmp_23344;\n                }\n                mem_fence_local();\n                \n                int8_t status_23345 = ((__local int8_t *) local_mem_23299)[(int64_t) 0];\n                \n                if (status_23345 == (int8_t) 2) {\n                    if (local_tid_23292 == 0) {\n                        prefix_23342 = ((volatile __global int64_t *) incprefixes_mem_23287)[dynamic_id_23309 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23346 = sext_i64_i32(dynamic_id_23309 - sext_i32_i64(wave_sizze_23294));\n                    \n             ",
                                    "       while (slt32(wave_sizze_23294 * -1, readOffset_23346)) {\n                        int32_t read_i_23347 = readOffset_23346 + local_tid_23292;\n                        int64_t aggr_23348 = (int64_t) 0;\n                        int8_t flag_23349 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23347)) {\n                            flag_23349 = ((volatile __global int8_t *) status_flags_mem_23283)[sext_i32_i64(read_i_23347)];\n                            if (flag_23349 == (int8_t) 2) {\n                                aggr_23348 = ((volatile __global int64_t *) incprefixes_mem_23287)[sext_i32_i64(read_i_23347)];\n                            } else if (flag_23349 == (int8_t) 1) {\n                                aggr_23348 = ((volatile __global int64_t *) aggregates_mem_23285)[sext_i32_i64(read_i_23347)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_23299)[(int64_t) 4 + sext_i32_i64(local_tid_23292)] = aggr_23348;\n                        ((__local int8_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)] = flag_23349;\n                        flag_23349 = ((__local int8_t *) local_mem_23299)[sext_i32_i64(wave_sizze_23294) - (int64_t) 1];\n                        if (slt8(flag_23349, (int8_t) 2)) {\n                            int8_t flg_x_23353;\n                            int8_t flg_y_23354;\n                            int64_t eta_p_23350;\n                            int64_t eta_p_23351;\n                            int32_t skip_threads_23355;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23354 = ((volatile __local int8_t *) local_mem_23299)[sext_i32_i64(local_tid_23292)];\n                                eta_p_23351 = ((volatile __local int64_t *) local_mem_23299)[(int64_t) 4 + sext_i32_i64(local_tid_23292)];\n                                if ((local_tid_23292 - squ", "ot32(local_tid_23292, 32) * 32) == 0) {\n                                    eta_p_23350 = eta_p_23351;\n                                    flg_x_23353 = flg_y_23354;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23355 = 1;\n                                while (slt32(skip_threads_23355, 32)) {\n                                    if (sle32(skip_threads_23355, local_tid_23292 - squot32(local_tid_23292, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23353 = ((volatile __local int8_t *) local_mem_23299)[sext_i32_i64(local_tid_23292) - sext_i32_i64(skip_threads_23355)];\n                                            eta_p_23350 = ((volatile __local int64_t *) local_mem_23299)[(int64_t) 4 + (sext_i32_i64(local_tid_23292) - sext_i32_i64(skip_threads_23355))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23354 == (int8_t) 2 || flg_y_23354 == (int8_t) 0) {\n                                                flg_x_23353 = flg_y_23354;\n                                                eta_p_23350 = eta_p_23351;\n                                            } else {\n                                                int64_t defunc_0_op_res_23352 = add64(eta_p_23350, eta_p_23351);\n                                                \n                                                eta_p_23350 = defunc_0_op_res_23352;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t", " *) local_mem_23299)[sext_i32_i64(local_tid_23292)] = flg_x_23353;\n                                            flg_y_23354 = flg_x_23353;\n                                            ((volatile __local int64_t *) local_mem_23299)[(int64_t) 4 + sext_i32_i64(local_tid_23292)] = eta_p_23350;\n                                            eta_p_23351 = eta_p_23350;\n                                        }\n                                    }\n                                    skip_threads_23355 *= 2;\n                                }\n                            }\n                        }\n                        flag_23349 = ((__local int8_t *) local_mem_23299)[sext_i32_i64(wave_sizze_23294) - (int64_t) 1];\n                        aggr_23348 = ((__local int64_t *) local_mem_23299)[(int64_t) 4 + (sext_i32_i64(wave_sizze_23294) - (int64_t) 1)];\n                        if (flag_23349 == (int8_t) 2) {\n                            readOffset_23346 = wave_sizze_23294 * -1;\n                        } else if (flag_23349 == (int8_t) 1) {\n                            readOffset_23346 -= wave_sizze_23294;\n                        }\n                        if (slt8((int8_t) 0, flag_23349)) {\n                            int64_t eta_p_23356 = aggr_23348;\n                            int64_t eta_p_23357 = prefix_23342;\n                            int64_t defunc_0_op_res_23358 = add64(eta_p_23356, eta_p_23357);\n                            \n                            prefix_23342 = defunc_0_op_res_23358;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_23292 == 0) {\n                    if (boundary_23312 == sext_i64_i32(segscan_tblock_sizze_22145 * chunk_sizze_23280)) {\n                        int64_t eta_p_23359 = prefix_23342;\n                        int64_t eta_p_23360 = acc_23332;\n                        int64_t defunc_0_op_res_23361 = add64(eta_p_23359, eta_p_23360);\n                        \n     ",
                                    "                   ((volatile __global int64_t *) incprefixes_mem_23287)[dynamic_id_23309] = defunc_0_op_res_23361;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23283)[dynamic_id_23309] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_23299)[(int64_t) 4] = prefix_23342;\n                    acc_23332 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_23309 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23342 = ((__local int64_t *) local_mem_23299)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_23362;\n            int64_t eta_p_23363;\n            int64_t eta_p_23365 = prefix_23342;\n            int64_t eta_p_23366 = acc_23332;\n            \n            if (slt32(local_tid_23292 * chunk_sizze_32b_23296, boundary_23312) && !block_new_sgm_23343) {\n                int64_t defunc_0_op_res_23367 = add64(eta_p_23365, eta_p_23366);\n                \n                eta_p_23362 = defunc_0_op_res_23367;\n            } else {\n                eta_p_23362 = acc_23332;\n            }\n            \n            int32_t stopping_point_23368 = segsizze_compact_23313 - srem32(local_tid_23292 * chunk_sizze_32b_23296 - 1 + segsizze_compact_23313 - boundary_23312, segsizze_compact_23313);\n            \n            for (int64_t i_23369 = 0; i_23369 < chunk_sizze_23280; i_23369++) {\n                if (slt32(sext_i64_i32(i_23369), stopping_point_23368 - 1)) {\n                    eta_p_23363 = private_mem_23314[i_23369];\n                    \n                    int64_t defunc_0_op_res_23364 = add64(eta_p_23362, eta_p_23363);\n                    \n                    private_mem_23314[i_23369] = defunc_0_op_res_23364;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coales", "ced fashion\n        {\n            for (int64_t i_23370 = 0; i_23370 < chunk_sizze_23280; i_23370++) {\n                int64_t sharedIdx_23371 = sext_i32_i64(local_tid_23292) * chunk_sizze_23280 + i_23370;\n                int64_t tmp_23372 = private_mem_23314[i_23370];\n                \n                ((__local int64_t *) local_mem_23299)[sharedIdx_23371] = tmp_23372;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23373 = 0; i_23373 < chunk_sizze_23280; i_23373++) {\n                int64_t flat_idx_23374 = thd_offset_23316 + i_23373 * segscan_tblock_sizze_22145;\n                int64_t slice_23375 = loop_dz2087U_20987;\n                int64_t gtid_22149 = flat_idx_23374;\n                int64_t remnant_23376 = flat_idx_23374 - gtid_22149;\n                \n                if (slt64(flat_idx_23374, loop_dz2087U_20987)) {\n                    int64_t tmp_23377 = ((__local int64_t *) local_mem_23299)[flat_idx_23374 - block_offset_23310];\n                    \n                    ((__global int64_t *) mem_22814)[gtid_22149] = tmp_23377;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22145\n    #undef chunk_sizze_23280\n}\nFUTHARK_KERNEL_SIZED(human_regularziseghist_global_22277_dim1, 1, 1)\nvoid human_regularziseghist_global_22277(__global int *global_failure, int64_t mz2080U_17317, int64_t nz2081U_17318, int64_t num_tblocks_22272, int64_t num_subhistos_23344, int32_t chk_i_23425, int64_t hist_H_chk_23426, __global unsigned char *II1_mem_22768, __global unsigned char *mem_22786, __global unsigned char *mem_22787, __global unsigned char *defunc_0_map_res_subhistos_mem_23345, __global unsigned char *defunc_0_map_res_subhistos_mem_23347)\n{\n    #define seghist_tblock_sizze_22270 (human_regularziseghist_global_22277ziseghist_tblock_sizze_22270)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23428;\n    int32_t tblock_sizz", "e_23431;\n    int32_t wave_sizze_23430;\n    int32_t block_id_23429;\n    int32_t global_tid_23427;\n    int64_t phys_tid_22277;\n    int32_t subhisto_ind_23432;\n    int64_t num_chunks_23433;\n    \n    local_tid_23428 = get_local_id(0);\n    tblock_sizze_23431 = get_local_size(0);\n    wave_sizze_23430 = LOCKSTEP_WIDTH;\n    block_id_23429 = get_tblock_id(0);\n    global_tid_23427 = block_id_23429 * tblock_sizze_23431 + local_tid_23428;\n    phys_tid_22277 = sext_i32_i64(global_tid_23427);\n    subhisto_ind_23432 = squot32(global_tid_23427, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_22270 * num_tblocks_22272), sext_i64_i32(num_subhistos_23344)));\n    num_chunks_23433 = sdiv_up64(nz2081U_17318, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22270 * num_tblocks_22272)));\n    for (int64_t chunk_i_23434 = 0; chunk_i_23434 < num_chunks_23433; chunk_i_23434++) {\n        int64_t i_23435 = chunk_i_23434 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22270 * num_tblocks_22272)) + sext_i32_i64(global_tid_23427);\n        \n        if (slt64(i_23435, nz2081U_17318)) {\n            int64_t slice_23436;\n            int64_t gtid_22276;\n            int64_t remnant_23437;\n            \n            slice_23436 = nz2081U_17318;\n            gtid_22276 = i_23435;\n            remnant_23437 = i_23435 - gtid_22276;\n            if (slt64(i_23435, nz2081U_17318)) {\n                bool eta_p_22284;\n                bool eta_p_22285;\n                int32_t eta_p_22286;\n                int32_t bool_res_22287;\n                int32_t bool_res_22288;\n                int64_t i32_res_22289;\n                \n                eta_p_22284 = ((__global bool *) mem_22787)[gtid_22276];\n                eta_p_22285 = ((__global bool *) mem_22786)[gtid_22276];\n                eta_p_22286 = ((__global int32_t *) II1_mem_22768)[gtid_22276];\n                bool_res_22287 = btoi_bool_i32(eta_p_22284);\n                bool_res_22288 = btoi_bool_i32(eta_p_22285);\n                i32_res_22289 = sext_i32_i64(eta_p_22286);\n  ",
                                    "              // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_23425) * hist_H_chk_23426, i32_res_22289) && (slt64(i32_res_22289, sext_i32_i64(chk_i_23425) * hist_H_chk_23426 + hist_H_chk_23426) && (sle64((int64_t) 0, i32_res_22289) && slt64(i32_res_22289, mz2080U_17317)))) {\n                        int32_t eta_p_22278;\n                        int32_t eta_p_22279;\n                        int32_t eta_p_22280;\n                        int32_t eta_p_22281;\n                        \n                        eta_p_22280 = bool_res_22287;\n                        eta_p_22281 = bool_res_22288;\n                        \n                        int32_t old_23438;\n                        \n                        old_23438 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_23345)[sext_i32_i64(subhisto_ind_23432) * mz2080U_17317 + i32_res_22289], (int) eta_p_22280);\n                        \n                        int32_t old_23439;\n                        \n                        old_23439 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_23347)[sext_i32_i64(subhisto_ind_23432) * mz2080U_17317 + i32_res_22289], (int) eta_p_22281);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_22270\n}\nFUTHARK_KERNEL_SIZED(human_regularziseghist_global_22451_dim1, 1, 1)\nvoid human_regularziseghist_global_22451(__global int *global_failure, int64_t mz2080U_17317, int64_t loop_dz2081Uz2089Uz2081U_21167, int64_t num_tblocks_22446, int64_t num_subhistos_23791, int32_t chk_i_23872, int64_t hist_H_chk_23873, __global unsigned char *mem_param_22820, __global unsigned char *mem_22834, __global unsigned char *mem_22835, __global unsigned char *defunc_0_map_res_subhistos_mem_23792, __global unsigned char *defunc_0_map_res_subhistos_mem_23794)\n{\n    #define seghi", "st_tblock_sizze_22444 (human_regularziseghist_global_22451ziseghist_tblock_sizze_22444)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23875;\n    int32_t tblock_sizze_23878;\n    int32_t wave_sizze_23877;\n    int32_t block_id_23876;\n    int32_t global_tid_23874;\n    int64_t phys_tid_22451;\n    int32_t subhisto_ind_23879;\n    int64_t num_chunks_23880;\n    \n    local_tid_23875 = get_local_id(0);\n    tblock_sizze_23878 = get_local_size(0);\n    wave_sizze_23877 = LOCKSTEP_WIDTH;\n    block_id_23876 = get_tblock_id(0);\n    global_tid_23874 = block_id_23876 * tblock_sizze_23878 + local_tid_23875;\n    phys_tid_22451 = sext_i32_i64(global_tid_23874);\n    subhisto_ind_23879 = squot32(global_tid_23874, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_22444 * num_tblocks_22446), sext_i64_i32(num_subhistos_23791)));\n    num_chunks_23880 = sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22444 * num_tblocks_22446)));\n    for (int64_t chunk_i_23881 = 0; chunk_i_23881 < num_chunks_23880; chunk_i_23881++) {\n        int64_t i_23882 = chunk_i_23881 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_22444 * num_tblocks_22446)) + sext_i32_i64(global_tid_23874);\n        \n        if (slt64(i_23882, loop_dz2081Uz2089Uz2081U_21167)) {\n            int64_t slice_23883;\n            int64_t gtid_22450;\n            int64_t remnant_23884;\n            \n            slice_23883 = loop_dz2081Uz2089Uz2081U_21167;\n            gtid_22450 = i_23882;\n            remnant_23884 = i_23882 - gtid_22450;\n            if (slt64(i_23882, loop_dz2081Uz2089Uz2081U_21167)) {\n                bool eta_p_22458;\n                bool eta_p_22459;\n                int32_t eta_p_22460;\n                int32_t bool_res_22461;\n                int32_t bool_res_22462;\n                int64_t i32_res_22463;\n                \n                eta_p_22458 = ((__global bool *) mem_22835)[gtid_22450];\n                eta_p_22459 = ((__global bool *) mem_22834)[gtid_22450];\n    ", "            eta_p_22460 = ((__global int32_t *) mem_param_22820)[gtid_22450];\n                bool_res_22461 = btoi_bool_i32(eta_p_22458);\n                bool_res_22462 = btoi_bool_i32(eta_p_22459);\n                i32_res_22463 = sext_i32_i64(eta_p_22460);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_23872) * hist_H_chk_23873, i32_res_22463) && (slt64(i32_res_22463, sext_i32_i64(chk_i_23872) * hist_H_chk_23873 + hist_H_chk_23873) && (sle64((int64_t) 0, i32_res_22463) && slt64(i32_res_22463, mz2080U_17317)))) {\n                        int32_t eta_p_22452;\n                        int32_t eta_p_22453;\n                        int32_t eta_p_22454;\n                        int32_t eta_p_22455;\n                        \n                        eta_p_22454 = bool_res_22461;\n                        eta_p_22455 = bool_res_22462;\n                        \n                        int32_t old_23885;\n                        \n                        old_23885 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_23792)[sext_i32_i64(subhisto_ind_23879) * mz2080U_17317 + i32_res_22463], (int) eta_p_22454);\n                        \n                        int32_t old_23886;\n                        \n                        old_23886 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_23794)[sext_i32_i64(subhisto_ind_23879) * mz2080U_17317 + i32_res_22463], (int) eta_p_22455);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_22444\n}\nFUTHARK_KERNEL_SIZED(human_regularziseghist_local_22277_dim1, 1, 1)\nvoid human_regularziseghist_local_22277(__global int *global_failure, int64_t mz2080U_17317, int64_t nz2081U_17318, int64_t num_subhistos_23344, int64_t num_tblocks_23357, int32_t hist_M_23363, int32_t chk_i_23367, int64_t num_segm",
                                    "ents_23368, int64_t hist_H_chk_23369, int64_t histo_sizze_23370, int32_t init_per_thread_23371, __global unsigned char *II1_mem_22768, __global unsigned char *mem_22786, __global unsigned char *mem_22787, __global unsigned char *defunc_0_map_res_subhistos_mem_23345, __global unsigned char *defunc_0_map_res_subhistos_mem_23347)\n{\n    #define max_tblock_sizze_23356 (human_regularziseghist_local_22277zimax_tblock_sizze_23356)\n    \n    volatile __local unsigned char *subhistogram_local_mem_23387_backing_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_23387_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_23363 * hist_H_chk_23369) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23363 * hist_H_chk_23369), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_23385_backing_0 = &shared_mem[subhistogram_local_mem_23387_backing_1_offset];\n    const int64_t subhistogram_local_mem_23385_backing_0_offset = subhistogram_local_mem_23387_backing_1_offset + ((int64_t) 4 * (hist_M_23363 * hist_H_chk_23369) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23363 * hist_H_chk_23369), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23373;\n    int32_t tblock_sizze_23376;\n    int32_t wave_sizze_23375;\n    int32_t block_id_23374;\n    int32_t global_tid_23372;\n    int64_t phys_tid_22277;\n    int32_t phys_tblock_id_23377;\n    int32_t iterations_23378;\n    \n    local_tid_23373 = get_local_id(0);\n    tblock_sizze_23376 = get_local_size(0);\n    wave_sizze_23375 = LOCKSTEP_WIDTH;\n    block_id_23374 = get_tblock_id(0);\n    global_tid_23372 = block_id_23374 * tblock_sizze_23376 + local_tid_23373;\n    phys_tid_22277 = sext_i32_i64(global_tid_23372);\n    phys_tblock_id_23377 = get_tblock_id(0);\n    iterations_23378 = sdiv_up32(sext_i64_i32(num_tblocks_23357 * num_segments_23368) - phys_tblock_id_23377, sext_i64_i32(num_tblocks_23357));\n    for (int32_t i_23379 = 0; i_23379 < iterations_23378;", " i_23379++) {\n        int32_t virt_tblock_id_23380;\n        int32_t flat_segment_id_23381;\n        int32_t gid_in_segment_23382;\n        int32_t pgtid_in_segment_23383;\n        int32_t threads_per_segment_23384;\n        __local unsigned char *subhistogram_local_mem_23385;\n        __local unsigned char *subhistogram_local_mem_23387;\n        int32_t thread_local_subhisto_i_23389;\n        int64_t num_chunks_23402;\n        \n        virt_tblock_id_23380 = phys_tblock_id_23377 + i_23379 * sext_i64_i32(num_tblocks_23357);\n        flat_segment_id_23381 = squot32(virt_tblock_id_23380, sext_i64_i32(num_tblocks_23357));\n        gid_in_segment_23382 = srem32(virt_tblock_id_23380, sext_i64_i32(num_tblocks_23357));\n        pgtid_in_segment_23383 = gid_in_segment_23382 * sext_i64_i32(max_tblock_sizze_23356) + local_tid_23373;\n        threads_per_segment_23384 = sext_i64_i32(num_tblocks_23357 * max_tblock_sizze_23356);\n        subhistogram_local_mem_23385 = (__local unsigned char *) subhistogram_local_mem_23385_backing_0;\n        subhistogram_local_mem_23387 = (__local unsigned char *) subhistogram_local_mem_23387_backing_1;\n        thread_local_subhisto_i_23389 = srem32(local_tid_23373, hist_M_23363);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_23390 = 0; local_i_23390 < init_per_thread_23371; local_i_23390++) {\n                int32_t j_23391 = local_i_23390 * sext_i64_i32(max_tblock_sizze_23356) + local_tid_23373;\n                int32_t j_offset_23392 = hist_M_23363 * sext_i64_i32(histo_sizze_23370) * gid_in_segment_23382 + j_23391;\n                int32_t local_subhisto_i_23393 = squot32(j_23391, sext_i64_i32(histo_sizze_23370));\n                int32_t global_subhisto_i_23394 = squot32(j_offset_23392, sext_i64_i32(histo_sizze_23370));\n                \n                if (slt32(j_23391, hist_M_23363 * sext_i64_i32(histo_sizze_23370))) {\n                    // First subhistogram is initialised from global memory; others with neut", "ral element.\n                    {\n                        if (global_subhisto_i_23394 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23344)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23391, sext_i64_i32(histo_sizze_23370))) + sext_i32_i64(chk_i_23367) * hist_H_chk_23369) && slt64(sext_i32_i64(srem32(j_23391, sext_i64_i32(histo_sizze_23370))) + sext_i32_i64(chk_i_23367) * hist_H_chk_23369, mz2080U_17317)))) {\n                            int32_t tmp_23395 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23345)[sext_i32_i64(srem32(j_23391, sext_i64_i32(histo_sizze_23370))) + sext_i32_i64(chk_i_23367) * hist_H_chk_23369];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23385)[sext_i32_i64(local_subhisto_i_23393) * hist_H_chk_23369 + sext_i32_i64(srem32(j_23391, sext_i64_i32(histo_sizze_23370)))] = tmp_23395;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_23385)[sext_i32_i64(local_subhisto_i_23393) * hist_H_chk_23369 + sext_i32_i64(srem32(j_23391, sext_i64_i32(histo_sizze_23370)))] = 0;\n                        }\n                    }\n                }\n            }\n            for (int32_t local_i_23396 = 0; local_i_23396 < init_per_thread_23371; local_i_23396++) {\n                int32_t j_23397 = local_i_23396 * sext_i64_i32(max_tblock_sizze_23356) + local_tid_23373;\n                int32_t j_offset_23398 = hist_M_23363 * sext_i64_i32(histo_sizze_23370) * gid_in_segment_23382 + j_23397;\n                int32_t local_subhisto_i_23399 = squot32(j_23397, sext_i64_i32(histo_sizze_23370));\n                int32_t global_subhisto_i_23400 = squot32(j_offset_23398, sext_i64_i32(histo_sizze_23370));\n                \n                if (slt32(j_23397, hist_M_23363 * sext_i64_i32(histo_sizze_23370))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n  ",
                                    "                      if (global_subhisto_i_23400 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23344)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23397, sext_i64_i32(histo_sizze_23370))) + sext_i32_i64(chk_i_23367) * hist_H_chk_23369) && slt64(sext_i32_i64(srem32(j_23397, sext_i64_i32(histo_sizze_23370))) + sext_i32_i64(chk_i_23367) * hist_H_chk_23369, mz2080U_17317)))) {\n                            int32_t tmp_23401 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23347)[sext_i32_i64(srem32(j_23397, sext_i64_i32(histo_sizze_23370))) + sext_i32_i64(chk_i_23367) * hist_H_chk_23369];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23387)[sext_i32_i64(local_subhisto_i_23399) * hist_H_chk_23369 + sext_i32_i64(srem32(j_23397, sext_i64_i32(histo_sizze_23370)))] = tmp_23401;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_23387)[sext_i32_i64(local_subhisto_i_23399) * hist_H_chk_23369 + sext_i32_i64(srem32(j_23397, sext_i64_i32(histo_sizze_23370)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_23402 = sdiv_up64(nz2081U_17318, sext_i32_i64(threads_per_segment_23384));\n        for (int64_t chunk_i_23403 = 0; chunk_i_23403 < num_chunks_23402; chunk_i_23403++) {\n            int64_t i_23404 = chunk_i_23403 * sext_i32_i64(threads_per_segment_23384) + sext_i32_i64(pgtid_in_segment_23383);\n            \n            if (slt64(i_23404, nz2081U_17318)) {\n                int64_t gtid_22276;\n                bool eta_p_22284;\n                bool eta_p_22285;\n                int32_t eta_p_22286;\n                int32_t bool_res_22287;\n                int32_t bool_res_22288;\n                int64_t i32_res_22289;\n                \n                gtid_22276 = i_23404;\n                eta_p_22284 = ((__global bool *) mem_22787)[gtid_22276", "];\n                eta_p_22285 = ((__global bool *) mem_22786)[gtid_22276];\n                eta_p_22286 = ((__global int32_t *) II1_mem_22768)[gtid_22276];\n                bool_res_22287 = btoi_bool_i32(eta_p_22284);\n                bool_res_22288 = btoi_bool_i32(eta_p_22285);\n                i32_res_22289 = sext_i32_i64(eta_p_22286);\n                if (chk_i_23367 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, i32_res_22289) && slt64(i32_res_22289, mz2080U_17317)) && (sle64(sext_i32_i64(chk_i_23367) * hist_H_chk_23369, i32_res_22289) && slt64(i32_res_22289, sext_i32_i64(chk_i_23367) * hist_H_chk_23369 + hist_H_chk_23369))) {\n                        int32_t eta_p_22278;\n                        int32_t eta_p_22279;\n                        int32_t eta_p_22280;\n                        int32_t eta_p_22281;\n                        \n                        eta_p_22280 = bool_res_22287;\n                        eta_p_22281 = bool_res_22288;\n                        \n                        int32_t old_23405;\n                        \n                        old_23405 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23385)[sext_i32_i64(thread_local_subhisto_i_23389) * hist_H_chk_23369 + (i32_res_22289 - sext_i32_i64(chk_i_23367) * hist_H_chk_23369)], (int) eta_p_22280);\n                        \n                        int32_t old_23406;\n                        \n                        old_23406 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23387)[sext_i32_i64(thread_local_subhisto_i_23389) * hist_H_chk_23369 + (i32_res_22289 - sext_i32_i64(chk_i_23367) * hist_H_chk_23369)], (int) eta_p_22281);\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms ", "to result in global memory\n        {\n            int64_t trunc_H_23407 = smin64(hist_H_chk_23369, mz2080U_17317 - sext_i32_i64(chk_i_23367) * hist_H_chk_23369);\n            int32_t histo_sizze_23408 = sext_i64_i32(trunc_H_23407);\n            \n            for (int32_t local_i_23409 = 0; local_i_23409 < init_per_thread_23371; local_i_23409++) {\n                int32_t j_23410 = local_i_23409 * sext_i64_i32(max_tblock_sizze_23356) + local_tid_23373;\n                \n                if (slt32(j_23410, histo_sizze_23408)) {\n                    int32_t eta_p_22278;\n                    int32_t eta_p_22279;\n                    int32_t eta_p_22280;\n                    int32_t eta_p_22281;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_22278 = ((__local int32_t *) subhistogram_local_mem_23385)[sext_i32_i64(j_23410)];\n                        eta_p_22279 = ((__local int32_t *) subhistogram_local_mem_23387)[sext_i32_i64(j_23410)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_23411 = 0; subhisto_id_23411 < hist_M_23363 - 1; subhisto_id_23411++) {\n                            eta_p_22280 = ((__local int32_t *) subhistogram_local_mem_23385)[(sext_i32_i64(subhisto_id_23411) + (int64_t) 1) * hist_H_chk_23369 + sext_i32_i64(j_23410)];\n                            eta_p_22281 = ((__local int32_t *) subhistogram_local_mem_23387)[(sext_i32_i64(subhisto_id_23411) + (int64_t) 1) * hist_H_chk_23369 + sext_i32_i64(j_23410)];\n                            \n                            int32_t tmp_22282 = add32(eta_p_22278, eta_p_22280);\n                            int32_t tmp_22283 = add32(eta_p_22279, eta_p_22281);\n                            \n                            eta_p_22278 = tmp_22282;\n                            eta_p_22279 = tmp_22283;\n                        }\n                    }\n ",
                                    "                   // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_23345)[srem64(sext_i32_i64(virt_tblock_id_23380), num_tblocks_23357) * mz2080U_17317 + (sext_i32_i64(j_23410) + sext_i32_i64(chk_i_23367) * hist_H_chk_23369)] = eta_p_22278;\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_23347)[srem64(sext_i32_i64(virt_tblock_id_23380), num_tblocks_23357) * mz2080U_17317 + (sext_i32_i64(j_23410) + sext_i32_i64(chk_i_23367) * hist_H_chk_23369)] = eta_p_22279;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_23356\n}\nFUTHARK_KERNEL_SIZED(human_regularziseghist_local_22451_dim1, 1, 1)\nvoid human_regularziseghist_local_22451(__global int *global_failure, int64_t mz2080U_17317, int64_t loop_dz2081Uz2089Uz2081U_21167, int64_t num_subhistos_23791, int64_t num_tblocks_23804, int32_t hist_M_23810, int32_t chk_i_23814, int64_t num_segments_23815, int64_t hist_H_chk_23816, int64_t histo_sizze_23817, int32_t init_per_thread_23818, __global unsigned char *mem_param_22820, __global unsigned char *mem_22834, __global unsigned char *mem_22835, __global unsigned char *defunc_0_map_res_subhistos_mem_23792, __global unsigned char *defunc_0_map_res_subhistos_mem_23794)\n{\n    #define max_tblock_sizze_23803 (human_regularziseghist_local_22451zimax_tblock_sizze_23803)\n    \n    volatile __local unsigned char *subhistogram_local_mem_23834_backing_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_23834_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_23810 * hist_H_chk_23816) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23810 * hist_H_chk_23816), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_23832_backing_0 = &shared_mem[subhistogram_local_mem_23834_backing_1_offset];\n    const i", "nt64_t subhistogram_local_mem_23832_backing_0_offset = subhistogram_local_mem_23834_backing_1_offset + ((int64_t) 4 * (hist_M_23810 * hist_H_chk_23816) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23810 * hist_H_chk_23816), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23820;\n    int32_t tblock_sizze_23823;\n    int32_t wave_sizze_23822;\n    int32_t block_id_23821;\n    int32_t global_tid_23819;\n    int64_t phys_tid_22451;\n    int32_t phys_tblock_id_23824;\n    int32_t iterations_23825;\n    \n    local_tid_23820 = get_local_id(0);\n    tblock_sizze_23823 = get_local_size(0);\n    wave_sizze_23822 = LOCKSTEP_WIDTH;\n    block_id_23821 = get_tblock_id(0);\n    global_tid_23819 = block_id_23821 * tblock_sizze_23823 + local_tid_23820;\n    phys_tid_22451 = sext_i32_i64(global_tid_23819);\n    phys_tblock_id_23824 = get_tblock_id(0);\n    iterations_23825 = sdiv_up32(sext_i64_i32(num_tblocks_23804 * num_segments_23815) - phys_tblock_id_23824, sext_i64_i32(num_tblocks_23804));\n    for (int32_t i_23826 = 0; i_23826 < iterations_23825; i_23826++) {\n        int32_t virt_tblock_id_23827;\n        int32_t flat_segment_id_23828;\n        int32_t gid_in_segment_23829;\n        int32_t pgtid_in_segment_23830;\n        int32_t threads_per_segment_23831;\n        __local unsigned char *subhistogram_local_mem_23832;\n        __local unsigned char *subhistogram_local_mem_23834;\n        int32_t thread_local_subhisto_i_23836;\n        int64_t num_chunks_23849;\n        \n        virt_tblock_id_23827 = phys_tblock_id_23824 + i_23826 * sext_i64_i32(num_tblocks_23804);\n        flat_segment_id_23828 = squot32(virt_tblock_id_23827, sext_i64_i32(num_tblocks_23804));\n        gid_in_segment_23829 = srem32(virt_tblock_id_23827, sext_i64_i32(num_tblocks_23804));\n        pgtid_in_segment_23830 = gid_in_segment_23829 * sext_i64_i32(max_tblock_sizze_23803) + local_tid_23820;\n        threads_per_segment_23831 = sext_i64_i32(num_tblocks_23804 * max_tblo", "ck_sizze_23803);\n        subhistogram_local_mem_23832 = (__local unsigned char *) subhistogram_local_mem_23832_backing_0;\n        subhistogram_local_mem_23834 = (__local unsigned char *) subhistogram_local_mem_23834_backing_1;\n        thread_local_subhisto_i_23836 = srem32(local_tid_23820, hist_M_23810);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_23837 = 0; local_i_23837 < init_per_thread_23818; local_i_23837++) {\n                int32_t j_23838 = local_i_23837 * sext_i64_i32(max_tblock_sizze_23803) + local_tid_23820;\n                int32_t j_offset_23839 = hist_M_23810 * sext_i64_i32(histo_sizze_23817) * gid_in_segment_23829 + j_23838;\n                int32_t local_subhisto_i_23840 = squot32(j_23838, sext_i64_i32(histo_sizze_23817));\n                int32_t global_subhisto_i_23841 = squot32(j_offset_23839, sext_i64_i32(histo_sizze_23817));\n                \n                if (slt32(j_23838, hist_M_23810 * sext_i64_i32(histo_sizze_23817))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_23841 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23791)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23838, sext_i64_i32(histo_sizze_23817))) + sext_i32_i64(chk_i_23814) * hist_H_chk_23816) && slt64(sext_i32_i64(srem32(j_23838, sext_i64_i32(histo_sizze_23817))) + sext_i32_i64(chk_i_23814) * hist_H_chk_23816, mz2080U_17317)))) {\n                            int32_t tmp_23842 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23792)[sext_i32_i64(srem32(j_23838, sext_i64_i32(histo_sizze_23817))) + sext_i32_i64(chk_i_23814) * hist_H_chk_23816];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23832)[sext_i32_i64(local_subhisto_i_23840) * hist_H_chk_23816 + sext_i32_i64(srem32(j_23838, sext_i64_i32(histo_sizze_23817)))] = t",
                                    "mp_23842;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_23832)[sext_i32_i64(local_subhisto_i_23840) * hist_H_chk_23816 + sext_i32_i64(srem32(j_23838, sext_i64_i32(histo_sizze_23817)))] = 0;\n                        }\n                    }\n                }\n            }\n            for (int32_t local_i_23843 = 0; local_i_23843 < init_per_thread_23818; local_i_23843++) {\n                int32_t j_23844 = local_i_23843 * sext_i64_i32(max_tblock_sizze_23803) + local_tid_23820;\n                int32_t j_offset_23845 = hist_M_23810 * sext_i64_i32(histo_sizze_23817) * gid_in_segment_23829 + j_23844;\n                int32_t local_subhisto_i_23846 = squot32(j_23844, sext_i64_i32(histo_sizze_23817));\n                int32_t global_subhisto_i_23847 = squot32(j_offset_23845, sext_i64_i32(histo_sizze_23817));\n                \n                if (slt32(j_23844, hist_M_23810 * sext_i64_i32(histo_sizze_23817))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_23847 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_23791)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_23844, sext_i64_i32(histo_sizze_23817))) + sext_i32_i64(chk_i_23814) * hist_H_chk_23816) && slt64(sext_i32_i64(srem32(j_23844, sext_i64_i32(histo_sizze_23817))) + sext_i32_i64(chk_i_23814) * hist_H_chk_23816, mz2080U_17317)))) {\n                            int32_t tmp_23848 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23794)[sext_i32_i64(srem32(j_23844, sext_i64_i32(histo_sizze_23817))) + sext_i32_i64(chk_i_23814) * hist_H_chk_23816];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_23834)[sext_i32_i64(local_subhisto_i_23846) * hist_H_chk_23816 + sext_i32_i64(srem32(j_23844, sext_i64_i32(histo_sizze_23817)))] = tmp_23848;\n                        } e", "lse {\n                            ((__local int32_t *) subhistogram_local_mem_23834)[sext_i32_i64(local_subhisto_i_23846) * hist_H_chk_23816 + sext_i32_i64(srem32(j_23844, sext_i64_i32(histo_sizze_23817)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_23849 = sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, sext_i32_i64(threads_per_segment_23831));\n        for (int64_t chunk_i_23850 = 0; chunk_i_23850 < num_chunks_23849; chunk_i_23850++) {\n            int64_t i_23851 = chunk_i_23850 * sext_i32_i64(threads_per_segment_23831) + sext_i32_i64(pgtid_in_segment_23830);\n            \n            if (slt64(i_23851, loop_dz2081Uz2089Uz2081U_21167)) {\n                int64_t gtid_22450;\n                bool eta_p_22458;\n                bool eta_p_22459;\n                int32_t eta_p_22460;\n                int32_t bool_res_22461;\n                int32_t bool_res_22462;\n                int64_t i32_res_22463;\n                \n                gtid_22450 = i_23851;\n                eta_p_22458 = ((__global bool *) mem_22835)[gtid_22450];\n                eta_p_22459 = ((__global bool *) mem_22834)[gtid_22450];\n                eta_p_22460 = ((__global int32_t *) mem_param_22820)[gtid_22450];\n                bool_res_22461 = btoi_bool_i32(eta_p_22458);\n                bool_res_22462 = btoi_bool_i32(eta_p_22459);\n                i32_res_22463 = sext_i32_i64(eta_p_22460);\n                if (chk_i_23814 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, i32_res_22463) && slt64(i32_res_22463, mz2080U_17317)) && (sle64(sext_i32_i64(chk_i_23814) * hist_H_chk_23816, i32_res_22463) && slt64(i32_res_22463, sext_i32_i64(chk_i_23814) * hist_H_chk_23816 + hist_H_chk_23816))) {\n                        int32_t eta_p_22452;\n                        int32_t e", "ta_p_22453;\n                        int32_t eta_p_22454;\n                        int32_t eta_p_22455;\n                        \n                        eta_p_22454 = bool_res_22461;\n                        eta_p_22455 = bool_res_22462;\n                        \n                        int32_t old_23852;\n                        \n                        old_23852 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23832)[sext_i32_i64(thread_local_subhisto_i_23836) * hist_H_chk_23816 + (i32_res_22463 - sext_i32_i64(chk_i_23814) * hist_H_chk_23816)], (int) eta_p_22454);\n                        \n                        int32_t old_23853;\n                        \n                        old_23853 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_23834)[sext_i32_i64(thread_local_subhisto_i_23836) * hist_H_chk_23816 + (i32_res_22463 - sext_i32_i64(chk_i_23814) * hist_H_chk_23816)], (int) eta_p_22455);\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_23854 = smin64(hist_H_chk_23816, mz2080U_17317 - sext_i32_i64(chk_i_23814) * hist_H_chk_23816);\n            int32_t histo_sizze_23855 = sext_i64_i32(trunc_H_23854);\n            \n            for (int32_t local_i_23856 = 0; local_i_23856 < init_per_thread_23818; local_i_23856++) {\n                int32_t j_23857 = local_i_23856 * sext_i64_i32(max_tblock_sizze_23803) + local_tid_23820;\n                \n                if (slt32(j_23857, histo_sizze_23855)) {\n                    int32_t eta_p_22452;\n                    int32_t eta_p_22453;\n                    int32_t eta_p_22454;\n                    int32_t eta_p_22455;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_22452 = ((__local int32_t *) subhistogram_loca",
                                    "l_mem_23832)[sext_i32_i64(j_23857)];\n                        eta_p_22453 = ((__local int32_t *) subhistogram_local_mem_23834)[sext_i32_i64(j_23857)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_23858 = 0; subhisto_id_23858 < hist_M_23810 - 1; subhisto_id_23858++) {\n                            eta_p_22454 = ((__local int32_t *) subhistogram_local_mem_23832)[(sext_i32_i64(subhisto_id_23858) + (int64_t) 1) * hist_H_chk_23816 + sext_i32_i64(j_23857)];\n                            eta_p_22455 = ((__local int32_t *) subhistogram_local_mem_23834)[(sext_i32_i64(subhisto_id_23858) + (int64_t) 1) * hist_H_chk_23816 + sext_i32_i64(j_23857)];\n                            \n                            int32_t tmp_22456 = add32(eta_p_22452, eta_p_22454);\n                            int32_t tmp_22457 = add32(eta_p_22453, eta_p_22455);\n                            \n                            eta_p_22452 = tmp_22456;\n                            eta_p_22453 = tmp_22457;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_23792)[srem64(sext_i32_i64(virt_tblock_id_23827), num_tblocks_23804) * mz2080U_17317 + (sext_i32_i64(j_23857) + sext_i32_i64(chk_i_23814) * hist_H_chk_23816)] = eta_p_22452;\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_23794)[srem64(sext_i32_i64(virt_tblock_id_23827), num_tblocks_23804) * mz2080U_17317 + (sext_i32_i64(j_23857) + sext_i32_i64(chk_i_23814) * hist_H_chk_23816)] = eta_p_22453;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_23803\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22168_dim1, 1, 1)\nvoid human_regularzis", "egmap_22168(__global int *global_failure, int64_t mz2080U_17317, int64_t nz2081U_17318, int64_t num_tblocks_22173, int32_t virt_num_tblocks_23049, __global unsigned char *mem_22772, __global unsigned char *mem_22773)\n{\n    #define segmap_tblock_sizze_22171 (human_regularzisegmap_22168zisegmap_tblock_sizze_22171)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23051;\n    int32_t tblock_sizze_23054;\n    int32_t wave_sizze_23053;\n    int32_t block_id_23052;\n    int32_t global_tid_23050;\n    int64_t phys_tid_22168;\n    int32_t phys_tblock_id_23055;\n    int32_t iterations_23056;\n    \n    local_tid_23051 = get_local_id(0);\n    tblock_sizze_23054 = get_local_size(0);\n    wave_sizze_23053 = LOCKSTEP_WIDTH;\n    block_id_23052 = get_tblock_id(0);\n    global_tid_23050 = block_id_23052 * tblock_sizze_23054 + local_tid_23051;\n    phys_tid_22168 = sext_i32_i64(global_tid_23050);\n    phys_tblock_id_23055 = get_tblock_id(0);\n    iterations_23056 = sdiv_up32(virt_num_tblocks_23049 - phys_tblock_id_23055, sext_i64_i32(num_tblocks_22173));\n    for (int32_t i_23057 = 0; i_23057 < iterations_23056; i_23057++) {\n        int32_t virt_tblock_id_23058;\n        int64_t global_tid_23059;\n        int64_t slice_23060;\n        int64_t write_i_22167;\n        int64_t remnant_23061;\n        \n        virt_tblock_id_23058 = phys_tblock_id_23055 + i_23057 * sext_i64_i32(num_tblocks_22173);\n        global_tid_23059 = sext_i32_i64(virt_tblock_id_23058) * segmap_tblock_sizze_22171 + sext_i32_i64(local_tid_23051);\n        slice_23060 = mz2080U_17317;\n        write_i_22167 = global_tid_23059;\n        remnant_23061 = global_tid_23059 - write_i_22167;\n        if (slt64(write_i_22167, mz2080U_17317)) {\n            int64_t zv_lhs_21596;\n            int64_t tmp_21597;\n            bool cond_21600;\n            int64_t lifted_lambda_res_21601;\n            \n            zv_lhs_21596 = add64((int64_t) -1, write_i_22167);\n            tmp_21597 = smod64(zv_lhs_21596, mz2080U_17317);\n           ", " cond_21600 = write_i_22167 == (int64_t) 0;\n            if (cond_21600) {\n                lifted_lambda_res_21601 = (int64_t) 0;\n            } else {\n                int64_t lifted_lambda_res_21598 = ((__global int64_t *) mem_22772)[tmp_21597];\n                \n                lifted_lambda_res_21601 = lifted_lambda_res_21598;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21601) && slt64(lifted_lambda_res_21601, nz2081U_17318)) {\n                ((__global bool *) mem_22773)[lifted_lambda_res_21601] = 1;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22171\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22218_dim1, 1, 1)\nvoid human_regularzisegmap_22218(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_17317, int64_t nz2081U_17318, __global unsigned char *shp_mem_22767, __global unsigned char *mem_22778, __global unsigned char *mem_22781, __global unsigned char *mem_22784)\n{\n    #define segmap_tblock_sizze_22214 (human_regularzisegmap_22218zisegmap_tblock_sizze_22214)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23327;\n    int32_t tblock_sizze_23330;\n    int32_t wave_sizze_23329;\n    int32_t block_id_23328;\n    int32_t global_tid_23326;\n    int64_t phys_tid_22218;\n    int64_t global_tid_23331;\n    int64_t slice_23332;\n    int64_t gtid_22217;\n    int64_t remnant_23333;\n    \n    local_tid_23327 = get_local_id(0);\n    tblock_sizze_23330 = get_local_size(0);\n    wave_sizze_23329 = LOCKSTEP_WIDTH;\n    block_id_23328 = get_tblock_id(0);\n    global_tid_23326 = block_id_23328 * tblock_sizze_23330 + local_tid_23327;\n    phys_tid_22218 = sext_i32_i64(global_tid_23326);\n    global_tid_23331 = sext_i32_i64(block_id_23328) * segmap_tblock_sizze_22214 + sext_i32_i64(local_tid_23327);\n    slice_23332 = mz2080U_17317;\n    gtid_22217 = global_tid_23331;\n    remnant_23333 = glo",
                                    "bal_tid_23331 - gtid_22217;\n    if (slt64(gtid_22217, mz2080U_17317)) {\n        int32_t eta_p_22220;\n        bool cond_22222;\n        float lifted_lambda_res_22223;\n        float i32_res_22231;\n        float lifted_lambda_res_22232;\n        \n        eta_p_22220 = ((__global int32_t *) shp_mem_22767)[gtid_22217];\n        cond_22222 = eta_p_22220 == 0;\n        if (cond_22222) {\n            lifted_lambda_res_22223 = 0.0F;\n        } else {\n            int32_t eta_p_22219;\n            int32_t tmp_22224;\n            int64_t tmp_22225;\n            bool x_22226;\n            bool y_22227;\n            bool bounds_check_22228;\n            bool index_certs_22229;\n            float lifted_lambda_res_f_res_22230;\n            \n            eta_p_22219 = ((__global int32_t *) mem_22781)[gtid_22217];\n            tmp_22224 = sub32(eta_p_22219, 1);\n            tmp_22225 = sext_i32_i64(tmp_22224);\n            x_22226 = sle64((int64_t) 0, tmp_22225);\n            y_22227 = slt64(tmp_22225, nz2081U_17318);\n            bounds_check_22228 = x_22226 && y_22227;\n            if (!bounds_check_22228) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_22225;\n                        global_failure_args[1] = (int64_t) nz2081U_17318;\n                        ;\n                    }\n                    return;\n                }\n            }\n            lifted_lambda_res_f_res_22230 = ((__global float *) mem_22778)[tmp_22225];\n            lifted_lambda_res_22223 = lifted_lambda_res_f_res_22230;\n        }\n        i32_res_22231 = sitofp_i32_f32(eta_p_22220);\n        lifted_lambda_res_22232 = lifted_lambda_res_22223 / i32_res_22231;\n        ((__global float *) mem_22784)[gtid_22217] = lifted_lambda_res_22232;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22214\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22257_dim1, 1, 1)\nvoid human_regularzisegmap_22257(__global int *globa", "l_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_17317, int64_t nz2081U_17318, __global unsigned char *II1_mem_22768, __global unsigned char *A_mem_22769, __global unsigned char *mem_22784, __global unsigned char *mem_22786, __global unsigned char *mem_22787)\n{\n    #define segmap_tblock_sizze_22252 (human_regularzisegmap_22257zisegmap_tblock_sizze_22252)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23336;\n    int32_t tblock_sizze_23339;\n    int32_t wave_sizze_23338;\n    int32_t block_id_23337;\n    int32_t global_tid_23335;\n    int64_t phys_tid_22257;\n    int64_t global_tid_23340;\n    int64_t slice_23341;\n    int64_t gtid_22256;\n    int64_t remnant_23342;\n    \n    local_tid_23336 = get_local_id(0);\n    tblock_sizze_23339 = get_local_size(0);\n    wave_sizze_23338 = LOCKSTEP_WIDTH;\n    block_id_23337 = get_tblock_id(0);\n    global_tid_23335 = block_id_23337 * tblock_sizze_23339 + local_tid_23336;\n    phys_tid_22257 = sext_i32_i64(global_tid_23335);\n    global_tid_23340 = sext_i32_i64(block_id_23337) * segmap_tblock_sizze_22252 + sext_i32_i64(local_tid_23336);\n    slice_23341 = nz2081U_17318;\n    gtid_22256 = global_tid_23340;\n    remnant_23342 = global_tid_23340 - gtid_22256;\n    if (slt64(gtid_22256, nz2081U_17318)) {\n        int32_t eta_p_22259;\n        int64_t ii_22260;\n        bool x_22261;\n        bool y_22262;\n        bool bounds_check_22263;\n        bool index_certs_22264;\n        float eta_p_22258;\n        float zl_rhs_22265;\n        bool lifted_lambda_res_22266;\n        bool lifted_lambda_res_22267;\n        \n        eta_p_22259 = ((__global int32_t *) II1_mem_22768)[gtid_22256];\n        ii_22260 = sext_i32_i64(eta_p_22259);\n        x_22261 = sle64((int64_t) 0, ii_22260);\n        y_22262 = slt64(ii_22260, mz2080U_17317);\n        bounds_check_22263 = x_22261 && y_22262;\n        if (!bounds_check_22263) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1)", " {\n                    global_failure_args[0] = (int64_t) ii_22260;\n                    global_failure_args[1] = (int64_t) mz2080U_17317;\n                    ;\n                }\n                return;\n            }\n        }\n        eta_p_22258 = ((__global float *) A_mem_22769)[gtid_22256];\n        zl_rhs_22265 = ((__global float *) mem_22784)[ii_22260];\n        lifted_lambda_res_22266 = eta_p_22258 < zl_rhs_22265;\n        lifted_lambda_res_22267 = eta_p_22258 == zl_rhs_22265;\n        ((__global bool *) mem_22786)[gtid_22256] = lifted_lambda_res_22267;\n        ((__global bool *) mem_22787)[gtid_22256] = lifted_lambda_res_22266;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22252\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22326_dim1, 1, 1)\nvoid human_regularzisegmap_22326(__global int *global_failure, int64_t mz2080U_17317, __global unsigned char *ks_mem_22766, __global unsigned char *shp_mem_22767, __global unsigned char *mem_22784, __global unsigned char *mem_22789, __global unsigned char *mem_22791, __global unsigned char *mem_22795, __global unsigned char *mem_22797, __global unsigned char *mem_22799, __global unsigned char *mem_22801)\n{\n    #define segmap_tblock_sizze_22319 (human_regularzisegmap_22326zisegmap_tblock_sizze_22319)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23533;\n    int32_t tblock_sizze_23536;\n    int32_t wave_sizze_23535;\n    int32_t block_id_23534;\n    int32_t global_tid_23532;\n    int64_t phys_tid_22326;\n    int64_t global_tid_23537;\n    int64_t slice_23538;\n    int64_t gtid_22325;\n    int64_t remnant_23539;\n    \n    local_tid_23533 = get_local_id(0);\n    tblock_sizze_23536 = get_local_size(0);\n    wave_sizze_23535 = LOCKSTEP_WIDTH;\n    block_id_23534 = get_tblock_id(0);\n    global_tid_23532 = block_id_23534 * tblock_sizze_23536 + local_tid_23533;\n    phys_tid_22326 = sext_i32_i64(global_tid_23532);\n    global_tid_23537 = sext_i32_i64(block_id_23534) * segmap_tblock_sizze_22319 + sext_i32_i",
                                    "64(local_tid_23533);\n    slice_23538 = mz2080U_17317;\n    gtid_22325 = global_tid_23537;\n    remnant_23539 = global_tid_23537 - gtid_22325;\n    if (slt64(gtid_22325, mz2080U_17317)) {\n        int32_t eta_p_22327;\n        int32_t eta_p_22328;\n        int32_t eta_p_22329;\n        int32_t eta_p_22330;\n        bool cond_22332;\n        int32_t lifted_lambda_res_22333;\n        bool cond_22339;\n        float lifted_lambda_res_22340;\n        int32_t lifted_lambda_res_22341;\n        int32_t lifted_lambda_res_22344;\n        \n        eta_p_22327 = ((__global int32_t *) mem_22791)[gtid_22325];\n        eta_p_22328 = ((__global int32_t *) mem_22789)[gtid_22325];\n        eta_p_22329 = ((__global int32_t *) shp_mem_22767)[gtid_22325];\n        eta_p_22330 = ((__global int32_t *) ks_mem_22766)[gtid_22325];\n        cond_22332 = eta_p_22329 == 0;\n        if (cond_22332) {\n            lifted_lambda_res_22333 = -1;\n        } else {\n            bool cond_22334;\n            int32_t lifted_lambda_res_f_res_22335;\n            \n            cond_22334 = sle32(eta_p_22330, eta_p_22327);\n            if (cond_22334) {\n                lifted_lambda_res_f_res_22335 = 0;\n            } else {\n                int32_t zlze_rhs_22336;\n                bool cond_22337;\n                int32_t lifted_lambda_res_f_res_f_res_22338;\n                \n                zlze_rhs_22336 = add32(eta_p_22327, eta_p_22328);\n                cond_22337 = sle32(eta_p_22330, zlze_rhs_22336);\n                if (cond_22337) {\n                    lifted_lambda_res_f_res_f_res_22338 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_22338 = 2;\n                }\n                lifted_lambda_res_f_res_22335 = lifted_lambda_res_f_res_f_res_22338;\n            }\n            lifted_lambda_res_22333 = lifted_lambda_res_f_res_22335;\n        }\n        cond_22339 = lifted_lambda_res_22333 == 1;\n        if (cond_22339) {\n            float eta_p_22331 = ((__global float *) mem_22784)[gtid_22325];\n           ", " \n            lifted_lambda_res_22340 = eta_p_22331;\n        } else {\n            lifted_lambda_res_22340 = 0.0F;\n        }\n        if (lifted_lambda_res_22333 == -1) {\n            lifted_lambda_res_22341 = -1;\n        } else if (lifted_lambda_res_22333 == 0) {\n            lifted_lambda_res_22341 = eta_p_22330;\n        } else if (lifted_lambda_res_22333 == 1) {\n            lifted_lambda_res_22341 = -1;\n        } else if (lifted_lambda_res_22333 == 2) {\n            int32_t zm_lhs_22342;\n            int32_t case_res_22343;\n            \n            zm_lhs_22342 = sub32(eta_p_22330, eta_p_22327);\n            case_res_22343 = sub32(zm_lhs_22342, eta_p_22328);\n            lifted_lambda_res_22341 = case_res_22343;\n        } else {\n            lifted_lambda_res_22341 = -1;\n        }\n        if (lifted_lambda_res_22333 == -1) {\n            lifted_lambda_res_22344 = 0;\n        } else if (lifted_lambda_res_22333 == 0) {\n            lifted_lambda_res_22344 = eta_p_22327;\n        } else if (lifted_lambda_res_22333 == 1) {\n            lifted_lambda_res_22344 = 0;\n        } else if (lifted_lambda_res_22333 == 2) {\n            int32_t zm_lhs_22345;\n            int32_t case_res_22346;\n            \n            zm_lhs_22345 = sub32(eta_p_22329, eta_p_22327);\n            case_res_22346 = sub32(zm_lhs_22345, eta_p_22328);\n            lifted_lambda_res_22344 = case_res_22346;\n        } else {\n            lifted_lambda_res_22344 = -1;\n        }\n        ((__global int32_t *) mem_22795)[gtid_22325] = lifted_lambda_res_22344;\n        ((__global int32_t *) mem_22797)[gtid_22325] = lifted_lambda_res_22341;\n        ((__global float *) mem_22799)[gtid_22325] = lifted_lambda_res_22340;\n        ((__global int32_t *) mem_22801)[gtid_22325] = lifted_lambda_res_22333;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22319\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22356_dim1, 1, 1)\nvoid human_regularzisegmap_22356(__global int *global_failure, int64_t nz2081U_17318, int64_t m_21132,", " int64_t num_tblocks_22361, int32_t virt_num_tblocks_23644, __global unsigned char *II1_mem_22768, __global unsigned char *A_mem_22769, __global unsigned char *mem_22804, __global unsigned char *mem_22806, __global unsigned char *mem_22808, __global unsigned char *mem_22810)\n{\n    #define segmap_tblock_sizze_22359 (human_regularzisegmap_22356zisegmap_tblock_sizze_22359)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23646;\n    int32_t tblock_sizze_23649;\n    int32_t wave_sizze_23648;\n    int32_t block_id_23647;\n    int32_t global_tid_23645;\n    int64_t phys_tid_22356;\n    int32_t phys_tblock_id_23650;\n    int32_t iterations_23651;\n    \n    local_tid_23646 = get_local_id(0);\n    tblock_sizze_23649 = get_local_size(0);\n    wave_sizze_23648 = LOCKSTEP_WIDTH;\n    block_id_23647 = get_tblock_id(0);\n    global_tid_23645 = block_id_23647 * tblock_sizze_23649 + local_tid_23646;\n    phys_tid_22356 = sext_i32_i64(global_tid_23645);\n    phys_tblock_id_23650 = get_tblock_id(0);\n    iterations_23651 = sdiv_up32(virt_num_tblocks_23644 - phys_tblock_id_23650, sext_i64_i32(num_tblocks_22361));\n    for (int32_t i_23652 = 0; i_23652 < iterations_23651; i_23652++) {\n        int32_t virt_tblock_id_23653;\n        int64_t global_tid_23654;\n        int64_t slice_23655;\n        int64_t write_i_22355;\n        int64_t remnant_23656;\n        \n        virt_tblock_id_23653 = phys_tblock_id_23650 + i_23652 * sext_i64_i32(num_tblocks_22361);\n        global_tid_23654 = sext_i32_i64(virt_tblock_id_23653) * segmap_tblock_sizze_22359 + sext_i32_i64(local_tid_23646);\n        slice_23655 = nz2081U_17318;\n        write_i_22355 = global_tid_23654;\n        remnant_23656 = global_tid_23654 - write_i_22355;\n        if (slt64(write_i_22355, nz2081U_17318)) {\n            int64_t eta_p_21359;\n            float write_value_21361;\n            int32_t write_value_21362;\n            bool cond_21363;\n            int64_t lifted_lambda_res_21364;\n            \n            eta_p_21359 = ((__gl",
                                    "obal int64_t *) mem_22806)[write_i_22355];\n            write_value_21361 = ((__global float *) A_mem_22769)[write_i_22355];\n            write_value_21362 = ((__global int32_t *) II1_mem_22768)[write_i_22355];\n            cond_21363 = eta_p_21359 == (int64_t) 1;\n            if (cond_21363) {\n                int64_t eta_p_21360;\n                int64_t lifted_lambda_res_t_res_21930;\n                \n                eta_p_21360 = ((__global int64_t *) mem_22804)[write_i_22355];\n                lifted_lambda_res_t_res_21930 = sub64(eta_p_21360, (int64_t) 1);\n                lifted_lambda_res_21364 = lifted_lambda_res_t_res_21930;\n            } else {\n                lifted_lambda_res_21364 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21364) && slt64(lifted_lambda_res_21364, m_21132)) {\n                ((__global float *) mem_22810)[lifted_lambda_res_21364] = write_value_21361;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21364) && slt64(lifted_lambda_res_21364, m_21132)) {\n                ((__global int32_t *) mem_22808)[lifted_lambda_res_21364] = write_value_21362;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22359\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22395_dim1, 1, 1)\nvoid human_regularzisegmap_22395(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_17317, int64_t loop_dz2081Uz2089Uz2081U_21167, __global unsigned char *mem_param_22823, __global unsigned char *mem_22829, __global unsigned char *mem_22832)\n{\n    #define segmap_tblock_sizze_22391 (human_regularzisegmap_22395zisegmap_tblock_sizze_22391)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23774;\n    int32_t tblock_sizze_23777;\n    int32_t wave_sizze_23776;\n    int32_t block_id_23775;\n    int32_t global_tid_23773;\n    int64_t phys_tid_22395;\n    int64_t glo", "bal_tid_23778;\n    int64_t slice_23779;\n    int64_t gtid_22394;\n    int64_t remnant_23780;\n    \n    local_tid_23774 = get_local_id(0);\n    tblock_sizze_23777 = get_local_size(0);\n    wave_sizze_23776 = LOCKSTEP_WIDTH;\n    block_id_23775 = get_tblock_id(0);\n    global_tid_23773 = block_id_23775 * tblock_sizze_23777 + local_tid_23774;\n    phys_tid_22395 = sext_i32_i64(global_tid_23773);\n    global_tid_23778 = sext_i32_i64(block_id_23775) * segmap_tblock_sizze_22391 + sext_i32_i64(local_tid_23774);\n    slice_23779 = mz2080U_17317;\n    gtid_22394 = global_tid_23778;\n    remnant_23780 = global_tid_23778 - gtid_22394;\n    if (slt64(gtid_22394, mz2080U_17317)) {\n        int32_t eta_p_22396;\n        int32_t lifted_lambda_res_22398;\n        bool cond_22399;\n        int32_t max_res_22400;\n        int64_t tmp_22401;\n        bool x_22402;\n        bool y_22403;\n        bool bounds_check_22404;\n        bool index_certs_22405;\n        float lifted_lambda_res_22406;\n        \n        eta_p_22396 = ((__global int32_t *) mem_22829)[gtid_22394];\n        lifted_lambda_res_22398 = add32(-1, eta_p_22396);\n        cond_22399 = slt32(0, lifted_lambda_res_22398);\n        if (cond_22399) {\n            max_res_22400 = lifted_lambda_res_22398;\n        } else {\n            max_res_22400 = 0;\n        }\n        tmp_22401 = sext_i32_i64(max_res_22400);\n        x_22402 = sle64((int64_t) 0, tmp_22401);\n        y_22403 = slt64(tmp_22401, loop_dz2081Uz2089Uz2081U_21167);\n        bounds_check_22404 = x_22402 && y_22403;\n        if (!bounds_check_22404) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_22401;\n                    global_failure_args[1] = (int64_t) loop_dz2081Uz2089Uz2081U_21167;\n                    ;\n                }\n                return;\n            }\n        }\n        lifted_lambda_res_22406 = ((__global float *) mem_param_22823)[tmp_22401];\n        ((__global float *) mem_22832)[gt", "id_22394] = lifted_lambda_res_22406;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22391\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22431_dim1, 1, 1)\nvoid human_regularzisegmap_22431(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_17317, int64_t loop_dz2081Uz2089Uz2081U_21167, __global unsigned char *mem_param_22820, __global unsigned char *mem_param_22823, __global unsigned char *mem_22832, __global unsigned char *mem_22834, __global unsigned char *mem_22835)\n{\n    #define segmap_tblock_sizze_22426 (human_regularzisegmap_22431zisegmap_tblock_sizze_22426)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23783;\n    int32_t tblock_sizze_23786;\n    int32_t wave_sizze_23785;\n    int32_t block_id_23784;\n    int32_t global_tid_23782;\n    int64_t phys_tid_22431;\n    int64_t global_tid_23787;\n    int64_t slice_23788;\n    int64_t gtid_22430;\n    int64_t remnant_23789;\n    \n    local_tid_23783 = get_local_id(0);\n    tblock_sizze_23786 = get_local_size(0);\n    wave_sizze_23785 = LOCKSTEP_WIDTH;\n    block_id_23784 = get_tblock_id(0);\n    global_tid_23782 = block_id_23784 * tblock_sizze_23786 + local_tid_23783;\n    phys_tid_22431 = sext_i32_i64(global_tid_23782);\n    global_tid_23787 = sext_i32_i64(block_id_23784) * segmap_tblock_sizze_22426 + sext_i32_i64(local_tid_23783);\n    slice_23788 = loop_dz2081Uz2089Uz2081U_21167;\n    gtid_22430 = global_tid_23787;\n    remnant_23789 = global_tid_23787 - gtid_22430;\n    if (slt64(gtid_22430, loop_dz2081Uz2089Uz2081U_21167)) {\n        int32_t eta_p_22433;\n        int64_t ii_22434;\n        bool x_22435;\n        bool y_22436;\n        bool bounds_check_22437;\n        bool index_certs_22438;\n        float eta_p_22432;\n        float zl_rhs_22439;\n        bool lifted_lambda_res_22440;\n        bool lifted_lambda_res_22441;\n        \n        eta_p_22433 = ((__global int32_t *) mem_param_22820)[gtid_22430];\n        ii_22434 = sext_i32_i64(eta",
                                    "_p_22433);\n        x_22435 = sle64((int64_t) 0, ii_22434);\n        y_22436 = slt64(ii_22434, mz2080U_17317);\n        bounds_check_22437 = x_22435 && y_22436;\n        if (!bounds_check_22437) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 10) == -1) {\n                    global_failure_args[0] = (int64_t) ii_22434;\n                    global_failure_args[1] = (int64_t) mz2080U_17317;\n                    ;\n                }\n                return;\n            }\n        }\n        eta_p_22432 = ((__global float *) mem_param_22823)[gtid_22430];\n        zl_rhs_22439 = ((__global float *) mem_22832)[ii_22434];\n        lifted_lambda_res_22440 = eta_p_22432 < zl_rhs_22439;\n        lifted_lambda_res_22441 = eta_p_22432 == zl_rhs_22439;\n        ((__global bool *) mem_22834)[gtid_22430] = lifted_lambda_res_22441;\n        ((__global bool *) mem_22835)[gtid_22430] = lifted_lambda_res_22440;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22426\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22501_dim1, 1, 1)\nvoid human_regularzisegmap_22501(__global int *global_failure, int64_t mz2080U_17317, __global unsigned char *mem_param_22814, __global unsigned char *mem_param_22817, __global unsigned char *mem_param_22826, __global unsigned char *mem_22832, __global unsigned char *mem_22837, __global unsigned char *mem_22839, __global unsigned char *mem_22843, __global unsigned char *mem_22845, __global unsigned char *mem_22847, __global unsigned char *mem_22849)\n{\n    #define segmap_tblock_sizze_22494 (human_regularzisegmap_22501zisegmap_tblock_sizze_22494)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23980;\n    int32_t tblock_sizze_23983;\n    int32_t wave_sizze_23982;\n    int32_t block_id_23981;\n    int32_t global_tid_23979;\n    int64_t phys_tid_22501;\n    int64_t global_tid_23984;\n    int64_t slice_23985;\n    int64_t gtid_22500;\n    int64_t remnant_23986;\n    \n    local_tid_23980 = get_local_id(0);\n    tblock_s", "izze_23983 = get_local_size(0);\n    wave_sizze_23982 = LOCKSTEP_WIDTH;\n    block_id_23981 = get_tblock_id(0);\n    global_tid_23979 = block_id_23981 * tblock_sizze_23983 + local_tid_23980;\n    phys_tid_22501 = sext_i32_i64(global_tid_23979);\n    global_tid_23984 = sext_i32_i64(block_id_23981) * segmap_tblock_sizze_22494 + sext_i32_i64(local_tid_23980);\n    slice_23985 = mz2080U_17317;\n    gtid_22500 = global_tid_23984;\n    remnant_23986 = global_tid_23984 - gtid_22500;\n    if (slt64(gtid_22500, mz2080U_17317)) {\n        int32_t eta_p_22502;\n        int32_t eta_p_22503;\n        int32_t eta_p_22504;\n        int32_t eta_p_22505;\n        bool cond_22508;\n        int32_t lifted_lambda_res_22509;\n        bool cond_22515;\n        float lifted_lambda_res_22516;\n        int32_t lifted_lambda_res_22517;\n        int32_t lifted_lambda_res_22520;\n        \n        eta_p_22502 = ((__global int32_t *) mem_22839)[gtid_22500];\n        eta_p_22503 = ((__global int32_t *) mem_22837)[gtid_22500];\n        eta_p_22504 = ((__global int32_t *) mem_param_22817)[gtid_22500];\n        eta_p_22505 = ((__global int32_t *) mem_param_22814)[gtid_22500];\n        cond_22508 = eta_p_22504 == 0;\n        if (cond_22508) {\n            lifted_lambda_res_22509 = -1;\n        } else {\n            bool cond_22510;\n            int32_t lifted_lambda_res_f_res_22511;\n            \n            cond_22510 = sle32(eta_p_22505, eta_p_22502);\n            if (cond_22510) {\n                lifted_lambda_res_f_res_22511 = 0;\n            } else {\n                int32_t zlze_rhs_22512;\n                bool cond_22513;\n                int32_t lifted_lambda_res_f_res_f_res_22514;\n                \n                zlze_rhs_22512 = add32(eta_p_22502, eta_p_22503);\n                cond_22513 = sle32(eta_p_22505, zlze_rhs_22512);\n                if (cond_22513) {\n                    lifted_lambda_res_f_res_f_res_22514 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_22514 = 2;\n                }\n    ", "            lifted_lambda_res_f_res_22511 = lifted_lambda_res_f_res_f_res_22514;\n            }\n            lifted_lambda_res_22509 = lifted_lambda_res_f_res_22511;\n        }\n        cond_22515 = lifted_lambda_res_22509 == 1;\n        if (cond_22515) {\n            float eta_p_22507 = ((__global float *) mem_22832)[gtid_22500];\n            \n            lifted_lambda_res_22516 = eta_p_22507;\n        } else {\n            float eta_p_22506 = ((__global float *) mem_param_22826)[gtid_22500];\n            \n            lifted_lambda_res_22516 = eta_p_22506;\n        }\n        if (lifted_lambda_res_22509 == -1) {\n            lifted_lambda_res_22517 = -1;\n        } else if (lifted_lambda_res_22509 == 0) {\n            lifted_lambda_res_22517 = eta_p_22505;\n        } else if (lifted_lambda_res_22509 == 1) {\n            lifted_lambda_res_22517 = -1;\n        } else if (lifted_lambda_res_22509 == 2) {\n            int32_t zm_lhs_22518;\n            int32_t case_res_22519;\n            \n            zm_lhs_22518 = sub32(eta_p_22505, eta_p_22502);\n            case_res_22519 = sub32(zm_lhs_22518, eta_p_22503);\n            lifted_lambda_res_22517 = case_res_22519;\n        } else {\n            lifted_lambda_res_22517 = -1;\n        }\n        if (lifted_lambda_res_22509 == -1) {\n            lifted_lambda_res_22520 = 0;\n        } else if (lifted_lambda_res_22509 == 0) {\n            lifted_lambda_res_22520 = eta_p_22502;\n        } else if (lifted_lambda_res_22509 == 1) {\n            lifted_lambda_res_22520 = 0;\n        } else if (lifted_lambda_res_22509 == 2) {\n            int32_t zm_lhs_22521;\n            int32_t case_res_22522;\n            \n            zm_lhs_22521 = sub32(eta_p_22504, eta_p_22502);\n            case_res_22522 = sub32(zm_lhs_22521, eta_p_22503);\n            lifted_lambda_res_22520 = case_res_22522;\n        } else {\n            lifted_lambda_res_22520 = -1;\n        }\n        ((__global int32_t *) mem_22843)[gtid_22500] = lifted_lambda_res_22520;\n        ((__global int32_t *) mem_",
                                    "22845)[gtid_22500] = lifted_lambda_res_22517;\n        ((__global float *) mem_22847)[gtid_22500] = lifted_lambda_res_22516;\n        ((__global int32_t *) mem_22849)[gtid_22500] = lifted_lambda_res_22509;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_22494\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegmap_22532_dim1, 1, 1)\nvoid human_regularzisegmap_22532(__global int *global_failure, int64_t loop_dz2081Uz2089Uz2081U_21167, int64_t m_21307, int64_t num_tblocks_22537, int32_t virt_num_tblocks_24091, __global unsigned char *mem_param_22820, __global unsigned char *mem_param_22823, __global unsigned char *mem_22852, __global unsigned char *mem_22854, __global unsigned char *mem_22856, __global unsigned char *mem_22858)\n{\n    #define segmap_tblock_sizze_22535 (human_regularzisegmap_22532zisegmap_tblock_sizze_22535)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_24093;\n    int32_t tblock_sizze_24096;\n    int32_t wave_sizze_24095;\n    int32_t block_id_24094;\n    int32_t global_tid_24092;\n    int64_t phys_tid_22532;\n    int32_t phys_tblock_id_24097;\n    int32_t iterations_24098;\n    \n    local_tid_24093 = get_local_id(0);\n    tblock_sizze_24096 = get_local_size(0);\n    wave_sizze_24095 = LOCKSTEP_WIDTH;\n    block_id_24094 = get_tblock_id(0);\n    global_tid_24092 = block_id_24094 * tblock_sizze_24096 + local_tid_24093;\n    phys_tid_22532 = sext_i32_i64(global_tid_24092);\n    phys_tblock_id_24097 = get_tblock_id(0);\n    iterations_24098 = sdiv_up32(virt_num_tblocks_24091 - phys_tblock_id_24097, sext_i64_i32(num_tblocks_22537));\n    for (int32_t i_24099 = 0; i_24099 < iterations_24098; i_24099++) {\n        int32_t virt_tblock_id_24100;\n        int64_t global_tid_24101;\n        int64_t slice_24102;\n        int64_t write_i_22531;\n        int64_t remnant_24103;\n        \n        virt_tblock_id_24100 = phys_tblock_id_24097 + i_24099 * sext_i64_i32(num_tblocks_22537);\n        global_tid_24101 = sext_i32_i64(virt_tblock_id_24100) * segmap_tbloc", "k_sizze_22535 + sext_i32_i64(local_tid_24093);\n        slice_24102 = loop_dz2081Uz2089Uz2081U_21167;\n        write_i_22531 = global_tid_24101;\n        remnant_24103 = global_tid_24101 - write_i_22531;\n        if (slt64(write_i_22531, loop_dz2081Uz2089Uz2081U_21167)) {\n            int64_t eta_p_21652;\n            float write_value_21654;\n            int32_t write_value_21655;\n            bool cond_21656;\n            int64_t lifted_lambda_res_21657;\n            \n            eta_p_21652 = ((__global int64_t *) mem_22854)[write_i_22531];\n            write_value_21654 = ((__global float *) mem_param_22823)[write_i_22531];\n            write_value_21655 = ((__global int32_t *) mem_param_22820)[write_i_22531];\n            cond_21656 = eta_p_21652 == (int64_t) 1;\n            if (cond_21656) {\n                int64_t eta_p_21653;\n                int64_t lifted_lambda_res_t_res_21938;\n                \n                eta_p_21653 = ((__global int64_t *) mem_22852)[write_i_22531];\n                lifted_lambda_res_t_res_21938 = sub64(eta_p_21653, (int64_t) 1);\n                lifted_lambda_res_21657 = lifted_lambda_res_t_res_21938;\n            } else {\n                lifted_lambda_res_21657 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21657) && slt64(lifted_lambda_res_21657, m_21307)) {\n                ((__global float *) mem_22858)[lifted_lambda_res_21657] = write_value_21654;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_21657) && slt64(lifted_lambda_res_21657, m_21307)) {\n                ((__global int32_t *) mem_22856)[lifted_lambda_res_21657] = write_value_21655;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_22535\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegred_large_23442_dim1, 1, 1)\nvoid human_regularzisegred_large_23442(__global int *global_failure, int64_t mz2080U_17317, int64_t num_tblocks_22272, int64_t num_su", "bhistos_23344, int64_t blocks_per_segment_23480, int64_t q_23481, int64_t num_virtblocks_23482, int64_t threads_per_segment_23483, __global unsigned char *mem_22789, __global unsigned char *mem_22791, __global unsigned char *defunc_0_map_res_subhistos_mem_23345, __global unsigned char *defunc_0_map_res_subhistos_mem_23347, __global unsigned char *segred_tmp_mem_23484, __global unsigned char *segred_tmp_mem_23486, __global unsigned char *counters_mem_23488)\n{\n    #define seghist_tblock_sizze_22270 (human_regularzisegred_large_23442ziseghist_tblock_sizze_22270)\n    #define chunk_sizze_23443 (human_regularzisegred_large_23442zichunk_sizze_23443)\n    \n    volatile __local unsigned char *sync_arr_mem_23499_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_23499_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_23497_backing_1 = &shared_mem[sync_arr_mem_23499_backing_2_offset];\n    const int64_t red_arr_i32_mem_23497_backing_1_offset = sync_arr_mem_23499_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_22270 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22270, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_23495_backing_0 = &shared_mem[red_arr_i32_mem_23497_backing_1_offset];\n    const int64_t red_arr_i32_mem_23495_backing_0_offset = red_arr_i32_mem_23497_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22270 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22270, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23491;\n    int32_t tblock_sizze_23494;\n    int32_t wave_sizze_23493;\n    int32_t block_id_23492;\n    int32_t global_tid_23490;\n    int64_t flat_gtid_23442;\n    __local unsigned char *red_arr_i32_mem_23495;\n    __local unsigned char *red_arr_i32_mem_23497;\n    __local unsigned char *sync_arr_mem_23499;\n    int32_t phys_tblock_id_23501;\n    int32_t iterations_23502;\n    \n    local_tid_23491 = ",
                                    "get_local_id(0);\n    tblock_sizze_23494 = get_local_size(0);\n    wave_sizze_23493 = LOCKSTEP_WIDTH;\n    block_id_23492 = get_tblock_id(0);\n    global_tid_23490 = block_id_23492 * tblock_sizze_23494 + local_tid_23491;\n    flat_gtid_23442 = sext_i32_i64(global_tid_23490);\n    red_arr_i32_mem_23495 = (__local unsigned char *) red_arr_i32_mem_23495_backing_0;\n    red_arr_i32_mem_23497 = (__local unsigned char *) red_arr_i32_mem_23497_backing_1;\n    sync_arr_mem_23499 = (__local unsigned char *) sync_arr_mem_23499_backing_2;\n    phys_tblock_id_23501 = get_tblock_id(0);\n    iterations_23502 = sdiv_up32(sext_i64_i32(num_virtblocks_23482) - phys_tblock_id_23501, sext_i64_i32(num_tblocks_22272));\n    for (int32_t i_23503 = 0; i_23503 < iterations_23502; i_23503++) {\n        int32_t virt_tblock_id_23504;\n        int64_t flat_segment_id_23505;\n        int64_t global_tid_23506;\n        int64_t slice_23507;\n        int64_t bucket_id_23440;\n        int64_t remnant_23508;\n        int64_t subhistogram_id_23441;\n        int32_t eta_p_block_res_acc_23509;\n        int32_t eta_p_block_res_acc_23510;\n        int32_t eta_p_22278;\n        int32_t eta_p_22279;\n        int32_t eta_p_22280;\n        int32_t eta_p_22281;\n        int64_t tblock_id_in_segment_23517;\n        int64_t block_base_offset_23518;\n        int32_t offset_23521;\n        int32_t skip_waves_23522;\n        int32_t eta_p_23511;\n        int32_t eta_p_23512;\n        int32_t eta_p_23513;\n        int32_t eta_p_23514;\n        \n        virt_tblock_id_23504 = phys_tblock_id_23501 + i_23503 * sext_i64_i32(num_tblocks_22272);\n        flat_segment_id_23505 = squot64(sext_i32_i64(virt_tblock_id_23504), blocks_per_segment_23480);\n        global_tid_23506 = srem64(sext_i32_i64(virt_tblock_id_23504) * seghist_tblock_sizze_22270 + sext_i32_i64(local_tid_23491), threads_per_segment_23483);\n        slice_23507 = mz2080U_17317;\n        bucket_id_23440 = flat_segment_id_23505;\n        remnant_23508 = flat_segment_id_23505 - bucket_id_23440;\n   ", "     // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_23509 = 0;\n            eta_p_block_res_acc_23510 = 0;\n        }\n        tblock_id_in_segment_23517 = squot64(global_tid_23506, seghist_tblock_sizze_22270);\n        block_base_offset_23518 = tblock_id_in_segment_23517 * q_23481 * seghist_tblock_sizze_22270;\n        for (int64_t i_23519 = 0; i_23519 < q_23481; i_23519++) {\n            int64_t block_offset_23520 = block_base_offset_23518 + i_23519 * seghist_tblock_sizze_22270;\n            \n            subhistogram_id_23441 = global_tid_23506 + threads_per_segment_23483 * i_23519;\n            if (slt64(subhistogram_id_23441, num_subhistos_23344)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_22278 = eta_p_block_res_acc_23509;\n                        eta_p_22279 = eta_p_block_res_acc_23510;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_22280 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23345)[subhistogram_id_23441 * mz2080U_17317 + bucket_id_23440];\n                        eta_p_22281 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23347)[subhistogram_id_23441 * mz2080U_17317 + bucket_id_23440];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_22282 = add32(eta_p_22278, eta_p_22280);\n                        int32_t tmp_22283 = add32(eta_p_22279, eta_p_22281);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_23509 = tmp_22282;\n                            eta_p_block_res_acc_23510 = tmp_22283;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go ", "in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491)] = eta_p_block_res_acc_23509;\n            ((__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491)] = eta_p_block_res_acc_23510;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_23522 = 1;\n        offset_23521 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_23491, sext_i64_i32(seghist_tblock_sizze_22270))) {\n                eta_p_23511 = ((__local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491 + offset_23521)];\n                eta_p_23512 = ((__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491 + offset_23521)];\n            }\n        }\n        offset_23521 = 1;\n        while (slt32(offset_23521, wave_sizze_23493)) {\n            if (slt32(local_tid_23491 + offset_23521, sext_i64_i32(seghist_tblock_sizze_22270)) && ((local_tid_23491 - squot32(local_tid_23491, wave_sizze_23493) * wave_sizze_23493) & (2 * offset_23521 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_23513 = ((volatile __local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491 + offset_23521)];\n                    eta_p_23514 = ((volatile __local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491 + offset_23521)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_23515 = add32(eta_p_23511, eta_p_23513);\n                    int32_t tmp_23516 = add32(eta_p_23512, eta_p_23514);\n                    \n                    eta_p_23511 = tmp_23515;\n                    eta_p_23512 = tmp_23516;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491)] = eta_p_23511;\n                    ((volatile ",
                                    "__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491)] = eta_p_23512;\n                }\n            }\n            offset_23521 *= 2;\n        }\n        while (slt32(skip_waves_23522, squot32(sext_i64_i32(seghist_tblock_sizze_22270) + wave_sizze_23493 - 1, wave_sizze_23493))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23521 = skip_waves_23522 * wave_sizze_23493;\n            if (slt32(local_tid_23491 + offset_23521, sext_i64_i32(seghist_tblock_sizze_22270)) && ((local_tid_23491 - squot32(local_tid_23491, wave_sizze_23493) * wave_sizze_23493) == 0 && (squot32(local_tid_23491, wave_sizze_23493) & (2 * skip_waves_23522 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_23513 = ((__local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491 + offset_23521)];\n                    eta_p_23514 = ((__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491 + offset_23521)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_23515 = add32(eta_p_23511, eta_p_23513);\n                    int32_t tmp_23516 = add32(eta_p_23512, eta_p_23514);\n                    \n                    eta_p_23511 = tmp_23515;\n                    eta_p_23512 = tmp_23516;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491)] = eta_p_23511;\n                    ((__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491)] = eta_p_23512;\n                }\n            }\n            skip_waves_23522 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_23491) == (int64_t) 0) {\n                eta_p_block_res_acc_23509 = eta_p_23511;\n                eta_p_block_res_ac", "c_23510 = eta_p_23512;\n            } else {\n                eta_p_block_res_acc_23509 = 0;\n                eta_p_block_res_acc_23510 = 0;\n            }\n        }\n        if (blocks_per_segment_23480 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_23491 == 0) {\n                    ((__global int32_t *) mem_22791)[bucket_id_23440] = eta_p_block_res_acc_23509;\n                    ((__global int32_t *) mem_22789)[bucket_id_23440] = eta_p_block_res_acc_23510;\n                }\n            }\n        } else {\n            int32_t old_counter_23523;\n            bool is_last_block_23524;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_23491 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_23484)[sext_i32_i64(virt_tblock_id_23504)] = eta_p_block_res_acc_23509;\n                    mem_fence_global();\n                    ((__global int32_t *) segred_tmp_mem_23486)[sext_i32_i64(virt_tblock_id_23504)] = eta_p_block_res_acc_23510;\n                    mem_fence_global();\n                    old_counter_23523 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23488)[srem64(flat_segment_id_23505, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_23499)[(int64_t) 0] = old_counter_23523 == sext_i64_i32(blocks_per_segment_23480 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_23524 = ((__local bool *) sync_arr_mem_23499)[(int64_t) 0];\n            if (is_last_block_23524) {\n                if (local_tid_23491 == 0) {\n                    old_counter_23523 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23488)[srem64(flat_segment_id_23505, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_23480));\n                }\n                // read in the p", "er-block-results\n                {\n                    int64_t read_per_thread_23525 = sdiv_up64(blocks_per_segment_23480, seghist_tblock_sizze_22270);\n                    \n                    eta_p_22278 = 0;\n                    eta_p_22279 = 0;\n                    for (int64_t i_23526 = 0; i_23526 < read_per_thread_23525; i_23526++) {\n                        int64_t block_res_id_23527 = sext_i32_i64(local_tid_23491) * read_per_thread_23525 + i_23526;\n                        int64_t index_of_block_res_23528 = flat_segment_id_23505 * blocks_per_segment_23480 + block_res_id_23527;\n                        \n                        if (slt64(block_res_id_23527, blocks_per_segment_23480)) {\n                            eta_p_22280 = ((__global int32_t *) segred_tmp_mem_23484)[index_of_block_res_23528];\n                            eta_p_22281 = ((__global int32_t *) segred_tmp_mem_23486)[index_of_block_res_23528];\n                            \n                            int32_t tmp_22282 = add32(eta_p_22278, eta_p_22280);\n                            int32_t tmp_22283 = add32(eta_p_22279, eta_p_22281);\n                            \n                            eta_p_22278 = tmp_22282;\n                            eta_p_22279 = tmp_22283;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491)] = eta_p_22278;\n                ((__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491)] = eta_p_22279;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_23529;\n                    int32_t skip_waves_23530 = 1;\n                    int32_t eta_p_23511;\n                    int32_t eta_p_23512;\n                    int32_t eta_p_23513;\n                    int32_t eta_p_23514;\n                    \n                    offset_23529 = 0;\n                    // participating threads rea",
                                    "d initial accumulator\n                    {\n                        if (slt32(local_tid_23491, sext_i64_i32(seghist_tblock_sizze_22270))) {\n                            eta_p_23511 = ((__local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491 + offset_23529)];\n                            eta_p_23512 = ((__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491 + offset_23529)];\n                        }\n                    }\n                    offset_23529 = 1;\n                    while (slt32(offset_23529, wave_sizze_23493)) {\n                        if (slt32(local_tid_23491 + offset_23529, sext_i64_i32(seghist_tblock_sizze_22270)) && ((local_tid_23491 - squot32(local_tid_23491, wave_sizze_23493) * wave_sizze_23493) & (2 * offset_23529 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_23513 = ((volatile __local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491 + offset_23529)];\n                                eta_p_23514 = ((volatile __local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491 + offset_23529)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_23515 = add32(eta_p_23511, eta_p_23513);\n                                int32_t tmp_23516 = add32(eta_p_23512, eta_p_23514);\n                                \n                                eta_p_23511 = tmp_23515;\n                                eta_p_23512 = tmp_23516;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491)] = eta_p_23511;\n                                ((volatile __local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491)] = eta_p_23512;\n                           ", " }\n                        }\n                        offset_23529 *= 2;\n                    }\n                    while (slt32(skip_waves_23530, squot32(sext_i64_i32(seghist_tblock_sizze_22270) + wave_sizze_23493 - 1, wave_sizze_23493))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_23529 = skip_waves_23530 * wave_sizze_23493;\n                        if (slt32(local_tid_23491 + offset_23529, sext_i64_i32(seghist_tblock_sizze_22270)) && ((local_tid_23491 - squot32(local_tid_23491, wave_sizze_23493) * wave_sizze_23493) == 0 && (squot32(local_tid_23491, wave_sizze_23493) & (2 * skip_waves_23530 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_23513 = ((__local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491 + offset_23529)];\n                                eta_p_23514 = ((__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491 + offset_23529)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_23515 = add32(eta_p_23511, eta_p_23513);\n                                int32_t tmp_23516 = add32(eta_p_23512, eta_p_23514);\n                                \n                                eta_p_23511 = tmp_23515;\n                                eta_p_23512 = tmp_23516;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_23495)[sext_i32_i64(local_tid_23491)] = eta_p_23511;\n                                ((__local int32_t *) red_arr_i32_mem_23497)[sext_i32_i64(local_tid_23491)] = eta_p_23512;\n                            }\n                        }\n                        skip_waves_23530 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    /", "/ and back to memory with the final result\n                    {\n                        if (local_tid_23491 == 0) {\n                            ((__global int32_t *) mem_22791)[bucket_id_23440] = eta_p_23511;\n                            ((__global int32_t *) mem_22789)[bucket_id_23440] = eta_p_23512;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_22270\n    #undef chunk_sizze_23443\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegred_large_23889_dim1, 1, 1)\nvoid human_regularzisegred_large_23889(__global int *global_failure, int64_t mz2080U_17317, int64_t num_tblocks_22446, int64_t num_subhistos_23791, int64_t blocks_per_segment_23927, int64_t q_23928, int64_t num_virtblocks_23929, int64_t threads_per_segment_23930, __global unsigned char *mem_22837, __global unsigned char *mem_22839, __global unsigned char *defunc_0_map_res_subhistos_mem_23792, __global unsigned char *defunc_0_map_res_subhistos_mem_23794, __global unsigned char *segred_tmp_mem_23931, __global unsigned char *segred_tmp_mem_23933, __global unsigned char *counters_mem_23935)\n{\n    #define seghist_tblock_sizze_22444 (human_regularzisegred_large_23889ziseghist_tblock_sizze_22444)\n    #define chunk_sizze_23890 (human_regularzisegred_large_23889zichunk_sizze_23890)\n    \n    volatile __local unsigned char *sync_arr_mem_23946_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_23946_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_23944_backing_1 = &shared_mem[sync_arr_mem_23946_backing_2_offset];\n    const int64_t red_arr_i32_mem_23944_backing_1_offset = sync_arr_mem_23946_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_22444 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22444, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_23942_backing_0 = &shared_mem",
                                    "[red_arr_i32_mem_23944_backing_1_offset];\n    const int64_t red_arr_i32_mem_23942_backing_0_offset = red_arr_i32_mem_23944_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22444 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22444, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23938;\n    int32_t tblock_sizze_23941;\n    int32_t wave_sizze_23940;\n    int32_t block_id_23939;\n    int32_t global_tid_23937;\n    int64_t flat_gtid_23889;\n    __local unsigned char *red_arr_i32_mem_23942;\n    __local unsigned char *red_arr_i32_mem_23944;\n    __local unsigned char *sync_arr_mem_23946;\n    int32_t phys_tblock_id_23948;\n    int32_t iterations_23949;\n    \n    local_tid_23938 = get_local_id(0);\n    tblock_sizze_23941 = get_local_size(0);\n    wave_sizze_23940 = LOCKSTEP_WIDTH;\n    block_id_23939 = get_tblock_id(0);\n    global_tid_23937 = block_id_23939 * tblock_sizze_23941 + local_tid_23938;\n    flat_gtid_23889 = sext_i32_i64(global_tid_23937);\n    red_arr_i32_mem_23942 = (__local unsigned char *) red_arr_i32_mem_23942_backing_0;\n    red_arr_i32_mem_23944 = (__local unsigned char *) red_arr_i32_mem_23944_backing_1;\n    sync_arr_mem_23946 = (__local unsigned char *) sync_arr_mem_23946_backing_2;\n    phys_tblock_id_23948 = get_tblock_id(0);\n    iterations_23949 = sdiv_up32(sext_i64_i32(num_virtblocks_23929) - phys_tblock_id_23948, sext_i64_i32(num_tblocks_22446));\n    for (int32_t i_23950 = 0; i_23950 < iterations_23949; i_23950++) {\n        int32_t virt_tblock_id_23951;\n        int64_t flat_segment_id_23952;\n        int64_t global_tid_23953;\n        int64_t slice_23954;\n        int64_t bucket_id_23887;\n        int64_t remnant_23955;\n        int64_t subhistogram_id_23888;\n        int32_t eta_p_block_res_acc_23956;\n        int32_t eta_p_block_res_acc_23957;\n        int32_t eta_p_22452;\n        int32_t eta_p_22453;\n        int32_t eta_p_22454;\n        int32_t eta_p_22455;\n        int64_t tblock_id_in_s", "egment_23964;\n        int64_t block_base_offset_23965;\n        int32_t offset_23968;\n        int32_t skip_waves_23969;\n        int32_t eta_p_23958;\n        int32_t eta_p_23959;\n        int32_t eta_p_23960;\n        int32_t eta_p_23961;\n        \n        virt_tblock_id_23951 = phys_tblock_id_23948 + i_23950 * sext_i64_i32(num_tblocks_22446);\n        flat_segment_id_23952 = squot64(sext_i32_i64(virt_tblock_id_23951), blocks_per_segment_23927);\n        global_tid_23953 = srem64(sext_i32_i64(virt_tblock_id_23951) * seghist_tblock_sizze_22444 + sext_i32_i64(local_tid_23938), threads_per_segment_23930);\n        slice_23954 = mz2080U_17317;\n        bucket_id_23887 = flat_segment_id_23952;\n        remnant_23955 = flat_segment_id_23952 - bucket_id_23887;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_23956 = 0;\n            eta_p_block_res_acc_23957 = 0;\n        }\n        tblock_id_in_segment_23964 = squot64(global_tid_23953, seghist_tblock_sizze_22444);\n        block_base_offset_23965 = tblock_id_in_segment_23964 * q_23928 * seghist_tblock_sizze_22444;\n        for (int64_t i_23966 = 0; i_23966 < q_23928; i_23966++) {\n            int64_t block_offset_23967 = block_base_offset_23965 + i_23966 * seghist_tblock_sizze_22444;\n            \n            subhistogram_id_23888 = global_tid_23953 + threads_per_segment_23930 * i_23966;\n            if (slt64(subhistogram_id_23888, num_subhistos_23791)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_22452 = eta_p_block_res_acc_23956;\n                        eta_p_22453 = eta_p_block_res_acc_23957;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_22454 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23792)[subhistogram_id_23888 * mz2080U_17317 + bucket_id_23887];\n                        eta_p_22455 = ((__gl", "obal int32_t *) defunc_0_map_res_subhistos_mem_23794)[subhistogram_id_23888 * mz2080U_17317 + bucket_id_23887];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_22456 = add32(eta_p_22452, eta_p_22454);\n                        int32_t tmp_22457 = add32(eta_p_22453, eta_p_22455);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_23956 = tmp_22456;\n                            eta_p_block_res_acc_23957 = tmp_22457;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938)] = eta_p_block_res_acc_23956;\n            ((__local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938)] = eta_p_block_res_acc_23957;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_23969 = 1;\n        offset_23968 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_23938, sext_i64_i32(seghist_tblock_sizze_22444))) {\n                eta_p_23958 = ((__local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938 + offset_23968)];\n                eta_p_23959 = ((__local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938 + offset_23968)];\n            }\n        }\n        offset_23968 = 1;\n        while (slt32(offset_23968, wave_sizze_23940)) {\n            if (slt32(local_tid_23938 + offset_23968, sext_i64_i32(seghist_tblock_sizze_22444)) && ((local_tid_23938 - squot32(local_tid_23938, wave_sizze_23940) * wave_sizze_23940) & (2 * offset_23968 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_23960 = ((volatile __local int32_t *) red_arr_i32_mem_",
                                    "23942)[sext_i32_i64(local_tid_23938 + offset_23968)];\n                    eta_p_23961 = ((volatile __local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938 + offset_23968)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_23962 = add32(eta_p_23958, eta_p_23960);\n                    int32_t tmp_23963 = add32(eta_p_23959, eta_p_23961);\n                    \n                    eta_p_23958 = tmp_23962;\n                    eta_p_23959 = tmp_23963;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938)] = eta_p_23958;\n                    ((volatile __local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938)] = eta_p_23959;\n                }\n            }\n            offset_23968 *= 2;\n        }\n        while (slt32(skip_waves_23969, squot32(sext_i64_i32(seghist_tblock_sizze_22444) + wave_sizze_23940 - 1, wave_sizze_23940))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_23968 = skip_waves_23969 * wave_sizze_23940;\n            if (slt32(local_tid_23938 + offset_23968, sext_i64_i32(seghist_tblock_sizze_22444)) && ((local_tid_23938 - squot32(local_tid_23938, wave_sizze_23940) * wave_sizze_23940) == 0 && (squot32(local_tid_23938, wave_sizze_23940) & (2 * skip_waves_23969 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_23960 = ((__local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938 + offset_23968)];\n                    eta_p_23961 = ((__local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938 + offset_23968)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_23962 = add32(eta_p_23958, eta_p_23960);\n                    int32_t tmp_23963 = add32(eta_p_23959, eta_p_23961);\n                    \n               ", "     eta_p_23958 = tmp_23962;\n                    eta_p_23959 = tmp_23963;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938)] = eta_p_23958;\n                    ((__local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938)] = eta_p_23959;\n                }\n            }\n            skip_waves_23969 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_23938) == (int64_t) 0) {\n                eta_p_block_res_acc_23956 = eta_p_23958;\n                eta_p_block_res_acc_23957 = eta_p_23959;\n            } else {\n                eta_p_block_res_acc_23956 = 0;\n                eta_p_block_res_acc_23957 = 0;\n            }\n        }\n        if (blocks_per_segment_23927 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_23938 == 0) {\n                    ((__global int32_t *) mem_22839)[bucket_id_23887] = eta_p_block_res_acc_23956;\n                    ((__global int32_t *) mem_22837)[bucket_id_23887] = eta_p_block_res_acc_23957;\n                }\n            }\n        } else {\n            int32_t old_counter_23970;\n            bool is_last_block_23971;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_23938 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_23931)[sext_i32_i64(virt_tblock_id_23951)] = eta_p_block_res_acc_23956;\n                    mem_fence_global();\n                    ((__global int32_t *) segred_tmp_mem_23933)[sext_i32_i64(virt_tblock_id_23951)] = eta_p_block_res_acc_23957;\n                    mem_fence_global();\n                    old_counter_23970 = atomic_add_i32_global(&((volatile __global int *) counte", "rs_mem_23935)[srem64(flat_segment_id_23952, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_23946)[(int64_t) 0] = old_counter_23970 == sext_i64_i32(blocks_per_segment_23927 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_23971 = ((__local bool *) sync_arr_mem_23946)[(int64_t) 0];\n            if (is_last_block_23971) {\n                if (local_tid_23938 == 0) {\n                    old_counter_23970 = atomic_add_i32_global(&((volatile __global int *) counters_mem_23935)[srem64(flat_segment_id_23952, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_23927));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_23972 = sdiv_up64(blocks_per_segment_23927, seghist_tblock_sizze_22444);\n                    \n                    eta_p_22452 = 0;\n                    eta_p_22453 = 0;\n                    for (int64_t i_23973 = 0; i_23973 < read_per_thread_23972; i_23973++) {\n                        int64_t block_res_id_23974 = sext_i32_i64(local_tid_23938) * read_per_thread_23972 + i_23973;\n                        int64_t index_of_block_res_23975 = flat_segment_id_23952 * blocks_per_segment_23927 + block_res_id_23974;\n                        \n                        if (slt64(block_res_id_23974, blocks_per_segment_23927)) {\n                            eta_p_22454 = ((__global int32_t *) segred_tmp_mem_23931)[index_of_block_res_23975];\n                            eta_p_22455 = ((__global int32_t *) segred_tmp_mem_23933)[index_of_block_res_23975];\n                            \n                            int32_t tmp_22456 = add32(eta_p_22452, eta_p_22454);\n                            int32_t tmp_22457 = add32(eta_p_22453, eta_p_22455);\n                            \n                            eta_p_22452 = tmp_22456;\n                            eta_p_22453 = tmp_224",
                                    "57;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938)] = eta_p_22452;\n                ((__local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938)] = eta_p_22453;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_23976;\n                    int32_t skip_waves_23977 = 1;\n                    int32_t eta_p_23958;\n                    int32_t eta_p_23959;\n                    int32_t eta_p_23960;\n                    int32_t eta_p_23961;\n                    \n                    offset_23976 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_23938, sext_i64_i32(seghist_tblock_sizze_22444))) {\n                            eta_p_23958 = ((__local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938 + offset_23976)];\n                            eta_p_23959 = ((__local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938 + offset_23976)];\n                        }\n                    }\n                    offset_23976 = 1;\n                    while (slt32(offset_23976, wave_sizze_23940)) {\n                        if (slt32(local_tid_23938 + offset_23976, sext_i64_i32(seghist_tblock_sizze_22444)) && ((local_tid_23938 - squot32(local_tid_23938, wave_sizze_23940) * wave_sizze_23940) & (2 * offset_23976 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_23960 = ((volatile __local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938 + offset_23976)];\n                                eta_p_23961 = ((volatile __local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938 + offset_23976)];\n                            }\n                            // apply reduction operat", "ion\n                            {\n                                int32_t tmp_23962 = add32(eta_p_23958, eta_p_23960);\n                                int32_t tmp_23963 = add32(eta_p_23959, eta_p_23961);\n                                \n                                eta_p_23958 = tmp_23962;\n                                eta_p_23959 = tmp_23963;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938)] = eta_p_23958;\n                                ((volatile __local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938)] = eta_p_23959;\n                            }\n                        }\n                        offset_23976 *= 2;\n                    }\n                    while (slt32(skip_waves_23977, squot32(sext_i64_i32(seghist_tblock_sizze_22444) + wave_sizze_23940 - 1, wave_sizze_23940))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_23976 = skip_waves_23977 * wave_sizze_23940;\n                        if (slt32(local_tid_23938 + offset_23976, sext_i64_i32(seghist_tblock_sizze_22444)) && ((local_tid_23938 - squot32(local_tid_23938, wave_sizze_23940) * wave_sizze_23940) == 0 && (squot32(local_tid_23938, wave_sizze_23940) & (2 * skip_waves_23977 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_23960 = ((__local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938 + offset_23976)];\n                                eta_p_23961 = ((__local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938 + offset_23976)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_23962 = add32(eta_p_23958, eta_p_23960);\n                                ", "int32_t tmp_23963 = add32(eta_p_23959, eta_p_23961);\n                                \n                                eta_p_23958 = tmp_23962;\n                                eta_p_23959 = tmp_23963;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_23942)[sext_i32_i64(local_tid_23938)] = eta_p_23958;\n                                ((__local int32_t *) red_arr_i32_mem_23944)[sext_i32_i64(local_tid_23938)] = eta_p_23959;\n                            }\n                        }\n                        skip_waves_23977 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_23938 == 0) {\n                            ((__global int32_t *) mem_22839)[bucket_id_23887] = eta_p_23958;\n                            ((__global int32_t *) mem_22837)[bucket_id_23887] = eta_p_23959;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_22444\n    #undef chunk_sizze_23890\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegred_small_23442_dim1, 1, 1)\nvoid human_regularzisegred_small_23442(__global int *global_failure, int64_t mz2080U_17317, int64_t num_tblocks_22272, int64_t num_subhistos_23344, int64_t segment_sizze_nonzzero_23444, __global unsigned char *mem_22789, __global unsigned char *mem_22791, __global unsigned char *defunc_0_map_res_subhistos_mem_23345, __global unsigned char *defunc_0_map_res_subhistos_mem_23347)\n{\n    #define seghist_tblock_sizze_22270 (human_regularzisegred_small_23442ziseghist_tblock_sizze_22270)\n    \n    volatile __local unsigned char *red_arr_i32_mem_23453_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_23453_bac",
                                    "king_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_22270 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22270, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_23451_backing_0 = &shared_mem[red_arr_i32_mem_23453_backing_1_offset];\n    const int64_t red_arr_i32_mem_23451_backing_0_offset = red_arr_i32_mem_23453_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22270 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22270, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23447;\n    int32_t tblock_sizze_23450;\n    int32_t wave_sizze_23449;\n    int32_t block_id_23448;\n    int32_t global_tid_23446;\n    int64_t flat_gtid_23442;\n    __local unsigned char *red_arr_i32_mem_23451;\n    __local unsigned char *red_arr_i32_mem_23453;\n    int32_t phys_tblock_id_23455;\n    int32_t iterations_23456;\n    \n    local_tid_23447 = get_local_id(0);\n    tblock_sizze_23450 = get_local_size(0);\n    wave_sizze_23449 = LOCKSTEP_WIDTH;\n    block_id_23448 = get_tblock_id(0);\n    global_tid_23446 = block_id_23448 * tblock_sizze_23450 + local_tid_23447;\n    flat_gtid_23442 = sext_i32_i64(global_tid_23446);\n    red_arr_i32_mem_23451 = (__local unsigned char *) red_arr_i32_mem_23451_backing_0;\n    red_arr_i32_mem_23453 = (__local unsigned char *) red_arr_i32_mem_23453_backing_1;\n    phys_tblock_id_23455 = get_tblock_id(0);\n    iterations_23456 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_17317, squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444))) - phys_tblock_id_23455, sext_i64_i32(num_tblocks_22272));\n    for (int32_t i_23457 = 0; i_23457 < iterations_23456; i_23457++) {\n        int32_t virt_tblock_id_23458;\n        int64_t slice_23459;\n        int64_t bucket_id_23440;\n        int64_t remnant_23460;\n        int64_t subhistogram_id_23441;\n        \n        virt_tblock_id_23458 = phys_tblock_id_23455 + i_23457 * sext_i64_i32(num_tblocks_22272);\n        slic", "e_23459 = mz2080U_17317;\n        bucket_id_23440 = squot64(sext_i32_i64(local_tid_23447), segment_sizze_nonzzero_23444) + sext_i32_i64(virt_tblock_id_23458) * squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444);\n        remnant_23460 = squot64(sext_i32_i64(local_tid_23447), segment_sizze_nonzzero_23444) + sext_i32_i64(virt_tblock_id_23458) * squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444) - bucket_id_23440;\n        subhistogram_id_23441 = srem64(sext_i32_i64(local_tid_23447), num_subhistos_23344);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_23344) && (slt64(bucket_id_23440, mz2080U_17317) && slt64(sext_i32_i64(local_tid_23447), num_subhistos_23344 * squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_23461 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23345)[subhistogram_id_23441 * mz2080U_17317 + bucket_id_23440];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447)] = tmp_23461;\n                    \n                    int32_t tmp_23462 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23347)[subhistogram_id_23441 * mz2080U_17317 + bucket_id_23440];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447)] = tmp_23462;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_23344)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_22278;\n                int32_t eta_p_22279;\n                int32_t eta", "_p_22280;\n                int32_t eta_p_22281;\n                int32_t eta_p_23463;\n                int32_t eta_p_23464;\n                int32_t eta_p_23465;\n                int32_t eta_p_23466;\n                bool ltid_in_bounds_23469 = slt64(sext_i32_i64(local_tid_23447), num_subhistos_23344 * squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444));\n                int32_t skip_threads_23470;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_23469) {\n                        eta_p_22280 = ((volatile __local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447)];\n                        eta_p_22281 = ((volatile __local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447)];\n                        if ((local_tid_23447 - squot32(local_tid_23447, 32) * 32) == 0) {\n                            eta_p_22278 = eta_p_22280;\n                            eta_p_22279 = eta_p_22281;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23470 = 1;\n                    while (slt32(skip_threads_23470, 32)) {\n                        bool thread_active_23471 = sle32(skip_threads_23470, local_tid_23447 - squot32(local_tid_23447, 32) * 32) && ltid_in_bounds_23469;\n                        \n                        if (thread_active_23471) {\n                            // read operands\n                            {\n                                eta_p_22278 = ((volatile __local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447) - sext_i32_i64(skip_threads_23470)];\n                                eta_p_22279 = ((volatile __local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447) - sext_i32_i64(skip_threads_23470)];\n                            }\n                        }\n                        // perform operation\n                      ",
                                    "  {\n                            bool inactive_23472 = slt64(srem64(sext_i32_i64(local_tid_23447), num_subhistos_23344), sext_i32_i64(local_tid_23447) - sext_i32_i64(local_tid_23447 - skip_threads_23470));\n                            \n                            if (thread_active_23471 && inactive_23472) {\n                                eta_p_22278 = eta_p_22280;\n                                eta_p_22279 = eta_p_22281;\n                            }\n                            if (thread_active_23471) {\n                                if (!inactive_23472) {\n                                    int32_t tmp_22282 = add32(eta_p_22278, eta_p_22280);\n                                    int32_t tmp_22283 = add32(eta_p_22279, eta_p_22281);\n                                    \n                                    eta_p_22278 = tmp_22282;\n                                    eta_p_22279 = tmp_22283;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_23449, skip_threads_23470)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23471) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447)] = eta_p_22278;\n                                eta_p_22280 = eta_p_22278;\n                                ((volatile __local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447)] = eta_p_22279;\n                                eta_p_22281 = eta_p_22279;\n                            }\n                        }\n                        if (sle32(wave_sizze_23449, skip_threads_23470)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23470 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FE", "NCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_23447 - squot32(local_tid_23447, 32) * 32) == 31 && ltid_in_bounds_23469) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(squot32(local_tid_23447, 32))] = eta_p_22278;\n                        ((volatile __local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(squot32(local_tid_23447, 32))] = eta_p_22279;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_23473;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_23447, 32) == 0 && ltid_in_bounds_23469) {\n                            eta_p_23465 = ((volatile __local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447)];\n                            eta_p_23466 = ((volatile __local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447)];\n                            if ((local_tid_23447 - squot32(local_tid_23447, 32) * 32) == 0) {\n                                eta_p_23463 = eta_p_23465;\n                                eta_p_23464 = eta_p_23466;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_23473 = 1;\n                        while (slt32(skip_threads_23473, 32)) {\n                            bool thread_active_23474 = sle32(skip_threads_23473, local_tid_23447 - squot32(local_tid_23447, 32) * 32) && (squot32(local_tid_23447, 32) == 0 && ltid_in_bounds_23469);\n                            \n                            if (thread_active_23474) {\n                                // read operands\n      ", "                          {\n                                    eta_p_23463 = ((volatile __local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447) - sext_i32_i64(skip_threads_23473)];\n                                    eta_p_23464 = ((volatile __local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447) - sext_i32_i64(skip_threads_23473)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_23475 = slt64(srem64(sext_i32_i64(local_tid_23447 * 32 + 32 - 1), num_subhistos_23344), sext_i32_i64(local_tid_23447 * 32 + 32 - 1) - sext_i32_i64((local_tid_23447 - skip_threads_23473) * 32 + 32 - 1));\n                                \n                                if (thread_active_23474 && inactive_23475) {\n                                    eta_p_23463 = eta_p_23465;\n                                    eta_p_23464 = eta_p_23466;\n                                }\n                                if (thread_active_23474) {\n                                    if (!inactive_23475) {\n                                        int32_t tmp_23467 = add32(eta_p_23463, eta_p_23465);\n                                        int32_t tmp_23468 = add32(eta_p_23464, eta_p_23466);\n                                        \n                                        eta_p_23463 = tmp_23467;\n                                        eta_p_23464 = tmp_23468;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_23449, skip_threads_23473)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_23474) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_234",
                                    "51)[sext_i32_i64(local_tid_23447)] = eta_p_23463;\n                                    eta_p_23465 = eta_p_23463;\n                                    ((volatile __local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447)] = eta_p_23464;\n                                    eta_p_23466 = eta_p_23464;\n                                }\n                            }\n                            if (sle32(wave_sizze_23449, skip_threads_23473)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_23473 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_23476 = squot32(local_tid_23447, 32) == 0 || !ltid_in_bounds_23469;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_23476) {\n                            eta_p_22280 = eta_p_22278;\n                            eta_p_22281 = eta_p_22279;\n                            eta_p_22278 = ((__local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(squot32(local_tid_23447, 32)) - (int64_t) 1];\n                            eta_p_22279 = ((__local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(squot32(local_tid_23447, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_23477 = slt64(srem64(sext_i32_i64(local_tid_23447), num_subhistos_23344), sext_i32_i64(local_tid_23447) - sext_i32_i64(squot32(local_tid_23447, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_23476) {\n                            if (inactive_23477) {\n                                eta_p_22278 = eta_p_22280;\n                                eta_p_22279 = eta_p_22281;\n              ", "              }\n                        }\n                        if (!no_carry_in_23476) {\n                            if (!inactive_23477) {\n                                int32_t tmp_22282 = add32(eta_p_22278, eta_p_22280);\n                                int32_t tmp_22283 = add32(eta_p_22279, eta_p_22281);\n                                \n                                eta_p_22278 = tmp_22282;\n                                eta_p_22279 = tmp_22283;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_23476) {\n                            ((__local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447)] = eta_p_22278;\n                            ((__local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447)] = eta_p_22279;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_23447, 32) == 0 && ltid_in_bounds_23469) {\n                        ((__local int32_t *) red_arr_i32_mem_23451)[sext_i32_i64(local_tid_23447)] = eta_p_22280;\n                        ((__local int32_t *) red_arr_i32_mem_23453)[sext_i32_i64(local_tid_23447)] = eta_p_22281;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_23458) * squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444) + sext_i32_i64(local_tid_23447), mz2080U_17317) && slt64(sext_i32_i64(local_tid_23447), squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444))) {\n                int32_t tmp_23478 = ((__local int32_t *) red_arr_i32_mem_23451)[(sext_i32_i64(local_tid_23447) + (int64_t) 1) * s", "egment_sizze_nonzzero_23444 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_22791)[sext_i32_i64(virt_tblock_id_23458) * squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444) + sext_i32_i64(local_tid_23447)] = tmp_23478;\n                \n                int32_t tmp_23479 = ((__local int32_t *) red_arr_i32_mem_23453)[(sext_i32_i64(local_tid_23447) + (int64_t) 1) * segment_sizze_nonzzero_23444 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_22789)[sext_i32_i64(virt_tblock_id_23458) * squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444) + sext_i32_i64(local_tid_23447)] = tmp_23479;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_22270\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegred_small_23889_dim1, 1, 1)\nvoid human_regularzisegred_small_23889(__global int *global_failure, int64_t mz2080U_17317, int64_t num_tblocks_22446, int64_t num_subhistos_23791, int64_t segment_sizze_nonzzero_23891, __global unsigned char *mem_22837, __global unsigned char *mem_22839, __global unsigned char *defunc_0_map_res_subhistos_mem_23792, __global unsigned char *defunc_0_map_res_subhistos_mem_23794)\n{\n    #define seghist_tblock_sizze_22444 (human_regularzisegred_small_23889ziseghist_tblock_sizze_22444)\n    \n    volatile __local unsigned char *red_arr_i32_mem_23900_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_23900_backing_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_22444 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22444, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_23898_backing_0 = &shared_mem[red_arr_i32_mem_23900_backing_1_offset];\n    const int64_t red_arr_i32_mem_23898_backing_0_offset = red_arr_i32_mem_23900_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_22444 + srem64((int64_t) 8 - sr",
                                    "em64((int64_t) 4 * seghist_tblock_sizze_22444, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23894;\n    int32_t tblock_sizze_23897;\n    int32_t wave_sizze_23896;\n    int32_t block_id_23895;\n    int32_t global_tid_23893;\n    int64_t flat_gtid_23889;\n    __local unsigned char *red_arr_i32_mem_23898;\n    __local unsigned char *red_arr_i32_mem_23900;\n    int32_t phys_tblock_id_23902;\n    int32_t iterations_23903;\n    \n    local_tid_23894 = get_local_id(0);\n    tblock_sizze_23897 = get_local_size(0);\n    wave_sizze_23896 = LOCKSTEP_WIDTH;\n    block_id_23895 = get_tblock_id(0);\n    global_tid_23893 = block_id_23895 * tblock_sizze_23897 + local_tid_23894;\n    flat_gtid_23889 = sext_i32_i64(global_tid_23893);\n    red_arr_i32_mem_23898 = (__local unsigned char *) red_arr_i32_mem_23898_backing_0;\n    red_arr_i32_mem_23900 = (__local unsigned char *) red_arr_i32_mem_23900_backing_1;\n    phys_tblock_id_23902 = get_tblock_id(0);\n    iterations_23903 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_17317, squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891))) - phys_tblock_id_23902, sext_i64_i32(num_tblocks_22446));\n    for (int32_t i_23904 = 0; i_23904 < iterations_23903; i_23904++) {\n        int32_t virt_tblock_id_23905;\n        int64_t slice_23906;\n        int64_t bucket_id_23887;\n        int64_t remnant_23907;\n        int64_t subhistogram_id_23888;\n        \n        virt_tblock_id_23905 = phys_tblock_id_23902 + i_23904 * sext_i64_i32(num_tblocks_22446);\n        slice_23906 = mz2080U_17317;\n        bucket_id_23887 = squot64(sext_i32_i64(local_tid_23894), segment_sizze_nonzzero_23891) + sext_i32_i64(virt_tblock_id_23905) * squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891);\n        remnant_23907 = squot64(sext_i32_i64(local_tid_23894), segment_sizze_nonzzero_23891) + sext_i32_i64(virt_tblock_id_23905) * squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891) - bucket_id_23887;\n        su", "bhistogram_id_23888 = srem64(sext_i32_i64(local_tid_23894), num_subhistos_23791);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_23791) && (slt64(bucket_id_23887, mz2080U_17317) && slt64(sext_i32_i64(local_tid_23894), num_subhistos_23791 * squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_23908 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23792)[subhistogram_id_23888 * mz2080U_17317 + bucket_id_23887];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894)] = tmp_23908;\n                    \n                    int32_t tmp_23909 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_23794)[subhistogram_id_23888 * mz2080U_17317 + bucket_id_23887];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894)] = tmp_23909;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_23791)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_22452;\n                int32_t eta_p_22453;\n                int32_t eta_p_22454;\n                int32_t eta_p_22455;\n                int32_t eta_p_23910;\n                int32_t eta_p_23911;\n                int32_t eta_p_23912;\n                int32_t eta_p_23913;\n                bool ltid_in_bounds_23916 = slt64(sext_i32_i64(local_tid_23894), num_subhistos_23791 * squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891));\n                int32_t skip_threads_23917;\n                \n                // read in", "put for in-block scan\n                {\n                    if (ltid_in_bounds_23916) {\n                        eta_p_22454 = ((volatile __local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894)];\n                        eta_p_22455 = ((volatile __local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894)];\n                        if ((local_tid_23894 - squot32(local_tid_23894, 32) * 32) == 0) {\n                            eta_p_22452 = eta_p_22454;\n                            eta_p_22453 = eta_p_22455;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23917 = 1;\n                    while (slt32(skip_threads_23917, 32)) {\n                        bool thread_active_23918 = sle32(skip_threads_23917, local_tid_23894 - squot32(local_tid_23894, 32) * 32) && ltid_in_bounds_23916;\n                        \n                        if (thread_active_23918) {\n                            // read operands\n                            {\n                                eta_p_22452 = ((volatile __local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894) - sext_i32_i64(skip_threads_23917)];\n                                eta_p_22453 = ((volatile __local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894) - sext_i32_i64(skip_threads_23917)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_23919 = slt64(srem64(sext_i32_i64(local_tid_23894), num_subhistos_23791), sext_i32_i64(local_tid_23894) - sext_i32_i64(local_tid_23894 - skip_threads_23917));\n                            \n                            if (thread_active_23918 && inactive_23919) {\n                                eta_p_22452 = eta_p_22454;\n                                eta_p_22453 = eta_p_22455;\n                            ",
                                    "}\n                            if (thread_active_23918) {\n                                if (!inactive_23919) {\n                                    int32_t tmp_22456 = add32(eta_p_22452, eta_p_22454);\n                                    int32_t tmp_22457 = add32(eta_p_22453, eta_p_22455);\n                                    \n                                    eta_p_22452 = tmp_22456;\n                                    eta_p_22453 = tmp_22457;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_23896, skip_threads_23917)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23918) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894)] = eta_p_22452;\n                                eta_p_22454 = eta_p_22452;\n                                ((volatile __local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894)] = eta_p_22453;\n                                eta_p_22455 = eta_p_22453;\n                            }\n                        }\n                        if (sle32(wave_sizze_23896, skip_threads_23917)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23917 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_23894 - squot32(local_tid_23894, 32) * 32) == 31 && ltid_in_bounds_23916) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(squot32(local_tid_23894, 32))] = eta_p_22452;\n                        ((volatile __local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(squot32(local_ti", "d_23894, 32))] = eta_p_22453;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_23920;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_23894, 32) == 0 && ltid_in_bounds_23916) {\n                            eta_p_23912 = ((volatile __local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894)];\n                            eta_p_23913 = ((volatile __local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894)];\n                            if ((local_tid_23894 - squot32(local_tid_23894, 32) * 32) == 0) {\n                                eta_p_23910 = eta_p_23912;\n                                eta_p_23911 = eta_p_23913;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_23920 = 1;\n                        while (slt32(skip_threads_23920, 32)) {\n                            bool thread_active_23921 = sle32(skip_threads_23920, local_tid_23894 - squot32(local_tid_23894, 32) * 32) && (squot32(local_tid_23894, 32) == 0 && ltid_in_bounds_23916);\n                            \n                            if (thread_active_23921) {\n                                // read operands\n                                {\n                                    eta_p_23910 = ((volatile __local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894) - sext_i32_i64(skip_threads_23920)];\n                                    eta_p_23911 = ((volatile __local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894) - sext_i32_i64(skip_threads_23920)];\n                                }\n                            }\n                     ", "       // perform operation\n                            {\n                                bool inactive_23922 = slt64(srem64(sext_i32_i64(local_tid_23894 * 32 + 32 - 1), num_subhistos_23791), sext_i32_i64(local_tid_23894 * 32 + 32 - 1) - sext_i32_i64((local_tid_23894 - skip_threads_23920) * 32 + 32 - 1));\n                                \n                                if (thread_active_23921 && inactive_23922) {\n                                    eta_p_23910 = eta_p_23912;\n                                    eta_p_23911 = eta_p_23913;\n                                }\n                                if (thread_active_23921) {\n                                    if (!inactive_23922) {\n                                        int32_t tmp_23914 = add32(eta_p_23910, eta_p_23912);\n                                        int32_t tmp_23915 = add32(eta_p_23911, eta_p_23913);\n                                        \n                                        eta_p_23910 = tmp_23914;\n                                        eta_p_23911 = tmp_23915;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_23896, skip_threads_23920)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_23921) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894)] = eta_p_23910;\n                                    eta_p_23912 = eta_p_23910;\n                                    ((volatile __local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894)] = eta_p_23911;\n                                    eta_p_23913 = eta_p_23911;\n                                }\n                            }\n                            if (sle32(wave_sizze_23896, skip_threads_23920)) {",
                                    "\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_23920 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_23923 = squot32(local_tid_23894, 32) == 0 || !ltid_in_bounds_23916;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_23923) {\n                            eta_p_22454 = eta_p_22452;\n                            eta_p_22455 = eta_p_22453;\n                            eta_p_22452 = ((__local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(squot32(local_tid_23894, 32)) - (int64_t) 1];\n                            eta_p_22453 = ((__local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(squot32(local_tid_23894, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_23924 = slt64(srem64(sext_i32_i64(local_tid_23894), num_subhistos_23791), sext_i32_i64(local_tid_23894) - sext_i32_i64(squot32(local_tid_23894, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_23923) {\n                            if (inactive_23924) {\n                                eta_p_22452 = eta_p_22454;\n                                eta_p_22453 = eta_p_22455;\n                            }\n                        }\n                        if (!no_carry_in_23923) {\n                            if (!inactive_23924) {\n                                int32_t tmp_22456 = add32(eta_p_22452, eta_p_22454);\n                                int32_t tmp_22457 = add32(eta_p_22453, eta_p_22455);\n                                \n                                eta_p_22452 = tmp_22456;\n                                eta_p_22453 = tmp_", "22457;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_23923) {\n                            ((__local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894)] = eta_p_22452;\n                            ((__local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894)] = eta_p_22453;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_23894, 32) == 0 && ltid_in_bounds_23916) {\n                        ((__local int32_t *) red_arr_i32_mem_23898)[sext_i32_i64(local_tid_23894)] = eta_p_22454;\n                        ((__local int32_t *) red_arr_i32_mem_23900)[sext_i32_i64(local_tid_23894)] = eta_p_22455;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_23905) * squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891) + sext_i32_i64(local_tid_23894), mz2080U_17317) && slt64(sext_i32_i64(local_tid_23894), squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891))) {\n                int32_t tmp_23925 = ((__local int32_t *) red_arr_i32_mem_23898)[(sext_i32_i64(local_tid_23894) + (int64_t) 1) * segment_sizze_nonzzero_23891 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_22839)[sext_i32_i64(virt_tblock_id_23905) * squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891) + sext_i32_i64(local_tid_23894)] = tmp_23925;\n                \n                int32_t tmp_23926 = ((__local int32_t *) red_arr_i32_mem_23900)[(sext_i32_i64(local_tid_23894) + (int64_t) 1) * segment_sizze_nonzzero_23891 - (int64_t) 1];\n    ", "            \n                ((__global int32_t *) mem_22837)[sext_i32_i64(virt_tblock_id_23905) * squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891) + sext_i32_i64(local_tid_23894)] = tmp_23926;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_22444\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegscan_22166_dim1, 1, 1)\nvoid human_regularzisegscan_22166(__global int *global_failure, int64_t mz2080U_17317, int64_t num_tblocks_22163, int64_t num_virt_blocks_22891, int64_t num_virt_threads_22892, __global unsigned char *shp_mem_22767, __global unsigned char *mem_22772, __global unsigned char *status_flags_mem_22893, __global unsigned char *aggregates_mem_22915, __global unsigned char *incprefixes_mem_22917, __global unsigned char *global_dynid_mem_22919)\n{\n    #define segscan_tblock_sizze_22161 (human_regularzisegscan_22166zisegscan_tblock_sizze_22161)\n    #define chunk_sizze_22890 (human_regularzisegscan_22166zichunk_sizze_22890)\n    \n    volatile __local unsigned char *local_mem_22949_backing_0 = &shared_mem[0];\n    const int64_t local_mem_22949_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22161), chunk_sizze_22890 * segscan_tblock_sizze_22161 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22161), chunk_sizze_22890 * segscan_tblock_sizze_22161 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_22942;\n    int32_t tblock_sizze_22945;\n    int32_t wave_sizze_22944;\n    int32_t block_id_22943;\n    int32_t global_tid_22941;\n    int64_t phys_tid_22166;\n    int32_t chunk_sizze_32b_22946;\n    int64_t byte_offsets_22947;\n    int64_t warp_byte_offset_22948;\n    __local unsigned char *local_mem_22949;\n    int64_t trans_arr_len_22950;\n    int64_t phys_block_id_",
                                    "22956;\n    int64_t virtloop_bound_22957;\n    \n    local_tid_22942 = get_local_id(0);\n    tblock_sizze_22945 = get_local_size(0);\n    wave_sizze_22944 = LOCKSTEP_WIDTH;\n    block_id_22943 = get_tblock_id(0);\n    global_tid_22941 = block_id_22943 * tblock_sizze_22945 + local_tid_22942;\n    phys_tid_22166 = sext_i32_i64(global_tid_22941);\n    chunk_sizze_32b_22946 = sext_i64_i32(chunk_sizze_22890);\n    byte_offsets_22947 = segscan_tblock_sizze_22161 * (int64_t) 8;\n    warp_byte_offset_22948 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_22949 = (__local unsigned char *) local_mem_22949_backing_0;\n    trans_arr_len_22950 = chunk_sizze_22890 * segscan_tblock_sizze_22161;\n    phys_block_id_22956 = get_tblock_id(0);\n    virtloop_bound_22957 = sdiv_up64(num_virt_blocks_22891 - phys_block_id_22956, num_tblocks_22163);\n    for (int64_t virtloop_i_22958 = 0; virtloop_i_22958 < virtloop_bound_22957; virtloop_i_22958++) {\n        int64_t dynamic_id_22959;\n        int64_t block_offset_22960;\n        int64_t sgm_idx_22961;\n        int32_t boundary_22962;\n        int32_t segsizze_compact_22963;\n        int64_t private_mem_22964[chunk_sizze_22890];\n        int64_t thd_offset_22966;\n        int64_t acc_22982;\n        int64_t prefix_22992;\n        bool block_new_sgm_22993;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_22942 == 0) {\n                dynamic_id_22959 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_22919)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_22949)[(int64_t) 0] = dynamic_id_22959;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_22959 == num_virt_blocks_22891 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_22919)[(int64_t)", " 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_22959 = ((__local int32_t *) local_mem_22949)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_22960 = dynamic_id_22959 * chunk_sizze_22890 * segscan_tblock_sizze_22161;\n        sgm_idx_22961 = smod64(block_offset_22960, mz2080U_17317);\n        boundary_22962 = sext_i64_i32(smin64(chunk_sizze_22890 * segscan_tblock_sizze_22161, mz2080U_17317 - sgm_idx_22961));\n        segsizze_compact_22963 = sext_i64_i32(smin64(chunk_sizze_22890 * segscan_tblock_sizze_22161, mz2080U_17317));\n        thd_offset_22966 = block_offset_22960 + sext_i32_i64(local_tid_22942);\n        // Load and map\n        {\n            for (int64_t i_22967 = 0; i_22967 < chunk_sizze_22890; i_22967++) {\n                int64_t virt_tid_22968 = thd_offset_22966 + i_22967 * segscan_tblock_sizze_22161;\n                int64_t slice_22969 = mz2080U_17317;\n                int64_t gtid_22165 = virt_tid_22968;\n                int64_t remnant_22970 = virt_tid_22968 - gtid_22165;\n                \n                if (slt64(virt_tid_22968, mz2080U_17317)) {\n                    int32_t eta_p_21604 = ((__global int32_t *) shp_mem_22767)[gtid_22165];\n                    int64_t i32_res_21605 = sext_i32_i64(eta_p_21604);\n                    \n                    private_mem_22964[i_22967] = i32_res_21605;\n                } else {\n                    private_mem_22964[i_22967] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_22971 = 0; i_22971 < chunk_sizze_22890; i_22971++) {\n                int64_t sharedIdx_22972 = sext_i32_i64(local_tid_22942) + i_22971 * segscan_tblock_sizze_22161;\n                int64_t tmp_22973 = private_mem_22964[i_22971];\n                \n                ((__local int64_t *) local_mem_22949)[sharedIdx_22972] = tmp_22973;\n       ", "     }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_22974 = 0; i_22974 < chunk_sizze_22890; i_22974++) {\n                int64_t sharedIdx_22975 = sext_i32_i64(local_tid_22942) * chunk_sizze_22890 + i_22974;\n                int64_t tmp_22976 = ((__local int64_t *) local_mem_22949)[sharedIdx_22975];\n                \n                private_mem_22964[i_22974] = tmp_22976;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_22977 = 0; i_22977 < chunk_sizze_22890 - (int64_t) 1; i_22977++) {\n                int64_t eta_p_21341;\n                int64_t eta_p_21342;\n                \n                eta_p_21341 = private_mem_22964[i_22977];\n                eta_p_21342 = private_mem_22964[i_22977 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_21343 = add64(eta_p_21341, eta_p_21342);\n                \n                private_mem_22964[i_22977 + (int64_t) 1] = defunc_0_op_res_21343;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_22978 = private_mem_22964[chunk_sizze_22890 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)] = tmp_22978;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_22979;\n            int64_t eta_p_22980;\n            int64_t eta_p_22983;\n            int64_t eta_p_22984;\n            bool ltid_in_bounds_22986 = slt64(sext_i32_i64(local_tid_22942), num_virt_threads_22892);\n            int32_t skip_threads_22987;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_22986) {\n                    eta_p_22980 = ((volatile __local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)];\n                    if ((local_tid_22942 - squot32(local_tid_22942, 32) * 32) == 0) {\n                        eta_",
                                    "p_22979 = eta_p_22980;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_22987 = 1;\n                while (slt32(skip_threads_22987, 32)) {\n                    bool thread_active_22988 = sle32(skip_threads_22987, local_tid_22942 - squot32(local_tid_22942, 32) * 32) && ltid_in_bounds_22986;\n                    \n                    if (thread_active_22988) {\n                        // read operands\n                        {\n                            eta_p_22979 = ((volatile __local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942) - sext_i32_i64(skip_threads_22987)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_22988) {\n                            int64_t defunc_0_op_res_22981 = add64(eta_p_22979, eta_p_22980);\n                            \n                            eta_p_22979 = defunc_0_op_res_22981;\n                        }\n                    }\n                    if (sle32(wave_sizze_22944, skip_threads_22987)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_22988) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)] = eta_p_22979;\n                            eta_p_22980 = eta_p_22979;\n                        }\n                    }\n                    if (sle32(wave_sizze_22944, skip_threads_22987)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_22987 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_22942 - squot32(local_tid_22942, 32) * 32) == 3", "1 && ltid_in_bounds_22986) {\n                    ((volatile __local int64_t *) local_mem_22949)[sext_i32_i64(squot32(local_tid_22942, 32))] = eta_p_22979;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_22989;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_22942, 32) == 0 && ltid_in_bounds_22986) {\n                        eta_p_22984 = ((volatile __local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)];\n                        if ((local_tid_22942 - squot32(local_tid_22942, 32) * 32) == 0) {\n                            eta_p_22983 = eta_p_22984;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_22989 = 1;\n                    while (slt32(skip_threads_22989, 32)) {\n                        bool thread_active_22990 = sle32(skip_threads_22989, local_tid_22942 - squot32(local_tid_22942, 32) * 32) && (squot32(local_tid_22942, 32) == 0 && ltid_in_bounds_22986);\n                        \n                        if (thread_active_22990) {\n                            // read operands\n                            {\n                                eta_p_22983 = ((volatile __local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942) - sext_i32_i64(skip_threads_22989)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_22990) {\n                                int64_t defunc_0_op_res_22985 = add64(eta_p_22983, eta_p_22984);\n                                \n                                eta_p_22983 = defunc_0_op_res_22985;\n                            }\n                     ", "   }\n                        if (sle32(wave_sizze_22944, skip_threads_22989)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_22990) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)] = eta_p_22983;\n                                eta_p_22984 = eta_p_22983;\n                            }\n                        }\n                        if (sle32(wave_sizze_22944, skip_threads_22989)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_22989 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_22991 = squot32(local_tid_22942, 32) == 0 || !ltid_in_bounds_22986;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_22991) {\n                        eta_p_22980 = eta_p_22979;\n                        eta_p_22979 = ((__local int64_t *) local_mem_22949)[sext_i32_i64(squot32(local_tid_22942, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_22991) {\n                        int64_t defunc_0_op_res_22981 = add64(eta_p_22979, eta_p_22980);\n                        \n                        eta_p_22979 = defunc_0_op_res_22981;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_22991) {\n                        ((__local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)] = eta_p_22979;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore corre",
                                    "ct values for first block\n            {\n                if (squot32(local_tid_22942, 32) == 0 && ltid_in_bounds_22986) {\n                    ((__local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)] = eta_p_22980;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_22942 == 0) {\n                acc_22982 = ((__local int64_t *) local_mem_22949)[segscan_tblock_sizze_22161 - (int64_t) 1];\n            } else {\n                acc_22982 = ((__local int64_t *) local_mem_22949)[sext_i32_i64(local_tid_22942) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_22992 = (int64_t) 0;\n        block_new_sgm_22993 = sgm_idx_22961 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_22993 && local_tid_22942 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_22917)[dynamic_id_22959] = acc_22982;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_22893)[dynamic_id_22959] = (int8_t) 2;\n                acc_22982 = (int64_t) 0;\n            }\n            if (!block_new_sgm_22993 && slt32(local_tid_22942, wave_sizze_22944)) {\n                if (local_tid_22942 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_22915)[dynamic_id_22959] = acc_22982;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_22893)[dynamic_id_22959] = (int8_t) 1;\n                    \n                    int8_t tmp_22994 = ((volatile __global int8_t *) status_flags_mem_22893)[dynamic_id_22959 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_22949)[(int64_t) 0] = tmp_22994;\n                }\n                mem_fence_local();\n                \n                int8_t status_22995 = ((__local int8_t *) local_mem_22949)[(int64_t) 0];\n                \n      ", "          if (status_22995 == (int8_t) 2) {\n                    if (local_tid_22942 == 0) {\n                        prefix_22992 = ((volatile __global int64_t *) incprefixes_mem_22917)[dynamic_id_22959 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_22996 = sext_i64_i32(dynamic_id_22959 - sext_i32_i64(wave_sizze_22944));\n                    \n                    while (slt32(wave_sizze_22944 * -1, readOffset_22996)) {\n                        int32_t read_i_22997 = readOffset_22996 + local_tid_22942;\n                        int64_t aggr_22998 = (int64_t) 0;\n                        int8_t flag_22999 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_22997)) {\n                            flag_22999 = ((volatile __global int8_t *) status_flags_mem_22893)[sext_i32_i64(read_i_22997)];\n                            if (flag_22999 == (int8_t) 2) {\n                                aggr_22998 = ((volatile __global int64_t *) incprefixes_mem_22917)[sext_i32_i64(read_i_22997)];\n                            } else if (flag_22999 == (int8_t) 1) {\n                                aggr_22998 = ((volatile __global int64_t *) aggregates_mem_22915)[sext_i32_i64(read_i_22997)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_22949)[(int64_t) 4 + sext_i32_i64(local_tid_22942)] = aggr_22998;\n                        ((__local int8_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)] = flag_22999;\n                        flag_22999 = ((__local int8_t *) local_mem_22949)[sext_i32_i64(wave_sizze_22944) - (int64_t) 1];\n                        if (slt8(flag_22999, (int8_t) 2)) {\n                            int8_t flg_x_23003;\n                            int8_t flg_y_23004;\n                            int64_t eta_p_23000;\n                            int64_t eta_p_23001;\n                            int32_t skip_threads_23005;\n                            \n", "                            // read input for in-block scan\n                            {\n                                flg_y_23004 = ((volatile __local int8_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)];\n                                eta_p_23001 = ((volatile __local int64_t *) local_mem_22949)[(int64_t) 4 + sext_i32_i64(local_tid_22942)];\n                                if ((local_tid_22942 - squot32(local_tid_22942, 32) * 32) == 0) {\n                                    eta_p_23000 = eta_p_23001;\n                                    flg_x_23003 = flg_y_23004;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23005 = 1;\n                                while (slt32(skip_threads_23005, 32)) {\n                                    if (sle32(skip_threads_23005, local_tid_22942 - squot32(local_tid_22942, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23003 = ((volatile __local int8_t *) local_mem_22949)[sext_i32_i64(local_tid_22942) - sext_i32_i64(skip_threads_23005)];\n                                            eta_p_23000 = ((volatile __local int64_t *) local_mem_22949)[(int64_t) 4 + (sext_i32_i64(local_tid_22942) - sext_i32_i64(skip_threads_23005))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23004 == (int8_t) 2 || flg_y_23004 == (int8_t) 0) {\n                                                flg_x_23003 = flg_y_23004;\n                                                eta_p_23000 = eta_p_23001;\n                                            } else {\n                                                int64_t defunc_0_op_res_23002 = add64(eta_p",
                                    "_23000, eta_p_23001);\n                                                \n                                                eta_p_23000 = defunc_0_op_res_23002;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_22949)[sext_i32_i64(local_tid_22942)] = flg_x_23003;\n                                            flg_y_23004 = flg_x_23003;\n                                            ((volatile __local int64_t *) local_mem_22949)[(int64_t) 4 + sext_i32_i64(local_tid_22942)] = eta_p_23000;\n                                            eta_p_23001 = eta_p_23000;\n                                        }\n                                    }\n                                    skip_threads_23005 *= 2;\n                                }\n                            }\n                        }\n                        flag_22999 = ((__local int8_t *) local_mem_22949)[sext_i32_i64(wave_sizze_22944) - (int64_t) 1];\n                        aggr_22998 = ((__local int64_t *) local_mem_22949)[(int64_t) 4 + (sext_i32_i64(wave_sizze_22944) - (int64_t) 1)];\n                        if (flag_22999 == (int8_t) 2) {\n                            readOffset_22996 = wave_sizze_22944 * -1;\n                        } else if (flag_22999 == (int8_t) 1) {\n                            readOffset_22996 -= wave_sizze_22944;\n                        }\n                        if (slt8((int8_t) 0, flag_22999)) {\n                            int64_t eta_p_23006 = aggr_22998;\n                            int64_t eta_p_23007 = prefix_22992;\n                            int64_t defunc_0_op_res_23008 = add64(eta_p_23006, eta_p_23007);\n                            \n                            prefix_22992 = defunc_0_op_res_23008;\n                        }\n                        mem_fence_local();\n               ", "     }\n                }\n                if (local_tid_22942 == 0) {\n                    if (boundary_22962 == sext_i64_i32(segscan_tblock_sizze_22161 * chunk_sizze_22890)) {\n                        int64_t eta_p_23009 = prefix_22992;\n                        int64_t eta_p_23010 = acc_22982;\n                        int64_t defunc_0_op_res_23011 = add64(eta_p_23009, eta_p_23010);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_22917)[dynamic_id_22959] = defunc_0_op_res_23011;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_22893)[dynamic_id_22959] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_22949)[(int64_t) 4] = prefix_22992;\n                    acc_22982 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_22959 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_22992 = ((__local int64_t *) local_mem_22949)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_23012;\n            int64_t eta_p_23013;\n            int64_t eta_p_23015 = prefix_22992;\n            int64_t eta_p_23016 = acc_22982;\n            \n            if (slt32(local_tid_22942 * chunk_sizze_32b_22946, boundary_22962) && !block_new_sgm_22993) {\n                int64_t defunc_0_op_res_23017 = add64(eta_p_23015, eta_p_23016);\n                \n                eta_p_23012 = defunc_0_op_res_23017;\n            } else {\n                eta_p_23012 = acc_22982;\n            }\n            \n            int32_t stopping_point_23018 = segsizze_compact_22963 - srem32(local_tid_22942 * chunk_sizze_32b_22946 - 1 + segsizze_compact_22963 - boundary_22962, segsizze_compact_22963);\n            \n            for (int64_t i_23019 = 0; i_23019 < chunk_sizze_22890; i_23019++) {\n                if (slt32(sext_i64_i32(i_2", "3019), stopping_point_23018 - 1)) {\n                    eta_p_23013 = private_mem_22964[i_23019];\n                    \n                    int64_t defunc_0_op_res_23014 = add64(eta_p_23012, eta_p_23013);\n                    \n                    private_mem_22964[i_23019] = defunc_0_op_res_23014;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23020 = 0; i_23020 < chunk_sizze_22890; i_23020++) {\n                int64_t sharedIdx_23021 = sext_i32_i64(local_tid_22942) * chunk_sizze_22890 + i_23020;\n                int64_t tmp_23022 = private_mem_22964[i_23020];\n                \n                ((__local int64_t *) local_mem_22949)[sharedIdx_23021] = tmp_23022;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23023 = 0; i_23023 < chunk_sizze_22890; i_23023++) {\n                int64_t flat_idx_23024 = thd_offset_22966 + i_23023 * segscan_tblock_sizze_22161;\n                int64_t slice_23025 = mz2080U_17317;\n                int64_t gtid_22165 = flat_idx_23024;\n                int64_t remnant_23026 = flat_idx_23024 - gtid_22165;\n                \n                if (slt64(flat_idx_23024, mz2080U_17317)) {\n                    int64_t tmp_23027 = ((__local int64_t *) local_mem_22949)[flat_idx_23024 - block_offset_22960];\n                    \n                    ((__global int64_t *) mem_22772)[gtid_22165] = tmp_23027;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22161\n    #undef chunk_sizze_22890\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegscan_22182_dim1, 1, 1)\nvoid human_regularzisegscan_22182(__global int *global_failure, int64_t nz2081U_17318, int64_t num_tblocks_22179, int64_t num_virt_blocks_23068, int64_t num_virt_threads_23069, __global unsigned char *A_mem_22769, __global unsigned char *mem_22773, __global unsigned ch",
                                    "ar *mem_22776, __global unsigned char *mem_22778, __global unsigned char *status_flags_mem_23070, __global unsigned char *aggregates_mem_23072, __global unsigned char *incprefixes_mem_23074, __global unsigned char *aggregates_mem_23076, __global unsigned char *incprefixes_mem_23078, __global unsigned char *global_dynid_mem_23080)\n{\n    #define segscan_tblock_sizze_22177 (human_regularzisegscan_22182zisegscan_tblock_sizze_22177)\n    #define chunk_sizze_23067 (human_regularzisegscan_22182zichunk_sizze_23067)\n    \n    volatile __local unsigned char *local_mem_23092_backing_0 = &shared_mem[0];\n    const int64_t local_mem_23092_backing_0_offset = 0 + (smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_22177, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_22177), smax64(chunk_sizze_23067 * segscan_tblock_sizze_22177, chunk_sizze_23067 * segscan_tblock_sizze_22177 * (int64_t) 4)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_22177, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_22177), smax64(chunk_sizze_23067 * segscan_tblock_sizze_22177, chunk_sizze_23067 * segscan_tblock_sizze_22177 * (int64_t) 4)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23083;\n    int32_t tblock_sizze_23086;\n    int32_t wave_sizze_23085;\n    int32_t block_id_23084;\n    int32_t global_tid_23082;\n    int64_t phys_tid_22182;\n    int32_t chunk_sizze_32b_23087;\n    int64_t byte_offsets_23088;\n    int64_t byte_offsets_23089;\n    int64_t warp_byte_offset_23090;\n    int64_t warp_byte_offset_23091;\n    __local unsigned char *local_mem_23092;\n    int64_t trans_arr_len_23093;\n    int64_t phys_block_id_23102;\n    int64_t virtloop_bound_23103;\n    \n    local_tid_23083 = get_local_id(0);\n    tblock_sizze_23086 = get_local_size(0);\n    wave_sizze_23085 = LOCKSTEP_WIDTH;\n    block_id_23084 = get_tblock_id(0);\n    global_tid_23082 = block_id_23084 * tblock_sizze_2308", "6 + local_tid_23083;\n    phys_tid_22182 = sext_i32_i64(global_tid_23082);\n    chunk_sizze_32b_23087 = sext_i64_i32(chunk_sizze_23067);\n    byte_offsets_23088 = segscan_tblock_sizze_22177;\n    byte_offsets_23089 = sdiv_up64(byte_offsets_23088, (int64_t) 4) * (int64_t) 4 + segscan_tblock_sizze_22177 * (int64_t) 4;\n    warp_byte_offset_23090 = (int64_t) 64;\n    warp_byte_offset_23091 = sdiv_up64(warp_byte_offset_23090, (int64_t) 4) * (int64_t) 4 + (int64_t) 128;\n    // Allocate reusable shared memory\n    { }\n    local_mem_23092 = (__local unsigned char *) local_mem_23092_backing_0;\n    trans_arr_len_23093 = chunk_sizze_23067 * segscan_tblock_sizze_22177;\n    phys_block_id_23102 = get_tblock_id(0);\n    virtloop_bound_23103 = sdiv_up64(num_virt_blocks_23068 - phys_block_id_23102, num_tblocks_22179);\n    for (int64_t virtloop_i_23104 = 0; virtloop_i_23104 < virtloop_bound_23103; virtloop_i_23104++) {\n        int64_t dynamic_id_23105;\n        int64_t block_offset_23106;\n        int64_t sgm_idx_23107;\n        int32_t boundary_23108;\n        int32_t segsizze_compact_23109;\n        bool private_mem_23110[chunk_sizze_23067];\n        float private_mem_23112[chunk_sizze_23067];\n        int64_t thd_offset_23114;\n        bool acc_23141;\n        float acc_23142;\n        bool prefix_23156;\n        float prefix_23157;\n        bool block_new_sgm_23158;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_23083 == 0) {\n                dynamic_id_23105 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_23080)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_23092)[(int64_t) 0] = dynamic_id_23105;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_23105 == num_virt_blocks_23068 - (int64_t) 1) {\n                        ((__g", "lobal int32_t *) global_dynid_mem_23080)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_23105 = ((__local int32_t *) local_mem_23092)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_23106 = dynamic_id_23105 * chunk_sizze_23067 * segscan_tblock_sizze_22177;\n        sgm_idx_23107 = smod64(block_offset_23106, nz2081U_17318);\n        boundary_23108 = sext_i64_i32(smin64(chunk_sizze_23067 * segscan_tblock_sizze_22177, nz2081U_17318 - sgm_idx_23107));\n        segsizze_compact_23109 = sext_i64_i32(smin64(chunk_sizze_23067 * segscan_tblock_sizze_22177, nz2081U_17318));\n        thd_offset_23114 = block_offset_23106 + sext_i32_i64(local_tid_23083);\n        // Load and map\n        {\n            for (int64_t i_23115 = 0; i_23115 < chunk_sizze_23067; i_23115++) {\n                int64_t virt_tid_23116 = thd_offset_23114 + i_23115 * segscan_tblock_sizze_22177;\n                int64_t slice_23117 = nz2081U_17318;\n                int64_t gtid_22181 = virt_tid_23116;\n                int64_t remnant_23118 = virt_tid_23116 - gtid_22181;\n                \n                if (slt64(virt_tid_23116, nz2081U_17318)) {\n                    bool x_20992 = ((__global bool *) mem_22773)[gtid_22181];\n                    float x_20993 = ((__global float *) A_mem_22769)[gtid_22181];\n                    \n                    private_mem_23110[i_23115] = x_20992;\n                    private_mem_23112[i_23115] = x_20993;\n                } else {\n                    private_mem_23110[i_23115] = 0;\n                    private_mem_23112[i_23115] = 0.0F;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_23119 = 0; i_23119 < chunk_sizze_23067; i_23119++) {\n                int64_t sharedIdx_23120 = sext_i32_i64(local_tid_23083) + i_23119 * segscan_tblock_sizze_22177;\n                bool tmp_231",
                                    "21 = private_mem_23110[i_23119];\n                \n                ((__local bool *) local_mem_23092)[sharedIdx_23120] = tmp_23121;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23122 = 0; i_23122 < chunk_sizze_23067; i_23122++) {\n                int64_t sharedIdx_23123 = sext_i32_i64(local_tid_23083) * chunk_sizze_23067 + i_23122;\n                bool tmp_23124 = ((__local bool *) local_mem_23092)[sharedIdx_23123];\n                \n                private_mem_23110[i_23122] = tmp_23124;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23125 = 0; i_23125 < chunk_sizze_23067; i_23125++) {\n                int64_t sharedIdx_23126 = sext_i32_i64(local_tid_23083) + i_23125 * segscan_tblock_sizze_22177;\n                float tmp_23127 = private_mem_23112[i_23125];\n                \n                ((__local float *) local_mem_23092)[sharedIdx_23126] = tmp_23127;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23128 = 0; i_23128 < chunk_sizze_23067; i_23128++) {\n                int64_t sharedIdx_23129 = sext_i32_i64(local_tid_23083) * chunk_sizze_23067 + i_23128;\n                float tmp_23130 = ((__local float *) local_mem_23092)[sharedIdx_23129];\n                \n                private_mem_23112[i_23128] = tmp_23130;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_23131 = 0; i_23131 < chunk_sizze_23067 - (int64_t) 1; i_23131++) {\n                bool eta_p_20985;\n                bool eta_p_20987;\n                \n                eta_p_20985 = private_mem_23110[i_23131];\n                eta_p_20987 = private_mem_23110[i_23131 + (int64_t) 1];\n                \n                float eta_p_20986;\n                float eta_p_20988;\n                \n                eta_p_20986 = private_mem_23112[i_23131];\n                eta_p_20988 = private_mem_23112[i_23131 + (int64_t) 1];\n                ", "\n                bool tmp_20989 = eta_p_20985 || eta_p_20987;\n                float tmp_20990;\n                \n                if (eta_p_20987) {\n                    tmp_20990 = eta_p_20988;\n                } else {\n                    float defunc_0_op_res_20991 = eta_p_20986 + eta_p_20988;\n                    \n                    tmp_20990 = defunc_0_op_res_20991;\n                }\n                private_mem_23110[i_23131 + (int64_t) 1] = tmp_20989;\n                private_mem_23112[i_23131 + (int64_t) 1] = tmp_20990;\n            }\n        }\n        // Publish results in shared memory\n        {\n            bool tmp_23132 = private_mem_23110[chunk_sizze_23067 - (int64_t) 1];\n            \n            ((__local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083)] = tmp_23132;\n            \n            float tmp_23133 = private_mem_23112[chunk_sizze_23067 - (int64_t) 1];\n            \n            ((__local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + sext_i32_i64(local_tid_23083)] = tmp_23133;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            bool eta_p_23134;\n            float eta_p_23135;\n            bool eta_p_23136;\n            float eta_p_23137;\n            bool eta_p_23143;\n            float eta_p_23144;\n            bool eta_p_23145;\n            float eta_p_23146;\n            bool ltid_in_bounds_23150 = slt64(sext_i32_i64(local_tid_23083), num_virt_threads_23069);\n            int32_t skip_threads_23151;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23150) {\n                    eta_p_23136 = ((volatile __local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083)];\n                    eta_p_23137 = ((volatile __local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + sext_i32_i64(local_tid_23083)];\n                    if ((local_tid_23083 - squot32(local_tid_23083, 32) * 32) == 0) {\n            ", "            eta_p_23134 = eta_p_23136;\n                        eta_p_23135 = eta_p_23137;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23151 = 1;\n                while (slt32(skip_threads_23151, 32)) {\n                    bool thread_active_23152 = sle32(skip_threads_23151, local_tid_23083 - squot32(local_tid_23083, 32) * 32) && ltid_in_bounds_23150;\n                    \n                    if (thread_active_23152) {\n                        // read operands\n                        {\n                            eta_p_23134 = ((volatile __local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083) - sext_i32_i64(skip_threads_23151)];\n                            eta_p_23135 = ((volatile __local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + (sext_i32_i64(local_tid_23083) - sext_i32_i64(skip_threads_23151))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23152) {\n                            bool tmp_23138 = eta_p_23134 || eta_p_23136;\n                            float tmp_23139;\n                            \n                            if (eta_p_23136) {\n                                tmp_23139 = eta_p_23137;\n                            } else {\n                                float defunc_0_op_res_23140 = eta_p_23135 + eta_p_23137;\n                                \n                                tmp_23139 = defunc_0_op_res_23140;\n                            }\n                            eta_p_23134 = tmp_23138;\n                            eta_p_23135 = tmp_23139;\n                        }\n                    }\n                    if (sle32(wave_sizze_23085, skip_threads_23151)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23152) {\n                        // writ",
                                    "e result\n                        {\n                            ((volatile __local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083)] = eta_p_23134;\n                            eta_p_23136 = eta_p_23134;\n                            ((volatile __local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + sext_i32_i64(local_tid_23083)] = eta_p_23135;\n                            eta_p_23137 = eta_p_23135;\n                        }\n                    }\n                    if (sle32(wave_sizze_23085, skip_threads_23151)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23151 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_23083 - squot32(local_tid_23083, 32) * 32) == 31 && ltid_in_bounds_23150) {\n                    ((volatile __local bool *) local_mem_23092)[sext_i32_i64(squot32(local_tid_23083, 32))] = eta_p_23134;\n                    ((volatile __local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + sext_i32_i64(squot32(local_tid_23083, 32))] = eta_p_23135;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23153;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_23083, 32) == 0 && ltid_in_bounds_23150) {\n                        eta_p_23145 = ((volatile __local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083)];\n                        eta_p_23146 = ((volatile __local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + sext_i32_i64(local_tid_23083)];\n                        if ((local_tid_23083 - squot32(local_tid_23083, 32) * 32) == 0) {\n                      ", "      eta_p_23143 = eta_p_23145;\n                            eta_p_23144 = eta_p_23146;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23153 = 1;\n                    while (slt32(skip_threads_23153, 32)) {\n                        bool thread_active_23154 = sle32(skip_threads_23153, local_tid_23083 - squot32(local_tid_23083, 32) * 32) && (squot32(local_tid_23083, 32) == 0 && ltid_in_bounds_23150);\n                        \n                        if (thread_active_23154) {\n                            // read operands\n                            {\n                                eta_p_23143 = ((volatile __local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083) - sext_i32_i64(skip_threads_23153)];\n                                eta_p_23144 = ((volatile __local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + (sext_i32_i64(local_tid_23083) - sext_i32_i64(skip_threads_23153))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_23154) {\n                                bool tmp_23147 = eta_p_23143 || eta_p_23145;\n                                float tmp_23148;\n                                \n                                if (eta_p_23145) {\n                                    tmp_23148 = eta_p_23146;\n                                } else {\n                                    float defunc_0_op_res_23149 = eta_p_23144 + eta_p_23146;\n                                    \n                                    tmp_23148 = defunc_0_op_res_23149;\n                                }\n                                eta_p_23143 = tmp_23147;\n                                eta_p_23144 = tmp_23148;\n                            }\n                        }\n                        if (sle32(wave_sizze_23085, skip", "_threads_23153)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23154) {\n                            // write result\n                            {\n                                ((volatile __local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083)] = eta_p_23143;\n                                eta_p_23145 = eta_p_23143;\n                                ((volatile __local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + sext_i32_i64(local_tid_23083)] = eta_p_23144;\n                                eta_p_23146 = eta_p_23144;\n                            }\n                        }\n                        if (sle32(wave_sizze_23085, skip_threads_23153)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23153 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23155 = squot32(local_tid_23083, 32) == 0 || !ltid_in_bounds_23150;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23155) {\n                        eta_p_23136 = eta_p_23134;\n                        eta_p_23137 = eta_p_23135;\n                        eta_p_23134 = ((__local bool *) local_mem_23092)[sext_i32_i64(squot32(local_tid_23083, 32)) - (int64_t) 1];\n                        eta_p_23135 = ((__local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + (sext_i32_i64(squot32(local_tid_23083, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23155) {\n                        bool tmp_23138 = eta_p_23134 || eta_p_23136;\n                        float tmp_23139;\n                        \n                        if ",
                                    "(eta_p_23136) {\n                            tmp_23139 = eta_p_23137;\n                        } else {\n                            float defunc_0_op_res_23140 = eta_p_23135 + eta_p_23137;\n                            \n                            tmp_23139 = defunc_0_op_res_23140;\n                        }\n                        eta_p_23134 = tmp_23138;\n                        eta_p_23135 = tmp_23139;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_23155) {\n                        ((__local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083)] = eta_p_23134;\n                        ((__local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + sext_i32_i64(local_tid_23083)] = eta_p_23135;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_23083, 32) == 0 && ltid_in_bounds_23150) {\n                    ((__local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083)] = eta_p_23136;\n                    ((__local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + sext_i32_i64(local_tid_23083)] = eta_p_23137;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_23083 == 0) {\n                acc_23141 = ((__local bool *) local_mem_23092)[segscan_tblock_sizze_22177 - (int64_t) 1];\n                acc_23142 = ((__local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + (segscan_tblock_sizze_22177 - (int64_t) 1)];\n            } else {\n                acc_23141 = ((__local bool *) local_mem_23092)[sext_i32_i64(local_tid_23083) - (int64_t) 1];\n                acc_23142 = ((__local float *) local_mem_23092)[squot64(byte_offsets_23088, (int64_t) 4) + (sext_i32_i64(local_tid_23083) - (int64_t) 1)];\n           ", " }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23156 = 0;\n        prefix_23157 = 0.0F;\n        block_new_sgm_23158 = sgm_idx_23107 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23158 && local_tid_23083 == 0) {\n                ((volatile __global bool *) incprefixes_mem_23074)[dynamic_id_23105] = acc_23141;\n                ((volatile __global float *) incprefixes_mem_23078)[dynamic_id_23105] = acc_23142;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23070)[dynamic_id_23105] = (int8_t) 2;\n                acc_23141 = 0;\n                acc_23142 = 0.0F;\n            }\n            if (!block_new_sgm_23158 && slt32(local_tid_23083, wave_sizze_23085)) {\n                if (local_tid_23083 == 0) {\n                    ((volatile __global bool *) aggregates_mem_23072)[dynamic_id_23105] = acc_23141;\n                    ((volatile __global float *) aggregates_mem_23076)[dynamic_id_23105] = acc_23142;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23070)[dynamic_id_23105] = (int8_t) 1;\n                    \n                    int8_t tmp_23159 = ((volatile __global int8_t *) status_flags_mem_23070)[dynamic_id_23105 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_23092)[(int64_t) 0] = tmp_23159;\n                }\n                mem_fence_local();\n                \n                int8_t status_23160 = ((__local int8_t *) local_mem_23092)[(int64_t) 0];\n                \n                if (status_23160 == (int8_t) 2) {\n                    if (local_tid_23083 == 0) {\n                        prefix_23156 = ((volatile __global bool *) incprefixes_mem_23074)[dynamic_id_23105 - (int64_t) 1];\n                        prefix_23157 = ((volatile __global float *) incprefixes_mem_23078)[dynamic_id_23105 - (int64_t) 1];\n                    }\n                } else {\n          ", "          int32_t readOffset_23161 = sext_i64_i32(dynamic_id_23105 - sext_i32_i64(wave_sizze_23085));\n                    \n                    while (slt32(wave_sizze_23085 * -1, readOffset_23161)) {\n                        int32_t read_i_23162 = readOffset_23161 + local_tid_23083;\n                        bool aggr_23163 = 0;\n                        float aggr_23164 = 0.0F;\n                        int8_t flag_23165 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23162)) {\n                            flag_23165 = ((volatile __global int8_t *) status_flags_mem_23070)[sext_i32_i64(read_i_23162)];\n                            if (flag_23165 == (int8_t) 2) {\n                                aggr_23163 = ((volatile __global bool *) incprefixes_mem_23074)[sext_i32_i64(read_i_23162)];\n                                aggr_23164 = ((volatile __global float *) incprefixes_mem_23078)[sext_i32_i64(read_i_23162)];\n                            } else if (flag_23165 == (int8_t) 1) {\n                                aggr_23163 = ((volatile __global bool *) aggregates_mem_23072)[sext_i32_i64(read_i_23162)];\n                                aggr_23164 = ((volatile __global float *) aggregates_mem_23076)[sext_i32_i64(read_i_23162)];\n                            }\n                        }\n                        ((__local bool *) local_mem_23092)[(int64_t) 32 + sext_i32_i64(local_tid_23083)] = aggr_23163;\n                        ((__local float *) local_mem_23092)[squot64(warp_byte_offset_23090, (int64_t) 4) + sext_i32_i64(local_tid_23083)] = aggr_23164;\n                        ((__local int8_t *) local_mem_23092)[sext_i32_i64(local_tid_23083)] = flag_23165;\n                        flag_23165 = ((__local int8_t *) local_mem_23092)[sext_i32_i64(wave_sizze_23085) - (int64_t) 1];\n                        if (slt8(flag_23165, (int8_t) 2)) {\n                            int8_t flg_x_23173;\n                            int8_t flg_y_23174;\n                           ",
                                    " bool eta_p_23166;\n                            float eta_p_23167;\n                            bool eta_p_23168;\n                            float eta_p_23169;\n                            int32_t skip_threads_23175;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23174 = ((volatile __local int8_t *) local_mem_23092)[sext_i32_i64(local_tid_23083)];\n                                eta_p_23168 = ((volatile __local bool *) local_mem_23092)[(int64_t) 32 + sext_i32_i64(local_tid_23083)];\n                                eta_p_23169 = ((volatile __local float *) local_mem_23092)[squot64(warp_byte_offset_23090, (int64_t) 4) + sext_i32_i64(local_tid_23083)];\n                                if ((local_tid_23083 - squot32(local_tid_23083, 32) * 32) == 0) {\n                                    eta_p_23166 = eta_p_23168;\n                                    eta_p_23167 = eta_p_23169;\n                                    flg_x_23173 = flg_y_23174;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23175 = 1;\n                                while (slt32(skip_threads_23175, 32)) {\n                                    if (sle32(skip_threads_23175, local_tid_23083 - squot32(local_tid_23083, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23173 = ((volatile __local int8_t *) local_mem_23092)[sext_i32_i64(local_tid_23083) - sext_i32_i64(skip_threads_23175)];\n                                            eta_p_23166 = ((volatile __local bool *) local_mem_23092)[(int64_t) 32 + (sext_i32_i64(local_tid_23083) - sext_i32_i64(skip_threads_23175))];\n                                            eta_p_23167 = ((volatile __l", "ocal float *) local_mem_23092)[squot64(warp_byte_offset_23090, (int64_t) 4) + (sext_i32_i64(local_tid_23083) - sext_i32_i64(skip_threads_23175))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23174 == (int8_t) 2 || flg_y_23174 == (int8_t) 0) {\n                                                flg_x_23173 = flg_y_23174;\n                                                eta_p_23166 = eta_p_23168;\n                                                eta_p_23167 = eta_p_23169;\n                                            } else {\n                                                bool tmp_23170 = eta_p_23166 || eta_p_23168;\n                                                float tmp_23171;\n                                                \n                                                if (eta_p_23168) {\n                                                    tmp_23171 = eta_p_23169;\n                                                } else {\n                                                    float defunc_0_op_res_23172 = eta_p_23167 + eta_p_23169;\n                                                    \n                                                    tmp_23171 = defunc_0_op_res_23172;\n                                                }\n                                                eta_p_23166 = tmp_23170;\n                                                eta_p_23167 = tmp_23171;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_23092)[sext_i32_i64(local_tid_23083)] = flg_x_23173;\n                                            flg_y_23174 = flg_x_23173;\n                                            ((volatile __local bool *) local_m", "em_23092)[(int64_t) 32 + sext_i32_i64(local_tid_23083)] = eta_p_23166;\n                                            eta_p_23168 = eta_p_23166;\n                                            ((volatile __local float *) local_mem_23092)[squot64(warp_byte_offset_23090, (int64_t) 4) + sext_i32_i64(local_tid_23083)] = eta_p_23167;\n                                            eta_p_23169 = eta_p_23167;\n                                        }\n                                    }\n                                    skip_threads_23175 *= 2;\n                                }\n                            }\n                        }\n                        flag_23165 = ((__local int8_t *) local_mem_23092)[sext_i32_i64(wave_sizze_23085) - (int64_t) 1];\n                        aggr_23163 = ((__local bool *) local_mem_23092)[(int64_t) 32 + (sext_i32_i64(wave_sizze_23085) - (int64_t) 1)];\n                        aggr_23164 = ((__local float *) local_mem_23092)[squot64(warp_byte_offset_23090, (int64_t) 4) + (sext_i32_i64(wave_sizze_23085) - (int64_t) 1)];\n                        if (flag_23165 == (int8_t) 2) {\n                            readOffset_23161 = wave_sizze_23085 * -1;\n                        } else if (flag_23165 == (int8_t) 1) {\n                            readOffset_23161 -= wave_sizze_23085;\n                        }\n                        if (slt8((int8_t) 0, flag_23165)) {\n                            bool eta_p_23176 = aggr_23163;\n                            float eta_p_23177 = aggr_23164;\n                            bool eta_p_23178 = prefix_23156;\n                            float eta_p_23179 = prefix_23157;\n                            bool tmp_23180 = eta_p_23176 || eta_p_23178;\n                            float tmp_23181;\n                            \n                            if (eta_p_23178) {\n                                tmp_23181 = eta_p_23179;\n                            } else {\n                                float defunc_0_op_res_23182 = eta_p_23177 + e",
                                    "ta_p_23179;\n                                \n                                tmp_23181 = defunc_0_op_res_23182;\n                            }\n                            prefix_23156 = tmp_23180;\n                            prefix_23157 = tmp_23181;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_23083 == 0) {\n                    if (boundary_23108 == sext_i64_i32(segscan_tblock_sizze_22177 * chunk_sizze_23067)) {\n                        bool eta_p_23183 = prefix_23156;\n                        float eta_p_23184 = prefix_23157;\n                        bool eta_p_23185 = acc_23141;\n                        float eta_p_23186 = acc_23142;\n                        bool tmp_23187 = eta_p_23183 || eta_p_23185;\n                        float tmp_23188;\n                        \n                        if (eta_p_23185) {\n                            tmp_23188 = eta_p_23186;\n                        } else {\n                            float defunc_0_op_res_23189 = eta_p_23184 + eta_p_23186;\n                            \n                            tmp_23188 = defunc_0_op_res_23189;\n                        }\n                        ((volatile __global bool *) incprefixes_mem_23074)[dynamic_id_23105] = tmp_23187;\n                        ((volatile __global float *) incprefixes_mem_23078)[dynamic_id_23105] = tmp_23188;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23070)[dynamic_id_23105] = (int8_t) 2;\n                    }\n                    ((__local bool *) local_mem_23092)[(int64_t) 32] = prefix_23156;\n                    ((__local float *) local_mem_23092)[squot64(warp_byte_offset_23090, (int64_t) 4)] = prefix_23157;\n                    acc_23141 = 0;\n                    acc_23142 = 0.0F;\n                }\n            }\n            if (!(dynamic_id_23105 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n   ", "             prefix_23156 = ((__local bool *) local_mem_23092)[(int64_t) 32];\n                prefix_23157 = ((__local float *) local_mem_23092)[squot64(warp_byte_offset_23090, (int64_t) 4)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            bool eta_p_23190;\n            bool eta_p_23192;\n            bool eta_p_23197 = prefix_23156;\n            bool eta_p_23199 = acc_23141;\n            float eta_p_23191;\n            float eta_p_23193;\n            float eta_p_23198 = prefix_23157;\n            float eta_p_23200 = acc_23142;\n            \n            if (slt32(local_tid_23083 * chunk_sizze_32b_23087, boundary_23108) && !block_new_sgm_23158) {\n                bool tmp_23201 = eta_p_23197 || eta_p_23199;\n                float tmp_23202;\n                \n                if (eta_p_23199) {\n                    tmp_23202 = eta_p_23200;\n                } else {\n                    float defunc_0_op_res_23203 = eta_p_23198 + eta_p_23200;\n                    \n                    tmp_23202 = defunc_0_op_res_23203;\n                }\n                eta_p_23190 = tmp_23201;\n                eta_p_23191 = tmp_23202;\n            } else {\n                eta_p_23190 = acc_23141;\n                eta_p_23191 = acc_23142;\n            }\n            \n            int32_t stopping_point_23204 = segsizze_compact_23109 - srem32(local_tid_23083 * chunk_sizze_32b_23087 - 1 + segsizze_compact_23109 - boundary_23108, segsizze_compact_23109);\n            \n            for (int64_t i_23205 = 0; i_23205 < chunk_sizze_23067; i_23205++) {\n                if (slt32(sext_i64_i32(i_23205), stopping_point_23204 - 1)) {\n                    eta_p_23192 = private_mem_23110[i_23205];\n                    eta_p_23193 = private_mem_23112[i_23205];\n                    \n                    bool tmp_23194 = eta_p_23190 || eta_p_23192;\n                    float tmp_23195;\n                    \n                    if (eta_p_23192) {\n                 ", "       tmp_23195 = eta_p_23193;\n                    } else {\n                        float defunc_0_op_res_23196 = eta_p_23191 + eta_p_23193;\n                        \n                        tmp_23195 = defunc_0_op_res_23196;\n                    }\n                    private_mem_23110[i_23205] = tmp_23194;\n                    private_mem_23112[i_23205] = tmp_23195;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23206 = 0; i_23206 < chunk_sizze_23067; i_23206++) {\n                int64_t sharedIdx_23207 = sext_i32_i64(local_tid_23083) * chunk_sizze_23067 + i_23206;\n                bool tmp_23208 = private_mem_23110[i_23206];\n                \n                ((__local bool *) local_mem_23092)[sharedIdx_23207] = tmp_23208;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23209 = 0; i_23209 < chunk_sizze_23067; i_23209++) {\n                int64_t flat_idx_23210 = thd_offset_23114 + i_23209 * segscan_tblock_sizze_22177;\n                int64_t slice_23211 = nz2081U_17318;\n                int64_t gtid_22181 = flat_idx_23210;\n                int64_t remnant_23212 = flat_idx_23210 - gtid_22181;\n                \n                if (slt64(flat_idx_23210, nz2081U_17318)) {\n                    bool tmp_23213 = ((__local bool *) local_mem_23092)[flat_idx_23210 - block_offset_23106];\n                    \n                    ((__global bool *) mem_22776)[gtid_22181] = tmp_23213;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23214 = 0; i_23214 < chunk_sizze_23067; i_23214++) {\n                int64_t sharedIdx_23215 = sext_i32_i64(local_tid_23083) * chunk_sizze_23067 + i_23214;\n                float tmp_23216 = private_mem_23112[i_23214];\n                \n                ((__local float *) local_mem_23092)[sharedIdx_23215] = tmp_23216;\n            }\n            barrier(CLK_LOCAL_",
                                    "MEM_FENCE);\n            for (int64_t i_23217 = 0; i_23217 < chunk_sizze_23067; i_23217++) {\n                int64_t flat_idx_23218 = thd_offset_23114 + i_23217 * segscan_tblock_sizze_22177;\n                int64_t slice_23219 = nz2081U_17318;\n                int64_t gtid_22181 = flat_idx_23218;\n                int64_t remnant_23220 = flat_idx_23218 - gtid_22181;\n                \n                if (slt64(flat_idx_23218, nz2081U_17318)) {\n                    float tmp_23221 = ((__local float *) local_mem_23092)[flat_idx_23218 - block_offset_23106];\n                    \n                    ((__global float *) mem_22778)[gtid_22181] = tmp_23221;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22177\n    #undef chunk_sizze_23067\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegscan_22190_dim1, 1, 1)\nvoid human_regularzisegscan_22190(__global int *global_failure, int64_t mz2080U_17317, int64_t num_tblocks_22187, int64_t num_virt_blocks_23228, int64_t num_virt_threads_23229, __global unsigned char *shp_mem_22767, __global unsigned char *mem_22781, __global unsigned char *status_flags_mem_23230, __global unsigned char *aggregates_mem_23232, __global unsigned char *incprefixes_mem_23234, __global unsigned char *global_dynid_mem_23236)\n{\n    #define segscan_tblock_sizze_22185 (human_regularzisegscan_22190zisegscan_tblock_sizze_22185)\n    #define chunk_sizze_23227 (human_regularzisegscan_22190zichunk_sizze_23227)\n    \n    volatile __local unsigned char *local_mem_23246_backing_0 = &shared_mem[0];\n    const int64_t local_mem_23246_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22185), chunk_sizze_23227 * segscan_tblock_sizze_22185 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22185), chunk_sizze_23227 * segscan_tblock_sizze_22185 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    ", "if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23239;\n    int32_t tblock_sizze_23242;\n    int32_t wave_sizze_23241;\n    int32_t block_id_23240;\n    int32_t global_tid_23238;\n    int64_t phys_tid_22190;\n    int32_t chunk_sizze_32b_23243;\n    int64_t byte_offsets_23244;\n    int64_t warp_byte_offset_23245;\n    __local unsigned char *local_mem_23246;\n    int64_t trans_arr_len_23247;\n    int64_t phys_block_id_23253;\n    int64_t virtloop_bound_23254;\n    \n    local_tid_23239 = get_local_id(0);\n    tblock_sizze_23242 = get_local_size(0);\n    wave_sizze_23241 = LOCKSTEP_WIDTH;\n    block_id_23240 = get_tblock_id(0);\n    global_tid_23238 = block_id_23240 * tblock_sizze_23242 + local_tid_23239;\n    phys_tid_22190 = sext_i32_i64(global_tid_23238);\n    chunk_sizze_32b_23243 = sext_i64_i32(chunk_sizze_23227);\n    byte_offsets_23244 = segscan_tblock_sizze_22185 * (int64_t) 4;\n    warp_byte_offset_23245 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_23246 = (__local unsigned char *) local_mem_23246_backing_0;\n    trans_arr_len_23247 = chunk_sizze_23227 * segscan_tblock_sizze_22185;\n    phys_block_id_23253 = get_tblock_id(0);\n    virtloop_bound_23254 = sdiv_up64(num_virt_blocks_23228 - phys_block_id_23253, num_tblocks_22187);\n    for (int64_t virtloop_i_23255 = 0; virtloop_i_23255 < virtloop_bound_23254; virtloop_i_23255++) {\n        int64_t dynamic_id_23256;\n        int64_t block_offset_23257;\n        int64_t sgm_idx_23258;\n        int32_t boundary_23259;\n        int32_t segsizze_compact_23260;\n        int32_t private_mem_23261[chunk_sizze_23227];\n        int64_t thd_offset_23263;\n        int32_t acc_23279;\n        int32_t prefix_23289;\n        bool block_new_sgm_23290;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_23239 == 0) {\n                dynamic_id_23256 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_23236)[(int64_t) 0], (int) 1);\n       ", "         // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_23246)[(int64_t) 0] = dynamic_id_23256;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_23256 == num_virt_blocks_23228 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_23236)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_23256 = ((__local int32_t *) local_mem_23246)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_23257 = dynamic_id_23256 * chunk_sizze_23227 * segscan_tblock_sizze_22185;\n        sgm_idx_23258 = smod64(block_offset_23257, mz2080U_17317);\n        boundary_23259 = sext_i64_i32(smin64(chunk_sizze_23227 * segscan_tblock_sizze_22185, mz2080U_17317 - sgm_idx_23258));\n        segsizze_compact_23260 = sext_i64_i32(smin64(chunk_sizze_23227 * segscan_tblock_sizze_22185, mz2080U_17317));\n        thd_offset_23263 = block_offset_23257 + sext_i32_i64(local_tid_23239);\n        // Load and map\n        {\n            for (int64_t i_23264 = 0; i_23264 < chunk_sizze_23227; i_23264++) {\n                int64_t virt_tid_23265 = thd_offset_23263 + i_23264 * segscan_tblock_sizze_22185;\n                int64_t slice_23266 = mz2080U_17317;\n                int64_t gtid_22189 = virt_tid_23265;\n                int64_t remnant_23267 = virt_tid_23265 - gtid_22189;\n                \n                if (slt64(virt_tid_23265, mz2080U_17317)) {\n                    int32_t x_21557 = ((__global int32_t *) shp_mem_22767)[gtid_22189];\n                    \n                    private_mem_23261[i_23264] = x_21557;\n                } else {\n                    private_mem_23261[i_23264] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t ",
                                    "i_23268 = 0; i_23268 < chunk_sizze_23227; i_23268++) {\n                int64_t sharedIdx_23269 = sext_i32_i64(local_tid_23239) + i_23268 * segscan_tblock_sizze_22185;\n                int32_t tmp_23270 = private_mem_23261[i_23268];\n                \n                ((__local int32_t *) local_mem_23246)[sharedIdx_23269] = tmp_23270;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23271 = 0; i_23271 < chunk_sizze_23227; i_23271++) {\n                int64_t sharedIdx_23272 = sext_i32_i64(local_tid_23239) * chunk_sizze_23227 + i_23271;\n                int32_t tmp_23273 = ((__local int32_t *) local_mem_23246)[sharedIdx_23272];\n                \n                private_mem_23261[i_23271] = tmp_23273;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_23274 = 0; i_23274 < chunk_sizze_23227 - (int64_t) 1; i_23274++) {\n                int32_t eta_p_21554;\n                int32_t eta_p_21555;\n                \n                eta_p_21554 = private_mem_23261[i_23274];\n                eta_p_21555 = private_mem_23261[i_23274 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_21556 = add32(eta_p_21554, eta_p_21555);\n                \n                private_mem_23261[i_23274 + (int64_t) 1] = defunc_0_op_res_21556;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_23275 = private_mem_23261[chunk_sizze_23227 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)] = tmp_23275;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_23276;\n            int32_t eta_p_23277;\n            int32_t eta_p_23280;\n            int32_t eta_p_23281;\n            bool ltid_in_bounds_23283 = slt64(sext_i32_i64(local_tid_23239), num_virt_threads_23229);\n            int32_t skip_threads_23284;\n   ", "         \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23283) {\n                    eta_p_23277 = ((volatile __local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)];\n                    if ((local_tid_23239 - squot32(local_tid_23239, 32) * 32) == 0) {\n                        eta_p_23276 = eta_p_23277;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23284 = 1;\n                while (slt32(skip_threads_23284, 32)) {\n                    bool thread_active_23285 = sle32(skip_threads_23284, local_tid_23239 - squot32(local_tid_23239, 32) * 32) && ltid_in_bounds_23283;\n                    \n                    if (thread_active_23285) {\n                        // read operands\n                        {\n                            eta_p_23276 = ((volatile __local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239) - sext_i32_i64(skip_threads_23284)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23285) {\n                            int32_t defunc_0_op_res_23278 = add32(eta_p_23276, eta_p_23277);\n                            \n                            eta_p_23276 = defunc_0_op_res_23278;\n                        }\n                    }\n                    if (sle32(wave_sizze_23241, skip_threads_23284)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23285) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)] = eta_p_23276;\n                            eta_p_23277 = eta_p_23276;\n                        }\n                    }\n                    if (sle32(wave_sizze_23241, skip_threads_23284)) {\n                    ", "    barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23284 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_23239 - squot32(local_tid_23239, 32) * 32) == 31 && ltid_in_bounds_23283) {\n                    ((volatile __local int32_t *) local_mem_23246)[sext_i32_i64(squot32(local_tid_23239, 32))] = eta_p_23276;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23286;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_23239, 32) == 0 && ltid_in_bounds_23283) {\n                        eta_p_23281 = ((volatile __local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)];\n                        if ((local_tid_23239 - squot32(local_tid_23239, 32) * 32) == 0) {\n                            eta_p_23280 = eta_p_23281;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23286 = 1;\n                    while (slt32(skip_threads_23286, 32)) {\n                        bool thread_active_23287 = sle32(skip_threads_23286, local_tid_23239 - squot32(local_tid_23239, 32) * 32) && (squot32(local_tid_23239, 32) == 0 && ltid_in_bounds_23283);\n                        \n                        if (thread_active_23287) {\n                            // read operands\n                            {\n                                eta_p_23280 = ((volatile __local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239) - sext_i32_i64(skip_threads_23286)];\n                            }\n                        }\n                        // perform op",
                                    "eration\n                        {\n                            if (thread_active_23287) {\n                                int32_t defunc_0_op_res_23282 = add32(eta_p_23280, eta_p_23281);\n                                \n                                eta_p_23280 = defunc_0_op_res_23282;\n                            }\n                        }\n                        if (sle32(wave_sizze_23241, skip_threads_23286)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23287) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)] = eta_p_23280;\n                                eta_p_23281 = eta_p_23280;\n                            }\n                        }\n                        if (sle32(wave_sizze_23241, skip_threads_23286)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23286 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23288 = squot32(local_tid_23239, 32) == 0 || !ltid_in_bounds_23283;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23288) {\n                        eta_p_23277 = eta_p_23276;\n                        eta_p_23276 = ((__local int32_t *) local_mem_23246)[sext_i32_i64(squot32(local_tid_23239, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23288) {\n                        int32_t defunc_0_op_res_23278 = add32(eta_p_23276, eta_p_23277);\n                        \n                        eta_p_23276 = defunc_0_op_res_23278;\n                    }\n             ", "   }\n                // write final result\n                {\n                    if (!no_carry_in_23288) {\n                        ((__local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)] = eta_p_23276;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_23239, 32) == 0 && ltid_in_bounds_23283) {\n                    ((__local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)] = eta_p_23277;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_23239 == 0) {\n                acc_23279 = ((__local int32_t *) local_mem_23246)[segscan_tblock_sizze_22185 - (int64_t) 1];\n            } else {\n                acc_23279 = ((__local int32_t *) local_mem_23246)[sext_i32_i64(local_tid_23239) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23289 = 0;\n        block_new_sgm_23290 = sgm_idx_23258 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23290 && local_tid_23239 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_23234)[dynamic_id_23256] = acc_23279;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23230)[dynamic_id_23256] = (int8_t) 2;\n                acc_23279 = 0;\n            }\n            if (!block_new_sgm_23290 && slt32(local_tid_23239, wave_sizze_23241)) {\n                if (local_tid_23239 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_23232)[dynamic_id_23256] = acc_23279;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23230)[dynamic_id_23256] = (int8_t) 1;\n                    \n                    int8_t tmp_23291 = ((volatile __global int8_t *) status_flags_mem_23230)[dynamic_i", "d_23256 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_23246)[(int64_t) 0] = tmp_23291;\n                }\n                mem_fence_local();\n                \n                int8_t status_23292 = ((__local int8_t *) local_mem_23246)[(int64_t) 0];\n                \n                if (status_23292 == (int8_t) 2) {\n                    if (local_tid_23239 == 0) {\n                        prefix_23289 = ((volatile __global int32_t *) incprefixes_mem_23234)[dynamic_id_23256 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23293 = sext_i64_i32(dynamic_id_23256 - sext_i32_i64(wave_sizze_23241));\n                    \n                    while (slt32(wave_sizze_23241 * -1, readOffset_23293)) {\n                        int32_t read_i_23294 = readOffset_23293 + local_tid_23239;\n                        int32_t aggr_23295 = 0;\n                        int8_t flag_23296 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23294)) {\n                            flag_23296 = ((volatile __global int8_t *) status_flags_mem_23230)[sext_i32_i64(read_i_23294)];\n                            if (flag_23296 == (int8_t) 2) {\n                                aggr_23295 = ((volatile __global int32_t *) incprefixes_mem_23234)[sext_i32_i64(read_i_23294)];\n                            } else if (flag_23296 == (int8_t) 1) {\n                                aggr_23295 = ((volatile __global int32_t *) aggregates_mem_23232)[sext_i32_i64(read_i_23294)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_23246)[(int64_t) 8 + sext_i32_i64(local_tid_23239)] = aggr_23295;\n                        ((__local int8_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)] = flag_23296;\n                        flag_23296 = ((__local int8_t *) local_mem_23246)[sext_i32_i64(wave_sizze_23241) - (int64_t) 1];\n                        if (sl",
                                    "t8(flag_23296, (int8_t) 2)) {\n                            int8_t flg_x_23300;\n                            int8_t flg_y_23301;\n                            int32_t eta_p_23297;\n                            int32_t eta_p_23298;\n                            int32_t skip_threads_23302;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23301 = ((volatile __local int8_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)];\n                                eta_p_23298 = ((volatile __local int32_t *) local_mem_23246)[(int64_t) 8 + sext_i32_i64(local_tid_23239)];\n                                if ((local_tid_23239 - squot32(local_tid_23239, 32) * 32) == 0) {\n                                    eta_p_23297 = eta_p_23298;\n                                    flg_x_23300 = flg_y_23301;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23302 = 1;\n                                while (slt32(skip_threads_23302, 32)) {\n                                    if (sle32(skip_threads_23302, local_tid_23239 - squot32(local_tid_23239, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23300 = ((volatile __local int8_t *) local_mem_23246)[sext_i32_i64(local_tid_23239) - sext_i32_i64(skip_threads_23302)];\n                                            eta_p_23297 = ((volatile __local int32_t *) local_mem_23246)[(int64_t) 8 + (sext_i32_i64(local_tid_23239) - sext_i32_i64(skip_threads_23302))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23301 == (int8_t) 2 || flg_y_23301 ==", " (int8_t) 0) {\n                                                flg_x_23300 = flg_y_23301;\n                                                eta_p_23297 = eta_p_23298;\n                                            } else {\n                                                int32_t defunc_0_op_res_23299 = add32(eta_p_23297, eta_p_23298);\n                                                \n                                                eta_p_23297 = defunc_0_op_res_23299;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_23246)[sext_i32_i64(local_tid_23239)] = flg_x_23300;\n                                            flg_y_23301 = flg_x_23300;\n                                            ((volatile __local int32_t *) local_mem_23246)[(int64_t) 8 + sext_i32_i64(local_tid_23239)] = eta_p_23297;\n                                            eta_p_23298 = eta_p_23297;\n                                        }\n                                    }\n                                    skip_threads_23302 *= 2;\n                                }\n                            }\n                        }\n                        flag_23296 = ((__local int8_t *) local_mem_23246)[sext_i32_i64(wave_sizze_23241) - (int64_t) 1];\n                        aggr_23295 = ((__local int32_t *) local_mem_23246)[(int64_t) 8 + (sext_i32_i64(wave_sizze_23241) - (int64_t) 1)];\n                        if (flag_23296 == (int8_t) 2) {\n                            readOffset_23293 = wave_sizze_23241 * -1;\n                        } else if (flag_23296 == (int8_t) 1) {\n                            readOffset_23293 -= wave_sizze_23241;\n                        }\n                        if (slt8((int8_t) 0, flag_23296)) {\n                            int32_t eta_p_23303 = aggr_23295;\n                           ", " int32_t eta_p_23304 = prefix_23289;\n                            int32_t defunc_0_op_res_23305 = add32(eta_p_23303, eta_p_23304);\n                            \n                            prefix_23289 = defunc_0_op_res_23305;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_23239 == 0) {\n                    if (boundary_23259 == sext_i64_i32(segscan_tblock_sizze_22185 * chunk_sizze_23227)) {\n                        int32_t eta_p_23306 = prefix_23289;\n                        int32_t eta_p_23307 = acc_23279;\n                        int32_t defunc_0_op_res_23308 = add32(eta_p_23306, eta_p_23307);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_23234)[dynamic_id_23256] = defunc_0_op_res_23308;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23230)[dynamic_id_23256] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_23246)[(int64_t) 8] = prefix_23289;\n                    acc_23279 = 0;\n                }\n            }\n            if (!(dynamic_id_23256 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23289 = ((__local int32_t *) local_mem_23246)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_23309;\n            int32_t eta_p_23310;\n            int32_t eta_p_23312 = prefix_23289;\n            int32_t eta_p_23313 = acc_23279;\n            \n            if (slt32(local_tid_23239 * chunk_sizze_32b_23243, boundary_23259) && !block_new_sgm_23290) {\n                int32_t defunc_0_op_res_23314 = add32(eta_p_23312, eta_p_23313);\n                \n                eta_p_23309 = defunc_0_op_res_23314;\n            } else {\n                eta_p_23309 = acc_23279;\n            }\n            \n            int32_t sto",
                                    "pping_point_23315 = segsizze_compact_23260 - srem32(local_tid_23239 * chunk_sizze_32b_23243 - 1 + segsizze_compact_23260 - boundary_23259, segsizze_compact_23260);\n            \n            for (int64_t i_23316 = 0; i_23316 < chunk_sizze_23227; i_23316++) {\n                if (slt32(sext_i64_i32(i_23316), stopping_point_23315 - 1)) {\n                    eta_p_23310 = private_mem_23261[i_23316];\n                    \n                    int32_t defunc_0_op_res_23311 = add32(eta_p_23309, eta_p_23310);\n                    \n                    private_mem_23261[i_23316] = defunc_0_op_res_23311;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23317 = 0; i_23317 < chunk_sizze_23227; i_23317++) {\n                int64_t sharedIdx_23318 = sext_i32_i64(local_tid_23239) * chunk_sizze_23227 + i_23317;\n                int32_t tmp_23319 = private_mem_23261[i_23317];\n                \n                ((__local int32_t *) local_mem_23246)[sharedIdx_23318] = tmp_23319;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23320 = 0; i_23320 < chunk_sizze_23227; i_23320++) {\n                int64_t flat_idx_23321 = thd_offset_23263 + i_23320 * segscan_tblock_sizze_22185;\n                int64_t slice_23322 = mz2080U_17317;\n                int64_t gtid_22189 = flat_idx_23321;\n                int64_t remnant_23323 = flat_idx_23321 - gtid_22189;\n                \n                if (slt64(flat_idx_23321, mz2080U_17317)) {\n                    int32_t tmp_23324 = ((__local int32_t *) local_mem_23246)[flat_idx_23321 - block_offset_23257];\n                    \n                    ((__global int32_t *) mem_22781)[gtid_22189] = tmp_23324;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22185\n    #undef chunk_sizze_23227\n}\nFUTHARK_KERNEL_SIZED(human_regul", "arzisegscan_22354_dim1, 1, 1)\nvoid human_regularzisegscan_22354(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_17317, int64_t nz2081U_17318, int64_t num_tblocks_22351, int64_t num_virt_blocks_23546, int64_t num_virt_threads_23547, __global unsigned char *II1_mem_22768, __global unsigned char *mem_22786, __global unsigned char *mem_22787, __global unsigned char *mem_22801, __global unsigned char *mem_22804, __global unsigned char *mem_22806, __global unsigned char *status_flags_mem_23548, __global unsigned char *aggregates_mem_23550, __global unsigned char *incprefixes_mem_23552, __global unsigned char *global_dynid_mem_23554)\n{\n    #define segscan_tblock_sizze_22349 (human_regularzisegscan_22354zisegscan_tblock_sizze_22349)\n    #define chunk_sizze_23545 (human_regularzisegscan_22354zichunk_sizze_23545)\n    \n    volatile __local unsigned char *local_mem_23564_backing_0 = &shared_mem[0];\n    const int64_t local_mem_23564_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22349), chunk_sizze_23545 * segscan_tblock_sizze_22349 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22349), chunk_sizze_23545 * segscan_tblock_sizze_22349 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_23557;\n    int32_t tblock_sizze_23560;\n    int32_t wave_sizze_23559;\n    int32_t block_id_23558;\n    int32_t global_tid_23556;\n    int64_t phys_tid_22354;\n    int32_t chunk_sizze_32b_23561;\n    int64_t byte_offsets_23562;\n    int64_t warp_byte_offset_23563;\n    __local unsigned char *local_mem_23564;\n    int64_t trans_arr_len_23565;\n    int64_t phys_block_id_23571;\n    int64_t virtloop_bou", "nd_23572;\n    \n    local_tid_23557 = get_local_id(0);\n    tblock_sizze_23560 = get_local_size(0);\n    wave_sizze_23559 = LOCKSTEP_WIDTH;\n    block_id_23558 = get_tblock_id(0);\n    global_tid_23556 = block_id_23558 * tblock_sizze_23560 + local_tid_23557;\n    phys_tid_22354 = sext_i32_i64(global_tid_23556);\n    chunk_sizze_32b_23561 = sext_i64_i32(chunk_sizze_23545);\n    byte_offsets_23562 = segscan_tblock_sizze_22349 * (int64_t) 8;\n    warp_byte_offset_23563 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_23564 = (__local unsigned char *) local_mem_23564_backing_0;\n    trans_arr_len_23565 = chunk_sizze_23545 * segscan_tblock_sizze_22349;\n    phys_block_id_23571 = get_tblock_id(0);\n    virtloop_bound_23572 = sdiv_up64(num_virt_blocks_23546 - phys_block_id_23571, num_tblocks_22351);\n    for (int64_t virtloop_i_23573 = 0; virtloop_i_23573 < virtloop_bound_23572; virtloop_i_23573++) {\n        int64_t dynamic_id_23574;\n        int64_t block_offset_23575;\n        int64_t sgm_idx_23576;\n        int32_t boundary_23577;\n        int32_t segsizze_compact_23578;\n        int64_t private_mem_23579[chunk_sizze_23545];\n        int64_t thd_offset_23581;\n        int64_t acc_23597;\n        int64_t prefix_23607;\n        bool block_new_sgm_23608;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_23557 == 0) {\n                dynamic_id_23574 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_23554)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_23564)[(int64_t) 0] = dynamic_id_23574;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_23574 == num_virt_blocks_23546 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_23554)[(int64_t) 0] = 0;\n                    }\n",
                                    "                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_23574 = ((__local int32_t *) local_mem_23564)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_23575 = dynamic_id_23574 * chunk_sizze_23545 * segscan_tblock_sizze_22349;\n        sgm_idx_23576 = smod64(block_offset_23575, nz2081U_17318);\n        boundary_23577 = sext_i64_i32(smin64(chunk_sizze_23545 * segscan_tblock_sizze_22349, nz2081U_17318 - sgm_idx_23576));\n        segsizze_compact_23578 = sext_i64_i32(smin64(chunk_sizze_23545 * segscan_tblock_sizze_22349, nz2081U_17318));\n        thd_offset_23581 = block_offset_23575 + sext_i32_i64(local_tid_23557);\n        // Load and map\n        {\n            for (int64_t i_23582 = 0; i_23582 < chunk_sizze_23545; i_23582++) {\n                int64_t virt_tid_23583 = thd_offset_23581 + i_23582 * segscan_tblock_sizze_22349;\n                int64_t slice_23584 = nz2081U_17318;\n                int64_t gtid_22353 = virt_tid_23583;\n                int64_t remnant_23585 = virt_tid_23583 - gtid_22353;\n                \n                if (slt64(virt_tid_23583, nz2081U_17318)) {\n                    int32_t eta_p_21368 = ((__global int32_t *) II1_mem_22768)[gtid_22353];\n                    int64_t ii_21371 = sext_i32_i64(eta_p_21368);\n                    bool x_21372 = sle64((int64_t) 0, ii_21371);\n                    bool y_21373 = slt64(ii_21371, mz2080U_17317);\n                    bool bounds_check_21374 = x_21372 && y_21373;\n                    bool index_certs_21375;\n                    \n                    if (!bounds_check_21374) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n                                global_failure_args[0] = (int64_t) ii_21371;\n                                global_failure_args[1] = (int64_t) mz2080U_17317;\n                                ;\n                            }\n                            local_failure = 1;", "\n                            goto error_0;\n                        }\n                    }\n                    \n                    bool eta_p_21369 = ((__global bool *) mem_22787)[gtid_22353];\n                    bool eta_p_21370 = ((__global bool *) mem_22786)[gtid_22353];\n                    int32_t zeze_lhs_21376 = ((__global int32_t *) mem_22801)[ii_21371];\n                    bool cond_21377 = zeze_lhs_21376 == -1;\n                    bool cond_21378 = zeze_lhs_21376 == 0;\n                    bool cond_21379 = zeze_lhs_21376 == 1;\n                    bool tmp_21380 = eta_p_21369 || eta_p_21370;\n                    bool lifted_lambda_res_f_res_f_res_f_res_21381 = !tmp_21380;\n                    bool x_21382 = !cond_21379;\n                    bool y_21383 = lifted_lambda_res_f_res_f_res_f_res_21381 && x_21382;\n                    bool x_21384 = eta_p_21369 && cond_21378;\n                    bool x_21385 = !cond_21378;\n                    bool y_21386 = y_21383 && x_21385;\n                    bool lifted_lambda_res_f_res_21387 = x_21384 || y_21386;\n                    bool x_21388 = !cond_21377;\n                    bool y_21389 = lifted_lambda_res_f_res_21387 && x_21388;\n                    int64_t defunc_0_f_res_21390 = btoi_bool_i64(y_21389);\n                    \n                    ((__global int64_t *) mem_22806)[gtid_22353] = defunc_0_f_res_21390;\n                    private_mem_23579[i_23582] = defunc_0_f_res_21390;\n                } else {\n                    private_mem_23579[i_23582] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_23586 = 0; i_23586 < chunk_sizze_23545; i_23586++) {\n                int64_t sharedIdx_23587 = sext_i32_i64(local_tid_23557) + i_23586 * segscan_tblock_sizze_22349;\n                int64_t tmp_23588 = priv", "ate_mem_23579[i_23586];\n                \n                ((__local int64_t *) local_mem_23564)[sharedIdx_23587] = tmp_23588;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23589 = 0; i_23589 < chunk_sizze_23545; i_23589++) {\n                int64_t sharedIdx_23590 = sext_i32_i64(local_tid_23557) * chunk_sizze_23545 + i_23589;\n                int64_t tmp_23591 = ((__local int64_t *) local_mem_23564)[sharedIdx_23590];\n                \n                private_mem_23579[i_23589] = tmp_23591;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_23592 = 0; i_23592 < chunk_sizze_23545 - (int64_t) 1; i_23592++) {\n                int64_t eta_p_21118;\n                int64_t eta_p_21119;\n                \n                eta_p_21118 = private_mem_23579[i_23592];\n                eta_p_21119 = private_mem_23579[i_23592 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_21120 = add64(eta_p_21118, eta_p_21119);\n                \n                private_mem_23579[i_23592 + (int64_t) 1] = defunc_0_op_res_21120;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_23593 = private_mem_23579[chunk_sizze_23545 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)] = tmp_23593;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_23594;\n            int64_t eta_p_23595;\n            int64_t eta_p_23598;\n            int64_t eta_p_23599;\n            bool ltid_in_bounds_23601 = slt64(sext_i32_i64(local_tid_23557), num_virt_threads_23547);\n            int32_t skip_threads_23602;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23601) {\n                    eta_p_23595 = ((volatile __local int64_t *) local_mem_23564)[sext_i32_i64(l",
                                    "ocal_tid_23557)];\n                    if ((local_tid_23557 - squot32(local_tid_23557, 32) * 32) == 0) {\n                        eta_p_23594 = eta_p_23595;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23602 = 1;\n                while (slt32(skip_threads_23602, 32)) {\n                    bool thread_active_23603 = sle32(skip_threads_23602, local_tid_23557 - squot32(local_tid_23557, 32) * 32) && ltid_in_bounds_23601;\n                    \n                    if (thread_active_23603) {\n                        // read operands\n                        {\n                            eta_p_23594 = ((volatile __local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557) - sext_i32_i64(skip_threads_23602)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23603) {\n                            int64_t defunc_0_op_res_23596 = add64(eta_p_23594, eta_p_23595);\n                            \n                            eta_p_23594 = defunc_0_op_res_23596;\n                        }\n                    }\n                    if (sle32(wave_sizze_23559, skip_threads_23602)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23603) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)] = eta_p_23594;\n                            eta_p_23595 = eta_p_23594;\n                        }\n                    }\n                    if (sle32(wave_sizze_23559, skip_threads_23602)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23602 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of bl", "ock 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_23557 - squot32(local_tid_23557, 32) * 32) == 31 && ltid_in_bounds_23601) {\n                    ((volatile __local int64_t *) local_mem_23564)[sext_i32_i64(squot32(local_tid_23557, 32))] = eta_p_23594;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23604;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_23557, 32) == 0 && ltid_in_bounds_23601) {\n                        eta_p_23599 = ((volatile __local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)];\n                        if ((local_tid_23557 - squot32(local_tid_23557, 32) * 32) == 0) {\n                            eta_p_23598 = eta_p_23599;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23604 = 1;\n                    while (slt32(skip_threads_23604, 32)) {\n                        bool thread_active_23605 = sle32(skip_threads_23604, local_tid_23557 - squot32(local_tid_23557, 32) * 32) && (squot32(local_tid_23557, 32) == 0 && ltid_in_bounds_23601);\n                        \n                        if (thread_active_23605) {\n                            // read operands\n                            {\n                                eta_p_23598 = ((volatile __local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557) - sext_i32_i64(skip_threads_23604)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_23605) {\n                                int64_t defunc_0_op_res_23600 = add64(eta_p_23598, eta_p_23599);\n                     ", "           \n                                eta_p_23598 = defunc_0_op_res_23600;\n                            }\n                        }\n                        if (sle32(wave_sizze_23559, skip_threads_23604)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23605) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)] = eta_p_23598;\n                                eta_p_23599 = eta_p_23598;\n                            }\n                        }\n                        if (sle32(wave_sizze_23559, skip_threads_23604)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_23604 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23606 = squot32(local_tid_23557, 32) == 0 || !ltid_in_bounds_23601;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23606) {\n                        eta_p_23595 = eta_p_23594;\n                        eta_p_23594 = ((__local int64_t *) local_mem_23564)[sext_i32_i64(squot32(local_tid_23557, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23606) {\n                        int64_t defunc_0_op_res_23596 = add64(eta_p_23594, eta_p_23595);\n                        \n                        eta_p_23594 = defunc_0_op_res_23596;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_23606) {\n                        ((__local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)] = eta_p",
                                    "_23594;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_23557, 32) == 0 && ltid_in_bounds_23601) {\n                    ((__local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)] = eta_p_23595;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_23557 == 0) {\n                acc_23597 = ((__local int64_t *) local_mem_23564)[segscan_tblock_sizze_22349 - (int64_t) 1];\n            } else {\n                acc_23597 = ((__local int64_t *) local_mem_23564)[sext_i32_i64(local_tid_23557) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_23607 = (int64_t) 0;\n        block_new_sgm_23608 = sgm_idx_23576 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23608 && local_tid_23557 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_23552)[dynamic_id_23574] = acc_23597;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23548)[dynamic_id_23574] = (int8_t) 2;\n                acc_23597 = (int64_t) 0;\n            }\n            if (!block_new_sgm_23608 && slt32(local_tid_23557, wave_sizze_23559)) {\n                if (local_tid_23557 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_23550)[dynamic_id_23574] = acc_23597;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23548)[dynamic_id_23574] = (int8_t) 1;\n                    \n                    int8_t tmp_23609 = ((volatile __global int8_t *) status_flags_mem_23548)[dynamic_id_23574 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_23564)[(int64_t) 0] = tmp_23609;\n                }\n                mem_fence_local(", ");\n                \n                int8_t status_23610 = ((__local int8_t *) local_mem_23564)[(int64_t) 0];\n                \n                if (status_23610 == (int8_t) 2) {\n                    if (local_tid_23557 == 0) {\n                        prefix_23607 = ((volatile __global int64_t *) incprefixes_mem_23552)[dynamic_id_23574 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23611 = sext_i64_i32(dynamic_id_23574 - sext_i32_i64(wave_sizze_23559));\n                    \n                    while (slt32(wave_sizze_23559 * -1, readOffset_23611)) {\n                        int32_t read_i_23612 = readOffset_23611 + local_tid_23557;\n                        int64_t aggr_23613 = (int64_t) 0;\n                        int8_t flag_23614 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_23612)) {\n                            flag_23614 = ((volatile __global int8_t *) status_flags_mem_23548)[sext_i32_i64(read_i_23612)];\n                            if (flag_23614 == (int8_t) 2) {\n                                aggr_23613 = ((volatile __global int64_t *) incprefixes_mem_23552)[sext_i32_i64(read_i_23612)];\n                            } else if (flag_23614 == (int8_t) 1) {\n                                aggr_23613 = ((volatile __global int64_t *) aggregates_mem_23550)[sext_i32_i64(read_i_23612)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_23564)[(int64_t) 4 + sext_i32_i64(local_tid_23557)] = aggr_23613;\n                        ((__local int8_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)] = flag_23614;\n                        flag_23614 = ((__local int8_t *) local_mem_23564)[sext_i32_i64(wave_sizze_23559) - (int64_t) 1];\n                        if (slt8(flag_23614, (int8_t) 2)) {\n                            int8_t flg_x_23618;\n                            int8_t flg_y_23619;\n                            int64_t eta_p_23615;\n  ", "                          int64_t eta_p_23616;\n                            int32_t skip_threads_23620;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23619 = ((volatile __local int8_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)];\n                                eta_p_23616 = ((volatile __local int64_t *) local_mem_23564)[(int64_t) 4 + sext_i32_i64(local_tid_23557)];\n                                if ((local_tid_23557 - squot32(local_tid_23557, 32) * 32) == 0) {\n                                    eta_p_23615 = eta_p_23616;\n                                    flg_x_23618 = flg_y_23619;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_23620 = 1;\n                                while (slt32(skip_threads_23620, 32)) {\n                                    if (sle32(skip_threads_23620, local_tid_23557 - squot32(local_tid_23557, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23618 = ((volatile __local int8_t *) local_mem_23564)[sext_i32_i64(local_tid_23557) - sext_i32_i64(skip_threads_23620)];\n                                            eta_p_23615 = ((volatile __local int64_t *) local_mem_23564)[(int64_t) 4 + (sext_i32_i64(local_tid_23557) - sext_i32_i64(skip_threads_23620))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23619 == (int8_t) 2 || flg_y_23619 == (int8_t) 0) {\n                                                flg_x_23618 = flg_y_23619;\n                                                eta_p_23615 = eta_p_23616;\n            ",
                                    "                                } else {\n                                                int64_t defunc_0_op_res_23617 = add64(eta_p_23615, eta_p_23616);\n                                                \n                                                eta_p_23615 = defunc_0_op_res_23617;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_23564)[sext_i32_i64(local_tid_23557)] = flg_x_23618;\n                                            flg_y_23619 = flg_x_23618;\n                                            ((volatile __local int64_t *) local_mem_23564)[(int64_t) 4 + sext_i32_i64(local_tid_23557)] = eta_p_23615;\n                                            eta_p_23616 = eta_p_23615;\n                                        }\n                                    }\n                                    skip_threads_23620 *= 2;\n                                }\n                            }\n                        }\n                        flag_23614 = ((__local int8_t *) local_mem_23564)[sext_i32_i64(wave_sizze_23559) - (int64_t) 1];\n                        aggr_23613 = ((__local int64_t *) local_mem_23564)[(int64_t) 4 + (sext_i32_i64(wave_sizze_23559) - (int64_t) 1)];\n                        if (flag_23614 == (int8_t) 2) {\n                            readOffset_23611 = wave_sizze_23559 * -1;\n                        } else if (flag_23614 == (int8_t) 1) {\n                            readOffset_23611 -= wave_sizze_23559;\n                        }\n                        if (slt8((int8_t) 0, flag_23614)) {\n                            int64_t eta_p_23621 = aggr_23613;\n                            int64_t eta_p_23622 = prefix_23607;\n                            int64_t defunc_0_op_res_23623 = add64(eta_p_23621, eta_p_23622);\n                            \n                  ", "          prefix_23607 = defunc_0_op_res_23623;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_23557 == 0) {\n                    if (boundary_23577 == sext_i64_i32(segscan_tblock_sizze_22349 * chunk_sizze_23545)) {\n                        int64_t eta_p_23624 = prefix_23607;\n                        int64_t eta_p_23625 = acc_23597;\n                        int64_t defunc_0_op_res_23626 = add64(eta_p_23624, eta_p_23625);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_23552)[dynamic_id_23574] = defunc_0_op_res_23626;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23548)[dynamic_id_23574] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_23564)[(int64_t) 4] = prefix_23607;\n                    acc_23597 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_23574 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23607 = ((__local int64_t *) local_mem_23564)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_23627;\n            int64_t eta_p_23628;\n            int64_t eta_p_23630 = prefix_23607;\n            int64_t eta_p_23631 = acc_23597;\n            \n            if (slt32(local_tid_23557 * chunk_sizze_32b_23561, boundary_23577) && !block_new_sgm_23608) {\n                int64_t defunc_0_op_res_23632 = add64(eta_p_23630, eta_p_23631);\n                \n                eta_p_23627 = defunc_0_op_res_23632;\n            } else {\n                eta_p_23627 = acc_23597;\n            }\n            \n            int32_t stopping_point_23633 = segsizze_compact_23578 - srem32(local_tid_23557 * chunk_sizze_32b_23561 - 1 + segsizze_compact_23578 - boundary_23577, segsizze_compact_23578);\n   ", "         \n            for (int64_t i_23634 = 0; i_23634 < chunk_sizze_23545; i_23634++) {\n                if (slt32(sext_i64_i32(i_23634), stopping_point_23633 - 1)) {\n                    eta_p_23628 = private_mem_23579[i_23634];\n                    \n                    int64_t defunc_0_op_res_23629 = add64(eta_p_23627, eta_p_23628);\n                    \n                    private_mem_23579[i_23634] = defunc_0_op_res_23629;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23635 = 0; i_23635 < chunk_sizze_23545; i_23635++) {\n                int64_t sharedIdx_23636 = sext_i32_i64(local_tid_23557) * chunk_sizze_23545 + i_23635;\n                int64_t tmp_23637 = private_mem_23579[i_23635];\n                \n                ((__local int64_t *) local_mem_23564)[sharedIdx_23636] = tmp_23637;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23638 = 0; i_23638 < chunk_sizze_23545; i_23638++) {\n                int64_t flat_idx_23639 = thd_offset_23581 + i_23638 * segscan_tblock_sizze_22349;\n                int64_t slice_23640 = nz2081U_17318;\n                int64_t gtid_22353 = flat_idx_23639;\n                int64_t remnant_23641 = flat_idx_23639 - gtid_22353;\n                \n                if (slt64(flat_idx_23639, nz2081U_17318)) {\n                    int64_t tmp_23642 = ((__local int64_t *) local_mem_23564)[flat_idx_23639 - block_offset_23575];\n                    \n                    ((__global int64_t *) mem_22804)[gtid_22353] = tmp_23642;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22349\n    #undef chunk_sizze_23545\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegscan_22370_dim1, 1, 1)\nvoid human_regularzisegscan_22370(__global int *global_failure, int64_t mz2080U_17317, int64_t num_tblocks_22367, int64_t num_virt_blocks",
                                    "_23675, int64_t num_virt_threads_23676, __global unsigned char *mem_param_22817, __global unsigned char *mem_22829, __global unsigned char *status_flags_mem_23677, __global unsigned char *aggregates_mem_23679, __global unsigned char *incprefixes_mem_23681, __global unsigned char *global_dynid_mem_23683)\n{\n    #define segscan_tblock_sizze_22365 (human_regularzisegscan_22370zisegscan_tblock_sizze_22365)\n    #define chunk_sizze_23674 (human_regularzisegscan_22370zichunk_sizze_23674)\n    \n    volatile __local unsigned char *local_mem_23693_backing_0 = &shared_mem[0];\n    const int64_t local_mem_23693_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22365), chunk_sizze_23674 * segscan_tblock_sizze_22365 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22365), chunk_sizze_23674 * segscan_tblock_sizze_22365 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_23686;\n    int32_t tblock_sizze_23689;\n    int32_t wave_sizze_23688;\n    int32_t block_id_23687;\n    int32_t global_tid_23685;\n    int64_t phys_tid_22370;\n    int32_t chunk_sizze_32b_23690;\n    int64_t byte_offsets_23691;\n    int64_t warp_byte_offset_23692;\n    __local unsigned char *local_mem_23693;\n    int64_t trans_arr_len_23694;\n    int64_t phys_block_id_23700;\n    int64_t virtloop_bound_23701;\n    \n    local_tid_23686 = get_local_id(0);\n    tblock_sizze_23689 = get_local_size(0);\n    wave_sizze_23688 = LOCKSTEP_WIDTH;\n    block_id_23687 = get_tblock_id(0);\n    global_tid_23685 = block_id_23687 * tblock_sizze_23689 + local_tid_23686;\n    phys_tid_22370 = sext_i32_i64(global_tid_23685);\n    chunk_sizze_32b_23690 = sext_i64_i32(chunk_sizze_23674);\n    byte_offsets_23691 = segscan_tblock_sizze_22365 * (int64_t) 4;\n    warp_byte_offset_23692 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_23693 = (__local unsigned char *) ", "local_mem_23693_backing_0;\n    trans_arr_len_23694 = chunk_sizze_23674 * segscan_tblock_sizze_22365;\n    phys_block_id_23700 = get_tblock_id(0);\n    virtloop_bound_23701 = sdiv_up64(num_virt_blocks_23675 - phys_block_id_23700, num_tblocks_22367);\n    for (int64_t virtloop_i_23702 = 0; virtloop_i_23702 < virtloop_bound_23701; virtloop_i_23702++) {\n        int64_t dynamic_id_23703;\n        int64_t block_offset_23704;\n        int64_t sgm_idx_23705;\n        int32_t boundary_23706;\n        int32_t segsizze_compact_23707;\n        int32_t private_mem_23708[chunk_sizze_23674];\n        int64_t thd_offset_23710;\n        int32_t acc_23726;\n        int32_t prefix_23736;\n        bool block_new_sgm_23737;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_23686 == 0) {\n                dynamic_id_23703 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_23683)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_23693)[(int64_t) 0] = dynamic_id_23703;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_23703 == num_virt_blocks_23675 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_23683)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_23703 = ((__local int32_t *) local_mem_23693)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_23704 = dynamic_id_23703 * chunk_sizze_23674 * segscan_tblock_sizze_22365;\n        sgm_idx_23705 = smod64(block_offset_23704, mz2080U_17317);\n        boundary_23706 = sext_i64_i32(smin64(chunk_sizze_23674 * segscan_tblock_sizze_22365, mz2080U_17317 - sgm_idx_23705));\n        segsizze_compact_23707 = sext_i64_i32(smin64(chunk_sizze_23674 * segscan_tblock_", "sizze_22365, mz2080U_17317));\n        thd_offset_23710 = block_offset_23704 + sext_i32_i64(local_tid_23686);\n        // Load and map\n        {\n            for (int64_t i_23711 = 0; i_23711 < chunk_sizze_23674; i_23711++) {\n                int64_t virt_tid_23712 = thd_offset_23710 + i_23711 * segscan_tblock_sizze_22365;\n                int64_t slice_23713 = mz2080U_17317;\n                int64_t gtid_22369 = virt_tid_23712;\n                int64_t remnant_23714 = virt_tid_23712 - gtid_22369;\n                \n                if (slt64(virt_tid_23712, mz2080U_17317)) {\n                    int32_t x_21835 = ((__global int32_t *) mem_param_22817)[gtid_22369];\n                    \n                    private_mem_23708[i_23711] = x_21835;\n                } else {\n                    private_mem_23708[i_23711] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_23715 = 0; i_23715 < chunk_sizze_23674; i_23715++) {\n                int64_t sharedIdx_23716 = sext_i32_i64(local_tid_23686) + i_23715 * segscan_tblock_sizze_22365;\n                int32_t tmp_23717 = private_mem_23708[i_23715];\n                \n                ((__local int32_t *) local_mem_23693)[sharedIdx_23716] = tmp_23717;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23718 = 0; i_23718 < chunk_sizze_23674; i_23718++) {\n                int64_t sharedIdx_23719 = sext_i32_i64(local_tid_23686) * chunk_sizze_23674 + i_23718;\n                int32_t tmp_23720 = ((__local int32_t *) local_mem_23693)[sharedIdx_23719];\n                \n                private_mem_23708[i_23718] = tmp_23720;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_23721 = 0; i_23721 < chunk_sizze_23674 - (int64_t) 1; i_23721++) {\n                int32_t eta_p_21832;\n                int32_t eta_p_21833;\n                \n         ",
                                    "       eta_p_21832 = private_mem_23708[i_23721];\n                eta_p_21833 = private_mem_23708[i_23721 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_21834 = add32(eta_p_21832, eta_p_21833);\n                \n                private_mem_23708[i_23721 + (int64_t) 1] = defunc_0_op_res_21834;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_23722 = private_mem_23708[chunk_sizze_23674 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)] = tmp_23722;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_23723;\n            int32_t eta_p_23724;\n            int32_t eta_p_23727;\n            int32_t eta_p_23728;\n            bool ltid_in_bounds_23730 = slt64(sext_i32_i64(local_tid_23686), num_virt_threads_23676);\n            int32_t skip_threads_23731;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_23730) {\n                    eta_p_23724 = ((volatile __local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)];\n                    if ((local_tid_23686 - squot32(local_tid_23686, 32) * 32) == 0) {\n                        eta_p_23723 = eta_p_23724;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_23731 = 1;\n                while (slt32(skip_threads_23731, 32)) {\n                    bool thread_active_23732 = sle32(skip_threads_23731, local_tid_23686 - squot32(local_tid_23686, 32) * 32) && ltid_in_bounds_23730;\n                    \n                    if (thread_active_23732) {\n                        // read operands\n                        {\n                            eta_p_23723 = ((volatile __local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686) - sext_i32_i64(skip_threads_23731)];\n     ", "                   }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_23732) {\n                            int32_t defunc_0_op_res_23725 = add32(eta_p_23723, eta_p_23724);\n                            \n                            eta_p_23723 = defunc_0_op_res_23725;\n                        }\n                    }\n                    if (sle32(wave_sizze_23688, skip_threads_23731)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_23732) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)] = eta_p_23723;\n                            eta_p_23724 = eta_p_23723;\n                        }\n                    }\n                    if (sle32(wave_sizze_23688, skip_threads_23731)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_23731 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_23686 - squot32(local_tid_23686, 32) * 32) == 31 && ltid_in_bounds_23730) {\n                    ((volatile __local int32_t *) local_mem_23693)[sext_i32_i64(squot32(local_tid_23686, 32))] = eta_p_23723;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_23733;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_23686, 32) == 0 && ltid_in_bounds_23730) {\n                        eta_p_23728 = ((volatile __local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)];\n                        if (", "(local_tid_23686 - squot32(local_tid_23686, 32) * 32) == 0) {\n                            eta_p_23727 = eta_p_23728;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_23733 = 1;\n                    while (slt32(skip_threads_23733, 32)) {\n                        bool thread_active_23734 = sle32(skip_threads_23733, local_tid_23686 - squot32(local_tid_23686, 32) * 32) && (squot32(local_tid_23686, 32) == 0 && ltid_in_bounds_23730);\n                        \n                        if (thread_active_23734) {\n                            // read operands\n                            {\n                                eta_p_23727 = ((volatile __local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686) - sext_i32_i64(skip_threads_23733)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_23734) {\n                                int32_t defunc_0_op_res_23729 = add32(eta_p_23727, eta_p_23728);\n                                \n                                eta_p_23727 = defunc_0_op_res_23729;\n                            }\n                        }\n                        if (sle32(wave_sizze_23688, skip_threads_23733)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_23734) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)] = eta_p_23727;\n                                eta_p_23728 = eta_p_23727;\n                            }\n                        }\n                        if (sle32(wave_sizze_23688, skip_threads_23733)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n      ",
                                    "                  skip_threads_23733 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_23735 = squot32(local_tid_23686, 32) == 0 || !ltid_in_bounds_23730;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_23735) {\n                        eta_p_23724 = eta_p_23723;\n                        eta_p_23723 = ((__local int32_t *) local_mem_23693)[sext_i32_i64(squot32(local_tid_23686, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_23735) {\n                        int32_t defunc_0_op_res_23725 = add32(eta_p_23723, eta_p_23724);\n                        \n                        eta_p_23723 = defunc_0_op_res_23725;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_23735) {\n                        ((__local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)] = eta_p_23723;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_23686, 32) == 0 && ltid_in_bounds_23730) {\n                    ((__local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)] = eta_p_23724;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_23686 == 0) {\n                acc_23726 = ((__local int32_t *) local_mem_23693)[segscan_tblock_sizze_22365 - (int64_t) 1];\n            } else {\n                acc_23726 = ((__local int32_t *) local_mem_23693)[sext_i32_i64(local_tid_23686) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n     ", "   prefix_23736 = 0;\n        block_new_sgm_23737 = sgm_idx_23705 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_23737 && local_tid_23686 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_23681)[dynamic_id_23703] = acc_23726;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23677)[dynamic_id_23703] = (int8_t) 2;\n                acc_23726 = 0;\n            }\n            if (!block_new_sgm_23737 && slt32(local_tid_23686, wave_sizze_23688)) {\n                if (local_tid_23686 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_23679)[dynamic_id_23703] = acc_23726;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23677)[dynamic_id_23703] = (int8_t) 1;\n                    \n                    int8_t tmp_23738 = ((volatile __global int8_t *) status_flags_mem_23677)[dynamic_id_23703 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_23693)[(int64_t) 0] = tmp_23738;\n                }\n                mem_fence_local();\n                \n                int8_t status_23739 = ((__local int8_t *) local_mem_23693)[(int64_t) 0];\n                \n                if (status_23739 == (int8_t) 2) {\n                    if (local_tid_23686 == 0) {\n                        prefix_23736 = ((volatile __global int32_t *) incprefixes_mem_23681)[dynamic_id_23703 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_23740 = sext_i64_i32(dynamic_id_23703 - sext_i32_i64(wave_sizze_23688));\n                    \n                    while (slt32(wave_sizze_23688 * -1, readOffset_23740)) {\n                        int32_t read_i_23741 = readOffset_23740 + local_tid_23686;\n                        int32_t aggr_23742 = 0;\n                        int8_t flag_23743 = (int8_t) 0;\n                        \n                        if ", "(sle32(0, read_i_23741)) {\n                            flag_23743 = ((volatile __global int8_t *) status_flags_mem_23677)[sext_i32_i64(read_i_23741)];\n                            if (flag_23743 == (int8_t) 2) {\n                                aggr_23742 = ((volatile __global int32_t *) incprefixes_mem_23681)[sext_i32_i64(read_i_23741)];\n                            } else if (flag_23743 == (int8_t) 1) {\n                                aggr_23742 = ((volatile __global int32_t *) aggregates_mem_23679)[sext_i32_i64(read_i_23741)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_23693)[(int64_t) 8 + sext_i32_i64(local_tid_23686)] = aggr_23742;\n                        ((__local int8_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)] = flag_23743;\n                        flag_23743 = ((__local int8_t *) local_mem_23693)[sext_i32_i64(wave_sizze_23688) - (int64_t) 1];\n                        if (slt8(flag_23743, (int8_t) 2)) {\n                            int8_t flg_x_23747;\n                            int8_t flg_y_23748;\n                            int32_t eta_p_23744;\n                            int32_t eta_p_23745;\n                            int32_t skip_threads_23749;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_23748 = ((volatile __local int8_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)];\n                                eta_p_23745 = ((volatile __local int32_t *) local_mem_23693)[(int64_t) 8 + sext_i32_i64(local_tid_23686)];\n                                if ((local_tid_23686 - squot32(local_tid_23686, 32) * 32) == 0) {\n                                    eta_p_23744 = eta_p_23745;\n                                    flg_x_23747 = flg_y_23748;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n       ",
                                    "                     {\n                                skip_threads_23749 = 1;\n                                while (slt32(skip_threads_23749, 32)) {\n                                    if (sle32(skip_threads_23749, local_tid_23686 - squot32(local_tid_23686, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_23747 = ((volatile __local int8_t *) local_mem_23693)[sext_i32_i64(local_tid_23686) - sext_i32_i64(skip_threads_23749)];\n                                            eta_p_23744 = ((volatile __local int32_t *) local_mem_23693)[(int64_t) 8 + (sext_i32_i64(local_tid_23686) - sext_i32_i64(skip_threads_23749))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_23748 == (int8_t) 2 || flg_y_23748 == (int8_t) 0) {\n                                                flg_x_23747 = flg_y_23748;\n                                                eta_p_23744 = eta_p_23745;\n                                            } else {\n                                                int32_t defunc_0_op_res_23746 = add32(eta_p_23744, eta_p_23745);\n                                                \n                                                eta_p_23744 = defunc_0_op_res_23746;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_23693)[sext_i32_i64(local_tid_23686)] = flg_x_23747;\n                                            flg_y_23748 = flg_x_23747;\n                                            ((volatile __local int32_t *) local_mem_23693)[(int64_t) 8 + sext_i32_i64(local_tid_23686)] = eta_p_23744;\n                        ", "                    eta_p_23745 = eta_p_23744;\n                                        }\n                                    }\n                                    skip_threads_23749 *= 2;\n                                }\n                            }\n                        }\n                        flag_23743 = ((__local int8_t *) local_mem_23693)[sext_i32_i64(wave_sizze_23688) - (int64_t) 1];\n                        aggr_23742 = ((__local int32_t *) local_mem_23693)[(int64_t) 8 + (sext_i32_i64(wave_sizze_23688) - (int64_t) 1)];\n                        if (flag_23743 == (int8_t) 2) {\n                            readOffset_23740 = wave_sizze_23688 * -1;\n                        } else if (flag_23743 == (int8_t) 1) {\n                            readOffset_23740 -= wave_sizze_23688;\n                        }\n                        if (slt8((int8_t) 0, flag_23743)) {\n                            int32_t eta_p_23750 = aggr_23742;\n                            int32_t eta_p_23751 = prefix_23736;\n                            int32_t defunc_0_op_res_23752 = add32(eta_p_23750, eta_p_23751);\n                            \n                            prefix_23736 = defunc_0_op_res_23752;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_23686 == 0) {\n                    if (boundary_23706 == sext_i64_i32(segscan_tblock_sizze_22365 * chunk_sizze_23674)) {\n                        int32_t eta_p_23753 = prefix_23736;\n                        int32_t eta_p_23754 = acc_23726;\n                        int32_t defunc_0_op_res_23755 = add32(eta_p_23753, eta_p_23754);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_23681)[dynamic_id_23703] = defunc_0_op_res_23755;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23677)[dynamic_id_23703] = (int8_t) 2;\n                    }\n                    (", "(__local int32_t *) local_mem_23693)[(int64_t) 8] = prefix_23736;\n                    acc_23726 = 0;\n                }\n            }\n            if (!(dynamic_id_23703 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_23736 = ((__local int32_t *) local_mem_23693)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_23756;\n            int32_t eta_p_23757;\n            int32_t eta_p_23759 = prefix_23736;\n            int32_t eta_p_23760 = acc_23726;\n            \n            if (slt32(local_tid_23686 * chunk_sizze_32b_23690, boundary_23706) && !block_new_sgm_23737) {\n                int32_t defunc_0_op_res_23761 = add32(eta_p_23759, eta_p_23760);\n                \n                eta_p_23756 = defunc_0_op_res_23761;\n            } else {\n                eta_p_23756 = acc_23726;\n            }\n            \n            int32_t stopping_point_23762 = segsizze_compact_23707 - srem32(local_tid_23686 * chunk_sizze_32b_23690 - 1 + segsizze_compact_23707 - boundary_23706, segsizze_compact_23707);\n            \n            for (int64_t i_23763 = 0; i_23763 < chunk_sizze_23674; i_23763++) {\n                if (slt32(sext_i64_i32(i_23763), stopping_point_23762 - 1)) {\n                    eta_p_23757 = private_mem_23708[i_23763];\n                    \n                    int32_t defunc_0_op_res_23758 = add32(eta_p_23756, eta_p_23757);\n                    \n                    private_mem_23708[i_23763] = defunc_0_op_res_23758;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_23764 = 0; i_23764 < chunk_sizze_23674; i_23764++) {\n                int64_t sharedIdx_23765 = sext_i32_i64(local_tid_23686) * chunk_sizze_23674 + i_23764;\n                int32_t tmp_23766 = private_mem_23708[i_23764];\n                \n                ((__local int32_t *) ",
                                    "local_mem_23693)[sharedIdx_23765] = tmp_23766;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_23767 = 0; i_23767 < chunk_sizze_23674; i_23767++) {\n                int64_t flat_idx_23768 = thd_offset_23710 + i_23767 * segscan_tblock_sizze_22365;\n                int64_t slice_23769 = mz2080U_17317;\n                int64_t gtid_22369 = flat_idx_23768;\n                int64_t remnant_23770 = flat_idx_23768 - gtid_22369;\n                \n                if (slt64(flat_idx_23768, mz2080U_17317)) {\n                    int32_t tmp_23771 = ((__local int32_t *) local_mem_23693)[flat_idx_23768 - block_offset_23704];\n                    \n                    ((__global int32_t *) mem_22829)[gtid_22369] = tmp_23771;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22365\n    #undef chunk_sizze_23674\n}\nFUTHARK_KERNEL_SIZED(human_regularzisegscan_22530_dim1, 1, 1)\nvoid human_regularzisegscan_22530(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_17317, int64_t loop_dz2081Uz2089Uz2081U_21167, int64_t num_tblocks_22527, int64_t num_virt_blocks_23993, int64_t num_virt_threads_23994, __global unsigned char *mem_param_22820, __global unsigned char *mem_22834, __global unsigned char *mem_22835, __global unsigned char *mem_22849, __global unsigned char *mem_22852, __global unsigned char *mem_22854, __global unsigned char *status_flags_mem_23995, __global unsigned char *aggregates_mem_23997, __global unsigned char *incprefixes_mem_23999, __global unsigned char *global_dynid_mem_24001)\n{\n    #define segscan_tblock_sizze_22525 (human_regularzisegscan_22530zisegscan_tblock_sizze_22525)\n    #define chunk_sizze_23992 (human_regularzisegscan_22530zichunk_sizze_23992)\n    \n    volatile __local unsigned char *local_mem_24011_backing_0 = &shared_mem[0];\n    const int64_t local_mem_24011_backing_0_offset ", "= 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22525), chunk_sizze_23992 * segscan_tblock_sizze_22525 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22525), chunk_sizze_23992 * segscan_tblock_sizze_22525 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_24004;\n    int32_t tblock_sizze_24007;\n    int32_t wave_sizze_24006;\n    int32_t block_id_24005;\n    int32_t global_tid_24003;\n    int64_t phys_tid_22530;\n    int32_t chunk_sizze_32b_24008;\n    int64_t byte_offsets_24009;\n    int64_t warp_byte_offset_24010;\n    __local unsigned char *local_mem_24011;\n    int64_t trans_arr_len_24012;\n    int64_t phys_block_id_24018;\n    int64_t virtloop_bound_24019;\n    \n    local_tid_24004 = get_local_id(0);\n    tblock_sizze_24007 = get_local_size(0);\n    wave_sizze_24006 = LOCKSTEP_WIDTH;\n    block_id_24005 = get_tblock_id(0);\n    global_tid_24003 = block_id_24005 * tblock_sizze_24007 + local_tid_24004;\n    phys_tid_22530 = sext_i32_i64(global_tid_24003);\n    chunk_sizze_32b_24008 = sext_i64_i32(chunk_sizze_23992);\n    byte_offsets_24009 = segscan_tblock_sizze_22525 * (int64_t) 8;\n    warp_byte_offset_24010 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_24011 = (__local unsigned char *) local_mem_24011_backing_0;\n    trans_arr_len_24012 = chunk_sizze_23992 * segscan_tblock_sizze_22525;\n    phys_block_id_24018 = get_tblock_id(0);\n    virtloop_bound_24019 = sdiv_up64(num_virt_blocks_23993 - phys_block_id_24018, num_tblocks_22527);\n    for (int64_t virtloop_i_24020 = 0; virtloop_i_24020 < virtloop_bound_24019; virtloop_i_24020++) {\n        int64_t dynamic_id_24021;\n        int64_t block_offset_24022;\n        int64_t sgm_i", "dx_24023;\n        int32_t boundary_24024;\n        int32_t segsizze_compact_24025;\n        int64_t private_mem_24026[chunk_sizze_23992];\n        int64_t thd_offset_24028;\n        int64_t acc_24044;\n        int64_t prefix_24054;\n        bool block_new_sgm_24055;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_24004 == 0) {\n                dynamic_id_24021 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_24001)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_24011)[(int64_t) 0] = dynamic_id_24021;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_24021 == num_virt_blocks_23993 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_24001)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_24021 = ((__local int32_t *) local_mem_24011)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_24022 = dynamic_id_24021 * chunk_sizze_23992 * segscan_tblock_sizze_22525;\n        sgm_idx_24023 = smod64(block_offset_24022, loop_dz2081Uz2089Uz2081U_21167);\n        boundary_24024 = sext_i64_i32(smin64(chunk_sizze_23992 * segscan_tblock_sizze_22525, loop_dz2081Uz2089Uz2081U_21167 - sgm_idx_24023));\n        segsizze_compact_24025 = sext_i64_i32(smin64(chunk_sizze_23992 * segscan_tblock_sizze_22525, loop_dz2081Uz2089Uz2081U_21167));\n        thd_offset_24028 = block_offset_24022 + sext_i32_i64(local_tid_24004);\n        // Load and map\n        {\n            for (int64_t i_24029 = 0; i_24029 < chunk_sizze_23992; i_24029++) {\n                int64_t virt_tid_24030 = thd_offset_24028 + i_24029 * segscan_tblock_sizze_22525;\n                int64_t slice_24031 = loop_dz2081Uz2089Uz2081U_21167",
                                    ";\n                int64_t gtid_22529 = virt_tid_24030;\n                int64_t remnant_24032 = virt_tid_24030 - gtid_22529;\n                \n                if (slt64(virt_tid_24030, loop_dz2081Uz2089Uz2081U_21167)) {\n                    int32_t eta_p_21661 = ((__global int32_t *) mem_param_22820)[gtid_22529];\n                    int64_t ii_21664 = sext_i32_i64(eta_p_21661);\n                    bool x_21665 = sle64((int64_t) 0, ii_21664);\n                    bool y_21666 = slt64(ii_21664, mz2080U_17317);\n                    bool bounds_check_21667 = x_21665 && y_21666;\n                    bool index_certs_21668;\n                    \n                    if (!bounds_check_21667) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 11) == -1) {\n                                global_failure_args[0] = (int64_t) ii_21664;\n                                global_failure_args[1] = (int64_t) mz2080U_17317;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    bool eta_p_21662 = ((__global bool *) mem_22835)[gtid_22529];\n                    bool eta_p_21663 = ((__global bool *) mem_22834)[gtid_22529];\n                    int32_t zeze_lhs_21669 = ((__global int32_t *) mem_22849)[ii_21664];\n                    bool cond_21670 = zeze_lhs_21669 == -1;\n                    bool cond_21671 = zeze_lhs_21669 == 0;\n                    bool cond_21672 = zeze_lhs_21669 == 1;\n                    bool tmp_21673 = eta_p_21662 || eta_p_21663;\n                    bool lifted_lambda_res_f_res_f_res_f_res_21674 = !tmp_21673;\n                    bool x_21675 = !cond_21672;\n                    bool y_21676 = lifted_lambda_res_f_res_f_res_f_res_21674 && x_21675;\n                    bool x_21677 = eta_p_21662 && cond_21671;\n                    bool x_21678 = !co", "nd_21671;\n                    bool y_21679 = y_21676 && x_21678;\n                    bool lifted_lambda_res_f_res_21680 = x_21677 || y_21679;\n                    bool x_21681 = !cond_21670;\n                    bool y_21682 = lifted_lambda_res_f_res_21680 && x_21681;\n                    int64_t defunc_0_f_res_21683 = btoi_bool_i64(y_21682);\n                    \n                    ((__global int64_t *) mem_22854)[gtid_22529] = defunc_0_f_res_21683;\n                    private_mem_24026[i_24029] = defunc_0_f_res_21683;\n                } else {\n                    private_mem_24026[i_24029] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_24033 = 0; i_24033 < chunk_sizze_23992; i_24033++) {\n                int64_t sharedIdx_24034 = sext_i32_i64(local_tid_24004) + i_24033 * segscan_tblock_sizze_22525;\n                int64_t tmp_24035 = private_mem_24026[i_24033];\n                \n                ((__local int64_t *) local_mem_24011)[sharedIdx_24034] = tmp_24035;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_24036 = 0; i_24036 < chunk_sizze_23992; i_24036++) {\n                int64_t sharedIdx_24037 = sext_i32_i64(local_tid_24004) * chunk_sizze_23992 + i_24036;\n                int64_t tmp_24038 = ((__local int64_t *) local_mem_24011)[sharedIdx_24037];\n                \n                private_mem_24026[i_24036] = tmp_24038;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_24039 = 0; i_24039 < chunk_sizze_23992 - (int64_t) 1; i_24039++) {\n                int64_t eta_p_21293;\n                int64_t eta_p_21294;\n                \n                eta_p_21293 = private_mem_24026[i_24039];\n                eta_p_21294 = private_mem_24026[i_2", "4039 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_21295 = add64(eta_p_21293, eta_p_21294);\n                \n                private_mem_24026[i_24039 + (int64_t) 1] = defunc_0_op_res_21295;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_24040 = private_mem_24026[chunk_sizze_23992 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)] = tmp_24040;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_24041;\n            int64_t eta_p_24042;\n            int64_t eta_p_24045;\n            int64_t eta_p_24046;\n            bool ltid_in_bounds_24048 = slt64(sext_i32_i64(local_tid_24004), num_virt_threads_23994);\n            int32_t skip_threads_24049;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_24048) {\n                    eta_p_24042 = ((volatile __local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)];\n                    if ((local_tid_24004 - squot32(local_tid_24004, 32) * 32) == 0) {\n                        eta_p_24041 = eta_p_24042;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_24049 = 1;\n                while (slt32(skip_threads_24049, 32)) {\n                    bool thread_active_24050 = sle32(skip_threads_24049, local_tid_24004 - squot32(local_tid_24004, 32) * 32) && ltid_in_bounds_24048;\n                    \n                    if (thread_active_24050) {\n                        // read operands\n                        {\n                            eta_p_24041 = ((volatile __local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004) - sext_i32_i64(skip_threads_24049)];\n                        }\n                    }\n                    // perform operation\n                ",
                                    "    {\n                        if (thread_active_24050) {\n                            int64_t defunc_0_op_res_24043 = add64(eta_p_24041, eta_p_24042);\n                            \n                            eta_p_24041 = defunc_0_op_res_24043;\n                        }\n                    }\n                    if (sle32(wave_sizze_24006, skip_threads_24049)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_24050) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)] = eta_p_24041;\n                            eta_p_24042 = eta_p_24041;\n                        }\n                    }\n                    if (sle32(wave_sizze_24006, skip_threads_24049)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_24049 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_24004 - squot32(local_tid_24004, 32) * 32) == 31 && ltid_in_bounds_24048) {\n                    ((volatile __local int64_t *) local_mem_24011)[sext_i32_i64(squot32(local_tid_24004, 32))] = eta_p_24041;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_24051;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_24004, 32) == 0 && ltid_in_bounds_24048) {\n                        eta_p_24046 = ((volatile __local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)];\n                        if ((local_tid_24004 - squot32(local_tid_24004, 32) * 32) == 0) {\n                            eta_p_2404", "5 = eta_p_24046;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_24051 = 1;\n                    while (slt32(skip_threads_24051, 32)) {\n                        bool thread_active_24052 = sle32(skip_threads_24051, local_tid_24004 - squot32(local_tid_24004, 32) * 32) && (squot32(local_tid_24004, 32) == 0 && ltid_in_bounds_24048);\n                        \n                        if (thread_active_24052) {\n                            // read operands\n                            {\n                                eta_p_24045 = ((volatile __local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004) - sext_i32_i64(skip_threads_24051)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_24052) {\n                                int64_t defunc_0_op_res_24047 = add64(eta_p_24045, eta_p_24046);\n                                \n                                eta_p_24045 = defunc_0_op_res_24047;\n                            }\n                        }\n                        if (sle32(wave_sizze_24006, skip_threads_24051)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_24052) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)] = eta_p_24045;\n                                eta_p_24046 = eta_p_24045;\n                            }\n                        }\n                        if (sle32(wave_sizze_24006, skip_threads_24051)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_24051 *= 2;\n                    }\n                }\n            }\n   ", "         barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_24053 = squot32(local_tid_24004, 32) == 0 || !ltid_in_bounds_24048;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_24053) {\n                        eta_p_24042 = eta_p_24041;\n                        eta_p_24041 = ((__local int64_t *) local_mem_24011)[sext_i32_i64(squot32(local_tid_24004, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_24053) {\n                        int64_t defunc_0_op_res_24043 = add64(eta_p_24041, eta_p_24042);\n                        \n                        eta_p_24041 = defunc_0_op_res_24043;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_24053) {\n                        ((__local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)] = eta_p_24041;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_24004, 32) == 0 && ltid_in_bounds_24048) {\n                    ((__local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)] = eta_p_24042;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_24004 == 0) {\n                acc_24044 = ((__local int64_t *) local_mem_24011)[segscan_tblock_sizze_22525 - (int64_t) 1];\n            } else {\n                acc_24044 = ((__local int64_t *) local_mem_24011)[sext_i32_i64(local_tid_24004) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_24054 = (int64_t) 0;\n        block_new_sgm_24055 = sgm_idx_24023 == (int64_t) 0;\n        /",
                                    "/ Perform lookback\n        {\n            if (block_new_sgm_24055 && local_tid_24004 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_23999)[dynamic_id_24021] = acc_24044;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_23995)[dynamic_id_24021] = (int8_t) 2;\n                acc_24044 = (int64_t) 0;\n            }\n            if (!block_new_sgm_24055 && slt32(local_tid_24004, wave_sizze_24006)) {\n                if (local_tid_24004 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_23997)[dynamic_id_24021] = acc_24044;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_23995)[dynamic_id_24021] = (int8_t) 1;\n                    \n                    int8_t tmp_24056 = ((volatile __global int8_t *) status_flags_mem_23995)[dynamic_id_24021 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_24011)[(int64_t) 0] = tmp_24056;\n                }\n                mem_fence_local();\n                \n                int8_t status_24057 = ((__local int8_t *) local_mem_24011)[(int64_t) 0];\n                \n                if (status_24057 == (int8_t) 2) {\n                    if (local_tid_24004 == 0) {\n                        prefix_24054 = ((volatile __global int64_t *) incprefixes_mem_23999)[dynamic_id_24021 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_24058 = sext_i64_i32(dynamic_id_24021 - sext_i32_i64(wave_sizze_24006));\n                    \n                    while (slt32(wave_sizze_24006 * -1, readOffset_24058)) {\n                        int32_t read_i_24059 = readOffset_24058 + local_tid_24004;\n                        int64_t aggr_24060 = (int64_t) 0;\n                        int8_t flag_24061 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_24059)) {\n                            flag_24061 = ((", "volatile __global int8_t *) status_flags_mem_23995)[sext_i32_i64(read_i_24059)];\n                            if (flag_24061 == (int8_t) 2) {\n                                aggr_24060 = ((volatile __global int64_t *) incprefixes_mem_23999)[sext_i32_i64(read_i_24059)];\n                            } else if (flag_24061 == (int8_t) 1) {\n                                aggr_24060 = ((volatile __global int64_t *) aggregates_mem_23997)[sext_i32_i64(read_i_24059)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_24011)[(int64_t) 4 + sext_i32_i64(local_tid_24004)] = aggr_24060;\n                        ((__local int8_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)] = flag_24061;\n                        flag_24061 = ((__local int8_t *) local_mem_24011)[sext_i32_i64(wave_sizze_24006) - (int64_t) 1];\n                        if (slt8(flag_24061, (int8_t) 2)) {\n                            int8_t flg_x_24065;\n                            int8_t flg_y_24066;\n                            int64_t eta_p_24062;\n                            int64_t eta_p_24063;\n                            int32_t skip_threads_24067;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_24066 = ((volatile __local int8_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)];\n                                eta_p_24063 = ((volatile __local int64_t *) local_mem_24011)[(int64_t) 4 + sext_i32_i64(local_tid_24004)];\n                                if ((local_tid_24004 - squot32(local_tid_24004, 32) * 32) == 0) {\n                                    eta_p_24062 = eta_p_24063;\n                                    flg_x_24065 = flg_y_24066;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_24", "067 = 1;\n                                while (slt32(skip_threads_24067, 32)) {\n                                    if (sle32(skip_threads_24067, local_tid_24004 - squot32(local_tid_24004, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_24065 = ((volatile __local int8_t *) local_mem_24011)[sext_i32_i64(local_tid_24004) - sext_i32_i64(skip_threads_24067)];\n                                            eta_p_24062 = ((volatile __local int64_t *) local_mem_24011)[(int64_t) 4 + (sext_i32_i64(local_tid_24004) - sext_i32_i64(skip_threads_24067))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_24066 == (int8_t) 2 || flg_y_24066 == (int8_t) 0) {\n                                                flg_x_24065 = flg_y_24066;\n                                                eta_p_24062 = eta_p_24063;\n                                            } else {\n                                                int64_t defunc_0_op_res_24064 = add64(eta_p_24062, eta_p_24063);\n                                                \n                                                eta_p_24062 = defunc_0_op_res_24064;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_24011)[sext_i32_i64(local_tid_24004)] = flg_x_24065;\n                                            flg_y_24066 = flg_x_24065;\n                                            ((volatile __local int64_t *) local_mem_24011)[(int64_t) 4 + sext_i32_i64(local_tid_24004)] = eta_p_24062;\n                                            eta_p_24063 = eta_p_24062;\n                       ",
                                    "                 }\n                                    }\n                                    skip_threads_24067 *= 2;\n                                }\n                            }\n                        }\n                        flag_24061 = ((__local int8_t *) local_mem_24011)[sext_i32_i64(wave_sizze_24006) - (int64_t) 1];\n                        aggr_24060 = ((__local int64_t *) local_mem_24011)[(int64_t) 4 + (sext_i32_i64(wave_sizze_24006) - (int64_t) 1)];\n                        if (flag_24061 == (int8_t) 2) {\n                            readOffset_24058 = wave_sizze_24006 * -1;\n                        } else if (flag_24061 == (int8_t) 1) {\n                            readOffset_24058 -= wave_sizze_24006;\n                        }\n                        if (slt8((int8_t) 0, flag_24061)) {\n                            int64_t eta_p_24068 = aggr_24060;\n                            int64_t eta_p_24069 = prefix_24054;\n                            int64_t defunc_0_op_res_24070 = add64(eta_p_24068, eta_p_24069);\n                            \n                            prefix_24054 = defunc_0_op_res_24070;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_24004 == 0) {\n                    if (boundary_24024 == sext_i64_i32(segscan_tblock_sizze_22525 * chunk_sizze_23992)) {\n                        int64_t eta_p_24071 = prefix_24054;\n                        int64_t eta_p_24072 = acc_24044;\n                        int64_t defunc_0_op_res_24073 = add64(eta_p_24071, eta_p_24072);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_23999)[dynamic_id_24021] = defunc_0_op_res_24073;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_23995)[dynamic_id_24021] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_24011)[(int64_t) 4] = prefix_24054;\n    ", "                acc_24044 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_24021 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_24054 = ((__local int64_t *) local_mem_24011)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_24074;\n            int64_t eta_p_24075;\n            int64_t eta_p_24077 = prefix_24054;\n            int64_t eta_p_24078 = acc_24044;\n            \n            if (slt32(local_tid_24004 * chunk_sizze_32b_24008, boundary_24024) && !block_new_sgm_24055) {\n                int64_t defunc_0_op_res_24079 = add64(eta_p_24077, eta_p_24078);\n                \n                eta_p_24074 = defunc_0_op_res_24079;\n            } else {\n                eta_p_24074 = acc_24044;\n            }\n            \n            int32_t stopping_point_24080 = segsizze_compact_24025 - srem32(local_tid_24004 * chunk_sizze_32b_24008 - 1 + segsizze_compact_24025 - boundary_24024, segsizze_compact_24025);\n            \n            for (int64_t i_24081 = 0; i_24081 < chunk_sizze_23992; i_24081++) {\n                if (slt32(sext_i64_i32(i_24081), stopping_point_24080 - 1)) {\n                    eta_p_24075 = private_mem_24026[i_24081];\n                    \n                    int64_t defunc_0_op_res_24076 = add64(eta_p_24074, eta_p_24075);\n                    \n                    private_mem_24026[i_24081] = defunc_0_op_res_24076;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_24082 = 0; i_24082 < chunk_sizze_23992; i_24082++) {\n                int64_t sharedIdx_24083 = sext_i32_i64(local_tid_24004) * chunk_sizze_23992 + i_24082;\n                int64_t tmp_24084 = private_mem_24026[i_24082];\n                \n                ((__local int64_t *) local_mem_24011)[sharedIdx_24083] = tmp_24084;\n            }", "\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_24085 = 0; i_24085 < chunk_sizze_23992; i_24085++) {\n                int64_t flat_idx_24086 = thd_offset_24028 + i_24085 * segscan_tblock_sizze_22525;\n                int64_t slice_24087 = loop_dz2081Uz2089Uz2081U_21167;\n                int64_t gtid_22529 = flat_idx_24086;\n                int64_t remnant_24088 = flat_idx_24086 - gtid_22529;\n                \n                if (slt64(flat_idx_24086, loop_dz2081Uz2089Uz2081U_21167)) {\n                    int64_t tmp_24089 = ((__local int64_t *) local_mem_24011)[flat_idx_24086 - block_offset_24022];\n                    \n                    ((__global int64_t *) mem_22852)[gtid_22529] = tmp_24089;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_22525\n    #undef chunk_sizze_23992\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 131;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "human_regularzisegmap_22532_dim1";
        values[0] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22534;
    }
    {
        names[1] = "human_regularzisegmap_22532zisegmap_tblock_sizze_22535";
        values[1] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22534;
    }
    {
        names[2] = "human_regularzisegscan_22530_dim1";
        values[2] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22524;
    }
    {
        names[3] = "human_regularzisegscan_22530zisegscan_tblock_sizze_22525";
        values[3] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22524;
    }
    {
        names[4] = "human_regularzisegscan_22530zichunk_sizze_23992";
        values[4] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[5] = "human_regularzisegmap_22501_dim1";
        values[5] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22467;
    }
    {
        names[6] = "human_regularzisegmap_22501zisegmap_tblock_sizze_22494";
        values[6] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22467;
    }
    {
        names[7] = "human_regularzisegred_large_23889_dim1";
        values[7] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443;
    }
    {
        names[8] = "human_regularzisegred_large_23889ziseghist_tblock_sizze_22444";
        values[8] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443;
    }
    {
        names[9] = "human_regularzisegred_large_23889zichunk_sizze_23890";
        values[9] = (int64_t) 1;
    }
    {
        names[10] = "human_regularzisegred_small_23889_dim1";
        values[10] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443;
    }
    {
        names[11] = "human_regularzisegred_small_23889ziseghist_tblock_sizze_22444";
        values[11] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443;
    }
    {
        names[12] = "human_regularziseghist_global_22451_dim1";
        values[12] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443;
    }
    {
        names[13] = "human_regularziseghist_global_22451ziseghist_tblock_sizze_22444";
        values[13] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443;
    }
    {
        names[14] = "human_regularziseghist_local_22451_dim1";
        values[14] = ctx->max_thread_block_size;
    }
    {
        names[15] = "human_regularziseghist_local_22451zimax_tblock_sizze_23803";
        values[15] = ctx->max_thread_block_size;
    }
    {
        names[16] = "human_regularzisegmap_22431_dim1";
        values[16] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22410;
    }
    {
        names[17] = "human_regularzisegmap_22431zisegmap_tblock_sizze_22426";
        values[17] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22410;
    }
    {
        names[18] = "human_regularzisegmap_22395_dim1";
        values[18] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22374;
    }
    {
        names[19] = "human_regularzisegmap_22395zisegmap_tblock_sizze_22391";
        values[19] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22374;
    }
    {
        names[20] = "human_regularzisegscan_22370_dim1";
        values[20] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22364;
    }
    {
        names[21] = "human_regularzisegscan_22370zisegscan_tblock_sizze_22365";
        values[21] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22364;
    }
    {
        names[22] = "human_regularzisegscan_22370zichunk_sizze_23674";
        values[22] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[23] = "human_regularzisegmap_22356_dim1";
        values[23] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22358;
    }
    {
        names[24] = "human_regularzisegmap_22356zisegmap_tblock_sizze_22359";
        values[24] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22358;
    }
    {
        names[25] = "human_regularzisegscan_22354_dim1";
        values[25] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22348;
    }
    {
        names[26] = "human_regularzisegscan_22354zisegscan_tblock_sizze_22349";
        values[26] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22348;
    }
    {
        names[27] = "human_regularzisegscan_22354zichunk_sizze_23545";
        values[27] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[28] = "human_regularzisegmap_22326_dim1";
        values[28] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22293;
    }
    {
        names[29] = "human_regularzisegmap_22326zisegmap_tblock_sizze_22319";
        values[29] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22293;
    }
    {
        names[30] = "human_regularzisegred_large_23442_dim1";
        values[30] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269;
    }
    {
        names[31] = "human_regularzisegred_large_23442ziseghist_tblock_sizze_22270";
        values[31] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269;
    }
    {
        names[32] = "human_regularzisegred_large_23442zichunk_sizze_23443";
        values[32] = (int64_t) 1;
    }
    {
        names[33] = "human_regularzisegred_small_23442_dim1";
        values[33] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269;
    }
    {
        names[34] = "human_regularzisegred_small_23442ziseghist_tblock_sizze_22270";
        values[34] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269;
    }
    {
        names[35] = "human_regularziseghist_global_22277_dim1";
        values[35] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269;
    }
    {
        names[36] = "human_regularziseghist_global_22277ziseghist_tblock_sizze_22270";
        values[36] = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269;
    }
    {
        names[37] = "human_regularziseghist_local_22277_dim1";
        values[37] = ctx->max_thread_block_size;
    }
    {
        names[38] = "human_regularziseghist_local_22277zimax_tblock_sizze_23356";
        values[38] = ctx->max_thread_block_size;
    }
    {
        names[39] = "human_regularzisegmap_22257_dim1";
        values[39] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22236;
    }
    {
        names[40] = "human_regularzisegmap_22257zisegmap_tblock_sizze_22252";
        values[40] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22236;
    }
    {
        names[41] = "human_regularzisegmap_22218_dim1";
        values[41] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22194;
    }
    {
        names[42] = "human_regularzisegmap_22218zisegmap_tblock_sizze_22214";
        values[42] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22194;
    }
    {
        names[43] = "human_regularzisegscan_22190_dim1";
        values[43] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22184;
    }
    {
        names[44] = "human_regularzisegscan_22190zisegscan_tblock_sizze_22185";
        values[44] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22184;
    }
    {
        names[45] = "human_regularzisegscan_22190zichunk_sizze_23227";
        values[45] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[46] = "human_regularzisegscan_22182_dim1";
        values[46] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22176;
    }
    {
        names[47] = "human_regularzisegscan_22182zisegscan_tblock_sizze_22177";
        values[47] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22176;
    }
    {
        names[48] = "human_regularzisegscan_22182zichunk_sizze_23067";
        values[48] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[49] = "human_regularzisegmap_22168_dim1";
        values[49] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22170;
    }
    {
        names[50] = "human_regularzisegmap_22168zisegmap_tblock_sizze_22171";
        values[50] = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22170;
    }
    {
        names[51] = "human_regularzisegscan_22166_dim1";
        values[51] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22160;
    }
    {
        names[52] = "human_regularzisegscan_22166zisegscan_tblock_sizze_22161";
        values[52] = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22160;
    }
    {
        names[53] = "human_regularzisegscan_22166zichunk_sizze_22890";
        values[53] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[54] = "humanzisegmap_22152_dim1";
        values[54] = *ctx->tuning_params.humanzisegmap_tblock_sizze_22154;
    }
    {
        names[55] = "humanzisegmap_22152zisegmap_tblock_sizze_22155";
        values[55] = *ctx->tuning_params.humanzisegmap_tblock_sizze_22154;
    }
    {
        names[56] = "humanzisegscan_22150_dim1";
        values[56] = *ctx->tuning_params.humanzisegscan_tblock_sizze_22144;
    }
    {
        names[57] = "humanzisegscan_22150zisegscan_tblock_sizze_22145";
        values[57] = *ctx->tuning_params.humanzisegscan_tblock_sizze_22144;
    }
    {
        names[58] = "humanzisegscan_22150zichunk_sizze_23280";
        values[58] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[59] = "humanzisegmap_22117_dim1";
        values[59] = *ctx->tuning_params.humanzisegmap_tblock_sizze_22079;
    }
    {
        names[60] = "humanzisegmap_22117zisegmap_tblock_sizze_22110";
        values[60] = *ctx->tuning_params.humanzisegmap_tblock_sizze_22079;
    }
    {
        names[61] = "humanzisegred_large_23177_dim1";
        values[61] = *ctx->tuning_params.humanziseghist_tblock_sizze_22057;
    }
    {
        names[62] = "humanzisegred_large_23177ziseghist_tblock_sizze_22058";
        values[62] = *ctx->tuning_params.humanziseghist_tblock_sizze_22057;
    }
    {
        names[63] = "humanzisegred_large_23177zichunk_sizze_23178";
        values[63] = (int64_t) 1;
    }
    {
        names[64] = "humanzisegred_small_23177_dim1";
        values[64] = *ctx->tuning_params.humanziseghist_tblock_sizze_22057;
    }
    {
        names[65] = "humanzisegred_small_23177ziseghist_tblock_sizze_22058";
        values[65] = *ctx->tuning_params.humanziseghist_tblock_sizze_22057;
    }
    {
        names[66] = "humanziseghist_global_22065_dim1";
        values[66] = *ctx->tuning_params.humanziseghist_tblock_sizze_22057;
    }
    {
        names[67] = "humanziseghist_global_22065ziseghist_tblock_sizze_22058";
        values[67] = *ctx->tuning_params.humanziseghist_tblock_sizze_22057;
    }
    {
        names[68] = "humanziseghist_local_22065_dim1";
        values[68] = ctx->max_thread_block_size;
    }
    {
        names[69] = "humanziseghist_local_22065zimax_tblock_sizze_23091";
        values[69] = ctx->max_thread_block_size;
    }
    {
        names[70] = "humanzisegmap_22043_dim1";
        values[70] = *ctx->tuning_params.humanzisegmap_tblock_sizze_22020;
    }
    {
        names[71] = "humanzisegmap_22043zisegmap_tblock_sizze_22038";
        values[71] = *ctx->tuning_params.humanzisegmap_tblock_sizze_22020;
    }
    {
        names[72] = "humanzisegmap_22004_dim1";
        values[72] = *ctx->tuning_params.humanzisegmap_tblock_sizze_21982;
    }
    {
        names[73] = "humanzisegmap_22004zisegmap_tblock_sizze_22000";
        values[73] = *ctx->tuning_params.humanzisegmap_tblock_sizze_21982;
    }
    {
        names[74] = "humanzisegscan_21978_dim1";
        values[74] = *ctx->tuning_params.humanzisegscan_tblock_sizze_21972;
    }
    {
        names[75] = "humanzisegscan_21978zisegscan_tblock_sizze_21973";
        values[75] = *ctx->tuning_params.humanzisegscan_tblock_sizze_21972;
    }
    {
        names[76] = "humanzisegscan_21978zichunk_sizze_22922";
        values[76] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[77] = "compilerzisegmap_22757_dim1";
        values[77] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22759;
    }
    {
        names[78] = "compilerzisegmap_22757zisegmap_tblock_sizze_22760";
        values[78] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22759;
    }
    {
        names[79] = "compilerzisegscan_22755_dim1";
        values[79] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22749;
    }
    {
        names[80] = "compilerzisegscan_22755zisegscan_tblock_sizze_22750";
        values[80] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22749;
    }
    {
        names[81] = "compilerzisegscan_22755zichunk_sizze_24032";
        values[81] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[82] = "compilerzisegmap_22727_dim1";
        values[82] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22694;
    }
    {
        names[83] = "compilerzisegmap_22727zisegmap_tblock_sizze_22720";
        values[83] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22694;
    }
    {
        names[84] = "compilerzisegred_large_23944_dim1";
        values[84] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22676;
    }
    {
        names[85] = "compilerzisegred_large_23944ziseghist_tblock_sizze_22677";
        values[85] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22676;
    }
    {
        names[86] = "compilerzisegred_large_23944zichunk_sizze_23945";
        values[86] = (int64_t) 1;
    }
    {
        names[87] = "compilerzisegred_small_23944_dim1";
        values[87] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22676;
    }
    {
        names[88] = "compilerzisegred_small_23944ziseghist_tblock_sizze_22677";
        values[88] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22676;
    }
    {
        names[89] = "compilerziseghist_global_22684_dim1";
        values[89] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22676;
    }
    {
        names[90] = "compilerziseghist_global_22684ziseghist_tblock_sizze_22677";
        values[90] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22676;
    }
    {
        names[91] = "compilerziseghist_local_22684_dim1";
        values[91] = ctx->max_thread_block_size;
    }
    {
        names[92] = "compilerziseghist_local_22684zimax_tblock_sizze_23868";
        values[92] = ctx->max_thread_block_size;
    }
    {
        names[93] = "compilerzisegred_large_23783_dim1";
        values[93] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22660;
    }
    {
        names[94] = "compilerzisegred_large_23783ziseghist_tblock_sizze_22661";
        values[94] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22660;
    }
    {
        names[95] = "compilerzisegred_large_23783zichunk_sizze_23784";
        values[95] = (int64_t) 1;
    }
    {
        names[96] = "compilerzisegred_small_23783_dim1";
        values[96] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22660;
    }
    {
        names[97] = "compilerzisegred_small_23783ziseghist_tblock_sizze_22661";
        values[97] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22660;
    }
    {
        names[98] = "compilerziseghist_global_22668_dim1";
        values[98] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22660;
    }
    {
        names[99] = "compilerziseghist_global_22668ziseghist_tblock_sizze_22661";
        values[99] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22660;
    }
    {
        names[100] = "compilerziseghist_local_22668_dim1";
        values[100] = ctx->max_thread_block_size;
    }
    {
        names[101] = "compilerziseghist_local_22668zimax_tblock_sizze_23707";
        values[101] = ctx->max_thread_block_size;
    }
    {
        names[102] = "compilerzisegred_large_23622_dim1";
        values[102] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22644;
    }
    {
        names[103] = "compilerzisegred_large_23622ziseghist_tblock_sizze_22645";
        values[103] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22644;
    }
    {
        names[104] = "compilerzisegred_large_23622zichunk_sizze_23623";
        values[104] = (int64_t) 1;
    }
    {
        names[105] = "compilerzisegred_small_23622_dim1";
        values[105] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22644;
    }
    {
        names[106] = "compilerzisegred_small_23622ziseghist_tblock_sizze_22645";
        values[106] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22644;
    }
    {
        names[107] = "compilerziseghist_global_22652_dim1";
        values[107] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22644;
    }
    {
        names[108] = "compilerziseghist_global_22652ziseghist_tblock_sizze_22645";
        values[108] = *ctx->tuning_params.compilerziseghist_tblock_sizze_22644;
    }
    {
        names[109] = "compilerziseghist_local_22652_dim1";
        values[109] = ctx->max_thread_block_size;
    }
    {
        names[110] = "compilerziseghist_local_22652zimax_tblock_sizze_23546";
        values[110] = ctx->max_thread_block_size;
    }
    {
        names[111] = "compilerzisegmap_22636_dim1";
        values[111] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22638;
    }
    {
        names[112] = "compilerzisegmap_22636zisegmap_tblock_sizze_22639";
        values[112] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22638;
    }
    {
        names[113] = "compilerzisegscan_22634_dim1";
        values[113] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22628;
    }
    {
        names[114] = "compilerzisegscan_22634zisegscan_tblock_sizze_22629";
        values[114] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22628;
    }
    {
        names[115] = "compilerzisegscan_22634zichunk_sizze_23323";
        values[115] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[116] = "compilerzisegmap_22615_dim1";
        values[116] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22594;
    }
    {
        names[117] = "compilerzisegmap_22615zisegmap_tblock_sizze_22611";
        values[117] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22594;
    }
    {
        names[118] = "compilerzisegscan_22590_dim1";
        values[118] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22584;
    }
    {
        names[119] = "compilerzisegscan_22590zisegscan_tblock_sizze_22585";
        values[119] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22584;
    }
    {
        names[120] = "compilerzisegscan_22590zichunk_sizze_23211";
        values[120] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[121] = "compilerzisegmap_22579_dim1";
        values[121] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22566;
    }
    {
        names[122] = "compilerzisegmap_22579zisegmap_tblock_sizze_22575";
        values[122] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22566;
    }
    {
        names[123] = "compilerzisegscan_22562_dim1";
        values[123] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22556;
    }
    {
        names[124] = "compilerzisegscan_22562zisegscan_tblock_sizze_22557";
        values[124] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22556;
    }
    {
        names[125] = "compilerzisegscan_22562zichunk_sizze_23087";
        values[125] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[126] = "compilerzisegmap_22548_dim1";
        values[126] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22550;
    }
    {
        names[127] = "compilerzisegmap_22548zisegmap_tblock_sizze_22551";
        values[127] = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22550;
    }
    {
        names[128] = "compilerzisegscan_22546_dim1";
        values[128] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22540;
    }
    {
        names[129] = "compilerzisegscan_22546zisegscan_tblock_sizze_22541";
        values[129] = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22540;
    }
    {
        names[130] = "compilerzisegscan_22546zichunk_sizze_22910";
        values[130] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  compiler.fut:19:35-45\n   #1  compiler.fut:19:48-55\n   #2  auto_test.fut:14:18-42\n   #3  auto_test.fut:14:1-42\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  compiler.fut:4:33-39\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  compiler.fut:4:42-43\n   #4  auto_test.fut:14:18-42\n   #5  auto_test.fut:14:1-42\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  compiler.fut:75:33-42\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  auto_test.fut:14:18-42\n   #5  auto_test.fut:14:1-42\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human.fut:20:33-46\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  auto_test.fut:8:15-36\n   #4  auto_test.fut:8:1-36\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human.fut:43:53-63\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  auto_test.fut:8:15-36\n   #4  auto_test.fut:8:1-36\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human.fut:107:42-51\n   #1  human.fut:107:53-56\n   #2  auto_test.fut:8:15-36\n   #3  auto_test.fut:8:1-36\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_regular.fut:11:62-71\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  auto_test.fut:9:23-52\n   #4  auto_test.fut:9:1-52\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_regular.fut:17:41-47\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  auto_test.fut:9:23-52\n   #4  auto_test.fut:9:1-52\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_regular.fut:62:29-38\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  auto_test.fut:9:23-52\n   #5  auto_test.fut:9:1-52\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_regular.fut:74:39-49\n   #1  human_regular.fut:74:52-59\n   #2  auto_test.fut:9:23-52\n   #3  auto_test.fut:9:1-52\n", args[0], args[1]);
            break;
        }
        
      case 10:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_regular.fut:75:49-55\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  auto_test.fut:9:23-52\n   #4  auto_test.fut:9:1-52\n", args[0], args[1]);
            break;
        }
        
      case 11:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_regular.fut:122:37-46\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  auto_test.fut:9:23-52\n   #5  auto_test.fut:9:1-52\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhreplicate_boolzireplicate_23053;
    gpu_kernel builtinzhreplicate_f32zireplicate_22890;
    gpu_kernel builtinzhreplicate_i32zireplicate_22946;
    gpu_kernel builtinzhreplicate_i8zireplicate_22920;
    gpu_kernel compilerziseghist_global_22652;
    gpu_kernel compilerziseghist_global_22668;
    gpu_kernel compilerziseghist_global_22684;
    gpu_kernel compilerziseghist_local_22652;
    gpu_kernel compilerziseghist_local_22668;
    gpu_kernel compilerziseghist_local_22684;
    gpu_kernel compilerzisegmap_22548;
    gpu_kernel compilerzisegmap_22579;
    gpu_kernel compilerzisegmap_22615;
    gpu_kernel compilerzisegmap_22636;
    gpu_kernel compilerzisegmap_22727;
    gpu_kernel compilerzisegmap_22757;
    gpu_kernel compilerzisegred_large_23622;
    gpu_kernel compilerzisegred_large_23783;
    gpu_kernel compilerzisegred_large_23944;
    gpu_kernel compilerzisegred_small_23622;
    gpu_kernel compilerzisegred_small_23783;
    gpu_kernel compilerzisegred_small_23944;
    gpu_kernel compilerzisegscan_22546;
    gpu_kernel compilerzisegscan_22562;
    gpu_kernel compilerzisegscan_22590;
    gpu_kernel compilerzisegscan_22634;
    gpu_kernel compilerzisegscan_22755;
    gpu_kernel humanziseghist_global_22065;
    gpu_kernel humanziseghist_local_22065;
    gpu_kernel humanzisegmap_22004;
    gpu_kernel humanzisegmap_22043;
    gpu_kernel humanzisegmap_22117;
    gpu_kernel humanzisegmap_22152;
    gpu_kernel humanzisegred_large_23177;
    gpu_kernel humanzisegred_small_23177;
    gpu_kernel humanzisegscan_21978;
    gpu_kernel humanzisegscan_22150;
    gpu_kernel human_regularziseghist_global_22277;
    gpu_kernel human_regularziseghist_global_22451;
    gpu_kernel human_regularziseghist_local_22277;
    gpu_kernel human_regularziseghist_local_22451;
    gpu_kernel human_regularzisegmap_22168;
    gpu_kernel human_regularzisegmap_22218;
    gpu_kernel human_regularzisegmap_22257;
    gpu_kernel human_regularzisegmap_22326;
    gpu_kernel human_regularzisegmap_22356;
    gpu_kernel human_regularzisegmap_22395;
    gpu_kernel human_regularzisegmap_22431;
    gpu_kernel human_regularzisegmap_22501;
    gpu_kernel human_regularzisegmap_22532;
    gpu_kernel human_regularzisegred_large_23442;
    gpu_kernel human_regularzisegred_large_23889;
    gpu_kernel human_regularzisegred_small_23442;
    gpu_kernel human_regularzisegred_small_23889;
    gpu_kernel human_regularzisegscan_22166;
    gpu_kernel human_regularzisegscan_22182;
    gpu_kernel human_regularzisegscan_22190;
    gpu_kernel human_regularzisegscan_22354;
    gpu_kernel human_regularzisegscan_22370;
    gpu_kernel human_regularzisegscan_22530;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_boolzireplicate_23053, "builtinzhreplicate_boolzireplicate_23053");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_f32zireplicate_22890, "builtinzhreplicate_f32zireplicate_22890");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_22946, "builtinzhreplicate_i32zireplicate_22946");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_22920, "builtinzhreplicate_i8zireplicate_22920");
    gpu_create_kernel(ctx, &ctx->program->compilerziseghist_global_22652, "compilerziseghist_global_22652");
    gpu_create_kernel(ctx, &ctx->program->compilerziseghist_global_22668, "compilerziseghist_global_22668");
    gpu_create_kernel(ctx, &ctx->program->compilerziseghist_global_22684, "compilerziseghist_global_22684");
    gpu_create_kernel(ctx, &ctx->program->compilerziseghist_local_22652, "compilerziseghist_local_22652");
    gpu_create_kernel(ctx, &ctx->program->compilerziseghist_local_22668, "compilerziseghist_local_22668");
    gpu_create_kernel(ctx, &ctx->program->compilerziseghist_local_22684, "compilerziseghist_local_22684");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegmap_22548, "compilerzisegmap_22548");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegmap_22579, "compilerzisegmap_22579");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegmap_22615, "compilerzisegmap_22615");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegmap_22636, "compilerzisegmap_22636");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegmap_22727, "compilerzisegmap_22727");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegmap_22757, "compilerzisegmap_22757");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegred_large_23622, "compilerzisegred_large_23622");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegred_large_23783, "compilerzisegred_large_23783");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegred_large_23944, "compilerzisegred_large_23944");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegred_small_23622, "compilerzisegred_small_23622");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegred_small_23783, "compilerzisegred_small_23783");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegred_small_23944, "compilerzisegred_small_23944");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegscan_22546, "compilerzisegscan_22546");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegscan_22562, "compilerzisegscan_22562");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegscan_22590, "compilerzisegscan_22590");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegscan_22634, "compilerzisegscan_22634");
    gpu_create_kernel(ctx, &ctx->program->compilerzisegscan_22755, "compilerzisegscan_22755");
    gpu_create_kernel(ctx, &ctx->program->humanziseghist_global_22065, "humanziseghist_global_22065");
    gpu_create_kernel(ctx, &ctx->program->humanziseghist_local_22065, "humanziseghist_local_22065");
    gpu_create_kernel(ctx, &ctx->program->humanzisegmap_22004, "humanzisegmap_22004");
    gpu_create_kernel(ctx, &ctx->program->humanzisegmap_22043, "humanzisegmap_22043");
    gpu_create_kernel(ctx, &ctx->program->humanzisegmap_22117, "humanzisegmap_22117");
    gpu_create_kernel(ctx, &ctx->program->humanzisegmap_22152, "humanzisegmap_22152");
    gpu_create_kernel(ctx, &ctx->program->humanzisegred_large_23177, "humanzisegred_large_23177");
    gpu_create_kernel(ctx, &ctx->program->humanzisegred_small_23177, "humanzisegred_small_23177");
    gpu_create_kernel(ctx, &ctx->program->humanzisegscan_21978, "humanzisegscan_21978");
    gpu_create_kernel(ctx, &ctx->program->humanzisegscan_22150, "humanzisegscan_22150");
    gpu_create_kernel(ctx, &ctx->program->human_regularziseghist_global_22277, "human_regularziseghist_global_22277");
    gpu_create_kernel(ctx, &ctx->program->human_regularziseghist_global_22451, "human_regularziseghist_global_22451");
    gpu_create_kernel(ctx, &ctx->program->human_regularziseghist_local_22277, "human_regularziseghist_local_22277");
    gpu_create_kernel(ctx, &ctx->program->human_regularziseghist_local_22451, "human_regularziseghist_local_22451");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22168, "human_regularzisegmap_22168");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22218, "human_regularzisegmap_22218");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22257, "human_regularzisegmap_22257");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22326, "human_regularzisegmap_22326");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22356, "human_regularzisegmap_22356");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22395, "human_regularzisegmap_22395");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22431, "human_regularzisegmap_22431");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22501, "human_regularzisegmap_22501");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegmap_22532, "human_regularzisegmap_22532");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegred_large_23442, "human_regularzisegred_large_23442");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegred_large_23889, "human_regularzisegred_large_23889");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegred_small_23442, "human_regularzisegred_small_23442");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegred_small_23889, "human_regularzisegred_small_23889");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegscan_22166, "human_regularzisegscan_22166");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegscan_22182, "human_regularzisegscan_22182");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegscan_22190, "human_regularzisegscan_22190");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegscan_22354, "human_regularzisegscan_22354");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegscan_22370, "human_regularzisegscan_22370");
    gpu_create_kernel(ctx, &ctx->program->human_regularzisegscan_22530, "human_regularzisegscan_22530");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_boolzireplicate_23053);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_f32zireplicate_22890);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_22946);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_22920);
    gpu_free_kernel(ctx, ctx->program->compilerziseghist_global_22652);
    gpu_free_kernel(ctx, ctx->program->compilerziseghist_global_22668);
    gpu_free_kernel(ctx, ctx->program->compilerziseghist_global_22684);
    gpu_free_kernel(ctx, ctx->program->compilerziseghist_local_22652);
    gpu_free_kernel(ctx, ctx->program->compilerziseghist_local_22668);
    gpu_free_kernel(ctx, ctx->program->compilerziseghist_local_22684);
    gpu_free_kernel(ctx, ctx->program->compilerzisegmap_22548);
    gpu_free_kernel(ctx, ctx->program->compilerzisegmap_22579);
    gpu_free_kernel(ctx, ctx->program->compilerzisegmap_22615);
    gpu_free_kernel(ctx, ctx->program->compilerzisegmap_22636);
    gpu_free_kernel(ctx, ctx->program->compilerzisegmap_22727);
    gpu_free_kernel(ctx, ctx->program->compilerzisegmap_22757);
    gpu_free_kernel(ctx, ctx->program->compilerzisegred_large_23622);
    gpu_free_kernel(ctx, ctx->program->compilerzisegred_large_23783);
    gpu_free_kernel(ctx, ctx->program->compilerzisegred_large_23944);
    gpu_free_kernel(ctx, ctx->program->compilerzisegred_small_23622);
    gpu_free_kernel(ctx, ctx->program->compilerzisegred_small_23783);
    gpu_free_kernel(ctx, ctx->program->compilerzisegred_small_23944);
    gpu_free_kernel(ctx, ctx->program->compilerzisegscan_22546);
    gpu_free_kernel(ctx, ctx->program->compilerzisegscan_22562);
    gpu_free_kernel(ctx, ctx->program->compilerzisegscan_22590);
    gpu_free_kernel(ctx, ctx->program->compilerzisegscan_22634);
    gpu_free_kernel(ctx, ctx->program->compilerzisegscan_22755);
    gpu_free_kernel(ctx, ctx->program->humanziseghist_global_22065);
    gpu_free_kernel(ctx, ctx->program->humanziseghist_local_22065);
    gpu_free_kernel(ctx, ctx->program->humanzisegmap_22004);
    gpu_free_kernel(ctx, ctx->program->humanzisegmap_22043);
    gpu_free_kernel(ctx, ctx->program->humanzisegmap_22117);
    gpu_free_kernel(ctx, ctx->program->humanzisegmap_22152);
    gpu_free_kernel(ctx, ctx->program->humanzisegred_large_23177);
    gpu_free_kernel(ctx, ctx->program->humanzisegred_small_23177);
    gpu_free_kernel(ctx, ctx->program->humanzisegscan_21978);
    gpu_free_kernel(ctx, ctx->program->humanzisegscan_22150);
    gpu_free_kernel(ctx, ctx->program->human_regularziseghist_global_22277);
    gpu_free_kernel(ctx, ctx->program->human_regularziseghist_global_22451);
    gpu_free_kernel(ctx, ctx->program->human_regularziseghist_local_22277);
    gpu_free_kernel(ctx, ctx->program->human_regularziseghist_local_22451);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22168);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22218);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22257);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22326);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22356);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22395);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22431);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22501);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegmap_22532);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegred_large_23442);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegred_large_23889);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegred_small_23442);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegred_small_23889);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegscan_22166);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegscan_22182);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegscan_22190);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegscan_22354);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegscan_22370);
    gpu_free_kernel(ctx, ctx->program->human_regularzisegscan_22530);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhreplicate_boolzitblock_sizze_23057 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_f32zitblock_sizze_22894 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_22950 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_22924 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.compilerzihist_L2_23598 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.compilerzihist_L2_23759 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.compilerzihist_L2_23920 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.compilerzihist_L_23545 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.compilerzihist_L_23706 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.compilerzihist_L_23867 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.compilerziseghist_num_tblocks_22646 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.compilerziseghist_num_tblocks_22662 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.compilerziseghist_num_tblocks_22678 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.compilerziseghist_tblock_sizze_22644 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.compilerziseghist_tblock_sizze_22660 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.compilerziseghist_tblock_sizze_22676 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.compilerzisegmap_num_tblocks_22552 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.compilerzisegmap_num_tblocks_22640 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.compilerzisegmap_num_tblocks_22761 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.compilerzisegmap_tblock_sizze_22550 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.compilerzisegmap_tblock_sizze_22566 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.compilerzisegmap_tblock_sizze_22594 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.compilerzisegmap_tblock_sizze_22638 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.compilerzisegmap_tblock_sizze_22694 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.compilerzisegmap_tblock_sizze_22759 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.compilerzisegscan_num_tblocks_22542 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.compilerzisegscan_num_tblocks_22558 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.compilerzisegscan_num_tblocks_22586 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.compilerzisegscan_num_tblocks_22630 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.compilerzisegscan_num_tblocks_22751 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.compilerzisegscan_tblock_sizze_22540 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.compilerzisegscan_tblock_sizze_22556 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.compilerzisegscan_tblock_sizze_22584 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.compilerzisegscan_tblock_sizze_22628 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.compilerzisegscan_tblock_sizze_22749 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.humanzihist_L2_23152 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.humanzihist_L_23090 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.humanziseghist_num_tblocks_22059 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.humanziseghist_tblock_sizze_22057 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.humanzisegmap_num_tblocks_22156 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.humanzisegmap_tblock_sizze_21982 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.humanzisegmap_tblock_sizze_22020 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.humanzisegmap_tblock_sizze_22079 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.humanzisegmap_tblock_sizze_22154 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.humanzisegscan_num_tblocks_21974 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.humanzisegscan_num_tblocks_22146 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.humanzisegscan_tblock_sizze_21972 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.humanzisegscan_tblock_sizze_22144 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.human_regularzihist_L2_23417 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.human_regularzihist_L2_23864 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.human_regularzihist_L_23355 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.human_regularzihist_L_23802 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.human_regularziseghist_num_tblocks_22271 = &ctx->cfg->tuning_params[52];
    ctx->tuning_params.human_regularziseghist_num_tblocks_22445 = &ctx->cfg->tuning_params[53];
    ctx->tuning_params.human_regularziseghist_tblock_sizze_22269 = &ctx->cfg->tuning_params[54];
    ctx->tuning_params.human_regularziseghist_tblock_sizze_22443 = &ctx->cfg->tuning_params[55];
    ctx->tuning_params.human_regularzisegmap_num_tblocks_22172 = &ctx->cfg->tuning_params[56];
    ctx->tuning_params.human_regularzisegmap_num_tblocks_22360 = &ctx->cfg->tuning_params[57];
    ctx->tuning_params.human_regularzisegmap_num_tblocks_22536 = &ctx->cfg->tuning_params[58];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22170 = &ctx->cfg->tuning_params[59];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22194 = &ctx->cfg->tuning_params[60];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22236 = &ctx->cfg->tuning_params[61];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22293 = &ctx->cfg->tuning_params[62];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22358 = &ctx->cfg->tuning_params[63];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22374 = &ctx->cfg->tuning_params[64];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22410 = &ctx->cfg->tuning_params[65];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22467 = &ctx->cfg->tuning_params[66];
    ctx->tuning_params.human_regularzisegmap_tblock_sizze_22534 = &ctx->cfg->tuning_params[67];
    ctx->tuning_params.human_regularzisegscan_num_tblocks_22162 = &ctx->cfg->tuning_params[68];
    ctx->tuning_params.human_regularzisegscan_num_tblocks_22178 = &ctx->cfg->tuning_params[69];
    ctx->tuning_params.human_regularzisegscan_num_tblocks_22186 = &ctx->cfg->tuning_params[70];
    ctx->tuning_params.human_regularzisegscan_num_tblocks_22350 = &ctx->cfg->tuning_params[71];
    ctx->tuning_params.human_regularzisegscan_num_tblocks_22366 = &ctx->cfg->tuning_params[72];
    ctx->tuning_params.human_regularzisegscan_num_tblocks_22526 = &ctx->cfg->tuning_params[73];
    ctx->tuning_params.human_regularzisegscan_tblock_sizze_22160 = &ctx->cfg->tuning_params[74];
    ctx->tuning_params.human_regularzisegscan_tblock_sizze_22176 = &ctx->cfg->tuning_params[75];
    ctx->tuning_params.human_regularzisegscan_tblock_sizze_22184 = &ctx->cfg->tuning_params[76];
    ctx->tuning_params.human_regularzisegscan_tblock_sizze_22348 = &ctx->cfg->tuning_params[77];
    ctx->tuning_params.human_regularzisegscan_tblock_sizze_22364 = &ctx->cfg->tuning_params[78];
    ctx->tuning_params.human_regularzisegscan_tblock_sizze_22524 = &ctx->cfg->tuning_params[79];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_23048, int64_t num_elems_23049, bool val_23050);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f32(struct futhark_context *ctx, struct memblock_device mem_22885, int64_t num_elems_22886, float val_22887);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_22941, int64_t num_elems_22942, int32_t val_22943);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_22915, int64_t num_elems_22916, int8_t val_22917);
FUTHARK_FUN_ATTR int futrts_entry_compiler(struct futhark_context *ctx, struct memblock_device *mem_out_p_24144, struct memblock_device ks_mem_22766, struct memblock_device shp_mem_22767, struct memblock_device A_mem_22768, int64_t mz2080U_19405, int64_t nz2081U_19406);
FUTHARK_FUN_ATTR int futrts_entry_human(struct futhark_context *ctx, struct memblock_device *mem_out_p_24149, struct memblock_device ks_mem_22766, struct memblock_device shp_mem_22767, struct memblock_device II1_mem_22768, struct memblock_device A_mem_22769, int64_t mz2080U_14093, int64_t nz2081U_14094);
FUTHARK_FUN_ATTR int futrts_entry_human_regular(struct futhark_context *ctx, struct memblock_device *mem_out_p_24151, struct memblock_device ks_mem_22766, struct memblock_device shp_mem_22767, struct memblock_device II1_mem_22768, struct memblock_device A_mem_22769, int64_t mz2080U_17317, int64_t nz2081U_17318);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_23223 (ctx->constants->counters_mem_23223)
    #define counters_mem_23488 (ctx->constants->counters_mem_23488)
    #define counters_mem_23659 (ctx->constants->counters_mem_23659)
    #define counters_mem_23820 (ctx->constants->counters_mem_23820)
    #define counters_mem_23935 (ctx->constants->counters_mem_23935)
    #define counters_mem_23981 (ctx->constants->counters_mem_23981)
    #define global_dynid_mem_22919 (ctx->constants->global_dynid_mem_22919)
    #define global_dynid_mem_22939 (ctx->constants->global_dynid_mem_22939)
    #define global_dynid_mem_22951 (ctx->constants->global_dynid_mem_22951)
    #define global_dynid_mem_23080 (ctx->constants->global_dynid_mem_23080)
    #define global_dynid_mem_23096 (ctx->constants->global_dynid_mem_23096)
    #define global_dynid_mem_23220 (ctx->constants->global_dynid_mem_23220)
    #define global_dynid_mem_23236 (ctx->constants->global_dynid_mem_23236)
    #define global_dynid_mem_23289 (ctx->constants->global_dynid_mem_23289)
    #define global_dynid_mem_23340 (ctx->constants->global_dynid_mem_23340)
    #define global_dynid_mem_23554 (ctx->constants->global_dynid_mem_23554)
    #define global_dynid_mem_23683 (ctx->constants->global_dynid_mem_23683)
    #define global_dynid_mem_24001 (ctx->constants->global_dynid_mem_24001)
    #define global_dynid_mem_24041 (ctx->constants->global_dynid_mem_24041)
    counters_mem_23223.references = NULL;
    counters_mem_23488.references = NULL;
    counters_mem_23659.references = NULL;
    counters_mem_23820.references = NULL;
    counters_mem_23935.references = NULL;
    counters_mem_23981.references = NULL;
    global_dynid_mem_22919.references = NULL;
    global_dynid_mem_22939.references = NULL;
    global_dynid_mem_22951.references = NULL;
    global_dynid_mem_23080.references = NULL;
    global_dynid_mem_23096.references = NULL;
    global_dynid_mem_23220.references = NULL;
    global_dynid_mem_23236.references = NULL;
    global_dynid_mem_23289.references = NULL;
    global_dynid_mem_23340.references = NULL;
    global_dynid_mem_23554.references = NULL;
    global_dynid_mem_23683.references = NULL;
    global_dynid_mem_24001.references = NULL;
    global_dynid_mem_24041.references = NULL;
    if (memblock_alloc_device(ctx, &global_dynid_mem_22951, (int64_t) 4, "global_dynid_mem_22951")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_22951, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23223, (int64_t) 81920, "counters_mem_23223")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23223, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_23289, (int64_t) 4, "global_dynid_mem_23289")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_23289, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_22919, (int64_t) 4, "global_dynid_mem_22919")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_22919, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_23080, (int64_t) 4, "global_dynid_mem_23080")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_23080, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_23236, (int64_t) 4, "global_dynid_mem_23236")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_23236, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23488, (int64_t) 81920, "counters_mem_23488")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23488, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_23554, (int64_t) 4, "global_dynid_mem_23554")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_23554, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_23683, (int64_t) 4, "global_dynid_mem_23683")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_23683, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23935, (int64_t) 81920, "counters_mem_23935")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23935, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_24001, (int64_t) 4, "global_dynid_mem_24001")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_24001, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_22939, (int64_t) 4, "global_dynid_mem_22939")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_22939, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_23096, (int64_t) 4, "global_dynid_mem_23096")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_23096, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_23220, (int64_t) 4, "global_dynid_mem_23220")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_23220, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_23340, (int64_t) 4, "global_dynid_mem_23340")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_23340, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23659, (int64_t) 81920, "counters_mem_23659")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23659, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23820, (int64_t) 81920, "counters_mem_23820")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23820, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_23981, (int64_t) 81920, "counters_mem_23981")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_23981, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_24041, (int64_t) 4, "global_dynid_mem_24041")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_24041, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_23223
    #undef counters_mem_23488
    #undef counters_mem_23659
    #undef counters_mem_23820
    #undef counters_mem_23935
    #undef counters_mem_23981
    #undef global_dynid_mem_22919
    #undef global_dynid_mem_22939
    #undef global_dynid_mem_22951
    #undef global_dynid_mem_23080
    #undef global_dynid_mem_23096
    #undef global_dynid_mem_23220
    #undef global_dynid_mem_23236
    #undef global_dynid_mem_23289
    #undef global_dynid_mem_23340
    #undef global_dynid_mem_23554
    #undef global_dynid_mem_23683
    #undef global_dynid_mem_24001
    #undef global_dynid_mem_24041
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23223, "ctx->constants->counters_mem_23223") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23488, "ctx->constants->counters_mem_23488") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23659, "ctx->constants->counters_mem_23659") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23820, "ctx->constants->counters_mem_23820") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23935, "ctx->constants->counters_mem_23935") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_23981, "ctx->constants->counters_mem_23981") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_22919, "ctx->constants->global_dynid_mem_22919") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_22939, "ctx->constants->global_dynid_mem_22939") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_22951, "ctx->constants->global_dynid_mem_22951") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_23080, "ctx->constants->global_dynid_mem_23080") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_23096, "ctx->constants->global_dynid_mem_23096") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_23220, "ctx->constants->global_dynid_mem_23220") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_23236, "ctx->constants->global_dynid_mem_23236") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_23289, "ctx->constants->global_dynid_mem_23289") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_23340, "ctx->constants->global_dynid_mem_23340") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_23554, "ctx->constants->global_dynid_mem_23554") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_23683, "ctx->constants->global_dynid_mem_23683") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_24001, "ctx->constants->global_dynid_mem_24001") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_24041, "ctx->constants->global_dynid_mem_24041") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhreplicate_boolzireplicate_23053(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, bool arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_boolzireplicate_23053, "builtin#replicate_bool.replicate_23053", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_f32zireplicate_22890(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, float arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_f32zireplicate_22890, "builtin#replicate_f32.replicate_22890", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_22946(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_22946, "builtin#replicate_i32.replicate_22946", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_22920(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_22920, "builtin#replicate_i8.replicate_22920", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegscan_22546(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegscan_22546, "compiler.segscan_22546", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegmap_22548(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegmap_22548, "compiler.segmap_22548", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegscan_22562(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegscan_22562, "compiler.segscan_22562", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegmap_22579(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegmap_22579, "compiler.segmap_22579", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegscan_22590(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegscan_22590, "compiler.segscan_22590", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegmap_22615(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegmap_22615, "compiler.segmap_22615", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegscan_22634(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17, gpu_mem arg18, gpu_mem arg19, gpu_mem arg20, gpu_mem arg21)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[25] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17, &arg18, &arg19, &arg20, &arg21};
        size_t args_sizes[25] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17), sizeof(arg18), sizeof(arg19), sizeof(arg20), sizeof(arg21)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegscan_22634, "compiler.segscan_22634", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 25, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegmap_22636(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int32_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[17] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15};
        size_t args_sizes[17] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegmap_22636, "compiler.segmap_22636", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 17, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerziseghist_local_22652(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerziseghist_local_22652, "compiler.seghist_local_22652", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerziseghist_global_22652(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerziseghist_global_22652, "compiler.seghist_global_22652", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegred_small_23622(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegred_small_23622, "compiler.segred_small_23622", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegred_large_23622(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegred_large_23622, "compiler.segred_large_23622", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerziseghist_local_22668(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerziseghist_local_22668, "compiler.seghist_local_22668", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerziseghist_global_22668(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerziseghist_global_22668, "compiler.seghist_global_22668", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegred_small_23783(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegred_small_23783, "compiler.segred_small_23783", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegred_large_23783(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegred_large_23783, "compiler.segred_large_23783", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerziseghist_local_22684(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerziseghist_local_22684, "compiler.seghist_local_22684", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerziseghist_global_22684(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerziseghist_global_22684, "compiler.seghist_global_22684", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegred_small_23944(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegred_small_23944, "compiler.segred_small_23944", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegred_large_23944(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegred_large_23944, "compiler.segred_large_23944", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegmap_22727(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[13] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[13] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegmap_22727, "compiler.segmap_22727", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 13, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegscan_22755(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegscan_22755, "compiler.segscan_22755", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_compilerzisegmap_22757(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->compilerzisegmap_22757, "compiler.segmap_22757", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanzisegscan_21978(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanzisegscan_21978, "human.segscan_21978", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanzisegmap_22004(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanzisegmap_22004, "human.segmap_22004", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanzisegmap_22043(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanzisegmap_22043, "human.segmap_22043", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanziseghist_local_22065(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[16] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[16] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanziseghist_local_22065, "human.seghist_local_22065", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 16, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanziseghist_global_22065(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanziseghist_global_22065, "human.seghist_global_22065", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanzisegred_small_23177(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanzisegred_small_23177, "human.segred_small_23177", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanzisegred_large_23177(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanzisegred_large_23177, "human.segred_large_23177", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanzisegmap_22117(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanzisegmap_22117, "human.segmap_22117", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanzisegscan_22150(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanzisegscan_22150, "human.segscan_22150", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_humanzisegmap_22152(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->humanzisegmap_22152, "human.segmap_22152", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegscan_22166(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegscan_22166, "human_regular.segscan_22166", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22168(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22168, "human_regular.segmap_22168", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegscan_22182(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegscan_22182, "human_regular.segscan_22182", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegscan_22190(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegscan_22190, "human_regular.segscan_22190", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22218(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22218, "human_regular.segmap_22218", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22257(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22257, "human_regular.segmap_22257", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularziseghist_local_22277(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[16] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[16] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularziseghist_local_22277, "human_regular.seghist_local_22277", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 16, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularziseghist_global_22277(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularziseghist_global_22277, "human_regular.seghist_global_22277", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegred_small_23442(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegred_small_23442, "human_regular.segred_small_23442", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegred_large_23442(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegred_large_23442, "human_regular.segred_large_23442", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22326(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22326, "human_regular.segmap_22326", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegscan_22354(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegscan_22354, "human_regular.segscan_22354", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22356(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22356, "human_regular.segmap_22356", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegscan_22370(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegscan_22370, "human_regular.segscan_22370", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22395(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[8] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[8] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22395, "human_regular.segmap_22395", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 8, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22431(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[10] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6};
        size_t args_sizes[10] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22431, "human_regular.segmap_22431", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 10, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularziseghist_local_22451(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[16] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[16] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularziseghist_local_22451, "human_regular.seghist_local_22451", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 16, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularziseghist_global_22451(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularziseghist_global_22451, "human_regular.seghist_global_22451", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegred_small_23889(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegred_small_23889, "human_regular.segred_small_23889", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegred_large_23889(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegred_large_23889, "human_regular.segred_large_23889", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22501(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22501, "human_regular.segmap_22501", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegscan_22530(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegscan_22530, "human_regular.segscan_22530", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_regularzisegmap_22532(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_regularzisegmap_22532, "human_regular.segmap_22532", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_23048, int64_t num_elems_23049, bool val_23050)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
    struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
    struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
    struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
    struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
    struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
    struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
    struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
    struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
    struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
    struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
    struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
    struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
    struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
    struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
    struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
    struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
    struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
    struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
    int64_t replicate_n_23052 = num_elems_23049;
    int64_t tblock_sizze_23057;
    
    tblock_sizze_23057 = *ctx->tuning_params.builtinzhreplicate_boolzitblock_sizze_23057;
    
    int64_t virt_num_tblocks_23058 = sdiv_up64(replicate_n_23052, tblock_sizze_23057);
    int64_t num_tblocks_23059 = smin64(virt_num_tblocks_23058, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_boolzireplicate_23053(ctx, num_tblocks_23059, 1, 1, tblock_sizze_23057, 1, 1, (int64_t) 0, num_elems_23049, val_23050, replicate_n_23052, virt_num_tblocks_23058, num_tblocks_23059, mem_23048.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_f32(struct futhark_context *ctx, struct memblock_device mem_22885, int64_t num_elems_22886, float val_22887)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
    struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
    struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
    struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
    struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
    struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
    struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
    struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
    struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
    struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
    struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
    struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
    struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
    struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
    struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
    struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
    struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
    struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
    struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
    int64_t replicate_n_22889 = num_elems_22886;
    int64_t tblock_sizze_22894;
    
    tblock_sizze_22894 = *ctx->tuning_params.builtinzhreplicate_f32zitblock_sizze_22894;
    
    int64_t virt_num_tblocks_22895 = sdiv_up64(replicate_n_22889, tblock_sizze_22894);
    int64_t num_tblocks_22896 = smin64(virt_num_tblocks_22895, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_f32zireplicate_22890(ctx, num_tblocks_22896, 1, 1, tblock_sizze_22894, 1, 1, (int64_t) 0, num_elems_22886, val_22887, replicate_n_22889, virt_num_tblocks_22895, num_tblocks_22896, mem_22885.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_22941, int64_t num_elems_22942, int32_t val_22943)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
    struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
    struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
    struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
    struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
    struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
    struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
    struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
    struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
    struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
    struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
    struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
    struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
    struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
    struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
    struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
    struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
    struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
    struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
    int64_t replicate_n_22945 = num_elems_22942;
    int64_t tblock_sizze_22950;
    
    tblock_sizze_22950 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_22950;
    
    int64_t virt_num_tblocks_22951 = sdiv_up64(replicate_n_22945, tblock_sizze_22950);
    int64_t num_tblocks_22952 = smin64(virt_num_tblocks_22951, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_22946(ctx, num_tblocks_22952, 1, 1, tblock_sizze_22950, 1, 1, (int64_t) 0, num_elems_22942, val_22943, replicate_n_22945, virt_num_tblocks_22951, num_tblocks_22952, mem_22941.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_22915, int64_t num_elems_22916, int8_t val_22917)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
    struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
    struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
    struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
    struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
    struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
    struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
    struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
    struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
    struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
    struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
    struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
    struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
    struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
    struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
    struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
    struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
    struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
    struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
    int64_t replicate_n_22919 = num_elems_22916;
    int64_t tblock_sizze_22924;
    
    tblock_sizze_22924 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_22924;
    
    int64_t virt_num_tblocks_22925 = sdiv_up64(replicate_n_22919, tblock_sizze_22924);
    int64_t num_tblocks_22926 = smin64(virt_num_tblocks_22925, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_22920(ctx, num_tblocks_22926, 1, 1, tblock_sizze_22924, 1, 1, (int64_t) 0, num_elems_22916, val_22917, replicate_n_22919, virt_num_tblocks_22925, num_tblocks_22926, mem_22915.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_compiler(struct futhark_context *ctx, struct memblock_device *mem_out_p_24144, struct memblock_device ks_mem_22766, struct memblock_device shp_mem_22767, struct memblock_device A_mem_22768, int64_t mz2080U_19405, int64_t nz2081U_19406)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_param_tmp_23199;
    
    mem_param_tmp_23199.references = NULL;
    
    struct memblock_device mem_param_tmp_23198;
    
    mem_param_tmp_23198.references = NULL;
    
    struct memblock_device mem_param_tmp_23197;
    
    mem_param_tmp_23197.references = NULL;
    
    struct memblock_device mem_param_tmp_23196;
    
    mem_param_tmp_23196.references = NULL;
    
    struct memblock_device mem_param_tmp_23195;
    
    mem_param_tmp_23195.references = NULL;
    
    struct memblock_device mem_22849;
    
    mem_22849.references = NULL;
    
    struct memblock_device mem_22847;
    
    mem_22847.references = NULL;
    
    struct memblock_device incprefixes_mem_24039;
    
    incprefixes_mem_24039.references = NULL;
    
    struct memblock_device aggregates_mem_24037;
    
    aggregates_mem_24037.references = NULL;
    
    struct memblock_device status_flags_mem_24035;
    
    status_flags_mem_24035.references = NULL;
    
    struct memblock_device mem_22845;
    
    mem_22845.references = NULL;
    
    struct memblock_device mem_22843;
    
    mem_22843.references = NULL;
    
    struct memblock_device mem_22838;
    
    mem_22838.references = NULL;
    
    struct memblock_device mem_22836;
    
    mem_22836.references = NULL;
    
    struct memblock_device mem_22834;
    
    mem_22834.references = NULL;
    
    struct memblock_device segred_tmp_mem_23979;
    
    segred_tmp_mem_23979.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_23859;
    
    defunc_0_map_res_subhistos_mem_23859.references = NULL;
    
    struct memblock_device segred_tmp_mem_23818;
    
    segred_tmp_mem_23818.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_23698;
    
    defunc_0_map_res_subhistos_mem_23698.references = NULL;
    
    struct memblock_device segred_tmp_mem_23657;
    
    segred_tmp_mem_23657.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_23537;
    
    defunc_0_map_res_subhistos_mem_23537.references = NULL;
    
    struct memblock_device mem_22821;
    
    mem_22821.references = NULL;
    
    struct memblock_device mem_22819;
    
    mem_22819.references = NULL;
    
    struct memblock_device mem_22817;
    
    mem_22817.references = NULL;
    
    struct memblock_device incprefixes_mem_23338;
    
    incprefixes_mem_23338.references = NULL;
    
    struct memblock_device aggregates_mem_23336;
    
    aggregates_mem_23336.references = NULL;
    
    struct memblock_device incprefixes_mem_23334;
    
    incprefixes_mem_23334.references = NULL;
    
    struct memblock_device aggregates_mem_23332;
    
    aggregates_mem_23332.references = NULL;
    
    struct memblock_device incprefixes_mem_23330;
    
    incprefixes_mem_23330.references = NULL;
    
    struct memblock_device aggregates_mem_23328;
    
    aggregates_mem_23328.references = NULL;
    
    struct memblock_device status_flags_mem_23326;
    
    status_flags_mem_23326.references = NULL;
    
    struct memblock_device mem_22815;
    
    mem_22815.references = NULL;
    
    struct memblock_device mem_22813;
    
    mem_22813.references = NULL;
    
    struct memblock_device mem_22811;
    
    mem_22811.references = NULL;
    
    struct memblock_device mem_22809;
    
    mem_22809.references = NULL;
    
    struct memblock_device mem_22807;
    
    mem_22807.references = NULL;
    
    struct memblock_device mem_22805;
    
    mem_22805.references = NULL;
    
    struct memblock_device incprefixes_mem_23218;
    
    incprefixes_mem_23218.references = NULL;
    
    struct memblock_device aggregates_mem_23216;
    
    aggregates_mem_23216.references = NULL;
    
    struct memblock_device status_flags_mem_23214;
    
    status_flags_mem_23214.references = NULL;
    
    struct memblock_device mem_param_22796;
    
    mem_param_22796.references = NULL;
    
    struct memblock_device mem_param_22793;
    
    mem_param_22793.references = NULL;
    
    struct memblock_device mem_param_22790;
    
    mem_param_22790.references = NULL;
    
    struct memblock_device mem_param_22787;
    
    mem_param_22787.references = NULL;
    
    struct memblock_device mem_param_22784;
    
    mem_param_22784.references = NULL;
    
    struct memblock_device ext_mem_22861;
    
    ext_mem_22861.references = NULL;
    
    struct memblock_device ext_mem_22862;
    
    ext_mem_22862.references = NULL;
    
    struct memblock_device ext_mem_22863;
    
    ext_mem_22863.references = NULL;
    
    struct memblock_device ext_mem_22864;
    
    ext_mem_22864.references = NULL;
    
    struct memblock_device ext_mem_22865;
    
    ext_mem_22865.references = NULL;
    
    struct memblock_device mem_22840;
    
    mem_22840.references = NULL;
    
    struct memblock_device mem_22830;
    
    mem_22830.references = NULL;
    
    struct memblock_device mem_22827;
    
    mem_22827.references = NULL;
    
    struct memblock_device mem_22824;
    
    mem_22824.references = NULL;
    
    struct memblock_device mem_22802;
    
    mem_22802.references = NULL;
    
    struct memblock_device mem_22799;
    
    mem_22799.references = NULL;
    
    struct memblock_device incprefixes_mem_23094;
    
    incprefixes_mem_23094.references = NULL;
    
    struct memblock_device aggregates_mem_23092;
    
    aggregates_mem_23092.references = NULL;
    
    struct memblock_device status_flags_mem_23090;
    
    status_flags_mem_23090.references = NULL;
    
    struct memblock_device mem_22781;
    
    mem_22781.references = NULL;
    
    struct memblock_device mem_22774;
    
    mem_22774.references = NULL;
    
    struct memblock_device incprefixes_mem_22937;
    
    incprefixes_mem_22937.references = NULL;
    
    struct memblock_device aggregates_mem_22935;
    
    aggregates_mem_22935.references = NULL;
    
    struct memblock_device status_flags_mem_22913;
    
    status_flags_mem_22913.references = NULL;
    
    struct memblock_device mem_22773;
    
    mem_22773.references = NULL;
    
    struct memblock_device mem_22770;
    
    mem_22770.references = NULL;
    
    struct memblock_device mem_out_22884;
    
    mem_out_22884.references = NULL;
    
    struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
    struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
    struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
    struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
    struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
    struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
    struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
    struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
    struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
    struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
    struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
    struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
    struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
    struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
    struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
    struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
    struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
    struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
    struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
    int64_t bytes_22769 = (int64_t) 4 * mz2080U_19405;
    int64_t bytes_22772 = (int64_t) 8 * mz2080U_19405;
    int64_t bytes_22777 = (int64_t) 4 * nz2081U_19406;
    
    if (memblock_alloc_device(ctx, &mem_22770, bytes_22769, "mem_22770")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f32(ctx, mem_22770, mz2080U_19405, 0.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segscan_tblock_sizze_22541;
    
    segscan_tblock_sizze_22541 = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22540;
    
    int64_t num_tblocks_22543;
    int64_t max_num_tblocks_22905;
    
    max_num_tblocks_22905 = *ctx->tuning_params.compilerzisegscan_num_tblocks_22542;
    num_tblocks_22543 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_19405, segscan_tblock_sizze_22541), max_num_tblocks_22905)));
    if (memblock_alloc_device(ctx, &mem_22773, bytes_22772, "mem_22773")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_19405)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_22906;
        
        shared_memory_22906 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_22907;
        
        thread_block_sizze_22907 = ctx->max_thread_block_size;
        
        int64_t registers_22908;
        
        registers_22908 = ctx->max_registers;
        
        int64_t thread_block_sizze_22909;
        
        thread_block_sizze_22909 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_22910 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_22906, thread_block_sizze_22907), (int64_t) 8), squot64(squot64(registers_22908, thread_block_sizze_22909) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_22911 = sdiv_up64(mz2080U_19405, segscan_tblock_sizze_22541 * chunk_sizze_22910);
        int64_t num_virt_threads_22912 = num_virt_blocks_22911 * segscan_tblock_sizze_22541;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_22910, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_22913, num_virt_blocks_22911, "status_flags_mem_22913")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_22913, num_virt_blocks_22911, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_22935, (int64_t) 8 * num_virt_blocks_22911, "aggregates_mem_22935")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_22937, (int64_t) 8 * num_virt_blocks_22911, "incprefixes_mem_22937")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_compilerzisegscan_22546(ctx, num_tblocks_22543, 1, 1, *ctx->tuning_params.compilerzisegscan_tblock_sizze_22540, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22541), chunk_sizze_22910 * segscan_tblock_sizze_22541 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22541), chunk_sizze_22910 * segscan_tblock_sizze_22541 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_19405, num_tblocks_22543, num_virt_blocks_22911, num_virt_threads_22912, shp_mem_22767.mem, mem_22773.mem, status_flags_mem_22913.mem, aggregates_mem_22935.mem, incprefixes_mem_22937.mem, global_dynid_mem_22939.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_alloc_device(ctx, &mem_22774, nz2081U_19406, "mem_22774")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_22774, nz2081U_19406, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_22551;
    
    segmap_tblock_sizze_22551 = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22550;
    
    int64_t num_tblocks_22553;
    int64_t max_num_tblocks_23068;
    
    max_num_tblocks_23068 = *ctx->tuning_params.compilerzisegmap_num_tblocks_22552;
    num_tblocks_22553 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_19405, segmap_tblock_sizze_22551), max_num_tblocks_23068)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23069 = sext_i64_i32(sdiv_up64(mz2080U_19405, segmap_tblock_sizze_22551));
    
    {
        err = gpu_kernel_compilerzisegmap_22548(ctx, num_tblocks_22553, 1, 1, *ctx->tuning_params.compilerzisegmap_tblock_sizze_22550, 1, 1, (int64_t) 0, mz2080U_19405, nz2081U_19406, num_tblocks_22553, virt_num_tblocks_23069, mem_22773.mem, mem_22774.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_22773, "mem_22773") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_22557;
    
    segscan_tblock_sizze_22557 = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22556;
    
    int64_t num_tblocks_22559;
    int64_t max_num_tblocks_23082;
    
    max_num_tblocks_23082 = *ctx->tuning_params.compilerzisegscan_num_tblocks_22558;
    num_tblocks_22559 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_19406, segscan_tblock_sizze_22557), max_num_tblocks_23082)));
    if (memblock_alloc_device(ctx, &mem_22781, bytes_22777, "mem_22781")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_19406)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_23083;
        
        shared_memory_23083 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_23084;
        
        thread_block_sizze_23084 = ctx->max_thread_block_size;
        
        int64_t registers_23085;
        
        registers_23085 = ctx->max_registers;
        
        int64_t thread_block_sizze_23086;
        
        thread_block_sizze_23086 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_23087 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23083, thread_block_sizze_23084), (int64_t) 4), squot64(squot64(registers_23085, thread_block_sizze_23086) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_23088 = sdiv_up64(nz2081U_19406, segscan_tblock_sizze_22557 * chunk_sizze_23087);
        int64_t num_virt_threads_23089 = num_virt_blocks_23088 * segscan_tblock_sizze_22557;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23087, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_23090, num_virt_blocks_23088, "status_flags_mem_23090")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23090, num_virt_blocks_23088, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_23092, (int64_t) 4 * num_virt_blocks_23088, "aggregates_mem_23092")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_23094, (int64_t) 4 * num_virt_blocks_23088, "incprefixes_mem_23094")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_compilerzisegscan_22562(ctx, num_tblocks_22559, 1, 1, *ctx->tuning_params.compilerzisegscan_tblock_sizze_22556, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22557), chunk_sizze_23087 * segscan_tblock_sizze_22557 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22557), chunk_sizze_23087 * segscan_tblock_sizze_22557 * (int64_t) 4), (int64_t) 8), (int64_t) 8), nz2081U_19406, num_tblocks_22559, num_virt_blocks_23088, num_virt_threads_23089, mem_22774.mem, mem_22781.mem, status_flags_mem_23090.mem, aggregates_mem_23092.mem, incprefixes_mem_23094.mem, global_dynid_mem_23096.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_22774, "mem_22774") != 0)
        return 1;
    
    int64_t segmap_tblock_sizze_22575;
    
    segmap_tblock_sizze_22575 = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22566;
    
    int64_t segmap_usable_groups_22576 = sdiv_up64(nz2081U_19406, segmap_tblock_sizze_22575);
    
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23185 = sext_i64_i32(sdiv_up64(nz2081U_19406, segmap_tblock_sizze_22575));
    
    {
        err = gpu_kernel_compilerzisegmap_22579(ctx, segmap_usable_groups_22576, 1, 1, *ctx->tuning_params.compilerzisegmap_tblock_sizze_22566, 1, 1, (int64_t) 0, nz2081U_19406, mem_22781.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    bool loop_cond_20994 = slt64((int64_t) 0, nz2081U_19406);
    int64_t segscan_tblock_sizze_22585;
    
    segscan_tblock_sizze_22585 = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22584;
    
    int64_t num_tblocks_22587;
    int64_t max_num_tblocks_23194;
    
    max_num_tblocks_23194 = *ctx->tuning_params.compilerzisegscan_num_tblocks_22586;
    num_tblocks_22587 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_19405, segscan_tblock_sizze_22585), max_num_tblocks_23194)));
    
    int64_t segmap_tblock_sizze_22611;
    
    segmap_tblock_sizze_22611 = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22594;
    
    int64_t segmap_usable_groups_22612 = sdiv_up_safe64(mz2080U_19405, segmap_tblock_sizze_22611);
    int64_t segscan_tblock_sizze_22629;
    
    segscan_tblock_sizze_22629 = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22628;
    
    int64_t segmap_tblock_sizze_22639;
    
    segmap_tblock_sizze_22639 = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22638;
    
    int64_t seghist_tblock_sizze_22645;
    
    seghist_tblock_sizze_22645 = *ctx->tuning_params.compilerziseghist_tblock_sizze_22644;
    
    int64_t seghist_tblock_sizze_22661;
    
    seghist_tblock_sizze_22661 = *ctx->tuning_params.compilerziseghist_tblock_sizze_22660;
    
    int64_t seghist_tblock_sizze_22677;
    
    seghist_tblock_sizze_22677 = *ctx->tuning_params.compilerziseghist_tblock_sizze_22676;
    
    int64_t segmap_tblock_sizze_22720;
    
    segmap_tblock_sizze_22720 = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22694;
    
    int64_t segmap_usable_groups_22721 = sdiv_up_safe64(mz2080U_19405, segmap_tblock_sizze_22720);
    int64_t segscan_tblock_sizze_22750;
    
    segscan_tblock_sizze_22750 = *ctx->tuning_params.compilerzisegscan_tblock_sizze_22749;
    
    int64_t segmap_tblock_sizze_22760;
    
    segmap_tblock_sizze_22760 = *ctx->tuning_params.compilerzisegmap_tblock_sizze_22759;
    if (memblock_alloc_device(ctx, &mem_22799, bytes_22769, "mem_22799")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22802, bytes_22769, "mem_22802")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22824, bytes_22769, "mem_22824")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22827, bytes_22769, "mem_22827")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22830, bytes_22769, "mem_22830")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22840, bytes_22769, "mem_22840")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t result_20995;
    bool result_20996;
    int64_t loop_dz2083Uz2082U_21002;
    bool loop_while_21003;
    
    if (memblock_set_device(ctx, &mem_param_22784, &ks_mem_22766, "ks_mem_22766") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22787, &shp_mem_22767, "shp_mem_22767") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22790, &mem_22781, "mem_22781") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22793, &A_mem_22768, "A_mem_22768") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22796, &mem_22770, "mem_22770") != 0)
        return 1;
    loop_dz2083Uz2082U_21002 = nz2081U_19406;
    loop_while_21003 = loop_cond_20994;
    while (loop_while_21003) {
        if (slt64((int64_t) 0, mz2080U_19405)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_23207;
            
            shared_memory_23207 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_23208;
            
            thread_block_sizze_23208 = ctx->max_thread_block_size;
            
            int64_t registers_23209;
            
            registers_23209 = ctx->max_registers;
            
            int64_t thread_block_sizze_23210;
            
            thread_block_sizze_23210 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_23211 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23207, thread_block_sizze_23208), (int64_t) 4), squot64(squot64(registers_23209, thread_block_sizze_23210) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
            int64_t num_virt_blocks_23212 = sdiv_up64(mz2080U_19405, segscan_tblock_sizze_22585 * chunk_sizze_23211);
            int64_t num_virt_threads_23213 = num_virt_blocks_23212 * segscan_tblock_sizze_22585;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23211, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_23214, num_virt_blocks_23212, "status_flags_mem_23214")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23214, num_virt_blocks_23212, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_23216, (int64_t) 4 * num_virt_blocks_23212, "aggregates_mem_23216")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_23218, (int64_t) 4 * num_virt_blocks_23212, "incprefixes_mem_23218")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_compilerzisegscan_22590(ctx, num_tblocks_22587, 1, 1, *ctx->tuning_params.compilerzisegscan_tblock_sizze_22584, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22585), chunk_sizze_23211 * segscan_tblock_sizze_22585 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22585), chunk_sizze_23211 * segscan_tblock_sizze_22585 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_19405, num_tblocks_22587, num_virt_blocks_23212, num_virt_threads_23213, mem_param_22787.mem, mem_22799.mem, status_flags_mem_23214.mem, aggregates_mem_23216.mem, incprefixes_mem_23218.mem, global_dynid_mem_23220.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23309 = sext_i64_i32(sdiv_up64(mz2080U_19405, segmap_tblock_sizze_22611));
        
        {
            err = gpu_kernel_compilerzisegmap_22615(ctx, segmap_usable_groups_22612, 1, 1, *ctx->tuning_params.compilerzisegmap_tblock_sizze_22594, 1, 1, (int64_t) 0, mz2080U_19405, loop_dz2083Uz2082U_21002, mem_param_22793.mem, mem_22799.mem, mem_22802.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t num_tblocks_22631;
        int64_t max_num_tblocks_23318;
        
        max_num_tblocks_23318 = *ctx->tuning_params.compilerzisegscan_num_tblocks_22630;
        num_tblocks_22631 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2083Uz2082U_21002, segscan_tblock_sizze_22629), max_num_tblocks_23318)));
        
        int64_t bytes_22804 = (int64_t) 8 * loop_dz2083Uz2082U_21002;
        
        if (memblock_alloc_device(ctx, &mem_22805, bytes_22804, "mem_22805")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22807, bytes_22804, "mem_22807")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22809, bytes_22804, "mem_22809")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22811, bytes_22804, "mem_22811")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22813, bytes_22804, "mem_22813")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22815, bytes_22804, "mem_22815")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, loop_dz2083Uz2082U_21002)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_23319;
            
            shared_memory_23319 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_23320;
            
            thread_block_sizze_23320 = ctx->max_thread_block_size;
            
            int64_t registers_23321;
            
            registers_23321 = ctx->max_registers;
            
            int64_t thread_block_sizze_23322;
            
            thread_block_sizze_23322 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_23323 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23319, thread_block_sizze_23320), (int64_t) 8), squot64(squot64(registers_23321, thread_block_sizze_23322) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_23324 = sdiv_up64(loop_dz2083Uz2082U_21002, segscan_tblock_sizze_22629 * chunk_sizze_23323);
            int64_t num_virt_threads_23325 = num_virt_blocks_23324 * segscan_tblock_sizze_22629;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23323, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_23326, num_virt_blocks_23324, "status_flags_mem_23326")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23326, num_virt_blocks_23324, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_23328, (int64_t) 8 * num_virt_blocks_23324, "aggregates_mem_23328")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_23330, (int64_t) 8 * num_virt_blocks_23324, "incprefixes_mem_23330")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_23332, (int64_t) 8 * num_virt_blocks_23324, "aggregates_mem_23332")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_23334, (int64_t) 8 * num_virt_blocks_23324, "incprefixes_mem_23334")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_23336, (int64_t) 8 * num_virt_blocks_23324, "aggregates_mem_23336")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_23338, (int64_t) 8 * num_virt_blocks_23324, "incprefixes_mem_23338")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_compilerzisegscan_22634(ctx, num_tblocks_22631, 1, 1, *ctx->tuning_params.compilerzisegscan_tblock_sizze_22628, 1, 1, smax64(smax64((int64_t) 800, sdiv_up64(sdiv_up64((int64_t) 8 * segscan_tblock_sizze_22629, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_22629, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_22629), smax64(smax64(chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8, chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8), chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 800, sdiv_up64(sdiv_up64((int64_t) 8 * segscan_tblock_sizze_22629, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_22629, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_22629), smax64(smax64(chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8, chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8), chunk_sizze_23323 * segscan_tblock_sizze_22629 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), mz2080U_19405, loop_dz2083Uz2082U_21002, num_tblocks_22631, num_virt_blocks_23324, num_virt_threads_23325, mem_param_22790.mem, mem_param_22793.mem, mem_22802.mem, mem_22805.mem, mem_22807.mem, mem_22809.mem, mem_22811.mem, mem_22813.mem, mem_22815.mem, status_flags_mem_23326.mem, aggregates_mem_23328.mem, incprefixes_mem_23330.mem, aggregates_mem_23332.mem, incprefixes_mem_23334.mem, aggregates_mem_23336.mem, incprefixes_mem_23338.mem, global_dynid_mem_23340.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        bool cond_21043 = loop_dz2083Uz2082U_21002 == (int64_t) 0;
        bool x_21044 = !cond_21043;
        int64_t tmp_21045 = sub64(loop_dz2083Uz2082U_21002, (int64_t) 1);
        bool x_21046 = sle64((int64_t) 0, tmp_21045);
        bool y_21047 = slt64(tmp_21045, loop_dz2083Uz2082U_21002);
        bool bounds_check_21048 = x_21046 && y_21047;
        bool protect_assert_disj_21049 = cond_21043 || bounds_check_21048;
        bool index_certs_21050;
        
        if (!protect_assert_disj_21049) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_21045, "] out of bounds for array of shape [", (long long) loop_dz2083Uz2082U_21002, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  compiler.fut:4:42-43\n   #2  auto_test.fut:14:18-42\n   #3  auto_test.fut:14:1-42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t m_f_res_21051;
        
        if (x_21044) {
            int64_t read_res_24145;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_24145, mem_22805.mem, tmp_21045 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_21902 = read_res_24145;
            
            m_f_res_21051 = x_21902;
        } else {
            m_f_res_21051 = (int64_t) 0;
        }
        
        int64_t m_21053;
        
        if (cond_21043) {
            m_21053 = (int64_t) 0;
        } else {
            m_21053 = m_f_res_21051;
        }
        
        int64_t m_f_res_21133;
        
        if (x_21044) {
            int64_t read_res_24146;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_24146, mem_22809.mem, tmp_21045 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_21903 = read_res_24146;
            
            m_f_res_21133 = x_21903;
        } else {
            m_f_res_21133 = (int64_t) 0;
        }
        
        int64_t m_21135;
        
        if (cond_21043) {
            m_21135 = (int64_t) 0;
        } else {
            m_21135 = m_f_res_21133;
        }
        
        int64_t m_21145 = sub64(m_21135, (int64_t) 1);
        bool i_p_m_t_s_leq_w_21147 = slt64(m_21145, loop_dz2083Uz2082U_21002);
        bool zzero_leq_i_p_m_t_s_21146 = sle64((int64_t) 0, m_21145);
        bool y_21149 = zzero_leq_i_p_m_t_s_21146 && i_p_m_t_s_leq_w_21147;
        bool i_lte_j_21148 = sle64((int64_t) 0, m_21135);
        bool forwards_ok_21150 = i_lte_j_21148 && y_21149;
        bool eq_x_zz_21142 = (int64_t) 0 == m_f_res_21133;
        bool p_and_eq_x_y_21143 = x_21044 && eq_x_zz_21142;
        bool empty_slice_21144 = cond_21043 || p_and_eq_x_y_21143;
        bool ok_or_empty_21151 = empty_slice_21144 || forwards_ok_21150;
        bool index_certs_21152;
        
        if (!ok_or_empty_21151) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_21135, "] out of bounds for array of shape [", (long long) loop_dz2083Uz2082U_21002, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  compiler.fut:4:42-43\n   #2  auto_test.fut:14:18-42\n   #3  auto_test.fut:14:1-42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_22816 = (int64_t) 4 * m_21135;
        
        if (memblock_alloc_device(ctx, &mem_22817, bytes_22816, "mem_22817")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22817.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22790.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21135})) != 0)
            goto cleanup;
        
        int64_t m_f_res_21092;
        
        if (x_21044) {
            int64_t read_res_24147;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_24147, mem_22807.mem, tmp_21045 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_21904 = read_res_24147;
            
            m_f_res_21092 = x_21904;
        } else {
            m_f_res_21092 = (int64_t) 0;
        }
        
        int64_t m_21094;
        
        if (cond_21043) {
            m_21094 = (int64_t) 0;
        } else {
            m_21094 = m_f_res_21092;
        }
        
        int64_t m_21104 = sub64(m_21094, (int64_t) 1);
        bool i_p_m_t_s_leq_w_21106 = slt64(m_21104, loop_dz2083Uz2082U_21002);
        bool zzero_leq_i_p_m_t_s_21105 = sle64((int64_t) 0, m_21104);
        bool y_21108 = zzero_leq_i_p_m_t_s_21105 && i_p_m_t_s_leq_w_21106;
        bool i_lte_j_21107 = sle64((int64_t) 0, m_21094);
        bool forwards_ok_21109 = i_lte_j_21107 && y_21108;
        bool eq_x_zz_21101 = (int64_t) 0 == m_f_res_21092;
        bool p_and_eq_x_y_21102 = x_21044 && eq_x_zz_21101;
        bool empty_slice_21103 = cond_21043 || p_and_eq_x_y_21102;
        bool ok_or_empty_21110 = empty_slice_21103 || forwards_ok_21109;
        bool index_certs_21111;
        
        if (!ok_or_empty_21110) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_21094, "] out of bounds for array of shape [", (long long) loop_dz2083Uz2082U_21002, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  compiler.fut:4:42-43\n   #2  auto_test.fut:14:18-42\n   #3  auto_test.fut:14:1-42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_22818 = (int64_t) 4 * m_21094;
        
        if (memblock_alloc_device(ctx, &mem_22819, bytes_22818, "mem_22819")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22819.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22790.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21094})) != 0)
            goto cleanup;
        
        int64_t m_21063 = sub64(m_21053, (int64_t) 1);
        bool i_p_m_t_s_leq_w_21065 = slt64(m_21063, loop_dz2083Uz2082U_21002);
        bool zzero_leq_i_p_m_t_s_21064 = sle64((int64_t) 0, m_21063);
        bool y_21067 = zzero_leq_i_p_m_t_s_21064 && i_p_m_t_s_leq_w_21065;
        bool i_lte_j_21066 = sle64((int64_t) 0, m_21053);
        bool forwards_ok_21068 = i_lte_j_21066 && y_21067;
        bool eq_x_zz_21060 = (int64_t) 0 == m_f_res_21051;
        bool p_and_eq_x_y_21061 = x_21044 && eq_x_zz_21060;
        bool empty_slice_21062 = cond_21043 || p_and_eq_x_y_21061;
        bool ok_or_empty_21069 = empty_slice_21062 || forwards_ok_21068;
        bool index_certs_21070;
        
        if (!ok_or_empty_21069) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_21053, "] out of bounds for array of shape [", (long long) loop_dz2083Uz2082U_21002, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  compiler.fut:4:42-43\n   #2  auto_test.fut:14:18-42\n   #3  auto_test.fut:14:1-42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_22820 = (int64_t) 4 * m_21053;
        
        if (memblock_alloc_device(ctx, &mem_22821, bytes_22820, "mem_22821")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22821.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22790.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21053})) != 0)
            goto cleanup;
        
        int64_t num_tblocks_22641;
        int64_t max_num_tblocks_23521;
        
        max_num_tblocks_23521 = *ctx->tuning_params.compilerzisegmap_num_tblocks_22640;
        num_tblocks_22641 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2083Uz2082U_21002, segmap_tblock_sizze_22639), max_num_tblocks_23521)));
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23522 = sext_i64_i32(sdiv_up64(loop_dz2083Uz2082U_21002, segmap_tblock_sizze_22639));
        
        {
            err = gpu_kernel_compilerzisegmap_22636(ctx, num_tblocks_22641, 1, 1, *ctx->tuning_params.compilerzisegmap_tblock_sizze_22638, 1, 1, (int64_t) 0, loop_dz2083Uz2082U_21002, m_21053, m_21094, m_21135, num_tblocks_22641, virt_num_tblocks_23522, mem_param_22790.mem, mem_22805.mem, mem_22807.mem, mem_22809.mem, mem_22811.mem, mem_22813.mem, mem_22815.mem, mem_22817.mem, mem_22819.mem, mem_22821.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_22805, "mem_22805") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22807, "mem_22807") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22809, "mem_22809") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22811, "mem_22811") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22813, "mem_22813") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22815, "mem_22815") != 0)
            return 1;
        if (futrts_builtinzhreplicate_i32(ctx, mem_22824, mz2080U_19405, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_tblocks_22647;
        int64_t max_num_tblocks_23535;
        
        max_num_tblocks_23535 = *ctx->tuning_params.compilerziseghist_num_tblocks_22646;
        num_tblocks_22647 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_21053, seghist_tblock_sizze_22645), max_num_tblocks_23535)));
        
        int64_t num_subhistos_23536;
        int64_t h_23539 = (int64_t) 4 * mz2080U_19405;
        int64_t seg_h_23540 = (int64_t) 4 * mz2080U_19405;
        
        if (!(seg_h_23540 == (int64_t) 0)) {
            int64_t hist_H_23541 = mz2080U_19405;
            int64_t hist_el_sizze_23542 = sdiv_up64(h_23539, hist_H_23541);
            int64_t hist_N_23543 = m_21053;
            int32_t hist_RF_23544 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegHist");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_22647 * seghist_tblock_sizze_22645), '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_22645, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23541, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_23543, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_23542, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_23544, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_23539, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_23540, '\n');
            
            int64_t hist_L_23545;
            
            hist_L_23545 = *ctx->tuning_params.compilerzihist_L_23545;
            
            int64_t max_tblock_sizze_23546;
            
            max_tblock_sizze_23546 = ctx->max_thread_block_size;
            
            int64_t num_tblocks_23547 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_22647 * seghist_tblock_sizze_22645)), max_tblock_sizze_23546);
            double hist_m_prime_23548 = sitofp_i64_f64(smin64(squot64(hist_L_23545, hist_el_sizze_23542), sdiv_up64(hist_N_23543, num_tblocks_23547))) / sitofp_i64_f64(hist_H_23541);
            int64_t hist_M0_23549 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_23548), max_tblock_sizze_23546));
            int64_t hist_Nout_23550 = (int64_t) 1;
            int64_t hist_Nin_23551 = m_21053;
            int64_t work_asymp_M_max_23552 = squot64(hist_Nout_23550 * hist_N_23543, (int64_t) 2 * num_tblocks_23547 * hist_H_23541);
            int32_t hist_M_23553 = sext_i64_i32(smin64(hist_M0_23549, work_asymp_M_max_23552));
            int64_t hist_C_23554 = sdiv_up64(max_tblock_sizze_23546, sext_i32_i64(smax32(1, hist_M_23553)));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_23549, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_23552, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_23554, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_23546, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_23553, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_23541 * hist_el_sizze_23542 * sext_i32_i64(hist_M_23553)), '\n');
            
            int64_t local_mem_needed_23555 = hist_el_sizze_23542 * sext_i32_i64(hist_M_23553);
            int32_t hist_S_23556 = sext_i64_i32(sdiv_up64(hist_H_23541 * local_mem_needed_23555 + (int64_t) 1, hist_L_23545));
            
            if (sle64(hist_H_23541, hist_Nin_23551) && (sle64(local_mem_needed_23555, hist_L_23545) && (sle32(hist_S_23556, 3) && (sle64(hist_C_23554, max_tblock_sizze_23546) && slt32(0, hist_M_23553))))) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using shared memory");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23541, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23553, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_23554, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23556, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_23553, '\n');
                num_subhistos_23536 = num_tblocks_23547;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_23536, '\n');
                if (num_subhistos_23536 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23537, &mem_22824, "mem_22824") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23537, num_subhistos_23536 * mz2080U_19405 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23537")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23537, num_subhistos_23536 * mz2080U_19405, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23537.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22824.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_19405})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23557 = 0; chk_i_23557 < hist_S_23556; chk_i_23557++) {
                    int64_t num_segments_23558 = (int64_t) 1;
                    int64_t hist_H_chk_23559 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23556));
                    int64_t histo_sizze_23560 = hist_H_chk_23559;
                    int32_t init_per_thread_23561 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_23553) * histo_sizze_23560, max_tblock_sizze_23546));
                    
                    {
                        err = gpu_kernel_compilerziseghist_local_22652(ctx, num_tblocks_23547, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_23553 * hist_H_chk_23559) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23553 * hist_H_chk_23559), (int64_t) 8), (int64_t) 8), mz2080U_19405, m_21053, num_subhistos_23536, num_tblocks_23547, hist_M_23553, chk_i_23557, num_segments_23558, hist_H_chk_23559, histo_sizze_23560, init_per_thread_23561, mem_22821.mem, defunc_0_map_res_subhistos_mem_23537.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using global memory");
                
                int64_t hist_H_23593 = mz2080U_19405;
                double hist_RF_23594 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
                int32_t hist_el_sizze_23595 = 4;
                double hist_C_max_23596 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22647 * seghist_tblock_sizze_22645)), sitofp_i32_f64(hist_H_23593) / 2.0);
                int32_t hist_M_min_23597 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22647 * seghist_tblock_sizze_22645)) / hist_C_max_23596)));
                int64_t hist_L2_23598;
                
                hist_L2_23598 = *ctx->tuning_params.compilerzihist_L2_23598;
                
                double hist_RACE_exp_23599 = fmax64(1.0, 0.75 * hist_RF_23594 / (64.0 / sitofp_i32_f64(hist_el_sizze_23595)));
                int32_t hist_S_23600;
                
                if (slt64(m_21053, hist_H_23593)) {
                    hist_S_23600 = 1;
                } else {
                    hist_S_23600 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_23597) * hist_H_23593 * sext_i32_i64(hist_el_sizze_23595), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_23598) * hist_RACE_exp_23599)));
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_23599, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23600, '\n');
                
                int64_t hist_H_chk_23601 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23600));
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_23601, '\n');
                
                double hist_k_max_23602 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_23598) / sitofp_i32_f64(4)) * hist_RACE_exp_23599, sitofp_i32_f64(m_21053)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_22647 * seghist_tblock_sizze_22645));
                int64_t hist_u_23603 = (int64_t) 2;
                double hist_C_23604 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22647 * seghist_tblock_sizze_22645)), sitofp_i32_f64(hist_u_23603 * hist_H_chk_23601) / hist_k_max_23602);
                int32_t hist_M_23605 = 1;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_23602, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23605, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_23604, '\n');
                num_subhistos_23536 = sext_i32_i64(hist_M_23605);
                if (hist_M_23605 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23537, &mem_22824, "mem_22824") != 0)
                        return 1;
                } else if (num_subhistos_23536 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23537, &mem_22824, "mem_22824") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23537, num_subhistos_23536 * mz2080U_19405 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23537")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23537, num_subhistos_23536 * mz2080U_19405, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23537.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22824.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_19405})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23606 = 0; chk_i_23606 < hist_S_23600; chk_i_23606++) {
                    int64_t hist_H_chk_23607 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23600));
                    
                    {
                        err = gpu_kernel_compilerziseghist_global_22652(ctx, num_tblocks_22647, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22644, 1, 1, (int64_t) 0, mz2080U_19405, m_21053, num_tblocks_22647, num_subhistos_23536, chk_i_23606, hist_H_chk_23607, mem_22821.mem, defunc_0_map_res_subhistos_mem_23537.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
            if (num_subhistos_23536 == (int64_t) 1) {
                if (memblock_set_device(ctx, &mem_22824, &defunc_0_map_res_subhistos_mem_23537, "defunc_0_map_res_subhistos_mem_23537") != 0)
                    return 1;
            } else {
                int64_t chunk_sizze_23623 = (int64_t) 1;
                
                if (slt64(num_subhistos_23536 * (int64_t) 2, seghist_tblock_sizze_22645 * chunk_sizze_23623)) {
                    int64_t segment_sizze_nonzzero_23624 = smax64((int64_t) 1, num_subhistos_23536);
                    int64_t num_threads_23625 = seghist_tblock_sizze_22645 * seghist_tblock_sizze_22645;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_19405, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23536, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_19405, squot64(seghist_tblock_sizze_22645, segment_sizze_nonzzero_23624))), '\n');
                    {
                        err = gpu_kernel_compilerzisegred_small_23622(ctx, num_tblocks_22647, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22644, 1, 1, (int64_t) 4 * seghist_tblock_sizze_22645 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22645, (int64_t) 8), (int64_t) 8), mz2080U_19405, num_tblocks_22647, num_subhistos_23536, segment_sizze_nonzzero_23624, mem_22824.mem, defunc_0_map_res_subhistos_mem_23537.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_23653 = sdiv_up64(num_tblocks_22647, smax64((int64_t) 1, mz2080U_19405));
                    int64_t q_23654 = sdiv_up64(num_subhistos_23536, seghist_tblock_sizze_22645 * blocks_per_segment_23653 * chunk_sizze_23623);
                    int64_t num_virtblocks_23655 = blocks_per_segment_23653 * mz2080U_19405;
                    int64_t threads_per_segment_23656 = blocks_per_segment_23653 * seghist_tblock_sizze_22645;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_19405, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23536, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_23655, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22647, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_22645, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_23654, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_23653, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_23657, (int64_t) 4 * num_virtblocks_23655, "segred_tmp_mem_23657")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_compilerzisegred_large_23622(ctx, num_tblocks_22647, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22644, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_22645 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22645, (int64_t) 8), (int64_t) 8)), mz2080U_19405, num_tblocks_22647, num_subhistos_23536, blocks_per_segment_23653, q_23654, num_virtblocks_23655, threads_per_segment_23656, mem_22824.mem, defunc_0_map_res_subhistos_mem_23537.mem, segred_tmp_mem_23657.mem, counters_mem_23659.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_22821, "mem_22821") != 0)
            return 1;
        if (futrts_builtinzhreplicate_i32(ctx, mem_22827, mz2080U_19405, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_tblocks_22663;
        int64_t max_num_tblocks_23696;
        
        max_num_tblocks_23696 = *ctx->tuning_params.compilerziseghist_num_tblocks_22662;
        num_tblocks_22663 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_21094, seghist_tblock_sizze_22661), max_num_tblocks_23696)));
        
        int64_t num_subhistos_23697;
        int64_t h_23700 = (int64_t) 4 * mz2080U_19405;
        int64_t seg_h_23701 = (int64_t) 4 * mz2080U_19405;
        
        if (!(seg_h_23701 == (int64_t) 0)) {
            int64_t hist_H_23702 = mz2080U_19405;
            int64_t hist_el_sizze_23703 = sdiv_up64(h_23700, hist_H_23702);
            int64_t hist_N_23704 = m_21094;
            int32_t hist_RF_23705 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegHist");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_22663 * seghist_tblock_sizze_22661), '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_22661, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23702, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_23704, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_23703, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_23705, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_23700, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_23701, '\n');
            
            int64_t hist_L_23706;
            
            hist_L_23706 = *ctx->tuning_params.compilerzihist_L_23706;
            
            int64_t max_tblock_sizze_23707;
            
            max_tblock_sizze_23707 = ctx->max_thread_block_size;
            
            int64_t num_tblocks_23708 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_22663 * seghist_tblock_sizze_22661)), max_tblock_sizze_23707);
            double hist_m_prime_23709 = sitofp_i64_f64(smin64(squot64(hist_L_23706, hist_el_sizze_23703), sdiv_up64(hist_N_23704, num_tblocks_23708))) / sitofp_i64_f64(hist_H_23702);
            int64_t hist_M0_23710 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_23709), max_tblock_sizze_23707));
            int64_t hist_Nout_23711 = (int64_t) 1;
            int64_t hist_Nin_23712 = m_21094;
            int64_t work_asymp_M_max_23713 = squot64(hist_Nout_23711 * hist_N_23704, (int64_t) 2 * num_tblocks_23708 * hist_H_23702);
            int32_t hist_M_23714 = sext_i64_i32(smin64(hist_M0_23710, work_asymp_M_max_23713));
            int64_t hist_C_23715 = sdiv_up64(max_tblock_sizze_23707, sext_i32_i64(smax32(1, hist_M_23714)));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_23710, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_23713, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_23715, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_23707, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_23714, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_23702 * hist_el_sizze_23703 * sext_i32_i64(hist_M_23714)), '\n');
            
            int64_t local_mem_needed_23716 = hist_el_sizze_23703 * sext_i32_i64(hist_M_23714);
            int32_t hist_S_23717 = sext_i64_i32(sdiv_up64(hist_H_23702 * local_mem_needed_23716 + (int64_t) 1, hist_L_23706));
            
            if (sle64(hist_H_23702, hist_Nin_23712) && (sle64(local_mem_needed_23716, hist_L_23706) && (sle32(hist_S_23717, 3) && (sle64(hist_C_23715, max_tblock_sizze_23707) && slt32(0, hist_M_23714))))) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using shared memory");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23702, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23714, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_23715, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23717, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_23714, '\n');
                num_subhistos_23697 = num_tblocks_23708;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_23697, '\n');
                if (num_subhistos_23697 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23698, &mem_22827, "mem_22827") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23698, num_subhistos_23697 * mz2080U_19405 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23698")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23698, num_subhistos_23697 * mz2080U_19405, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23698.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22827.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_19405})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23718 = 0; chk_i_23718 < hist_S_23717; chk_i_23718++) {
                    int64_t num_segments_23719 = (int64_t) 1;
                    int64_t hist_H_chk_23720 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23717));
                    int64_t histo_sizze_23721 = hist_H_chk_23720;
                    int32_t init_per_thread_23722 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_23714) * histo_sizze_23721, max_tblock_sizze_23707));
                    
                    {
                        err = gpu_kernel_compilerziseghist_local_22668(ctx, num_tblocks_23708, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_23714 * hist_H_chk_23720) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23714 * hist_H_chk_23720), (int64_t) 8), (int64_t) 8), mz2080U_19405, m_21094, num_subhistos_23697, num_tblocks_23708, hist_M_23714, chk_i_23718, num_segments_23719, hist_H_chk_23720, histo_sizze_23721, init_per_thread_23722, mem_22819.mem, defunc_0_map_res_subhistos_mem_23698.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using global memory");
                
                int64_t hist_H_23754 = mz2080U_19405;
                double hist_RF_23755 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
                int32_t hist_el_sizze_23756 = 4;
                double hist_C_max_23757 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22663 * seghist_tblock_sizze_22661)), sitofp_i32_f64(hist_H_23754) / 2.0);
                int32_t hist_M_min_23758 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22663 * seghist_tblock_sizze_22661)) / hist_C_max_23757)));
                int64_t hist_L2_23759;
                
                hist_L2_23759 = *ctx->tuning_params.compilerzihist_L2_23759;
                
                double hist_RACE_exp_23760 = fmax64(1.0, 0.75 * hist_RF_23755 / (64.0 / sitofp_i32_f64(hist_el_sizze_23756)));
                int32_t hist_S_23761;
                
                if (slt64(m_21094, hist_H_23754)) {
                    hist_S_23761 = 1;
                } else {
                    hist_S_23761 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_23758) * hist_H_23754 * sext_i32_i64(hist_el_sizze_23756), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_23759) * hist_RACE_exp_23760)));
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_23760, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23761, '\n');
                
                int64_t hist_H_chk_23762 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23761));
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_23762, '\n');
                
                double hist_k_max_23763 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_23759) / sitofp_i32_f64(4)) * hist_RACE_exp_23760, sitofp_i32_f64(m_21094)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_22663 * seghist_tblock_sizze_22661));
                int64_t hist_u_23764 = (int64_t) 2;
                double hist_C_23765 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22663 * seghist_tblock_sizze_22661)), sitofp_i32_f64(hist_u_23764 * hist_H_chk_23762) / hist_k_max_23763);
                int32_t hist_M_23766 = 1;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_23763, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23766, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_23765, '\n');
                num_subhistos_23697 = sext_i32_i64(hist_M_23766);
                if (hist_M_23766 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23698, &mem_22827, "mem_22827") != 0)
                        return 1;
                } else if (num_subhistos_23697 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23698, &mem_22827, "mem_22827") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23698, num_subhistos_23697 * mz2080U_19405 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23698")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23698, num_subhistos_23697 * mz2080U_19405, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23698.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22827.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_19405})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23767 = 0; chk_i_23767 < hist_S_23761; chk_i_23767++) {
                    int64_t hist_H_chk_23768 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23761));
                    
                    {
                        err = gpu_kernel_compilerziseghist_global_22668(ctx, num_tblocks_22663, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22660, 1, 1, (int64_t) 0, mz2080U_19405, m_21094, num_tblocks_22663, num_subhistos_23697, chk_i_23767, hist_H_chk_23768, mem_22819.mem, defunc_0_map_res_subhistos_mem_23698.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
            if (num_subhistos_23697 == (int64_t) 1) {
                if (memblock_set_device(ctx, &mem_22827, &defunc_0_map_res_subhistos_mem_23698, "defunc_0_map_res_subhistos_mem_23698") != 0)
                    return 1;
            } else {
                int64_t chunk_sizze_23784 = (int64_t) 1;
                
                if (slt64(num_subhistos_23697 * (int64_t) 2, seghist_tblock_sizze_22661 * chunk_sizze_23784)) {
                    int64_t segment_sizze_nonzzero_23785 = smax64((int64_t) 1, num_subhistos_23697);
                    int64_t num_threads_23786 = seghist_tblock_sizze_22661 * seghist_tblock_sizze_22661;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_19405, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23697, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_19405, squot64(seghist_tblock_sizze_22661, segment_sizze_nonzzero_23785))), '\n');
                    {
                        err = gpu_kernel_compilerzisegred_small_23783(ctx, num_tblocks_22663, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22660, 1, 1, (int64_t) 4 * seghist_tblock_sizze_22661 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22661, (int64_t) 8), (int64_t) 8), mz2080U_19405, num_tblocks_22663, num_subhistos_23697, segment_sizze_nonzzero_23785, mem_22827.mem, defunc_0_map_res_subhistos_mem_23698.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_23814 = sdiv_up64(num_tblocks_22663, smax64((int64_t) 1, mz2080U_19405));
                    int64_t q_23815 = sdiv_up64(num_subhistos_23697, seghist_tblock_sizze_22661 * blocks_per_segment_23814 * chunk_sizze_23784);
                    int64_t num_virtblocks_23816 = blocks_per_segment_23814 * mz2080U_19405;
                    int64_t threads_per_segment_23817 = blocks_per_segment_23814 * seghist_tblock_sizze_22661;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_19405, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23697, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_23816, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22663, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_22661, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_23815, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_23814, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_23818, (int64_t) 4 * num_virtblocks_23816, "segred_tmp_mem_23818")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_compilerzisegred_large_23783(ctx, num_tblocks_22663, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22660, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_22661 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22661, (int64_t) 8), (int64_t) 8)), mz2080U_19405, num_tblocks_22663, num_subhistos_23697, blocks_per_segment_23814, q_23815, num_virtblocks_23816, threads_per_segment_23817, mem_22827.mem, defunc_0_map_res_subhistos_mem_23698.mem, segred_tmp_mem_23818.mem, counters_mem_23820.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_22819, "mem_22819") != 0)
            return 1;
        if (futrts_builtinzhreplicate_i32(ctx, mem_22830, mz2080U_19405, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_tblocks_22679;
        int64_t max_num_tblocks_23857;
        
        max_num_tblocks_23857 = *ctx->tuning_params.compilerziseghist_num_tblocks_22678;
        num_tblocks_22679 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(m_21135, seghist_tblock_sizze_22677), max_num_tblocks_23857)));
        
        int64_t num_subhistos_23858;
        int64_t h_23861 = (int64_t) 4 * mz2080U_19405;
        int64_t seg_h_23862 = (int64_t) 4 * mz2080U_19405;
        
        if (!(seg_h_23862 == (int64_t) 0)) {
            int64_t hist_H_23863 = mz2080U_19405;
            int64_t hist_el_sizze_23864 = sdiv_up64(h_23861, hist_H_23863);
            int64_t hist_N_23865 = m_21135;
            int32_t hist_RF_23866 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegHist");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_22679 * seghist_tblock_sizze_22677), '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_22677, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23863, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_23865, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_23864, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_23866, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_23861, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_23862, '\n');
            
            int64_t hist_L_23867;
            
            hist_L_23867 = *ctx->tuning_params.compilerzihist_L_23867;
            
            int64_t max_tblock_sizze_23868;
            
            max_tblock_sizze_23868 = ctx->max_thread_block_size;
            
            int64_t num_tblocks_23869 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_22679 * seghist_tblock_sizze_22677)), max_tblock_sizze_23868);
            double hist_m_prime_23870 = sitofp_i64_f64(smin64(squot64(hist_L_23867, hist_el_sizze_23864), sdiv_up64(hist_N_23865, num_tblocks_23869))) / sitofp_i64_f64(hist_H_23863);
            int64_t hist_M0_23871 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_23870), max_tblock_sizze_23868));
            int64_t hist_Nout_23872 = (int64_t) 1;
            int64_t hist_Nin_23873 = m_21135;
            int64_t work_asymp_M_max_23874 = squot64(hist_Nout_23872 * hist_N_23865, (int64_t) 2 * num_tblocks_23869 * hist_H_23863);
            int32_t hist_M_23875 = sext_i64_i32(smin64(hist_M0_23871, work_asymp_M_max_23874));
            int64_t hist_C_23876 = sdiv_up64(max_tblock_sizze_23868, sext_i32_i64(smax32(1, hist_M_23875)));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_23871, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_23874, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_23876, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_23868, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_23875, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_23863 * hist_el_sizze_23864 * sext_i32_i64(hist_M_23875)), '\n');
            
            int64_t local_mem_needed_23877 = hist_el_sizze_23864 * sext_i32_i64(hist_M_23875);
            int32_t hist_S_23878 = sext_i64_i32(sdiv_up64(hist_H_23863 * local_mem_needed_23877 + (int64_t) 1, hist_L_23867));
            
            if (sle64(hist_H_23863, hist_Nin_23873) && (sle64(local_mem_needed_23877, hist_L_23867) && (sle32(hist_S_23878, 3) && (sle64(hist_C_23876, max_tblock_sizze_23868) && slt32(0, hist_M_23875))))) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using shared memory");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23863, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23875, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_23876, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23878, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_23875, '\n');
                num_subhistos_23858 = num_tblocks_23869;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_23858, '\n');
                if (num_subhistos_23858 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23859, &mem_22830, "mem_22830") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23859, num_subhistos_23858 * mz2080U_19405 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23859")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23859, num_subhistos_23858 * mz2080U_19405, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23859.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22830.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_19405})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23879 = 0; chk_i_23879 < hist_S_23878; chk_i_23879++) {
                    int64_t num_segments_23880 = (int64_t) 1;
                    int64_t hist_H_chk_23881 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23878));
                    int64_t histo_sizze_23882 = hist_H_chk_23881;
                    int32_t init_per_thread_23883 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_23875) * histo_sizze_23882, max_tblock_sizze_23868));
                    
                    {
                        err = gpu_kernel_compilerziseghist_local_22684(ctx, num_tblocks_23869, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_23875 * hist_H_chk_23881) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23875 * hist_H_chk_23881), (int64_t) 8), (int64_t) 8), mz2080U_19405, m_21135, num_subhistos_23858, num_tblocks_23869, hist_M_23875, chk_i_23879, num_segments_23880, hist_H_chk_23881, histo_sizze_23882, init_per_thread_23883, mem_22817.mem, defunc_0_map_res_subhistos_mem_23859.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using global memory");
                
                int64_t hist_H_23915 = mz2080U_19405;
                double hist_RF_23916 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
                int32_t hist_el_sizze_23917 = 4;
                double hist_C_max_23918 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22679 * seghist_tblock_sizze_22677)), sitofp_i32_f64(hist_H_23915) / 2.0);
                int32_t hist_M_min_23919 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22679 * seghist_tblock_sizze_22677)) / hist_C_max_23918)));
                int64_t hist_L2_23920;
                
                hist_L2_23920 = *ctx->tuning_params.compilerzihist_L2_23920;
                
                double hist_RACE_exp_23921 = fmax64(1.0, 0.75 * hist_RF_23916 / (64.0 / sitofp_i32_f64(hist_el_sizze_23917)));
                int32_t hist_S_23922;
                
                if (slt64(m_21135, hist_H_23915)) {
                    hist_S_23922 = 1;
                } else {
                    hist_S_23922 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_23919) * hist_H_23915 * sext_i32_i64(hist_el_sizze_23917), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_23920) * hist_RACE_exp_23921)));
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_23921, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23922, '\n');
                
                int64_t hist_H_chk_23923 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23922));
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_23923, '\n');
                
                double hist_k_max_23924 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_23920) / sitofp_i32_f64(4)) * hist_RACE_exp_23921, sitofp_i32_f64(m_21135)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_22679 * seghist_tblock_sizze_22677));
                int64_t hist_u_23925 = (int64_t) 2;
                double hist_C_23926 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22679 * seghist_tblock_sizze_22677)), sitofp_i32_f64(hist_u_23925 * hist_H_chk_23923) / hist_k_max_23924);
                int32_t hist_M_23927 = 1;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_23924, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23927, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_23926, '\n');
                num_subhistos_23858 = sext_i32_i64(hist_M_23927);
                if (hist_M_23927 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23859, &mem_22830, "mem_22830") != 0)
                        return 1;
                } else if (num_subhistos_23858 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23859, &mem_22830, "mem_22830") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23859, num_subhistos_23858 * mz2080U_19405 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23859")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23859, num_subhistos_23858 * mz2080U_19405, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23859.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22830.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_19405})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23928 = 0; chk_i_23928 < hist_S_23922; chk_i_23928++) {
                    int64_t hist_H_chk_23929 = sdiv_up64(mz2080U_19405, sext_i32_i64(hist_S_23922));
                    
                    {
                        err = gpu_kernel_compilerziseghist_global_22684(ctx, num_tblocks_22679, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22676, 1, 1, (int64_t) 0, mz2080U_19405, m_21135, num_tblocks_22679, num_subhistos_23858, chk_i_23928, hist_H_chk_23929, mem_22817.mem, defunc_0_map_res_subhistos_mem_23859.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
            if (num_subhistos_23858 == (int64_t) 1) {
                if (memblock_set_device(ctx, &mem_22830, &defunc_0_map_res_subhistos_mem_23859, "defunc_0_map_res_subhistos_mem_23859") != 0)
                    return 1;
            } else {
                int64_t chunk_sizze_23945 = (int64_t) 1;
                
                if (slt64(num_subhistos_23858 * (int64_t) 2, seghist_tblock_sizze_22677 * chunk_sizze_23945)) {
                    int64_t segment_sizze_nonzzero_23946 = smax64((int64_t) 1, num_subhistos_23858);
                    int64_t num_threads_23947 = seghist_tblock_sizze_22677 * seghist_tblock_sizze_22677;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_19405, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23858, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_19405, squot64(seghist_tblock_sizze_22677, segment_sizze_nonzzero_23946))), '\n');
                    {
                        err = gpu_kernel_compilerzisegred_small_23944(ctx, num_tblocks_22679, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22676, 1, 1, (int64_t) 4 * seghist_tblock_sizze_22677 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22677, (int64_t) 8), (int64_t) 8), mz2080U_19405, num_tblocks_22679, num_subhistos_23858, segment_sizze_nonzzero_23946, mem_22830.mem, defunc_0_map_res_subhistos_mem_23859.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_23975 = sdiv_up64(num_tblocks_22679, smax64((int64_t) 1, mz2080U_19405));
                    int64_t q_23976 = sdiv_up64(num_subhistos_23858, seghist_tblock_sizze_22677 * blocks_per_segment_23975 * chunk_sizze_23945);
                    int64_t num_virtblocks_23977 = blocks_per_segment_23975 * mz2080U_19405;
                    int64_t threads_per_segment_23978 = blocks_per_segment_23975 * seghist_tblock_sizze_22677;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_19405, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23858, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_23977, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22679, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_22677, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_23976, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_23975, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_23979, (int64_t) 4 * num_virtblocks_23977, "segred_tmp_mem_23979")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_compilerzisegred_large_23944(ctx, num_tblocks_22679, 1, 1, *ctx->tuning_params.compilerziseghist_tblock_sizze_22676, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_22677 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22677, (int64_t) 8), (int64_t) 8)), mz2080U_19405, num_tblocks_22679, num_subhistos_23858, blocks_per_segment_23975, q_23976, num_virtblocks_23977, threads_per_segment_23978, mem_22830.mem, defunc_0_map_res_subhistos_mem_23859.mem, segred_tmp_mem_23979.mem, counters_mem_23981.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_22817, "mem_22817") != 0)
            return 1;
        if (memblock_alloc_device(ctx, &mem_22834, bytes_22769, "mem_22834")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22836, bytes_22769, "mem_22836")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22838, bytes_22769, "mem_22838")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_24018 = sext_i64_i32(sdiv_up64(mz2080U_19405, segmap_tblock_sizze_22720));
        
        {
            err = gpu_kernel_compilerzisegmap_22727(ctx, segmap_usable_groups_22721, 1, 1, *ctx->tuning_params.compilerzisegmap_tblock_sizze_22694, 1, 1, (int64_t) 0, mz2080U_19405, mem_param_22784.mem, mem_param_22787.mem, mem_param_22796.mem, mem_22802.mem, mem_22824.mem, mem_22827.mem, mem_22830.mem, mem_22834.mem, mem_22836.mem, mem_22838.mem, mem_22840.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t num_tblocks_22752;
        int64_t max_num_tblocks_24027;
        
        max_num_tblocks_24027 = *ctx->tuning_params.compilerzisegscan_num_tblocks_22751;
        num_tblocks_22752 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2083Uz2082U_21002, segscan_tblock_sizze_22750), max_num_tblocks_24027)));
        if (memblock_alloc_device(ctx, &mem_22843, bytes_22804, "mem_22843")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22845, bytes_22804, "mem_22845")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, loop_dz2083Uz2082U_21002)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_24028;
            
            shared_memory_24028 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_24029;
            
            thread_block_sizze_24029 = ctx->max_thread_block_size;
            
            int64_t registers_24030;
            
            registers_24030 = ctx->max_registers;
            
            int64_t thread_block_sizze_24031;
            
            thread_block_sizze_24031 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_24032 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_24028, thread_block_sizze_24029), (int64_t) 8), squot64(squot64(registers_24030, thread_block_sizze_24031) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_24033 = sdiv_up64(loop_dz2083Uz2082U_21002, segscan_tblock_sizze_22750 * chunk_sizze_24032);
            int64_t num_virt_threads_24034 = num_virt_blocks_24033 * segscan_tblock_sizze_22750;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_24032, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_24035, num_virt_blocks_24033, "status_flags_mem_24035")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_24035, num_virt_blocks_24033, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_24037, (int64_t) 8 * num_virt_blocks_24033, "aggregates_mem_24037")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_24039, (int64_t) 8 * num_virt_blocks_24033, "incprefixes_mem_24039")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_compilerzisegscan_22755(ctx, num_tblocks_22752, 1, 1, *ctx->tuning_params.compilerzisegscan_tblock_sizze_22749, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22750), chunk_sizze_24032 * segscan_tblock_sizze_22750 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22750), chunk_sizze_24032 * segscan_tblock_sizze_22750 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_19405, loop_dz2083Uz2082U_21002, num_tblocks_22752, num_virt_blocks_24033, num_virt_threads_24034, mem_param_22790.mem, mem_param_22793.mem, mem_22802.mem, mem_22840.mem, mem_22843.mem, mem_22845.mem, status_flags_mem_24035.mem, aggregates_mem_24037.mem, incprefixes_mem_24039.mem, global_dynid_mem_24041.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        int64_t m_f_res_21247;
        
        if (x_21044) {
            int64_t read_res_24148;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_24148, mem_22843.mem, tmp_21045 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_21912 = read_res_24148;
            
            m_f_res_21247 = x_21912;
        } else {
            m_f_res_21247 = (int64_t) 0;
        }
        
        int64_t m_21249;
        
        if (cond_21043) {
            m_21249 = (int64_t) 0;
        } else {
            m_21249 = m_f_res_21247;
        }
        
        int64_t m_21259 = sub64(m_21249, (int64_t) 1);
        bool i_p_m_t_s_leq_w_21261 = slt64(m_21259, loop_dz2083Uz2082U_21002);
        bool zzero_leq_i_p_m_t_s_21260 = sle64((int64_t) 0, m_21259);
        bool y_21263 = zzero_leq_i_p_m_t_s_21260 && i_p_m_t_s_leq_w_21261;
        bool i_lte_j_21262 = sle64((int64_t) 0, m_21249);
        bool forwards_ok_21264 = i_lte_j_21262 && y_21263;
        bool eq_x_zz_21256 = (int64_t) 0 == m_f_res_21247;
        bool p_and_eq_x_y_21257 = x_21044 && eq_x_zz_21256;
        bool empty_slice_21258 = cond_21043 || p_and_eq_x_y_21257;
        bool ok_or_empty_21265 = empty_slice_21258 || forwards_ok_21264;
        bool index_certs_21266;
        
        if (!ok_or_empty_21265) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_21249, "] out of bounds for array of shape [", (long long) loop_dz2083Uz2082U_21002, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  auto_test.fut:14:18-42\n   #3  auto_test.fut:14:1-42\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_22846 = (int64_t) 4 * m_21249;
        
        if (memblock_alloc_device(ctx, &mem_22847, bytes_22846, "mem_22847")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22847.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22790.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21249})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_22849, bytes_22846, "mem_22849")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22849.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22793.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21249})) != 0)
            goto cleanup;
        
        int64_t num_tblocks_22762;
        int64_t max_num_tblocks_24130;
        
        max_num_tblocks_24130 = *ctx->tuning_params.compilerzisegmap_num_tblocks_22761;
        num_tblocks_22762 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2083Uz2082U_21002, segmap_tblock_sizze_22760), max_num_tblocks_24130)));
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_24131 = sext_i64_i32(sdiv_up64(loop_dz2083Uz2082U_21002, segmap_tblock_sizze_22760));
        
        {
            err = gpu_kernel_compilerzisegmap_22757(ctx, num_tblocks_22762, 1, 1, *ctx->tuning_params.compilerzisegmap_tblock_sizze_22759, 1, 1, (int64_t) 0, loop_dz2083Uz2082U_21002, m_21249, num_tblocks_22762, virt_num_tblocks_24131, mem_param_22790.mem, mem_param_22793.mem, mem_22843.mem, mem_22845.mem, mem_22847.mem, mem_22849.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_22843, "mem_22843") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22845, "mem_22845") != 0)
            return 1;
        
        bool loop_cond_21276 = slt64((int64_t) 0, m_21249);
        
        if (memblock_set_device(ctx, &mem_param_tmp_23195, &mem_22836, "mem_22836") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_23196, &mem_22834, "mem_22834") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_23197, &mem_22847, "mem_22847") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_23198, &mem_22849, "mem_22849") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_23199, &mem_22838, "mem_22838") != 0)
            return 1;
        
        int64_t loop_dz2083Uz2082U_tmp_23200 = m_21249;
        bool loop_while_tmp_23201 = loop_cond_21276;
        
        if (memblock_set_device(ctx, &mem_param_22784, &mem_param_tmp_23195, "mem_param_tmp_23195") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22787, &mem_param_tmp_23196, "mem_param_tmp_23196") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22790, &mem_param_tmp_23197, "mem_param_tmp_23197") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22793, &mem_param_tmp_23198, "mem_param_tmp_23198") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22796, &mem_param_tmp_23199, "mem_param_tmp_23199") != 0)
            return 1;
        loop_dz2083Uz2082U_21002 = loop_dz2083Uz2082U_tmp_23200;
        loop_while_21003 = loop_while_tmp_23201;
    }
    if (memblock_set_device(ctx, &ext_mem_22865, &mem_param_22784, "mem_param_22784") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22864, &mem_param_22787, "mem_param_22787") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22863, &mem_param_22790, "mem_param_22790") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22862, &mem_param_22793, "mem_param_22793") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22861, &mem_param_22796, "mem_param_22796") != 0)
        return 1;
    result_20995 = loop_dz2083Uz2082U_21002;
    result_20996 = loop_while_21003;
    if (memblock_unref_device(ctx, &mem_22770, "mem_22770") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22781, "mem_22781") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22799, "mem_22799") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22802, "mem_22802") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22824, "mem_22824") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22827, "mem_22827") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22830, "mem_22830") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22840, "mem_22840") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_22884, &ext_mem_22861, "ext_mem_22861") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_24144, &mem_out_22884, "mem_out_22884") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_param_tmp_23199, "mem_param_tmp_23199") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_23198, "mem_param_tmp_23198") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_23197, "mem_param_tmp_23197") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_23196, "mem_param_tmp_23196") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_23195, "mem_param_tmp_23195") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22849, "mem_22849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22847, "mem_22847") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_24039, "incprefixes_mem_24039") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_24037, "aggregates_mem_24037") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_24035, "status_flags_mem_24035") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22845, "mem_22845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22843, "mem_22843") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22838, "mem_22838") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22836, "mem_22836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22834, "mem_22834") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23979, "segred_tmp_mem_23979") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_23859, "defunc_0_map_res_subhistos_mem_23859") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23818, "segred_tmp_mem_23818") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_23698, "defunc_0_map_res_subhistos_mem_23698") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23657, "segred_tmp_mem_23657") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_23537, "defunc_0_map_res_subhistos_mem_23537") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22821, "mem_22821") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22819, "mem_22819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22817, "mem_22817") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23338, "incprefixes_mem_23338") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23336, "aggregates_mem_23336") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23334, "incprefixes_mem_23334") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23332, "aggregates_mem_23332") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23330, "incprefixes_mem_23330") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23328, "aggregates_mem_23328") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23326, "status_flags_mem_23326") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22815, "mem_22815") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22813, "mem_22813") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22811, "mem_22811") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22809, "mem_22809") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22807, "mem_22807") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22805, "mem_22805") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23218, "incprefixes_mem_23218") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23216, "aggregates_mem_23216") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23214, "status_flags_mem_23214") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22796, "mem_param_22796") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22793, "mem_param_22793") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22790, "mem_param_22790") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22787, "mem_param_22787") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22784, "mem_param_22784") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22861, "ext_mem_22861") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22862, "ext_mem_22862") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22863, "ext_mem_22863") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22864, "ext_mem_22864") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22865, "ext_mem_22865") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22840, "mem_22840") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22830, "mem_22830") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22827, "mem_22827") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22824, "mem_22824") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22802, "mem_22802") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22799, "mem_22799") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23094, "incprefixes_mem_23094") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23092, "aggregates_mem_23092") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23090, "status_flags_mem_23090") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22781, "mem_22781") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22774, "mem_22774") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_22937, "incprefixes_mem_22937") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_22935, "aggregates_mem_22935") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_22913, "status_flags_mem_22913") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22773, "mem_22773") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22770, "mem_22770") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_22884, "mem_out_22884") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_human(struct futhark_context *ctx, struct memblock_device *mem_out_p_24149, struct memblock_device ks_mem_22766, struct memblock_device shp_mem_22767, struct memblock_device II1_mem_22768, struct memblock_device A_mem_22769, int64_t mz2080U_14093, int64_t nz2081U_14094)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_param_tmp_22910;
    
    mem_param_tmp_22910.references = NULL;
    
    struct memblock_device mem_param_tmp_22909;
    
    mem_param_tmp_22909.references = NULL;
    
    struct memblock_device mem_param_tmp_22908;
    
    mem_param_tmp_22908.references = NULL;
    
    struct memblock_device mem_param_tmp_22907;
    
    mem_param_tmp_22907.references = NULL;
    
    struct memblock_device mem_param_tmp_22906;
    
    mem_param_tmp_22906.references = NULL;
    
    struct memblock_device mem_22820;
    
    mem_22820.references = NULL;
    
    struct memblock_device mem_22818;
    
    mem_22818.references = NULL;
    
    struct memblock_device incprefixes_mem_23287;
    
    incprefixes_mem_23287.references = NULL;
    
    struct memblock_device aggregates_mem_23285;
    
    aggregates_mem_23285.references = NULL;
    
    struct memblock_device status_flags_mem_23283;
    
    status_flags_mem_23283.references = NULL;
    
    struct memblock_device mem_22816;
    
    mem_22816.references = NULL;
    
    struct memblock_device mem_22814;
    
    mem_22814.references = NULL;
    
    struct memblock_device mem_22811;
    
    mem_22811.references = NULL;
    
    struct memblock_device mem_22809;
    
    mem_22809.references = NULL;
    
    struct memblock_device mem_22805;
    
    mem_22805.references = NULL;
    
    struct memblock_device segred_tmp_mem_23221;
    
    segred_tmp_mem_23221.references = NULL;
    
    struct memblock_device segred_tmp_mem_23219;
    
    segred_tmp_mem_23219.references = NULL;
    
    struct memblock_device zzip_copy_subhistos_mem_23082;
    
    zzip_copy_subhistos_mem_23082.references = NULL;
    
    struct memblock_device zzip_copy_subhistos_mem_23080;
    
    zzip_copy_subhistos_mem_23080.references = NULL;
    
    struct memblock_device mem_22797;
    
    mem_22797.references = NULL;
    
    struct memblock_device mem_22795;
    
    mem_22795.references = NULL;
    
    struct memblock_device incprefixes_mem_22949;
    
    incprefixes_mem_22949.references = NULL;
    
    struct memblock_device aggregates_mem_22947;
    
    aggregates_mem_22947.references = NULL;
    
    struct memblock_device status_flags_mem_22925;
    
    status_flags_mem_22925.references = NULL;
    
    struct memblock_device mem_param_22786;
    
    mem_param_22786.references = NULL;
    
    struct memblock_device mem_param_22783;
    
    mem_param_22783.references = NULL;
    
    struct memblock_device mem_param_22780;
    
    mem_param_22780.references = NULL;
    
    struct memblock_device mem_param_22777;
    
    mem_param_22777.references = NULL;
    
    struct memblock_device mem_param_22774;
    
    mem_param_22774.references = NULL;
    
    struct memblock_device ext_mem_22832;
    
    ext_mem_22832.references = NULL;
    
    struct memblock_device ext_mem_22833;
    
    ext_mem_22833.references = NULL;
    
    struct memblock_device ext_mem_22834;
    
    ext_mem_22834.references = NULL;
    
    struct memblock_device ext_mem_22835;
    
    ext_mem_22835.references = NULL;
    
    struct memblock_device ext_mem_22836;
    
    ext_mem_22836.references = NULL;
    
    struct memblock_device mem_22807;
    
    mem_22807.references = NULL;
    
    struct memblock_device mem_22801;
    
    mem_22801.references = NULL;
    
    struct memblock_device mem_22799;
    
    mem_22799.references = NULL;
    
    struct memblock_device mem_22792;
    
    mem_22792.references = NULL;
    
    struct memblock_device mem_22789;
    
    mem_22789.references = NULL;
    
    struct memblock_device mem_22771;
    
    mem_22771.references = NULL;
    
    struct memblock_device mem_out_22884;
    
    mem_out_22884.references = NULL;
    
    struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
    struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
    struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
    struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
    struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
    struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
    struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
    struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
    struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
    struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
    struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
    struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
    struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
    struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
    struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
    struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
    struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
    struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
    struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
    int64_t bytes_22770 = (int64_t) 4 * mz2080U_14093;
    
    if (memblock_alloc_device(ctx, &mem_22771, bytes_22770, "mem_22771")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_f32(ctx, mem_22771, mz2080U_14093, 0.0F) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool loop_cond_20979 = slt64((int64_t) 0, nz2081U_14094);
    int64_t segscan_tblock_sizze_21973;
    
    segscan_tblock_sizze_21973 = *ctx->tuning_params.humanzisegscan_tblock_sizze_21972;
    
    int64_t num_tblocks_21975;
    int64_t max_num_tblocks_22905;
    
    max_num_tblocks_22905 = *ctx->tuning_params.humanzisegscan_num_tblocks_21974;
    num_tblocks_21975 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_14093, segscan_tblock_sizze_21973), max_num_tblocks_22905)));
    
    int64_t segmap_tblock_sizze_22000;
    
    segmap_tblock_sizze_22000 = *ctx->tuning_params.humanzisegmap_tblock_sizze_21982;
    
    int64_t segmap_usable_groups_22001 = sdiv_up_safe64(mz2080U_14093, segmap_tblock_sizze_22000);
    int64_t segmap_tblock_sizze_22038;
    
    segmap_tblock_sizze_22038 = *ctx->tuning_params.humanzisegmap_tblock_sizze_22020;
    
    int64_t seghist_tblock_sizze_22058;
    
    seghist_tblock_sizze_22058 = *ctx->tuning_params.humanziseghist_tblock_sizze_22057;
    
    int64_t segmap_tblock_sizze_22110;
    
    segmap_tblock_sizze_22110 = *ctx->tuning_params.humanzisegmap_tblock_sizze_22079;
    
    int64_t segmap_usable_groups_22111 = sdiv_up_safe64(mz2080U_14093, segmap_tblock_sizze_22110);
    int64_t segscan_tblock_sizze_22145;
    
    segscan_tblock_sizze_22145 = *ctx->tuning_params.humanzisegscan_tblock_sizze_22144;
    
    int64_t segmap_tblock_sizze_22155;
    
    segmap_tblock_sizze_22155 = *ctx->tuning_params.humanzisegmap_tblock_sizze_22154;
    if (memblock_alloc_device(ctx, &mem_22789, bytes_22770, "mem_22789")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22792, bytes_22770, "mem_22792")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22799, bytes_22770, "mem_22799")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22801, bytes_22770, "mem_22801")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22807, bytes_22770, "mem_22807")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t result_20980;
    bool result_20981;
    int64_t loop_dz2087U_20987;
    bool loop_while_20988;
    
    if (memblock_set_device(ctx, &mem_param_22774, &ks_mem_22766, "ks_mem_22766") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22777, &shp_mem_22767, "shp_mem_22767") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22780, &II1_mem_22768, "II1_mem_22768") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22783, &A_mem_22769, "A_mem_22769") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22786, &mem_22771, "mem_22771") != 0)
        return 1;
    loop_dz2087U_20987 = nz2081U_14094;
    loop_while_20988 = loop_cond_20979;
    while (loop_while_20988) {
        if (slt64((int64_t) 0, mz2080U_14093)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_22918;
            
            shared_memory_22918 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_22919;
            
            thread_block_sizze_22919 = ctx->max_thread_block_size;
            
            int64_t registers_22920;
            
            registers_22920 = ctx->max_registers;
            
            int64_t thread_block_sizze_22921;
            
            thread_block_sizze_22921 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_22922 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_22918, thread_block_sizze_22919), (int64_t) 4), squot64(squot64(registers_22920, thread_block_sizze_22921) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
            int64_t num_virt_blocks_22923 = sdiv_up64(mz2080U_14093, segscan_tblock_sizze_21973 * chunk_sizze_22922);
            int64_t num_virt_threads_22924 = num_virt_blocks_22923 * segscan_tblock_sizze_21973;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_22922, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_22925, num_virt_blocks_22923, "status_flags_mem_22925")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_22925, num_virt_blocks_22923, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_22947, (int64_t) 4 * num_virt_blocks_22923, "aggregates_mem_22947")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_22949, (int64_t) 4 * num_virt_blocks_22923, "incprefixes_mem_22949")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_humanzisegscan_21978(ctx, num_tblocks_21975, 1, 1, *ctx->tuning_params.humanzisegscan_tblock_sizze_21972, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_21973), chunk_sizze_22922 * segscan_tblock_sizze_21973 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_21973), chunk_sizze_22922 * segscan_tblock_sizze_21973 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_14093, num_tblocks_21975, num_virt_blocks_22923, num_virt_threads_22924, mem_param_22777.mem, mem_22789.mem, status_flags_mem_22925.mem, aggregates_mem_22947.mem, incprefixes_mem_22949.mem, global_dynid_mem_22951.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23060 = sext_i64_i32(sdiv_up64(mz2080U_14093, segmap_tblock_sizze_22000));
        
        {
            err = gpu_kernel_humanzisegmap_22004(ctx, segmap_usable_groups_22001, 1, 1, *ctx->tuning_params.humanzisegmap_tblock_sizze_21982, 1, 1, (int64_t) 0, mz2080U_14093, loop_dz2087U_20987, mem_param_22777.mem, mem_param_22783.mem, mem_22789.mem, mem_22792.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t segmap_usable_groups_22039 = sdiv_up64(loop_dz2087U_20987, segmap_tblock_sizze_22038);
        int64_t bytes_22794 = (int64_t) 4 * loop_dz2087U_20987;
        
        if (memblock_alloc_device(ctx, &mem_22795, bytes_22794, "mem_22795")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22797, bytes_22794, "mem_22797")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23069 = sext_i64_i32(sdiv_up64(loop_dz2087U_20987, segmap_tblock_sizze_22038));
        
        {
            err = gpu_kernel_humanzisegmap_22043(ctx, segmap_usable_groups_22039, 1, 1, *ctx->tuning_params.humanzisegmap_tblock_sizze_22020, 1, 1, (int64_t) 0, mz2080U_14093, loop_dz2087U_20987, mem_param_22780.mem, mem_param_22783.mem, mem_22792.mem, mem_22795.mem, mem_22797.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (futrts_builtinzhreplicate_i32(ctx, mem_22799, mz2080U_14093, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i32(ctx, mem_22801, mz2080U_14093, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_tblocks_22060;
        int64_t max_num_tblocks_23078;
        
        max_num_tblocks_23078 = *ctx->tuning_params.humanziseghist_num_tblocks_22059;
        num_tblocks_22060 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2087U_20987, seghist_tblock_sizze_22058), max_num_tblocks_23078)));
        
        int64_t num_subhistos_23079;
        int64_t h_23084 = (int64_t) 4 * mz2080U_14093 + (int64_t) 4 * mz2080U_14093;
        int64_t seg_h_23085 = (int64_t) 4 * mz2080U_14093 + (int64_t) 4 * mz2080U_14093;
        
        if (!(seg_h_23085 == (int64_t) 0)) {
            int64_t hist_H_23086 = mz2080U_14093;
            int64_t hist_el_sizze_23087 = sdiv_up64(h_23084, hist_H_23086);
            int64_t hist_N_23088 = loop_dz2087U_20987;
            int32_t hist_RF_23089 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegHist");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_22060 * seghist_tblock_sizze_22058), '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_22058, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23086, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_23088, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_23087, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_23089, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_23084, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_23085, '\n');
            
            int64_t hist_L_23090;
            
            hist_L_23090 = *ctx->tuning_params.humanzihist_L_23090;
            
            int64_t max_tblock_sizze_23091;
            
            max_tblock_sizze_23091 = ctx->max_thread_block_size;
            
            int64_t num_tblocks_23092 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_22060 * seghist_tblock_sizze_22058)), max_tblock_sizze_23091);
            double hist_m_prime_23093 = sitofp_i64_f64(smin64(squot64(hist_L_23090, hist_el_sizze_23087), sdiv_up64(hist_N_23088, num_tblocks_23092))) / sitofp_i64_f64(hist_H_23086);
            int64_t hist_M0_23094 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_23093), max_tblock_sizze_23091));
            int64_t hist_Nout_23095 = (int64_t) 1;
            int64_t hist_Nin_23096 = loop_dz2087U_20987;
            int64_t work_asymp_M_max_23097 = squot64(hist_Nout_23095 * hist_N_23088, (int64_t) 2 * num_tblocks_23092 * hist_H_23086);
            int32_t hist_M_23098 = sext_i64_i32(smin64(hist_M0_23094, work_asymp_M_max_23097));
            int64_t hist_C_23099 = sdiv_up64(max_tblock_sizze_23091, sext_i32_i64(smax32(1, hist_M_23098)));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_23094, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_23097, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_23099, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_23091, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_23098, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_23086 * hist_el_sizze_23087 * sext_i32_i64(hist_M_23098)), '\n');
            
            int64_t local_mem_needed_23100 = hist_el_sizze_23087 * sext_i32_i64(hist_M_23098);
            int32_t hist_S_23101 = sext_i64_i32(sdiv_up64(hist_H_23086 * local_mem_needed_23100 + (int64_t) 1, hist_L_23090));
            
            if (sle64(hist_H_23086, hist_Nin_23096) && (sle64(local_mem_needed_23100, hist_L_23090) && (sle32(hist_S_23101, 3) && (sle64(hist_C_23099, max_tblock_sizze_23091) && slt32(0, hist_M_23098))))) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using shared memory");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23086, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23098, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_23099, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23101, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_23098, '\n');
                num_subhistos_23079 = num_tblocks_23092;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_23079, '\n');
                if (num_subhistos_23079 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &zzip_copy_subhistos_mem_23080, &mem_22801, "mem_22801") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &zzip_copy_subhistos_mem_23080, num_subhistos_23079 * mz2080U_14093 * (int64_t) 4, "zzip_copy_subhistos_mem_23080")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, zzip_copy_subhistos_mem_23080, num_subhistos_23079 * mz2080U_14093, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, zzip_copy_subhistos_mem_23080.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22801.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_14093})) != 0)
                        goto cleanup;
                }
                if (num_subhistos_23079 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &zzip_copy_subhistos_mem_23082, &mem_22799, "mem_22799") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &zzip_copy_subhistos_mem_23082, num_subhistos_23079 * mz2080U_14093 * (int64_t) 4, "zzip_copy_subhistos_mem_23082")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, zzip_copy_subhistos_mem_23082, num_subhistos_23079 * mz2080U_14093, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, zzip_copy_subhistos_mem_23082.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22799.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_14093})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23102 = 0; chk_i_23102 < hist_S_23101; chk_i_23102++) {
                    int64_t num_segments_23103 = (int64_t) 1;
                    int64_t hist_H_chk_23104 = sdiv_up64(mz2080U_14093, sext_i32_i64(hist_S_23101));
                    int64_t histo_sizze_23105 = hist_H_chk_23104;
                    int32_t init_per_thread_23106 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_23098) * histo_sizze_23105, max_tblock_sizze_23091));
                    
                    {
                        err = gpu_kernel_humanziseghist_local_22065(ctx, num_tblocks_23092, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_23098 * hist_H_chk_23104) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23098 * hist_H_chk_23104), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_23098 * hist_H_chk_23104) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23098 * hist_H_chk_23104), (int64_t) 8), (int64_t) 8)), mz2080U_14093, loop_dz2087U_20987, num_subhistos_23079, num_tblocks_23092, hist_M_23098, chk_i_23102, num_segments_23103, hist_H_chk_23104, histo_sizze_23105, init_per_thread_23106, mem_param_22780.mem, mem_22795.mem, mem_22797.mem, zzip_copy_subhistos_mem_23080.mem, zzip_copy_subhistos_mem_23082.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using global memory");
                
                int64_t hist_H_23147 = mz2080U_14093;
                double hist_RF_23148 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
                int32_t hist_el_sizze_23149 = 4;
                double hist_C_max_23150 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22060 * seghist_tblock_sizze_22058)), sitofp_i32_f64(hist_H_23147) / 2.0);
                int32_t hist_M_min_23151 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22060 * seghist_tblock_sizze_22058)) / hist_C_max_23150)));
                int64_t hist_L2_23152;
                
                hist_L2_23152 = *ctx->tuning_params.humanzihist_L2_23152;
                
                double hist_RACE_exp_23153 = fmax64(1.0, 0.75 * hist_RF_23148 / (64.0 / sitofp_i32_f64(hist_el_sizze_23149)));
                int32_t hist_S_23154;
                
                if (slt64(loop_dz2087U_20987, hist_H_23147)) {
                    hist_S_23154 = 1;
                } else {
                    hist_S_23154 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_23151) * hist_H_23147 * sext_i32_i64(hist_el_sizze_23149), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_23152) * hist_RACE_exp_23153)));
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_23153, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23154, '\n');
                
                int64_t hist_H_chk_23155 = sdiv_up64(mz2080U_14093, sext_i32_i64(hist_S_23154));
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_23155, '\n');
                
                double hist_k_max_23156 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_23152) / sitofp_i32_f64(8)) * hist_RACE_exp_23153, sitofp_i32_f64(loop_dz2087U_20987)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_22060 * seghist_tblock_sizze_22058));
                int64_t hist_u_23157 = (int64_t) 2;
                double hist_C_23158 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22060 * seghist_tblock_sizze_22058)), sitofp_i32_f64(hist_u_23157 * hist_H_chk_23155) / hist_k_max_23156);
                int32_t hist_M_23159 = 1;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_23156, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23159, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_23158, '\n');
                num_subhistos_23079 = sext_i32_i64(hist_M_23159);
                if (hist_M_23159 == 1) {
                    if (memblock_set_device(ctx, &zzip_copy_subhistos_mem_23080, &mem_22801, "mem_22801") != 0)
                        return 1;
                } else if (num_subhistos_23079 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &zzip_copy_subhistos_mem_23080, &mem_22801, "mem_22801") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &zzip_copy_subhistos_mem_23080, num_subhistos_23079 * mz2080U_14093 * (int64_t) 4, "zzip_copy_subhistos_mem_23080")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, zzip_copy_subhistos_mem_23080, num_subhistos_23079 * mz2080U_14093, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, zzip_copy_subhistos_mem_23080.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22801.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_14093})) != 0)
                        goto cleanup;
                }
                if (hist_M_23159 == 1) {
                    if (memblock_set_device(ctx, &zzip_copy_subhistos_mem_23082, &mem_22799, "mem_22799") != 0)
                        return 1;
                } else if (num_subhistos_23079 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &zzip_copy_subhistos_mem_23082, &mem_22799, "mem_22799") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &zzip_copy_subhistos_mem_23082, num_subhistos_23079 * mz2080U_14093 * (int64_t) 4, "zzip_copy_subhistos_mem_23082")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, zzip_copy_subhistos_mem_23082, num_subhistos_23079 * mz2080U_14093, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, zzip_copy_subhistos_mem_23082.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22799.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_14093})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23160 = 0; chk_i_23160 < hist_S_23154; chk_i_23160++) {
                    int64_t hist_H_chk_23161 = sdiv_up64(mz2080U_14093, sext_i32_i64(hist_S_23154));
                    
                    {
                        err = gpu_kernel_humanziseghist_global_22065(ctx, num_tblocks_22060, 1, 1, *ctx->tuning_params.humanziseghist_tblock_sizze_22057, 1, 1, (int64_t) 0, mz2080U_14093, loop_dz2087U_20987, num_tblocks_22060, num_subhistos_23079, chk_i_23160, hist_H_chk_23161, mem_param_22780.mem, mem_22795.mem, mem_22797.mem, zzip_copy_subhistos_mem_23080.mem, zzip_copy_subhistos_mem_23082.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
            if (num_subhistos_23079 == (int64_t) 1) {
                if (memblock_set_device(ctx, &mem_22801, &zzip_copy_subhistos_mem_23080, "zzip_copy_subhistos_mem_23080") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_22799, &zzip_copy_subhistos_mem_23082, "zzip_copy_subhistos_mem_23082") != 0)
                    return 1;
            } else {
                int64_t chunk_sizze_23178 = (int64_t) 1;
                
                if (slt64(num_subhistos_23079 * (int64_t) 2, seghist_tblock_sizze_22058 * chunk_sizze_23178)) {
                    int64_t segment_sizze_nonzzero_23179 = smax64((int64_t) 1, num_subhistos_23079);
                    int64_t num_threads_23180 = seghist_tblock_sizze_22058 * seghist_tblock_sizze_22058;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_14093, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23079, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_14093, squot64(seghist_tblock_sizze_22058, segment_sizze_nonzzero_23179))), '\n');
                    {
                        err = gpu_kernel_humanzisegred_small_23177(ctx, num_tblocks_22060, 1, 1, *ctx->tuning_params.humanziseghist_tblock_sizze_22057, 1, 1, (int64_t) 4 * seghist_tblock_sizze_22058 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22058, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_22058 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22058, (int64_t) 8), (int64_t) 8)), mz2080U_14093, num_tblocks_22060, num_subhistos_23079, segment_sizze_nonzzero_23179, mem_22799.mem, mem_22801.mem, zzip_copy_subhistos_mem_23080.mem, zzip_copy_subhistos_mem_23082.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_23215 = sdiv_up64(num_tblocks_22060, smax64((int64_t) 1, mz2080U_14093));
                    int64_t q_23216 = sdiv_up64(num_subhistos_23079, seghist_tblock_sizze_22058 * blocks_per_segment_23215 * chunk_sizze_23178);
                    int64_t num_virtblocks_23217 = blocks_per_segment_23215 * mz2080U_14093;
                    int64_t threads_per_segment_23218 = blocks_per_segment_23215 * seghist_tblock_sizze_22058;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_14093, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23079, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_23217, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22060, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_22058, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_23216, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_23215, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_23219, (int64_t) 4 * num_virtblocks_23217, "segred_tmp_mem_23219")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_23221, (int64_t) 4 * num_virtblocks_23217, "segred_tmp_mem_23221")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_humanzisegred_large_23177(ctx, num_tblocks_22060, 1, 1, *ctx->tuning_params.humanziseghist_tblock_sizze_22057, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_22058 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22058, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_22058 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22058, (int64_t) 8), (int64_t) 8)), mz2080U_14093, num_tblocks_22060, num_subhistos_23079, blocks_per_segment_23215, q_23216, num_virtblocks_23217, threads_per_segment_23218, mem_22799.mem, mem_22801.mem, zzip_copy_subhistos_mem_23080.mem, zzip_copy_subhistos_mem_23082.mem, segred_tmp_mem_23219.mem, segred_tmp_mem_23221.mem, counters_mem_23223.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_alloc_device(ctx, &mem_22805, bytes_22770, "mem_22805")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22809, bytes_22770, "mem_22809")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22811, bytes_22770, "mem_22811")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23266 = sext_i64_i32(sdiv_up64(mz2080U_14093, segmap_tblock_sizze_22110));
        
        {
            err = gpu_kernel_humanzisegmap_22117(ctx, segmap_usable_groups_22111, 1, 1, *ctx->tuning_params.humanzisegmap_tblock_sizze_22079, 1, 1, (int64_t) 0, mz2080U_14093, mem_param_22774.mem, mem_param_22777.mem, mem_param_22786.mem, mem_22792.mem, mem_22799.mem, mem_22801.mem, mem_22805.mem, mem_22807.mem, mem_22809.mem, mem_22811.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t num_tblocks_22147;
        int64_t max_num_tblocks_23275;
        
        max_num_tblocks_23275 = *ctx->tuning_params.humanzisegscan_num_tblocks_22146;
        num_tblocks_22147 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2087U_20987, segscan_tblock_sizze_22145), max_num_tblocks_23275)));
        
        int64_t bytes_22813 = (int64_t) 8 * loop_dz2087U_20987;
        
        if (memblock_alloc_device(ctx, &mem_22814, bytes_22813, "mem_22814")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22816, bytes_22813, "mem_22816")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, loop_dz2087U_20987)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_23276;
            
            shared_memory_23276 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_23277;
            
            thread_block_sizze_23277 = ctx->max_thread_block_size;
            
            int64_t registers_23278;
            
            registers_23278 = ctx->max_registers;
            
            int64_t thread_block_sizze_23279;
            
            thread_block_sizze_23279 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_23280 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23276, thread_block_sizze_23277), (int64_t) 8), squot64(squot64(registers_23278, thread_block_sizze_23279) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_23281 = sdiv_up64(loop_dz2087U_20987, segscan_tblock_sizze_22145 * chunk_sizze_23280);
            int64_t num_virt_threads_23282 = num_virt_blocks_23281 * segscan_tblock_sizze_22145;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23280, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_23283, num_virt_blocks_23281, "status_flags_mem_23283")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23283, num_virt_blocks_23281, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_23285, (int64_t) 8 * num_virt_blocks_23281, "aggregates_mem_23285")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_23287, (int64_t) 8 * num_virt_blocks_23281, "incprefixes_mem_23287")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_humanzisegscan_22150(ctx, num_tblocks_22147, 1, 1, *ctx->tuning_params.humanzisegscan_tblock_sizze_22144, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22145), chunk_sizze_23280 * segscan_tblock_sizze_22145 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22145), chunk_sizze_23280 * segscan_tblock_sizze_22145 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_14093, loop_dz2087U_20987, num_tblocks_22147, num_virt_blocks_23281, num_virt_threads_23282, mem_param_22780.mem, mem_22795.mem, mem_22797.mem, mem_22807.mem, mem_22814.mem, mem_22816.mem, status_flags_mem_23283.mem, aggregates_mem_23285.mem, incprefixes_mem_23287.mem, global_dynid_mem_23289.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        if (memblock_unref_device(ctx, &mem_22795, "mem_22795") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22797, "mem_22797") != 0)
            return 1;
        
        bool cond_21110 = loop_dz2087U_20987 == (int64_t) 0;
        bool x_21111 = !cond_21110;
        int64_t tmp_21112 = sub64(loop_dz2087U_20987, (int64_t) 1);
        bool x_21113 = sle64((int64_t) 0, tmp_21112);
        bool y_21114 = slt64(tmp_21112, loop_dz2087U_20987);
        bool bounds_check_21115 = x_21113 && y_21114;
        bool protect_assert_disj_21116 = cond_21110 || bounds_check_21115;
        bool index_certs_21117;
        
        if (!protect_assert_disj_21116) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_21112, "] out of bounds for array of shape [", (long long) loop_dz2087U_20987, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  auto_test.fut:8:15-36\n   #3  auto_test.fut:8:1-36\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t m_f_res_21118;
        
        if (x_21111) {
            int64_t read_res_24150;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_24150, mem_22814.mem, tmp_21112 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_21608 = read_res_24150;
            
            m_f_res_21118 = x_21608;
        } else {
            m_f_res_21118 = (int64_t) 0;
        }
        
        int64_t m_21120;
        
        if (cond_21110) {
            m_21120 = (int64_t) 0;
        } else {
            m_21120 = m_f_res_21118;
        }
        
        int64_t m_21130 = sub64(m_21120, (int64_t) 1);
        bool i_p_m_t_s_leq_w_21132 = slt64(m_21130, loop_dz2087U_20987);
        bool zzero_leq_i_p_m_t_s_21131 = sle64((int64_t) 0, m_21130);
        bool y_21134 = zzero_leq_i_p_m_t_s_21131 && i_p_m_t_s_leq_w_21132;
        bool i_lte_j_21133 = sle64((int64_t) 0, m_21120);
        bool forwards_ok_21135 = i_lte_j_21133 && y_21134;
        bool eq_x_zz_21127 = (int64_t) 0 == m_f_res_21118;
        bool p_and_eq_x_y_21128 = x_21111 && eq_x_zz_21127;
        bool empty_slice_21129 = cond_21110 || p_and_eq_x_y_21128;
        bool ok_or_empty_21136 = empty_slice_21129 || forwards_ok_21135;
        bool index_certs_21137;
        
        if (!ok_or_empty_21136) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_21120, "] out of bounds for array of shape [", (long long) loop_dz2087U_20987, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  auto_test.fut:8:15-36\n   #3  auto_test.fut:8:1-36\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_22817 = (int64_t) 4 * m_21120;
        
        if (memblock_alloc_device(ctx, &mem_22818, bytes_22817, "mem_22818")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22818.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22780.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21120})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_22820, bytes_22817, "mem_22820")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22820.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22783.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21120})) != 0)
            goto cleanup;
        
        int64_t num_tblocks_22157;
        int64_t max_num_tblocks_23378;
        
        max_num_tblocks_23378 = *ctx->tuning_params.humanzisegmap_num_tblocks_22156;
        num_tblocks_22157 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2087U_20987, segmap_tblock_sizze_22155), max_num_tblocks_23378)));
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23379 = sext_i64_i32(sdiv_up64(loop_dz2087U_20987, segmap_tblock_sizze_22155));
        
        {
            err = gpu_kernel_humanzisegmap_22152(ctx, num_tblocks_22157, 1, 1, *ctx->tuning_params.humanzisegmap_tblock_sizze_22154, 1, 1, (int64_t) 0, loop_dz2087U_20987, m_21120, num_tblocks_22157, virt_num_tblocks_23379, mem_param_22780.mem, mem_param_22783.mem, mem_22814.mem, mem_22816.mem, mem_22818.mem, mem_22820.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_22814, "mem_22814") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22816, "mem_22816") != 0)
            return 1;
        
        bool loop_cond_21147 = slt64((int64_t) 0, m_21120);
        
        if (memblock_set_device(ctx, &mem_param_tmp_22906, &mem_22811, "mem_22811") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_22907, &mem_22809, "mem_22809") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_22908, &mem_22818, "mem_22818") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_22909, &mem_22820, "mem_22820") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_22910, &mem_22805, "mem_22805") != 0)
            return 1;
        
        int64_t loop_dz2087U_tmp_22911 = m_21120;
        bool loop_while_tmp_22912 = loop_cond_21147;
        
        if (memblock_set_device(ctx, &mem_param_22774, &mem_param_tmp_22906, "mem_param_tmp_22906") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22777, &mem_param_tmp_22907, "mem_param_tmp_22907") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22780, &mem_param_tmp_22908, "mem_param_tmp_22908") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22783, &mem_param_tmp_22909, "mem_param_tmp_22909") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22786, &mem_param_tmp_22910, "mem_param_tmp_22910") != 0)
            return 1;
        loop_dz2087U_20987 = loop_dz2087U_tmp_22911;
        loop_while_20988 = loop_while_tmp_22912;
    }
    if (memblock_set_device(ctx, &ext_mem_22836, &mem_param_22774, "mem_param_22774") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22835, &mem_param_22777, "mem_param_22777") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22834, &mem_param_22780, "mem_param_22780") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22833, &mem_param_22783, "mem_param_22783") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22832, &mem_param_22786, "mem_param_22786") != 0)
        return 1;
    result_20980 = loop_dz2087U_20987;
    result_20981 = loop_while_20988;
    if (memblock_unref_device(ctx, &mem_22771, "mem_22771") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22789, "mem_22789") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22792, "mem_22792") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22799, "mem_22799") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22801, "mem_22801") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22807, "mem_22807") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_22884, &ext_mem_22832, "ext_mem_22832") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_24149, &mem_out_22884, "mem_out_22884") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_param_tmp_22910, "mem_param_tmp_22910") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_22909, "mem_param_tmp_22909") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_22908, "mem_param_tmp_22908") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_22907, "mem_param_tmp_22907") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_22906, "mem_param_tmp_22906") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22820, "mem_22820") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22818, "mem_22818") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23287, "incprefixes_mem_23287") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23285, "aggregates_mem_23285") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23283, "status_flags_mem_23283") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22816, "mem_22816") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22814, "mem_22814") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22811, "mem_22811") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22809, "mem_22809") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22805, "mem_22805") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23221, "segred_tmp_mem_23221") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23219, "segred_tmp_mem_23219") != 0)
            return 1;
        if (memblock_unref_device(ctx, &zzip_copy_subhistos_mem_23082, "zzip_copy_subhistos_mem_23082") != 0)
            return 1;
        if (memblock_unref_device(ctx, &zzip_copy_subhistos_mem_23080, "zzip_copy_subhistos_mem_23080") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22797, "mem_22797") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22795, "mem_22795") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_22949, "incprefixes_mem_22949") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_22947, "aggregates_mem_22947") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_22925, "status_flags_mem_22925") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22786, "mem_param_22786") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22783, "mem_param_22783") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22780, "mem_param_22780") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22777, "mem_param_22777") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22774, "mem_param_22774") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22832, "ext_mem_22832") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22833, "ext_mem_22833") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22834, "ext_mem_22834") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22835, "ext_mem_22835") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22836, "ext_mem_22836") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22807, "mem_22807") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22801, "mem_22801") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22799, "mem_22799") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22792, "mem_22792") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22789, "mem_22789") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22771, "mem_22771") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_22884, "mem_out_22884") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_human_regular(struct futhark_context *ctx, struct memblock_device *mem_out_p_24151, struct memblock_device ks_mem_22766, struct memblock_device shp_mem_22767, struct memblock_device II1_mem_22768, struct memblock_device A_mem_22769, int64_t mz2080U_17317, int64_t nz2081U_17318)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_param_tmp_23662;
    
    mem_param_tmp_23662.references = NULL;
    
    struct memblock_device mem_param_tmp_23661;
    
    mem_param_tmp_23661.references = NULL;
    
    struct memblock_device mem_param_tmp_23660;
    
    mem_param_tmp_23660.references = NULL;
    
    struct memblock_device mem_param_tmp_23659;
    
    mem_param_tmp_23659.references = NULL;
    
    struct memblock_device mem_param_tmp_23658;
    
    mem_param_tmp_23658.references = NULL;
    
    struct memblock_device mem_22858;
    
    mem_22858.references = NULL;
    
    struct memblock_device mem_22856;
    
    mem_22856.references = NULL;
    
    struct memblock_device incprefixes_mem_23999;
    
    incprefixes_mem_23999.references = NULL;
    
    struct memblock_device aggregates_mem_23997;
    
    aggregates_mem_23997.references = NULL;
    
    struct memblock_device status_flags_mem_23995;
    
    status_flags_mem_23995.references = NULL;
    
    struct memblock_device mem_22854;
    
    mem_22854.references = NULL;
    
    struct memblock_device mem_22852;
    
    mem_22852.references = NULL;
    
    struct memblock_device mem_22847;
    
    mem_22847.references = NULL;
    
    struct memblock_device mem_22845;
    
    mem_22845.references = NULL;
    
    struct memblock_device mem_22843;
    
    mem_22843.references = NULL;
    
    struct memblock_device segred_tmp_mem_23933;
    
    segred_tmp_mem_23933.references = NULL;
    
    struct memblock_device segred_tmp_mem_23931;
    
    segred_tmp_mem_23931.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_23794;
    
    defunc_0_map_res_subhistos_mem_23794.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_23792;
    
    defunc_0_map_res_subhistos_mem_23792.references = NULL;
    
    struct memblock_device mem_22835;
    
    mem_22835.references = NULL;
    
    struct memblock_device mem_22834;
    
    mem_22834.references = NULL;
    
    struct memblock_device incprefixes_mem_23681;
    
    incprefixes_mem_23681.references = NULL;
    
    struct memblock_device aggregates_mem_23679;
    
    aggregates_mem_23679.references = NULL;
    
    struct memblock_device status_flags_mem_23677;
    
    status_flags_mem_23677.references = NULL;
    
    struct memblock_device mem_param_22826;
    
    mem_param_22826.references = NULL;
    
    struct memblock_device mem_param_22823;
    
    mem_param_22823.references = NULL;
    
    struct memblock_device mem_param_22820;
    
    mem_param_22820.references = NULL;
    
    struct memblock_device mem_param_22817;
    
    mem_param_22817.references = NULL;
    
    struct memblock_device mem_param_22814;
    
    mem_param_22814.references = NULL;
    
    struct memblock_device ext_mem_22870;
    
    ext_mem_22870.references = NULL;
    
    struct memblock_device ext_mem_22871;
    
    ext_mem_22871.references = NULL;
    
    struct memblock_device ext_mem_22872;
    
    ext_mem_22872.references = NULL;
    
    struct memblock_device ext_mem_22873;
    
    ext_mem_22873.references = NULL;
    
    struct memblock_device ext_mem_22874;
    
    ext_mem_22874.references = NULL;
    
    struct memblock_device mem_22849;
    
    mem_22849.references = NULL;
    
    struct memblock_device mem_22839;
    
    mem_22839.references = NULL;
    
    struct memblock_device mem_22837;
    
    mem_22837.references = NULL;
    
    struct memblock_device mem_22832;
    
    mem_22832.references = NULL;
    
    struct memblock_device mem_22829;
    
    mem_22829.references = NULL;
    
    struct memblock_device mem_22810;
    
    mem_22810.references = NULL;
    
    struct memblock_device mem_22808;
    
    mem_22808.references = NULL;
    
    struct memblock_device incprefixes_mem_23552;
    
    incprefixes_mem_23552.references = NULL;
    
    struct memblock_device aggregates_mem_23550;
    
    aggregates_mem_23550.references = NULL;
    
    struct memblock_device status_flags_mem_23548;
    
    status_flags_mem_23548.references = NULL;
    
    struct memblock_device mem_22806;
    
    mem_22806.references = NULL;
    
    struct memblock_device mem_22804;
    
    mem_22804.references = NULL;
    
    struct memblock_device mem_22801;
    
    mem_22801.references = NULL;
    
    struct memblock_device mem_22799;
    
    mem_22799.references = NULL;
    
    struct memblock_device mem_22797;
    
    mem_22797.references = NULL;
    
    struct memblock_device mem_22795;
    
    mem_22795.references = NULL;
    
    struct memblock_device segred_tmp_mem_23486;
    
    segred_tmp_mem_23486.references = NULL;
    
    struct memblock_device segred_tmp_mem_23484;
    
    segred_tmp_mem_23484.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_23347;
    
    defunc_0_map_res_subhistos_mem_23347.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_23345;
    
    defunc_0_map_res_subhistos_mem_23345.references = NULL;
    
    struct memblock_device mem_22791;
    
    mem_22791.references = NULL;
    
    struct memblock_device mem_22789;
    
    mem_22789.references = NULL;
    
    struct memblock_device mem_22787;
    
    mem_22787.references = NULL;
    
    struct memblock_device mem_22786;
    
    mem_22786.references = NULL;
    
    struct memblock_device mem_22784;
    
    mem_22784.references = NULL;
    
    struct memblock_device incprefixes_mem_23234;
    
    incprefixes_mem_23234.references = NULL;
    
    struct memblock_device aggregates_mem_23232;
    
    aggregates_mem_23232.references = NULL;
    
    struct memblock_device status_flags_mem_23230;
    
    status_flags_mem_23230.references = NULL;
    
    struct memblock_device mem_22781;
    
    mem_22781.references = NULL;
    
    struct memblock_device incprefixes_mem_23078;
    
    incprefixes_mem_23078.references = NULL;
    
    struct memblock_device aggregates_mem_23076;
    
    aggregates_mem_23076.references = NULL;
    
    struct memblock_device incprefixes_mem_23074;
    
    incprefixes_mem_23074.references = NULL;
    
    struct memblock_device aggregates_mem_23072;
    
    aggregates_mem_23072.references = NULL;
    
    struct memblock_device status_flags_mem_23070;
    
    status_flags_mem_23070.references = NULL;
    
    struct memblock_device mem_22778;
    
    mem_22778.references = NULL;
    
    struct memblock_device mem_22776;
    
    mem_22776.references = NULL;
    
    struct memblock_device mem_22773;
    
    mem_22773.references = NULL;
    
    struct memblock_device incprefixes_mem_22917;
    
    incprefixes_mem_22917.references = NULL;
    
    struct memblock_device aggregates_mem_22915;
    
    aggregates_mem_22915.references = NULL;
    
    struct memblock_device status_flags_mem_22893;
    
    status_flags_mem_22893.references = NULL;
    
    struct memblock_device mem_22772;
    
    mem_22772.references = NULL;
    
    struct memblock_device mem_out_22884;
    
    mem_out_22884.references = NULL;
    
    struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
    struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
    struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
    struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
    struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
    struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
    struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
    struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
    struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
    struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
    struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
    struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
    struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
    struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
    struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
    struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
    struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
    struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
    struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
    int64_t segscan_tblock_sizze_22161;
    
    segscan_tblock_sizze_22161 = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22160;
    
    int64_t num_tblocks_22163;
    int64_t max_num_tblocks_22885;
    
    max_num_tblocks_22885 = *ctx->tuning_params.human_regularzisegscan_num_tblocks_22162;
    num_tblocks_22163 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_17317, segscan_tblock_sizze_22161), max_num_tblocks_22885)));
    
    int64_t bytes_22771 = (int64_t) 8 * mz2080U_17317;
    
    if (memblock_alloc_device(ctx, &mem_22772, bytes_22771, "mem_22772")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_17317)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_22886;
        
        shared_memory_22886 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_22887;
        
        thread_block_sizze_22887 = ctx->max_thread_block_size;
        
        int64_t registers_22888;
        
        registers_22888 = ctx->max_registers;
        
        int64_t thread_block_sizze_22889;
        
        thread_block_sizze_22889 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_22890 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_22886, thread_block_sizze_22887), (int64_t) 8), squot64(squot64(registers_22888, thread_block_sizze_22889) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_22891 = sdiv_up64(mz2080U_17317, segscan_tblock_sizze_22161 * chunk_sizze_22890);
        int64_t num_virt_threads_22892 = num_virt_blocks_22891 * segscan_tblock_sizze_22161;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_22890, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_22893, num_virt_blocks_22891, "status_flags_mem_22893")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_22893, num_virt_blocks_22891, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_22915, (int64_t) 8 * num_virt_blocks_22891, "aggregates_mem_22915")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_22917, (int64_t) 8 * num_virt_blocks_22891, "incprefixes_mem_22917")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_regularzisegscan_22166(ctx, num_tblocks_22163, 1, 1, *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22160, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22161), chunk_sizze_22890 * segscan_tblock_sizze_22161 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22161), chunk_sizze_22890 * segscan_tblock_sizze_22161 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_17317, num_tblocks_22163, num_virt_blocks_22891, num_virt_threads_22892, shp_mem_22767.mem, mem_22772.mem, status_flags_mem_22893.mem, aggregates_mem_22915.mem, incprefixes_mem_22917.mem, global_dynid_mem_22919.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_alloc_device(ctx, &mem_22773, nz2081U_17318, "mem_22773")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_22773, nz2081U_17318, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_22171;
    
    segmap_tblock_sizze_22171 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22170;
    
    int64_t num_tblocks_22173;
    int64_t max_num_tblocks_23048;
    
    max_num_tblocks_23048 = *ctx->tuning_params.human_regularzisegmap_num_tblocks_22172;
    num_tblocks_22173 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_17317, segmap_tblock_sizze_22171), max_num_tblocks_23048)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23049 = sext_i64_i32(sdiv_up64(mz2080U_17317, segmap_tblock_sizze_22171));
    
    {
        err = gpu_kernel_human_regularzisegmap_22168(ctx, num_tblocks_22173, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22170, 1, 1, (int64_t) 0, mz2080U_17317, nz2081U_17318, num_tblocks_22173, virt_num_tblocks_23049, mem_22772.mem, mem_22773.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_22772, "mem_22772") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_22177;
    
    segscan_tblock_sizze_22177 = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22176;
    
    int64_t num_tblocks_22179;
    int64_t max_num_tblocks_23062;
    
    max_num_tblocks_23062 = *ctx->tuning_params.human_regularzisegscan_num_tblocks_22178;
    num_tblocks_22179 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_17318, segscan_tblock_sizze_22177), max_num_tblocks_23062)));
    
    int64_t bytes_22777 = (int64_t) 4 * nz2081U_17318;
    
    if (memblock_alloc_device(ctx, &mem_22776, nz2081U_17318, "mem_22776")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22778, bytes_22777, "mem_22778")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_17318)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_23063;
        
        shared_memory_23063 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_23064;
        
        thread_block_sizze_23064 = ctx->max_thread_block_size;
        
        int64_t registers_23065;
        
        registers_23065 = ctx->max_registers;
        
        int64_t thread_block_sizze_23066;
        
        thread_block_sizze_23066 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_23067 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23063, thread_block_sizze_23064), (int64_t) 4), squot64(squot64(registers_23065, thread_block_sizze_23066) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_23068 = sdiv_up64(nz2081U_17318, segscan_tblock_sizze_22177 * chunk_sizze_23067);
        int64_t num_virt_threads_23069 = num_virt_blocks_23068 * segscan_tblock_sizze_22177;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23067, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_23070, num_virt_blocks_23068, "status_flags_mem_23070")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23070, num_virt_blocks_23068, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_23072, num_virt_blocks_23068, "aggregates_mem_23072")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_23074, num_virt_blocks_23068, "incprefixes_mem_23074")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_23076, (int64_t) 4 * num_virt_blocks_23068, "aggregates_mem_23076")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_23078, (int64_t) 4 * num_virt_blocks_23068, "incprefixes_mem_23078")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_regularzisegscan_22182(ctx, num_tblocks_22179, 1, 1, *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22176, 1, 1, smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_22177, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_22177), smax64(chunk_sizze_23067 * segscan_tblock_sizze_22177, chunk_sizze_23067 * segscan_tblock_sizze_22177 * (int64_t) 4)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_22177, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_22177), smax64(chunk_sizze_23067 * segscan_tblock_sizze_22177, chunk_sizze_23067 * segscan_tblock_sizze_22177 * (int64_t) 4)), (int64_t) 8), (int64_t) 8), nz2081U_17318, num_tblocks_22179, num_virt_blocks_23068, num_virt_threads_23069, A_mem_22769.mem, mem_22773.mem, mem_22776.mem, mem_22778.mem, status_flags_mem_23070.mem, aggregates_mem_23072.mem, incprefixes_mem_23074.mem, aggregates_mem_23076.mem, incprefixes_mem_23078.mem, global_dynid_mem_23080.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_22773, "mem_22773") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22776, "mem_22776") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_22185;
    
    segscan_tblock_sizze_22185 = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22184;
    
    int64_t num_tblocks_22187;
    int64_t max_num_tblocks_23222;
    
    max_num_tblocks_23222 = *ctx->tuning_params.human_regularzisegscan_num_tblocks_22186;
    num_tblocks_22187 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_17317, segscan_tblock_sizze_22185), max_num_tblocks_23222)));
    
    int64_t bytes_22780 = (int64_t) 4 * mz2080U_17317;
    
    if (memblock_alloc_device(ctx, &mem_22781, bytes_22780, "mem_22781")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_17317)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_23223;
        
        shared_memory_23223 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_23224;
        
        thread_block_sizze_23224 = ctx->max_thread_block_size;
        
        int64_t registers_23225;
        
        registers_23225 = ctx->max_registers;
        
        int64_t thread_block_sizze_23226;
        
        thread_block_sizze_23226 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_23227 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23223, thread_block_sizze_23224), (int64_t) 4), squot64(squot64(registers_23225, thread_block_sizze_23226) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_23228 = sdiv_up64(mz2080U_17317, segscan_tblock_sizze_22185 * chunk_sizze_23227);
        int64_t num_virt_threads_23229 = num_virt_blocks_23228 * segscan_tblock_sizze_22185;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23227, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_23230, num_virt_blocks_23228, "status_flags_mem_23230")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23230, num_virt_blocks_23228, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_23232, (int64_t) 4 * num_virt_blocks_23228, "aggregates_mem_23232")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_23234, (int64_t) 4 * num_virt_blocks_23228, "incprefixes_mem_23234")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_regularzisegscan_22190(ctx, num_tblocks_22187, 1, 1, *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22184, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22185), chunk_sizze_23227 * segscan_tblock_sizze_22185 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22185), chunk_sizze_23227 * segscan_tblock_sizze_22185 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_17317, num_tblocks_22187, num_virt_blocks_23228, num_virt_threads_23229, shp_mem_22767.mem, mem_22781.mem, status_flags_mem_23230.mem, aggregates_mem_23232.mem, incprefixes_mem_23234.mem, global_dynid_mem_23236.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_22214;
    
    segmap_tblock_sizze_22214 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22194;
    
    int64_t segmap_usable_groups_22215 = sdiv_up64(mz2080U_17317, segmap_tblock_sizze_22214);
    
    if (memblock_alloc_device(ctx, &mem_22784, bytes_22780, "mem_22784")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23325 = sext_i64_i32(sdiv_up64(mz2080U_17317, segmap_tblock_sizze_22214));
    
    {
        err = gpu_kernel_human_regularzisegmap_22218(ctx, segmap_usable_groups_22215, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22194, 1, 1, (int64_t) 0, mz2080U_17317, nz2081U_17318, shp_mem_22767.mem, mem_22778.mem, mem_22781.mem, mem_22784.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_22778, "mem_22778") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22781, "mem_22781") != 0)
        return 1;
    
    int64_t segmap_tblock_sizze_22252;
    
    segmap_tblock_sizze_22252 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22236;
    
    int64_t segmap_usable_groups_22253 = sdiv_up64(nz2081U_17318, segmap_tblock_sizze_22252);
    
    if (memblock_alloc_device(ctx, &mem_22786, nz2081U_17318, "mem_22786")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22787, nz2081U_17318, "mem_22787")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23334 = sext_i64_i32(sdiv_up64(nz2081U_17318, segmap_tblock_sizze_22252));
    
    {
        err = gpu_kernel_human_regularzisegmap_22257(ctx, segmap_usable_groups_22253, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22236, 1, 1, (int64_t) 0, mz2080U_17317, nz2081U_17318, II1_mem_22768.mem, A_mem_22769.mem, mem_22784.mem, mem_22786.mem, mem_22787.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_alloc_device(ctx, &mem_22789, bytes_22780, "mem_22789")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_22789, mz2080U_17317, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22791, bytes_22780, "mem_22791")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_22791, mz2080U_17317, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t seghist_tblock_sizze_22270;
    
    seghist_tblock_sizze_22270 = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269;
    
    int64_t num_tblocks_22272;
    int64_t max_num_tblocks_23343;
    
    max_num_tblocks_23343 = *ctx->tuning_params.human_regularziseghist_num_tblocks_22271;
    num_tblocks_22272 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_17318, seghist_tblock_sizze_22270), max_num_tblocks_23343)));
    
    int64_t num_subhistos_23344;
    int64_t h_23349 = (int64_t) 4 * mz2080U_17317 + (int64_t) 4 * mz2080U_17317;
    int64_t seg_h_23350 = (int64_t) 4 * mz2080U_17317 + (int64_t) 4 * mz2080U_17317;
    
    if (!(seg_h_23350 == (int64_t) 0)) {
        int64_t hist_H_23351 = mz2080U_17317;
        int64_t hist_el_sizze_23352 = sdiv_up64(h_23349, hist_H_23351);
        int64_t hist_N_23353 = nz2081U_17318;
        int32_t hist_RF_23354 = 1;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegHist");
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_22272 * seghist_tblock_sizze_22270), '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_22270, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23351, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_23353, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_23352, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_23354, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_23349, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_23350, '\n');
        
        int64_t hist_L_23355;
        
        hist_L_23355 = *ctx->tuning_params.human_regularzihist_L_23355;
        
        int64_t max_tblock_sizze_23356;
        
        max_tblock_sizze_23356 = ctx->max_thread_block_size;
        
        int64_t num_tblocks_23357 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_22272 * seghist_tblock_sizze_22270)), max_tblock_sizze_23356);
        double hist_m_prime_23358 = sitofp_i64_f64(smin64(squot64(hist_L_23355, hist_el_sizze_23352), sdiv_up64(hist_N_23353, num_tblocks_23357))) / sitofp_i64_f64(hist_H_23351);
        int64_t hist_M0_23359 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_23358), max_tblock_sizze_23356));
        int64_t hist_Nout_23360 = (int64_t) 1;
        int64_t hist_Nin_23361 = nz2081U_17318;
        int64_t work_asymp_M_max_23362 = squot64(hist_Nout_23360 * hist_N_23353, (int64_t) 2 * num_tblocks_23357 * hist_H_23351);
        int32_t hist_M_23363 = sext_i64_i32(smin64(hist_M0_23359, work_asymp_M_max_23362));
        int64_t hist_C_23364 = sdiv_up64(max_tblock_sizze_23356, sext_i32_i64(smax32(1, hist_M_23363)));
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_23359, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_23362, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_23364, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_23356, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_23363, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_23351 * hist_el_sizze_23352 * sext_i32_i64(hist_M_23363)), '\n');
        
        int64_t local_mem_needed_23365 = hist_el_sizze_23352 * sext_i32_i64(hist_M_23363);
        int32_t hist_S_23366 = sext_i64_i32(sdiv_up64(hist_H_23351 * local_mem_needed_23365 + (int64_t) 1, hist_L_23355));
        
        if (sle64(hist_H_23351, hist_Nin_23361) && (sle64(local_mem_needed_23365, hist_L_23355) && (sle32(hist_S_23366, 3) && (sle64(hist_C_23364, max_tblock_sizze_23356) && slt32(0, hist_M_23363))))) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using shared memory");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23351, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23363, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_23364, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23366, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_23363, '\n');
            num_subhistos_23344 = num_tblocks_23357;
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_23344, '\n');
            if (num_subhistos_23344 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23345, &mem_22791, "mem_22791") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23345, num_subhistos_23344 * mz2080U_17317 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23345")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23345, num_subhistos_23344 * mz2080U_17317, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23345.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22791.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_17317})) != 0)
                    goto cleanup;
            }
            if (num_subhistos_23344 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23347, &mem_22789, "mem_22789") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23347, num_subhistos_23344 * mz2080U_17317 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23347")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23347, num_subhistos_23344 * mz2080U_17317, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23347.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22789.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_17317})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_23367 = 0; chk_i_23367 < hist_S_23366; chk_i_23367++) {
                int64_t num_segments_23368 = (int64_t) 1;
                int64_t hist_H_chk_23369 = sdiv_up64(mz2080U_17317, sext_i32_i64(hist_S_23366));
                int64_t histo_sizze_23370 = hist_H_chk_23369;
                int32_t init_per_thread_23371 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_23363) * histo_sizze_23370, max_tblock_sizze_23356));
                
                {
                    err = gpu_kernel_human_regularziseghist_local_22277(ctx, num_tblocks_23357, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_23363 * hist_H_chk_23369) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23363 * hist_H_chk_23369), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_23363 * hist_H_chk_23369) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23363 * hist_H_chk_23369), (int64_t) 8), (int64_t) 8)), mz2080U_17317, nz2081U_17318, num_subhistos_23344, num_tblocks_23357, hist_M_23363, chk_i_23367, num_segments_23368, hist_H_chk_23369, histo_sizze_23370, init_per_thread_23371, II1_mem_22768.mem, mem_22786.mem, mem_22787.mem, defunc_0_map_res_subhistos_mem_23345.mem, defunc_0_map_res_subhistos_mem_23347.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        } else {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using global memory");
            
            int64_t hist_H_23412 = mz2080U_17317;
            double hist_RF_23413 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
            int32_t hist_el_sizze_23414 = 4;
            double hist_C_max_23415 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22272 * seghist_tblock_sizze_22270)), sitofp_i32_f64(hist_H_23412) / 2.0);
            int32_t hist_M_min_23416 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22272 * seghist_tblock_sizze_22270)) / hist_C_max_23415)));
            int64_t hist_L2_23417;
            
            hist_L2_23417 = *ctx->tuning_params.human_regularzihist_L2_23417;
            
            double hist_RACE_exp_23418 = fmax64(1.0, 0.75 * hist_RF_23413 / (64.0 / sitofp_i32_f64(hist_el_sizze_23414)));
            int32_t hist_S_23419;
            
            if (slt64(nz2081U_17318, hist_H_23412)) {
                hist_S_23419 = 1;
            } else {
                hist_S_23419 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_23416) * hist_H_23412 * sext_i32_i64(hist_el_sizze_23414), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_23417) * hist_RACE_exp_23418)));
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_23418, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23419, '\n');
            
            int64_t hist_H_chk_23420 = sdiv_up64(mz2080U_17317, sext_i32_i64(hist_S_23419));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_23420, '\n');
            
            double hist_k_max_23421 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_23417) / sitofp_i32_f64(8)) * hist_RACE_exp_23418, sitofp_i32_f64(nz2081U_17318)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_22272 * seghist_tblock_sizze_22270));
            int64_t hist_u_23422 = (int64_t) 2;
            double hist_C_23423 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22272 * seghist_tblock_sizze_22270)), sitofp_i32_f64(hist_u_23422 * hist_H_chk_23420) / hist_k_max_23421);
            int32_t hist_M_23424 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_23421, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23424, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_23423, '\n');
            num_subhistos_23344 = sext_i32_i64(hist_M_23424);
            if (hist_M_23424 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23345, &mem_22791, "mem_22791") != 0)
                    return 1;
            } else if (num_subhistos_23344 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23345, &mem_22791, "mem_22791") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23345, num_subhistos_23344 * mz2080U_17317 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23345")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23345, num_subhistos_23344 * mz2080U_17317, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23345.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22791.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_17317})) != 0)
                    goto cleanup;
            }
            if (hist_M_23424 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23347, &mem_22789, "mem_22789") != 0)
                    return 1;
            } else if (num_subhistos_23344 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23347, &mem_22789, "mem_22789") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23347, num_subhistos_23344 * mz2080U_17317 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23347")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23347, num_subhistos_23344 * mz2080U_17317, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23347.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22789.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_17317})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_23425 = 0; chk_i_23425 < hist_S_23419; chk_i_23425++) {
                int64_t hist_H_chk_23426 = sdiv_up64(mz2080U_17317, sext_i32_i64(hist_S_23419));
                
                {
                    err = gpu_kernel_human_regularziseghist_global_22277(ctx, num_tblocks_22272, 1, 1, *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269, 1, 1, (int64_t) 0, mz2080U_17317, nz2081U_17318, num_tblocks_22272, num_subhistos_23344, chk_i_23425, hist_H_chk_23426, II1_mem_22768.mem, mem_22786.mem, mem_22787.mem, defunc_0_map_res_subhistos_mem_23345.mem, defunc_0_map_res_subhistos_mem_23347.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        }
        if (num_subhistos_23344 == (int64_t) 1) {
            if (memblock_set_device(ctx, &mem_22791, &defunc_0_map_res_subhistos_mem_23345, "defunc_0_map_res_subhistos_mem_23345") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_22789, &defunc_0_map_res_subhistos_mem_23347, "defunc_0_map_res_subhistos_mem_23347") != 0)
                return 1;
        } else {
            int64_t chunk_sizze_23443 = (int64_t) 1;
            
            if (slt64(num_subhistos_23344 * (int64_t) 2, seghist_tblock_sizze_22270 * chunk_sizze_23443)) {
                int64_t segment_sizze_nonzzero_23444 = smax64((int64_t) 1, num_subhistos_23344);
                int64_t num_threads_23445 = seghist_tblock_sizze_22270 * seghist_tblock_sizze_22270;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-small");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_17317, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23344, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444), '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_17317, squot64(seghist_tblock_sizze_22270, segment_sizze_nonzzero_23444))), '\n');
                {
                    err = gpu_kernel_human_regularzisegred_small_23442(ctx, num_tblocks_22272, 1, 1, *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269, 1, 1, (int64_t) 4 * seghist_tblock_sizze_22270 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22270, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_22270 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22270, (int64_t) 8), (int64_t) 8)), mz2080U_17317, num_tblocks_22272, num_subhistos_23344, segment_sizze_nonzzero_23444, mem_22789.mem, mem_22791.mem, defunc_0_map_res_subhistos_mem_23345.mem, defunc_0_map_res_subhistos_mem_23347.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            } else {
                int64_t blocks_per_segment_23480 = sdiv_up64(num_tblocks_22272, smax64((int64_t) 1, mz2080U_17317));
                int64_t q_23481 = sdiv_up64(num_subhistos_23344, seghist_tblock_sizze_22270 * blocks_per_segment_23480 * chunk_sizze_23443);
                int64_t num_virtblocks_23482 = blocks_per_segment_23480 * mz2080U_17317;
                int64_t threads_per_segment_23483 = blocks_per_segment_23480 * seghist_tblock_sizze_22270;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-large");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_17317, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23344, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_23482, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22272, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_22270, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_23481, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_23480, '\n');
                if (memblock_alloc_device(ctx, &segred_tmp_mem_23484, (int64_t) 4 * num_virtblocks_23482, "segred_tmp_mem_23484")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &segred_tmp_mem_23486, (int64_t) 4 * num_virtblocks_23482, "segred_tmp_mem_23486")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_human_regularzisegred_large_23442(ctx, num_tblocks_22272, 1, 1, *ctx->tuning_params.human_regularziseghist_tblock_sizze_22269, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_22270 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22270, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_22270 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22270, (int64_t) 8), (int64_t) 8)), mz2080U_17317, num_tblocks_22272, num_subhistos_23344, blocks_per_segment_23480, q_23481, num_virtblocks_23482, threads_per_segment_23483, mem_22789.mem, mem_22791.mem, defunc_0_map_res_subhistos_mem_23345.mem, defunc_0_map_res_subhistos_mem_23347.mem, segred_tmp_mem_23484.mem, segred_tmp_mem_23486.mem, counters_mem_23488.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segmap_tblock_sizze_22319;
    
    segmap_tblock_sizze_22319 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22293;
    
    int64_t segmap_usable_groups_22320 = sdiv_up64(mz2080U_17317, segmap_tblock_sizze_22319);
    
    if (memblock_alloc_device(ctx, &mem_22795, bytes_22780, "mem_22795")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22797, bytes_22780, "mem_22797")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22799, bytes_22780, "mem_22799")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22801, bytes_22780, "mem_22801")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23531 = sext_i64_i32(sdiv_up64(mz2080U_17317, segmap_tblock_sizze_22319));
    
    {
        err = gpu_kernel_human_regularzisegmap_22326(ctx, segmap_usable_groups_22320, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22293, 1, 1, (int64_t) 0, mz2080U_17317, ks_mem_22766.mem, shp_mem_22767.mem, mem_22784.mem, mem_22789.mem, mem_22791.mem, mem_22795.mem, mem_22797.mem, mem_22799.mem, mem_22801.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_22784, "mem_22784") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22789, "mem_22789") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22791, "mem_22791") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_22349;
    
    segscan_tblock_sizze_22349 = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22348;
    
    int64_t num_tblocks_22351;
    int64_t max_num_tblocks_23540;
    
    max_num_tblocks_23540 = *ctx->tuning_params.human_regularzisegscan_num_tblocks_22350;
    num_tblocks_22351 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_17318, segscan_tblock_sizze_22349), max_num_tblocks_23540)));
    
    int64_t bytes_22803 = (int64_t) 8 * nz2081U_17318;
    
    if (memblock_alloc_device(ctx, &mem_22804, bytes_22803, "mem_22804")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22806, bytes_22803, "mem_22806")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_17318)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_23541;
        
        shared_memory_23541 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_23542;
        
        thread_block_sizze_23542 = ctx->max_thread_block_size;
        
        int64_t registers_23543;
        
        registers_23543 = ctx->max_registers;
        
        int64_t thread_block_sizze_23544;
        
        thread_block_sizze_23544 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_23545 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23541, thread_block_sizze_23542), (int64_t) 8), squot64(squot64(registers_23543, thread_block_sizze_23544) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_23546 = sdiv_up64(nz2081U_17318, segscan_tblock_sizze_22349 * chunk_sizze_23545);
        int64_t num_virt_threads_23547 = num_virt_blocks_23546 * segscan_tblock_sizze_22349;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23545, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_23548, num_virt_blocks_23546, "status_flags_mem_23548")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23548, num_virt_blocks_23546, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_23550, (int64_t) 8 * num_virt_blocks_23546, "aggregates_mem_23550")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_23552, (int64_t) 8 * num_virt_blocks_23546, "incprefixes_mem_23552")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_regularzisegscan_22354(ctx, num_tblocks_22351, 1, 1, *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22348, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22349), chunk_sizze_23545 * segscan_tblock_sizze_22349 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22349), chunk_sizze_23545 * segscan_tblock_sizze_22349 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_17317, nz2081U_17318, num_tblocks_22351, num_virt_blocks_23546, num_virt_threads_23547, II1_mem_22768.mem, mem_22786.mem, mem_22787.mem, mem_22801.mem, mem_22804.mem, mem_22806.mem, status_flags_mem_23548.mem, aggregates_mem_23550.mem, incprefixes_mem_23552.mem, global_dynid_mem_23554.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_22786, "mem_22786") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22787, "mem_22787") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22801, "mem_22801") != 0)
        return 1;
    
    bool cond_21122 = nz2081U_17318 == (int64_t) 0;
    bool x_21123 = !cond_21122;
    int64_t tmp_21124 = sub64(nz2081U_17318, (int64_t) 1);
    bool x_21125 = sle64((int64_t) 0, tmp_21124);
    bool y_21126 = slt64(tmp_21124, nz2081U_17318);
    bool bounds_check_21127 = x_21125 && y_21126;
    bool protect_assert_disj_21128 = cond_21122 || bounds_check_21127;
    bool index_certs_21129;
    
    if (!protect_assert_disj_21128) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_21124, "] out of bounds for array of shape [", (long long) nz2081U_17318, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  auto_test.fut:9:23-52\n   #3  auto_test.fut:9:1-52\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_21130;
    
    if (x_21123) {
        int64_t read_res_24152;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_24152, mem_22804.mem, tmp_21124 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_21929 = read_res_24152;
        
        m_f_res_21130 = x_21929;
    } else {
        m_f_res_21130 = (int64_t) 0;
    }
    
    int64_t m_21132;
    
    if (cond_21122) {
        m_21132 = (int64_t) 0;
    } else {
        m_21132 = m_f_res_21130;
    }
    
    int64_t m_21142 = sub64(m_21132, (int64_t) 1);
    bool i_p_m_t_s_leq_w_21144 = slt64(m_21142, nz2081U_17318);
    bool zzero_leq_i_p_m_t_s_21143 = sle64((int64_t) 0, m_21142);
    bool y_21146 = zzero_leq_i_p_m_t_s_21143 && i_p_m_t_s_leq_w_21144;
    bool i_lte_j_21145 = sle64((int64_t) 0, m_21132);
    bool forwards_ok_21147 = i_lte_j_21145 && y_21146;
    bool eq_x_zz_21139 = (int64_t) 0 == m_f_res_21130;
    bool p_and_eq_x_y_21140 = x_21123 && eq_x_zz_21139;
    bool empty_slice_21141 = cond_21122 || p_and_eq_x_y_21140;
    bool ok_or_empty_21148 = empty_slice_21141 || forwards_ok_21147;
    bool index_certs_21149;
    
    if (!ok_or_empty_21148) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_21132, "] out of bounds for array of shape [", (long long) nz2081U_17318, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  auto_test.fut:9:23-52\n   #3  auto_test.fut:9:1-52\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_22807 = (int64_t) 4 * m_21132;
    
    if (memblock_alloc_device(ctx, &mem_22808, bytes_22807, "mem_22808")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22808.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, II1_mem_22768.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21132})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_22810, bytes_22807, "mem_22810")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22810.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, A_mem_22769.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21132})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_22359;
    
    segmap_tblock_sizze_22359 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22358;
    
    int64_t num_tblocks_22361;
    int64_t max_num_tblocks_23643;
    
    max_num_tblocks_23643 = *ctx->tuning_params.human_regularzisegmap_num_tblocks_22360;
    num_tblocks_22361 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_17318, segmap_tblock_sizze_22359), max_num_tblocks_23643)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_23644 = sext_i64_i32(sdiv_up64(nz2081U_17318, segmap_tblock_sizze_22359));
    
    {
        err = gpu_kernel_human_regularzisegmap_22356(ctx, num_tblocks_22361, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22358, 1, 1, (int64_t) 0, nz2081U_17318, m_21132, num_tblocks_22361, virt_num_tblocks_23644, II1_mem_22768.mem, A_mem_22769.mem, mem_22804.mem, mem_22806.mem, mem_22808.mem, mem_22810.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_22804, "mem_22804") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22806, "mem_22806") != 0)
        return 1;
    
    bool loop_cond_21159 = slt64((int64_t) 0, m_21132);
    int64_t segscan_tblock_sizze_22365;
    
    segscan_tblock_sizze_22365 = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22364;
    
    int64_t num_tblocks_22367;
    int64_t max_num_tblocks_23657;
    
    max_num_tblocks_23657 = *ctx->tuning_params.human_regularzisegscan_num_tblocks_22366;
    num_tblocks_22367 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_17317, segscan_tblock_sizze_22365), max_num_tblocks_23657)));
    
    int64_t segmap_tblock_sizze_22391;
    
    segmap_tblock_sizze_22391 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22374;
    
    int64_t segmap_usable_groups_22392 = sdiv_up_safe64(mz2080U_17317, segmap_tblock_sizze_22391);
    int64_t segmap_tblock_sizze_22426;
    
    segmap_tblock_sizze_22426 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22410;
    
    int64_t seghist_tblock_sizze_22444;
    
    seghist_tblock_sizze_22444 = *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443;
    
    int64_t segmap_tblock_sizze_22494;
    
    segmap_tblock_sizze_22494 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22467;
    
    int64_t segmap_usable_groups_22495 = sdiv_up_safe64(mz2080U_17317, segmap_tblock_sizze_22494);
    int64_t segscan_tblock_sizze_22525;
    
    segscan_tblock_sizze_22525 = *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22524;
    
    int64_t segmap_tblock_sizze_22535;
    
    segmap_tblock_sizze_22535 = *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22534;
    if (memblock_alloc_device(ctx, &mem_22829, bytes_22780, "mem_22829")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22832, bytes_22780, "mem_22832")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22837, bytes_22780, "mem_22837")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22839, bytes_22780, "mem_22839")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_22849, bytes_22780, "mem_22849")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t result_21160;
    bool result_21161;
    int64_t loop_dz2081Uz2089Uz2081U_21167;
    bool loop_while_21168;
    
    if (memblock_set_device(ctx, &mem_param_22814, &mem_22797, "mem_22797") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22817, &mem_22795, "mem_22795") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22820, &mem_22808, "mem_22808") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22823, &mem_22810, "mem_22810") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_22826, &mem_22799, "mem_22799") != 0)
        return 1;
    loop_dz2081Uz2089Uz2081U_21167 = m_21132;
    loop_while_21168 = loop_cond_21159;
    while (loop_while_21168) {
        if (slt64((int64_t) 0, mz2080U_17317)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_23670;
            
            shared_memory_23670 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_23671;
            
            thread_block_sizze_23671 = ctx->max_thread_block_size;
            
            int64_t registers_23672;
            
            registers_23672 = ctx->max_registers;
            
            int64_t thread_block_sizze_23673;
            
            thread_block_sizze_23673 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_23674 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23670, thread_block_sizze_23671), (int64_t) 4), squot64(squot64(registers_23672, thread_block_sizze_23673) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
            int64_t num_virt_blocks_23675 = sdiv_up64(mz2080U_17317, segscan_tblock_sizze_22365 * chunk_sizze_23674);
            int64_t num_virt_threads_23676 = num_virt_blocks_23675 * segscan_tblock_sizze_22365;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23674, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_23677, num_virt_blocks_23675, "status_flags_mem_23677")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23677, num_virt_blocks_23675, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_23679, (int64_t) 4 * num_virt_blocks_23675, "aggregates_mem_23679")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_23681, (int64_t) 4 * num_virt_blocks_23675, "incprefixes_mem_23681")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_human_regularzisegscan_22370(ctx, num_tblocks_22367, 1, 1, *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22364, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22365), chunk_sizze_23674 * segscan_tblock_sizze_22365 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_22365), chunk_sizze_23674 * segscan_tblock_sizze_22365 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_17317, num_tblocks_22367, num_virt_blocks_23675, num_virt_threads_23676, mem_param_22817.mem, mem_22829.mem, status_flags_mem_23677.mem, aggregates_mem_23679.mem, incprefixes_mem_23681.mem, global_dynid_mem_23683.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23772 = sext_i64_i32(sdiv_up64(mz2080U_17317, segmap_tblock_sizze_22391));
        
        {
            err = gpu_kernel_human_regularzisegmap_22395(ctx, segmap_usable_groups_22392, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22374, 1, 1, (int64_t) 0, mz2080U_17317, loop_dz2081Uz2089Uz2081U_21167, mem_param_22823.mem, mem_22829.mem, mem_22832.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t segmap_usable_groups_22427 = sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, segmap_tblock_sizze_22426);
        
        if (memblock_alloc_device(ctx, &mem_22834, loop_dz2081Uz2089Uz2081U_21167, "mem_22834")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22835, loop_dz2081Uz2089Uz2081U_21167, "mem_22835")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23781 = sext_i64_i32(sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, segmap_tblock_sizze_22426));
        
        {
            err = gpu_kernel_human_regularzisegmap_22431(ctx, segmap_usable_groups_22427, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22410, 1, 1, (int64_t) 0, mz2080U_17317, loop_dz2081Uz2089Uz2081U_21167, mem_param_22820.mem, mem_param_22823.mem, mem_22832.mem, mem_22834.mem, mem_22835.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (futrts_builtinzhreplicate_i32(ctx, mem_22837, mz2080U_17317, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i32(ctx, mem_22839, mz2080U_17317, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_tblocks_22446;
        int64_t max_num_tblocks_23790;
        
        max_num_tblocks_23790 = *ctx->tuning_params.human_regularziseghist_num_tblocks_22445;
        num_tblocks_22446 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, seghist_tblock_sizze_22444), max_num_tblocks_23790)));
        
        int64_t num_subhistos_23791;
        int64_t h_23796 = (int64_t) 4 * mz2080U_17317 + (int64_t) 4 * mz2080U_17317;
        int64_t seg_h_23797 = (int64_t) 4 * mz2080U_17317 + (int64_t) 4 * mz2080U_17317;
        
        if (!(seg_h_23797 == (int64_t) 0)) {
            int64_t hist_H_23798 = mz2080U_17317;
            int64_t hist_el_sizze_23799 = sdiv_up64(h_23796, hist_H_23798);
            int64_t hist_N_23800 = loop_dz2081Uz2089Uz2081U_21167;
            int32_t hist_RF_23801 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegHist");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_22446 * seghist_tblock_sizze_22444), '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_22444, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23798, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_23800, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_23799, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_23801, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_23796, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_23797, '\n');
            
            int64_t hist_L_23802;
            
            hist_L_23802 = *ctx->tuning_params.human_regularzihist_L_23802;
            
            int64_t max_tblock_sizze_23803;
            
            max_tblock_sizze_23803 = ctx->max_thread_block_size;
            
            int64_t num_tblocks_23804 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_22446 * seghist_tblock_sizze_22444)), max_tblock_sizze_23803);
            double hist_m_prime_23805 = sitofp_i64_f64(smin64(squot64(hist_L_23802, hist_el_sizze_23799), sdiv_up64(hist_N_23800, num_tblocks_23804))) / sitofp_i64_f64(hist_H_23798);
            int64_t hist_M0_23806 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_23805), max_tblock_sizze_23803));
            int64_t hist_Nout_23807 = (int64_t) 1;
            int64_t hist_Nin_23808 = loop_dz2081Uz2089Uz2081U_21167;
            int64_t work_asymp_M_max_23809 = squot64(hist_Nout_23807 * hist_N_23800, (int64_t) 2 * num_tblocks_23804 * hist_H_23798);
            int32_t hist_M_23810 = sext_i64_i32(smin64(hist_M0_23806, work_asymp_M_max_23809));
            int64_t hist_C_23811 = sdiv_up64(max_tblock_sizze_23803, sext_i32_i64(smax32(1, hist_M_23810)));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_23806, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_23809, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_23811, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_23803, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_23810, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_23798 * hist_el_sizze_23799 * sext_i32_i64(hist_M_23810)), '\n');
            
            int64_t local_mem_needed_23812 = hist_el_sizze_23799 * sext_i32_i64(hist_M_23810);
            int32_t hist_S_23813 = sext_i64_i32(sdiv_up64(hist_H_23798 * local_mem_needed_23812 + (int64_t) 1, hist_L_23802));
            
            if (sle64(hist_H_23798, hist_Nin_23808) && (sle64(local_mem_needed_23812, hist_L_23802) && (sle32(hist_S_23813, 3) && (sle64(hist_C_23811, max_tblock_sizze_23803) && slt32(0, hist_M_23810))))) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using shared memory");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_23798, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23810, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_23811, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23813, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_23810, '\n');
                num_subhistos_23791 = num_tblocks_23804;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_23791, '\n');
                if (num_subhistos_23791 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23792, &mem_22839, "mem_22839") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23792, num_subhistos_23791 * mz2080U_17317 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23792")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23792, num_subhistos_23791 * mz2080U_17317, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23792.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22839.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_17317})) != 0)
                        goto cleanup;
                }
                if (num_subhistos_23791 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23794, &mem_22837, "mem_22837") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23794, num_subhistos_23791 * mz2080U_17317 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23794")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23794, num_subhistos_23791 * mz2080U_17317, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23794.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22837.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_17317})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23814 = 0; chk_i_23814 < hist_S_23813; chk_i_23814++) {
                    int64_t num_segments_23815 = (int64_t) 1;
                    int64_t hist_H_chk_23816 = sdiv_up64(mz2080U_17317, sext_i32_i64(hist_S_23813));
                    int64_t histo_sizze_23817 = hist_H_chk_23816;
                    int32_t init_per_thread_23818 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_23810) * histo_sizze_23817, max_tblock_sizze_23803));
                    
                    {
                        err = gpu_kernel_human_regularziseghist_local_22451(ctx, num_tblocks_23804, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_23810 * hist_H_chk_23816) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23810 * hist_H_chk_23816), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_23810 * hist_H_chk_23816) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_23810 * hist_H_chk_23816), (int64_t) 8), (int64_t) 8)), mz2080U_17317, loop_dz2081Uz2089Uz2081U_21167, num_subhistos_23791, num_tblocks_23804, hist_M_23810, chk_i_23814, num_segments_23815, hist_H_chk_23816, histo_sizze_23817, init_per_thread_23818, mem_param_22820.mem, mem_22834.mem, mem_22835.mem, defunc_0_map_res_subhistos_mem_23792.mem, defunc_0_map_res_subhistos_mem_23794.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using global memory");
                
                int64_t hist_H_23859 = mz2080U_17317;
                double hist_RF_23860 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
                int32_t hist_el_sizze_23861 = 4;
                double hist_C_max_23862 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22446 * seghist_tblock_sizze_22444)), sitofp_i32_f64(hist_H_23859) / 2.0);
                int32_t hist_M_min_23863 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22446 * seghist_tblock_sizze_22444)) / hist_C_max_23862)));
                int64_t hist_L2_23864;
                
                hist_L2_23864 = *ctx->tuning_params.human_regularzihist_L2_23864;
                
                double hist_RACE_exp_23865 = fmax64(1.0, 0.75 * hist_RF_23860 / (64.0 / sitofp_i32_f64(hist_el_sizze_23861)));
                int32_t hist_S_23866;
                
                if (slt64(loop_dz2081Uz2089Uz2081U_21167, hist_H_23859)) {
                    hist_S_23866 = 1;
                } else {
                    hist_S_23866 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_23863) * hist_H_23859 * sext_i32_i64(hist_el_sizze_23861), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_23864) * hist_RACE_exp_23865)));
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_23865, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_23866, '\n');
                
                int64_t hist_H_chk_23867 = sdiv_up64(mz2080U_17317, sext_i32_i64(hist_S_23866));
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_23867, '\n');
                
                double hist_k_max_23868 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_23864) / sitofp_i32_f64(8)) * hist_RACE_exp_23865, sitofp_i32_f64(loop_dz2081Uz2089Uz2081U_21167)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_22446 * seghist_tblock_sizze_22444));
                int64_t hist_u_23869 = (int64_t) 2;
                double hist_C_23870 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_22446 * seghist_tblock_sizze_22444)), sitofp_i32_f64(hist_u_23869 * hist_H_chk_23867) / hist_k_max_23868);
                int32_t hist_M_23871 = 1;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_23868, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_23871, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_23870, '\n');
                num_subhistos_23791 = sext_i32_i64(hist_M_23871);
                if (hist_M_23871 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23792, &mem_22839, "mem_22839") != 0)
                        return 1;
                } else if (num_subhistos_23791 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23792, &mem_22839, "mem_22839") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23792, num_subhistos_23791 * mz2080U_17317 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23792")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23792, num_subhistos_23791 * mz2080U_17317, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23792.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22839.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_17317})) != 0)
                        goto cleanup;
                }
                if (hist_M_23871 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23794, &mem_22837, "mem_22837") != 0)
                        return 1;
                } else if (num_subhistos_23791 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_23794, &mem_22837, "mem_22837") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_23794, num_subhistos_23791 * mz2080U_17317 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_23794")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_23794, num_subhistos_23791 * mz2080U_17317, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_23794.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_22837.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_17317})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_23872 = 0; chk_i_23872 < hist_S_23866; chk_i_23872++) {
                    int64_t hist_H_chk_23873 = sdiv_up64(mz2080U_17317, sext_i32_i64(hist_S_23866));
                    
                    {
                        err = gpu_kernel_human_regularziseghist_global_22451(ctx, num_tblocks_22446, 1, 1, *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443, 1, 1, (int64_t) 0, mz2080U_17317, loop_dz2081Uz2089Uz2081U_21167, num_tblocks_22446, num_subhistos_23791, chk_i_23872, hist_H_chk_23873, mem_param_22820.mem, mem_22834.mem, mem_22835.mem, defunc_0_map_res_subhistos_mem_23792.mem, defunc_0_map_res_subhistos_mem_23794.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
            if (num_subhistos_23791 == (int64_t) 1) {
                if (memblock_set_device(ctx, &mem_22839, &defunc_0_map_res_subhistos_mem_23792, "defunc_0_map_res_subhistos_mem_23792") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_22837, &defunc_0_map_res_subhistos_mem_23794, "defunc_0_map_res_subhistos_mem_23794") != 0)
                    return 1;
            } else {
                int64_t chunk_sizze_23890 = (int64_t) 1;
                
                if (slt64(num_subhistos_23791 * (int64_t) 2, seghist_tblock_sizze_22444 * chunk_sizze_23890)) {
                    int64_t segment_sizze_nonzzero_23891 = smax64((int64_t) 1, num_subhistos_23791);
                    int64_t num_threads_23892 = seghist_tblock_sizze_22444 * seghist_tblock_sizze_22444;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_17317, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23791, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_17317, squot64(seghist_tblock_sizze_22444, segment_sizze_nonzzero_23891))), '\n');
                    {
                        err = gpu_kernel_human_regularzisegred_small_23889(ctx, num_tblocks_22446, 1, 1, *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443, 1, 1, (int64_t) 4 * seghist_tblock_sizze_22444 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22444, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_22444 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22444, (int64_t) 8), (int64_t) 8)), mz2080U_17317, num_tblocks_22446, num_subhistos_23791, segment_sizze_nonzzero_23891, mem_22837.mem, mem_22839.mem, defunc_0_map_res_subhistos_mem_23792.mem, defunc_0_map_res_subhistos_mem_23794.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_23927 = sdiv_up64(num_tblocks_22446, smax64((int64_t) 1, mz2080U_17317));
                    int64_t q_23928 = sdiv_up64(num_subhistos_23791, seghist_tblock_sizze_22444 * blocks_per_segment_23927 * chunk_sizze_23890);
                    int64_t num_virtblocks_23929 = blocks_per_segment_23927 * mz2080U_17317;
                    int64_t threads_per_segment_23930 = blocks_per_segment_23927 * seghist_tblock_sizze_22444;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_17317, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_23791, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_23929, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_22446, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_22444, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_23928, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_23927, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_23931, (int64_t) 4 * num_virtblocks_23929, "segred_tmp_mem_23931")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_23933, (int64_t) 4 * num_virtblocks_23929, "segred_tmp_mem_23933")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_human_regularzisegred_large_23889(ctx, num_tblocks_22446, 1, 1, *ctx->tuning_params.human_regularziseghist_tblock_sizze_22443, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_22444 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22444, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_22444 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_22444, (int64_t) 8), (int64_t) 8)), mz2080U_17317, num_tblocks_22446, num_subhistos_23791, blocks_per_segment_23927, q_23928, num_virtblocks_23929, threads_per_segment_23930, mem_22837.mem, mem_22839.mem, defunc_0_map_res_subhistos_mem_23792.mem, defunc_0_map_res_subhistos_mem_23794.mem, segred_tmp_mem_23931.mem, segred_tmp_mem_23933.mem, counters_mem_23935.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_alloc_device(ctx, &mem_22843, bytes_22780, "mem_22843")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22845, bytes_22780, "mem_22845")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22847, bytes_22780, "mem_22847")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_23978 = sext_i64_i32(sdiv_up64(mz2080U_17317, segmap_tblock_sizze_22494));
        
        {
            err = gpu_kernel_human_regularzisegmap_22501(ctx, segmap_usable_groups_22495, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22467, 1, 1, (int64_t) 0, mz2080U_17317, mem_param_22814.mem, mem_param_22817.mem, mem_param_22826.mem, mem_22832.mem, mem_22837.mem, mem_22839.mem, mem_22843.mem, mem_22845.mem, mem_22847.mem, mem_22849.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t num_tblocks_22527;
        int64_t max_num_tblocks_23987;
        
        max_num_tblocks_23987 = *ctx->tuning_params.human_regularzisegscan_num_tblocks_22526;
        num_tblocks_22527 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, segscan_tblock_sizze_22525), max_num_tblocks_23987)));
        
        int64_t bytes_22851 = (int64_t) 8 * loop_dz2081Uz2089Uz2081U_21167;
        
        if (memblock_alloc_device(ctx, &mem_22852, bytes_22851, "mem_22852")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_22854, bytes_22851, "mem_22854")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, loop_dz2081Uz2089Uz2081U_21167)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_23988;
            
            shared_memory_23988 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_23989;
            
            thread_block_sizze_23989 = ctx->max_thread_block_size;
            
            int64_t registers_23990;
            
            registers_23990 = ctx->max_registers;
            
            int64_t thread_block_sizze_23991;
            
            thread_block_sizze_23991 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_23992 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_23988, thread_block_sizze_23989), (int64_t) 8), squot64(squot64(registers_23990, thread_block_sizze_23991) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_23993 = sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, segscan_tblock_sizze_22525 * chunk_sizze_23992);
            int64_t num_virt_threads_23994 = num_virt_blocks_23993 * segscan_tblock_sizze_22525;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_23992, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_23995, num_virt_blocks_23993, "status_flags_mem_23995")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_23995, num_virt_blocks_23993, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_23997, (int64_t) 8 * num_virt_blocks_23993, "aggregates_mem_23997")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_23999, (int64_t) 8 * num_virt_blocks_23993, "incprefixes_mem_23999")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_human_regularzisegscan_22530(ctx, num_tblocks_22527, 1, 1, *ctx->tuning_params.human_regularzisegscan_tblock_sizze_22524, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22525), chunk_sizze_23992 * segscan_tblock_sizze_22525 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_22525), chunk_sizze_23992 * segscan_tblock_sizze_22525 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_17317, loop_dz2081Uz2089Uz2081U_21167, num_tblocks_22527, num_virt_blocks_23993, num_virt_threads_23994, mem_param_22820.mem, mem_22834.mem, mem_22835.mem, mem_22849.mem, mem_22852.mem, mem_22854.mem, status_flags_mem_23995.mem, aggregates_mem_23997.mem, incprefixes_mem_23999.mem, global_dynid_mem_24001.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        if (memblock_unref_device(ctx, &mem_22834, "mem_22834") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22835, "mem_22835") != 0)
            return 1;
        
        bool cond_21297 = loop_dz2081Uz2089Uz2081U_21167 == (int64_t) 0;
        bool x_21298 = !cond_21297;
        int64_t tmp_21299 = sub64(loop_dz2081Uz2089Uz2081U_21167, (int64_t) 1);
        bool x_21300 = sle64((int64_t) 0, tmp_21299);
        bool y_21301 = slt64(tmp_21299, loop_dz2081Uz2089Uz2081U_21167);
        bool bounds_check_21302 = x_21300 && y_21301;
        bool protect_assert_disj_21303 = cond_21297 || bounds_check_21302;
        bool index_certs_21304;
        
        if (!protect_assert_disj_21303) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_21299, "] out of bounds for array of shape [", (long long) loop_dz2081Uz2089Uz2081U_21167, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  auto_test.fut:9:23-52\n   #3  auto_test.fut:9:1-52\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t m_f_res_21305;
        
        if (x_21298) {
            int64_t read_res_24153;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_24153, mem_22852.mem, tmp_21299 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_21937 = read_res_24153;
            
            m_f_res_21305 = x_21937;
        } else {
            m_f_res_21305 = (int64_t) 0;
        }
        
        int64_t m_21307;
        
        if (cond_21297) {
            m_21307 = (int64_t) 0;
        } else {
            m_21307 = m_f_res_21305;
        }
        
        int64_t m_21317 = sub64(m_21307, (int64_t) 1);
        bool i_p_m_t_s_leq_w_21319 = slt64(m_21317, loop_dz2081Uz2089Uz2081U_21167);
        bool zzero_leq_i_p_m_t_s_21318 = sle64((int64_t) 0, m_21317);
        bool y_21321 = zzero_leq_i_p_m_t_s_21318 && i_p_m_t_s_leq_w_21319;
        bool i_lte_j_21320 = sle64((int64_t) 0, m_21307);
        bool forwards_ok_21322 = i_lte_j_21320 && y_21321;
        bool eq_x_zz_21314 = (int64_t) 0 == m_f_res_21305;
        bool p_and_eq_x_y_21315 = x_21298 && eq_x_zz_21314;
        bool empty_slice_21316 = cond_21297 || p_and_eq_x_y_21315;
        bool ok_or_empty_21323 = empty_slice_21316 || forwards_ok_21322;
        bool index_certs_21324;
        
        if (!ok_or_empty_21323) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_21307, "] out of bounds for array of shape [", (long long) loop_dz2081Uz2089Uz2081U_21167, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  auto_test.fut:9:23-52\n   #3  auto_test.fut:9:1-52\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_22855 = (int64_t) 4 * m_21307;
        
        if (memblock_alloc_device(ctx, &mem_22856, bytes_22855, "mem_22856")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22856.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22820.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21307})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_22858, bytes_22855, "mem_22858")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_22858.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_22823.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_21307})) != 0)
            goto cleanup;
        
        int64_t num_tblocks_22537;
        int64_t max_num_tblocks_24090;
        
        max_num_tblocks_24090 = *ctx->tuning_params.human_regularzisegmap_num_tblocks_22536;
        num_tblocks_22537 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, segmap_tblock_sizze_22535), max_num_tblocks_24090)));
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_24091 = sext_i64_i32(sdiv_up64(loop_dz2081Uz2089Uz2081U_21167, segmap_tblock_sizze_22535));
        
        {
            err = gpu_kernel_human_regularzisegmap_22532(ctx, num_tblocks_22537, 1, 1, *ctx->tuning_params.human_regularzisegmap_tblock_sizze_22534, 1, 1, (int64_t) 0, loop_dz2081Uz2089Uz2081U_21167, m_21307, num_tblocks_22537, virt_num_tblocks_24091, mem_param_22820.mem, mem_param_22823.mem, mem_22852.mem, mem_22854.mem, mem_22856.mem, mem_22858.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_22852, "mem_22852") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22854, "mem_22854") != 0)
            return 1;
        
        bool loop_cond_21334 = slt64((int64_t) 0, m_21307);
        
        if (memblock_set_device(ctx, &mem_param_tmp_23658, &mem_22845, "mem_22845") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_23659, &mem_22843, "mem_22843") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_23660, &mem_22856, "mem_22856") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_23661, &mem_22858, "mem_22858") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_23662, &mem_22847, "mem_22847") != 0)
            return 1;
        
        int64_t loop_dz2081Uz2089Uz2081U_tmp_23663 = m_21307;
        bool loop_while_tmp_23664 = loop_cond_21334;
        
        if (memblock_set_device(ctx, &mem_param_22814, &mem_param_tmp_23658, "mem_param_tmp_23658") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22817, &mem_param_tmp_23659, "mem_param_tmp_23659") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22820, &mem_param_tmp_23660, "mem_param_tmp_23660") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22823, &mem_param_tmp_23661, "mem_param_tmp_23661") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_22826, &mem_param_tmp_23662, "mem_param_tmp_23662") != 0)
            return 1;
        loop_dz2081Uz2089Uz2081U_21167 = loop_dz2081Uz2089Uz2081U_tmp_23663;
        loop_while_21168 = loop_while_tmp_23664;
    }
    if (memblock_set_device(ctx, &ext_mem_22874, &mem_param_22814, "mem_param_22814") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22873, &mem_param_22817, "mem_param_22817") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22872, &mem_param_22820, "mem_param_22820") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22871, &mem_param_22823, "mem_param_22823") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_22870, &mem_param_22826, "mem_param_22826") != 0)
        return 1;
    result_21160 = loop_dz2081Uz2089Uz2081U_21167;
    result_21161 = loop_while_21168;
    if (memblock_unref_device(ctx, &mem_22795, "mem_22795") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22797, "mem_22797") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22799, "mem_22799") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22808, "mem_22808") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22810, "mem_22810") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22829, "mem_22829") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22832, "mem_22832") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22837, "mem_22837") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22839, "mem_22839") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_22849, "mem_22849") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_22884, &ext_mem_22870, "ext_mem_22870") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_24151, &mem_out_22884, "mem_out_22884") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_param_tmp_23662, "mem_param_tmp_23662") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_23661, "mem_param_tmp_23661") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_23660, "mem_param_tmp_23660") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_23659, "mem_param_tmp_23659") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_23658, "mem_param_tmp_23658") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22858, "mem_22858") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22856, "mem_22856") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23999, "incprefixes_mem_23999") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23997, "aggregates_mem_23997") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23995, "status_flags_mem_23995") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22854, "mem_22854") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22852, "mem_22852") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22847, "mem_22847") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22845, "mem_22845") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22843, "mem_22843") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23933, "segred_tmp_mem_23933") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23931, "segred_tmp_mem_23931") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_23794, "defunc_0_map_res_subhistos_mem_23794") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_23792, "defunc_0_map_res_subhistos_mem_23792") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22835, "mem_22835") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22834, "mem_22834") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23681, "incprefixes_mem_23681") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23679, "aggregates_mem_23679") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23677, "status_flags_mem_23677") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22826, "mem_param_22826") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22823, "mem_param_22823") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22820, "mem_param_22820") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22817, "mem_param_22817") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_22814, "mem_param_22814") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22870, "ext_mem_22870") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22871, "ext_mem_22871") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22872, "ext_mem_22872") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22873, "ext_mem_22873") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_22874, "ext_mem_22874") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22849, "mem_22849") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22839, "mem_22839") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22837, "mem_22837") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22832, "mem_22832") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22829, "mem_22829") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22810, "mem_22810") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22808, "mem_22808") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23552, "incprefixes_mem_23552") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23550, "aggregates_mem_23550") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23548, "status_flags_mem_23548") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22806, "mem_22806") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22804, "mem_22804") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22801, "mem_22801") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22799, "mem_22799") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22797, "mem_22797") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22795, "mem_22795") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23486, "segred_tmp_mem_23486") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_23484, "segred_tmp_mem_23484") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_23347, "defunc_0_map_res_subhistos_mem_23347") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_23345, "defunc_0_map_res_subhistos_mem_23345") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22791, "mem_22791") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22789, "mem_22789") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22787, "mem_22787") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22786, "mem_22786") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22784, "mem_22784") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23234, "incprefixes_mem_23234") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23232, "aggregates_mem_23232") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23230, "status_flags_mem_23230") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22781, "mem_22781") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23078, "incprefixes_mem_23078") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23076, "aggregates_mem_23076") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_23074, "incprefixes_mem_23074") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_23072, "aggregates_mem_23072") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_23070, "status_flags_mem_23070") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22778, "mem_22778") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22776, "mem_22776") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22773, "mem_22773") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_22917, "incprefixes_mem_22917") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_22915, "aggregates_mem_22915") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_22893, "status_flags_mem_22893") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_22772, "mem_22772") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_22884, "mem_out_22884") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_compiler(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_f32_1d *in2)
{
    int64_t mz2080U_19405 = (int64_t) 0;
    int64_t nz2081U_19406 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_22884;
    
    mem_out_22884.references = NULL;
    
    struct memblock_device A_mem_22768;
    
    A_mem_22768.references = NULL;
    
    struct memblock_device shp_mem_22767;
    
    shp_mem_22767.references = NULL;
    
    struct memblock_device ks_mem_22766;
    
    ks_mem_22766.references = NULL;
    ks_mem_22766 = in0->mem;
    mz2080U_19405 = in0->shape[0];
    shp_mem_22767 = in1->mem;
    mz2080U_19405 = in1->shape[0];
    A_mem_22768 = in2->mem;
    nz2081U_19406 = in2->shape[0];
    if (!(mz2080U_19405 == in0->shape[0] && (mz2080U_19405 == in1->shape[0] && nz2081U_19406 == in2->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_compiler(ctx, &mem_out_22884, ks_mem_22766, shp_mem_22767, A_mem_22768, mz2080U_19405, nz2081U_19406);
        if (ret == 0) {
            struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
            struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
            struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
            struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
            struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
            struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
            struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
            struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
            struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
            struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
            struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
            struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
            struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
            struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
            struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
            struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
            struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
            struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
            struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_22884;
            (*out0)->shape[0] = mz2080U_19405;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_human(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_f32_1d *in3)
{
    int64_t mz2080U_14093 = (int64_t) 0;
    int64_t nz2081U_14094 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_22884;
    
    mem_out_22884.references = NULL;
    
    struct memblock_device A_mem_22769;
    
    A_mem_22769.references = NULL;
    
    struct memblock_device II1_mem_22768;
    
    II1_mem_22768.references = NULL;
    
    struct memblock_device shp_mem_22767;
    
    shp_mem_22767.references = NULL;
    
    struct memblock_device ks_mem_22766;
    
    ks_mem_22766.references = NULL;
    ks_mem_22766 = in0->mem;
    mz2080U_14093 = in0->shape[0];
    shp_mem_22767 = in1->mem;
    mz2080U_14093 = in1->shape[0];
    II1_mem_22768 = in2->mem;
    nz2081U_14094 = in2->shape[0];
    A_mem_22769 = in3->mem;
    nz2081U_14094 = in3->shape[0];
    if (!(mz2080U_14093 == in0->shape[0] && (mz2080U_14093 == in1->shape[0] && (nz2081U_14094 == in2->shape[0] && nz2081U_14094 == in3->shape[0])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_human(ctx, &mem_out_22884, ks_mem_22766, shp_mem_22767, II1_mem_22768, A_mem_22769, mz2080U_14093, nz2081U_14094);
        if (ret == 0) {
            struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
            struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
            struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
            struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
            struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
            struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
            struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
            struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
            struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
            struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
            struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
            struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
            struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
            struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
            struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
            struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
            struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
            struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
            struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_22884;
            (*out0)->shape[0] = mz2080U_14093;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_human_regular(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_f32_1d *in3)
{
    int64_t mz2080U_17317 = (int64_t) 0;
    int64_t nz2081U_17318 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_22884;
    
    mem_out_22884.references = NULL;
    
    struct memblock_device A_mem_22769;
    
    A_mem_22769.references = NULL;
    
    struct memblock_device II1_mem_22768;
    
    II1_mem_22768.references = NULL;
    
    struct memblock_device shp_mem_22767;
    
    shp_mem_22767.references = NULL;
    
    struct memblock_device ks_mem_22766;
    
    ks_mem_22766.references = NULL;
    ks_mem_22766 = in0->mem;
    mz2080U_17317 = in0->shape[0];
    shp_mem_22767 = in1->mem;
    mz2080U_17317 = in1->shape[0];
    II1_mem_22768 = in2->mem;
    nz2081U_17318 = in2->shape[0];
    A_mem_22769 = in3->mem;
    nz2081U_17318 = in3->shape[0];
    if (!(mz2080U_17317 == in0->shape[0] && (mz2080U_17317 == in1->shape[0] && (nz2081U_17318 == in2->shape[0] && nz2081U_17318 == in3->shape[0])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_human_regular(ctx, &mem_out_22884, ks_mem_22766, shp_mem_22767, II1_mem_22768, A_mem_22769, mz2080U_17317, nz2081U_17318);
        if (ret == 0) {
            struct memblock_device counters_mem_23223 = ctx->constants->counters_mem_23223;
            struct memblock_device counters_mem_23488 = ctx->constants->counters_mem_23488;
            struct memblock_device counters_mem_23659 = ctx->constants->counters_mem_23659;
            struct memblock_device counters_mem_23820 = ctx->constants->counters_mem_23820;
            struct memblock_device counters_mem_23935 = ctx->constants->counters_mem_23935;
            struct memblock_device counters_mem_23981 = ctx->constants->counters_mem_23981;
            struct memblock_device global_dynid_mem_22919 = ctx->constants->global_dynid_mem_22919;
            struct memblock_device global_dynid_mem_22939 = ctx->constants->global_dynid_mem_22939;
            struct memblock_device global_dynid_mem_22951 = ctx->constants->global_dynid_mem_22951;
            struct memblock_device global_dynid_mem_23080 = ctx->constants->global_dynid_mem_23080;
            struct memblock_device global_dynid_mem_23096 = ctx->constants->global_dynid_mem_23096;
            struct memblock_device global_dynid_mem_23220 = ctx->constants->global_dynid_mem_23220;
            struct memblock_device global_dynid_mem_23236 = ctx->constants->global_dynid_mem_23236;
            struct memblock_device global_dynid_mem_23289 = ctx->constants->global_dynid_mem_23289;
            struct memblock_device global_dynid_mem_23340 = ctx->constants->global_dynid_mem_23340;
            struct memblock_device global_dynid_mem_23554 = ctx->constants->global_dynid_mem_23554;
            struct memblock_device global_dynid_mem_23683 = ctx->constants->global_dynid_mem_23683;
            struct memblock_device global_dynid_mem_24001 = ctx->constants->global_dynid_mem_24001;
            struct memblock_device global_dynid_mem_24041 = ctx->constants->global_dynid_mem_24041;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_22884;
            (*out0)->shape[0] = mz2080U_17317;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
