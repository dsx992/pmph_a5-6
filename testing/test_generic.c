// Generated by Futhark 0.25.24.
// git: 0bb3d37e788daf859346a635efd215ab37aa72f6
// Compiled with GHC 9.6.6.

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_unified_memory(struct futhark_context_config *cfg, int flag);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_f32_1d;
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0);
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data);
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr);
struct futhark_f64_1d;
struct futhark_f64_1d *futhark_new_f64_1d(struct futhark_context *ctx, const double *data, int64_t dim0);
struct futhark_f64_1d *futhark_new_raw_f64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
int futhark_values_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr, double *data);
int futhark_index_f64_1d(struct futhark_context *ctx, double *out, struct futhark_f64_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
const int64_t *futhark_shape_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr);
struct futhark_i32_1d;
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0);
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0);
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data);
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0);
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr);

// Opaque values



// Entry points
int futhark_entry_human_genericf32(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_f32_1d *in3);
int futhark_entry_human_genericf64(struct futhark_context *ctx, struct futhark_f64_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_f64_1d *in3);
int futhark_entry_human_generici32(struct futhark_context *ctx, struct futhark_i32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_i32_1d *in3);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
char *futhark_context_report(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

static void str_builder_str(struct str_builder *b, const char *s) {
  size_t needed = strlen(s);
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  strcpy(b->str+b->used, s);
  b->used += needed;
}

static void str_builder_char(struct str_builder *b, char c) {
  size_t needed = 1;
  if (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }
  b->str[b->used] = c;
  b->str[b->used+1] = 0;
  b->used += needed;
}

static void str_builder_json_str(struct str_builder* sb, const char* s) {
  str_builder_char(sb, '"');
  for (int j = 0; s[j]; j++) {
    char c = s[j];
    switch (c) {
    case '\n':
      str_builder_str(sb, "\\n");
      break;
    case '"':
      str_builder_str(sb, "\\\"");
      break;
    default:
      str_builder_char(sb, c);
    }
  }
  str_builder_char(sb, '"');
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
// Start of event_list.h

typedef int (*event_report_fn)(struct str_builder*, void*);

struct event {
  void* data;
  event_report_fn f;
  const char* name;
  char *description;
};

struct event_list {
  struct event *events;
  int num_events;
  int capacity;
};

static void event_list_init(struct event_list *l) {
  l->capacity = 100;
  l->num_events = 0;
  l->events = calloc(l->capacity, sizeof(struct event));
}

static void event_list_free(struct event_list *l) {
  free(l->events);
}

static void add_event_to_list(struct event_list *l,
                              const char* name,
                              char* description,
                              void* data,
                              event_report_fn f) {
  if (l->num_events == l->capacity) {
    l->capacity *= 2;
    l->events = realloc(l->events, l->capacity * sizeof(struct event));
  }
  l->events[l->num_events].name = name;
  l->events[l->num_events].description = description;
  l->events[l->num_events].data = data;
  l->events[l->num_events].f = f;
  l->num_events++;
}

static int report_events_in_list(struct event_list *l,
                                 struct str_builder* sb) {
  int ret = 0;
  for (int i = 0; i < l->num_events; i++) {
    if (i != 0) {
      str_builder_str(sb, ",");
    }
    str_builder_str(sb, "{\"name\":");
    str_builder_json_str(sb, l->events[i].name);
    str_builder_str(sb, ",\"description\":");
    str_builder_json_str(sb, l->events[i].description);
    free(l->events[i].description);
    if (l->events[i].f(sb, l->events[i].data) != 0) {
      ret = 1;
      break;
    }
    str_builder(sb, "}");
  }
  event_list_free(l);
  event_list_init(l);
  return ret;
}

// End of event_list.h
#include <getopt.h>
#include <ctype.h>
#include <inttypes.h>
static const char *entry_point = "main";
// Start of values.h.

//// Text I/O

typedef int (*writer)(FILE*, const void*);
typedef int (*bin_reader)(void*);
typedef int (*str_reader)(const char *, void*);

struct array_reader {
  char* elems;
  int64_t n_elems_space;
  int64_t elem_size;
  int64_t n_elems_used;
  int64_t *shape;
  str_reader elem_reader;
};

static void skipspaces(FILE *f) {
  int c;
  do {
    c = getc(f);
  } while (isspace(c));

  if (c != EOF) {
    ungetc(c, f);
  }
}

static int constituent(char c) {
  return isalnum(c) || c == '.' || c == '-' || c == '+' || c == '_';
}

// Produces an empty token only on EOF.
static void next_token(FILE *f, char *buf, int bufsize) {
 start:
  skipspaces(f);

  int i = 0;
  while (i < bufsize) {
    int c = getc(f);
    buf[i] = (char)c;

    if (c == EOF) {
      buf[i] = 0;
      return;
    } else if (c == '-' && i == 1 && buf[0] == '-') {
      // Line comment, so skip to end of line and start over.
      for (; c != '\n' && c != EOF; c = getc(f));
      goto start;
    } else if (!constituent((char)c)) {
      if (i == 0) {
        // We permit single-character tokens that are not
        // constituents; this lets things like ']' and ',' be
        // tokens.
        buf[i+1] = 0;
        return;
      } else {
        ungetc(c, f);
        buf[i] = 0;
        return;
      }
    }

    i++;
  }

  buf[bufsize-1] = 0;
}

static int next_token_is(FILE *f, char *buf, int bufsize, const char* expected) {
  next_token(f, buf, bufsize);
  return strcmp(buf, expected) == 0;
}

static void remove_underscores(char *buf) {
  char *w = buf;

  for (char *r = buf; *r; r++) {
    if (*r != '_') {
      *w++ = *r;
    }
  }

  *w++ = 0;
}

static int read_str_elem(char *buf, struct array_reader *reader) {
  int ret;
  if (reader->n_elems_used == reader->n_elems_space) {
    reader->n_elems_space *= 2;
    reader->elems = (char*) realloc(reader->elems,
                                    (size_t)(reader->n_elems_space * reader->elem_size));
  }

  ret = reader->elem_reader(buf, reader->elems + reader->n_elems_used * reader->elem_size);

  if (ret == 0) {
    reader->n_elems_used++;
  }

  return ret;
}

static int read_str_array_elems(FILE *f,
                                char *buf, int bufsize,
                                struct array_reader *reader, int64_t dims) {
  int ret = 1;
  int expect_elem = 1;
  char *knows_dimsize = (char*) calloc((size_t)dims, sizeof(char));
  int cur_dim = (int)dims-1;
  int64_t *elems_read_in_dim = (int64_t*) calloc((size_t)dims, sizeof(int64_t));

  while (1) {
    next_token(f, buf, bufsize);
    if (strcmp(buf, "]") == 0) {
      expect_elem = 0;
      if (knows_dimsize[cur_dim]) {
        if (reader->shape[cur_dim] != elems_read_in_dim[cur_dim]) {
          ret = 1;
          break;
        }
      } else {
        knows_dimsize[cur_dim] = 1;
        reader->shape[cur_dim] = elems_read_in_dim[cur_dim];
      }
      if (cur_dim == 0) {
        ret = 0;
        break;
      } else {
        cur_dim--;
        elems_read_in_dim[cur_dim]++;
      }
    } else if (!expect_elem && strcmp(buf, ",") == 0) {
      expect_elem = 1;
    } else if (expect_elem) {
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else if (cur_dim == dims - 1) {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        expect_elem = 0;
        elems_read_in_dim[cur_dim]++;
      } else {
        ret = 1;
        break;
      }
    } else {
      ret = 1;
      break;
    }
  }

  free(knows_dimsize);
  free(elems_read_in_dim);
  return ret;
}

static int read_str_empty_array(FILE *f, char *buf, int bufsize,
                                const char *type_name, int64_t *shape, int64_t dims) {
  if (strlen(buf) == 0) {
    // EOF
    return 1;
  }

  if (strcmp(buf, "empty") != 0) {
    return 1;
  }

  if (!next_token_is(f, buf, bufsize, "(")) {
    return 1;
  }

  for (int i = 0; i < dims; i++) {
    if (!next_token_is(f, buf, bufsize, "[")) {
      return 1;
    }

    next_token(f, buf, bufsize);

    if (sscanf(buf, "%"SCNu64, (uint64_t*)&shape[i]) != 1) {
      return 1;
    }

    if (!next_token_is(f, buf, bufsize, "]")) {
      return 1;
    }
  }

  if (!next_token_is(f, buf, bufsize, type_name)) {
    return 1;
  }


  if (!next_token_is(f, buf, bufsize, ")")) {
    return 1;
  }

  // Check whether the array really is empty.
  for (int i = 0; i < dims; i++) {
    if (shape[i] == 0) {
      return 0;
    }
  }

  // Not an empty array!
  return 1;
}

static int read_str_array(FILE *f,
                          int64_t elem_size, str_reader elem_reader,
                          const char *type_name,
                          void **data, int64_t *shape, int64_t dims) {
  int ret;
  struct array_reader reader;
  char buf[100];

  int dims_seen;
  for (dims_seen = 0; dims_seen < dims; dims_seen++) {
    if (!next_token_is(f, buf, sizeof(buf), "[")) {
      break;
    }
  }

  if (dims_seen == 0) {
    return read_str_empty_array(f, buf, sizeof(buf), type_name, shape, dims);
  }

  if (dims_seen != dims) {
    return 1;
  }

  reader.shape = shape;
  reader.n_elems_used = 0;
  reader.elem_size = elem_size;
  reader.n_elems_space = 16;
  reader.elems = (char*) realloc(*data, (size_t)(elem_size*reader.n_elems_space));
  reader.elem_reader = elem_reader;

  ret = read_str_array_elems(f, buf, sizeof(buf), &reader, dims);

  *data = reader.elems;

  return ret;
}

#define READ_STR(MACRO, PTR, SUFFIX)                                   \
  remove_underscores(buf);                                              \
  int j;                                                                \
  if (sscanf(buf, "%"MACRO"%n", (PTR*)dest, &j) == 1) {                 \
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, SUFFIX) == 0);     \
  } else {                                                              \
    return 1;                                                           \
  }

static int read_str_i8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNi8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(int8_t*)dest = (int8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "i8") == 0);
  } else {
    return 1;
  }
}

static int read_str_u8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNu8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(uint8_t*)dest = (uint8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "u8") == 0);
  } else {
    return 1;
  }
}

static int read_str_i16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "i16");
}

static int read_str_u16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "u16");
}

static int read_str_i32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "i32");
}

static int read_str_u32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "u32");
}

static int read_str_i64(char *buf, void* dest) {
  READ_STR(SCNi64, int64_t, "i64");
}

static int read_str_u64(char *buf, void* dest) {
  // FIXME: This is not correct, as SCNu64 only permits decimal
  // literals.  However, SCNi64 does not handle very large numbers
  // correctly (it's really for signed numbers, so that's fair).
  READ_STR(SCNu64, uint64_t, "u64");
}

static int read_str_f16(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f16.nan") == 0) {
    *(uint16_t*)dest = float2halfbits(NAN);
    return 0;
  } else if (strcmp(buf, "f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(INFINITY);
    return 0;
  } else if (strcmp(buf, "-f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(-INFINITY);
    return 0;
  } else {
    int j;
    float x;
    if (sscanf(buf, "%f%n", &x, &j) == 1) {
      if (strcmp(buf+j, "") == 0 || strcmp(buf+j, "f16") == 0) {
        *(uint16_t*)dest = float2halfbits(x);
        return 0;
      }
    }
    return 1;
  }
}

static int read_str_f32(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f32.nan") == 0) {
    *(float*)dest = (float)NAN;
    return 0;
  } else if (strcmp(buf, "f32.inf") == 0) {
    *(float*)dest = (float)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f32.inf") == 0) {
    *(float*)dest = (float)-INFINITY;
    return 0;
  } else {
    READ_STR("f", float, "f32");
  }
}

static int read_str_f64(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f64.nan") == 0) {
    *(double*)dest = (double)NAN;
    return 0;
  } else if (strcmp(buf, "f64.inf") == 0) {
    *(double*)dest = (double)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f64.inf") == 0) {
    *(double*)dest = (double)-INFINITY;
    return 0;
  } else {
    READ_STR("lf", double, "f64");
  }
}

static int read_str_bool(char *buf, void* dest) {
  if (strcmp(buf, "true") == 0) {
    *(char*)dest = 1;
    return 0;
  } else if (strcmp(buf, "false") == 0) {
    *(char*)dest = 0;
    return 0;
  } else {
    return 1;
  }
}

static int write_str_i8(FILE *out, int8_t *src) {
  return fprintf(out, "%hhdi8", *src);
}

static int write_str_u8(FILE *out, uint8_t *src) {
  return fprintf(out, "%hhuu8", *src);
}

static int write_str_i16(FILE *out, int16_t *src) {
  return fprintf(out, "%hdi16", *src);
}

static int write_str_u16(FILE *out, uint16_t *src) {
  return fprintf(out, "%huu16", *src);
}

static int write_str_i32(FILE *out, int32_t *src) {
  return fprintf(out, "%di32", *src);
}

static int write_str_u32(FILE *out, uint32_t *src) {
  return fprintf(out, "%uu32", *src);
}

static int write_str_i64(FILE *out, int64_t *src) {
  return fprintf(out, "%"PRIi64"i64", *src);
}

static int write_str_u64(FILE *out, uint64_t *src) {
  return fprintf(out, "%"PRIu64"u64", *src);
}

static int write_str_f16(FILE *out, uint16_t *src) {
  float x = halfbits2float(*src);
  if (isnan(x)) {
    return fprintf(out, "f16.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f16.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f16.inf");
  } else {
    return fprintf(out, "%.*ff16", FLT_DIG, x);
  }
}

static int write_str_f32(FILE *out, float *src) {
  float x = *src;
  if (isnan(x)) {
    return fprintf(out, "f32.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f32.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f32.inf");
  } else {
    return fprintf(out, "%.*ff32", FLT_DIG, x);
  }
}

static int write_str_f64(FILE *out, double *src) {
  double x = *src;
  if (isnan(x)) {
    return fprintf(out, "f64.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f64.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f64.inf");
  } else {
    return fprintf(out, "%.*ff64", DBL_DIG, x);
  }
}

static int write_str_bool(FILE *out, void *src) {
  return fprintf(out, *(char*)src ? "true" : "false");
}

//// Binary I/O

#define BINARY_FORMAT_VERSION 2
#define IS_BIG_ENDIAN (!*(unsigned char *)&(uint16_t){1})

static void flip_bytes(size_t elem_size, unsigned char *elem) {
  for (size_t j=0; j<elem_size/2; j++) {
    unsigned char head = elem[j];
    size_t tail_index = elem_size-1-j;
    elem[j] = elem[tail_index];
    elem[tail_index] = head;
  }
}

// On Windows we need to explicitly set the file mode to not mangle
// newline characters.  On *nix there is no difference.
#ifdef _WIN32
#include <io.h>
#include <fcntl.h>
static void set_binary_mode(FILE *f) {
  setmode(fileno(f), O_BINARY);
}
#else
static void set_binary_mode(FILE *f) {
  (void)f;
}
#endif

static int read_byte(FILE *f, void* dest) {
  size_t num_elems_read = fread(dest, 1, 1, f);
  return num_elems_read == 1 ? 0 : 1;
}

//// Types

struct primtype_info_t {
  const char binname[4]; // Used for parsing binary data.
  const char* type_name; // Same name as in Futhark.
  const int64_t size; // in bytes
  const writer write_str; // Write in text format.
  const str_reader read_str; // Read in text format.
};

static const struct primtype_info_t i8_info =
  {.binname = "  i8", .type_name = "i8",   .size = 1,
   .write_str = (writer)write_str_i8, .read_str = (str_reader)read_str_i8};
static const struct primtype_info_t i16_info =
  {.binname = " i16", .type_name = "i16",  .size = 2,
   .write_str = (writer)write_str_i16, .read_str = (str_reader)read_str_i16};
static const struct primtype_info_t i32_info =
  {.binname = " i32", .type_name = "i32",  .size = 4,
   .write_str = (writer)write_str_i32, .read_str = (str_reader)read_str_i32};
static const struct primtype_info_t i64_info =
  {.binname = " i64", .type_name = "i64",  .size = 8,
   .write_str = (writer)write_str_i64, .read_str = (str_reader)read_str_i64};
static const struct primtype_info_t u8_info =
  {.binname = "  u8", .type_name = "u8",   .size = 1,
   .write_str = (writer)write_str_u8, .read_str = (str_reader)read_str_u8};
static const struct primtype_info_t u16_info =
  {.binname = " u16", .type_name = "u16",  .size = 2,
   .write_str = (writer)write_str_u16, .read_str = (str_reader)read_str_u16};
static const struct primtype_info_t u32_info =
  {.binname = " u32", .type_name = "u32",  .size = 4,
   .write_str = (writer)write_str_u32, .read_str = (str_reader)read_str_u32};
static const struct primtype_info_t u64_info =
  {.binname = " u64", .type_name = "u64",  .size = 8,
   .write_str = (writer)write_str_u64, .read_str = (str_reader)read_str_u64};
static const struct primtype_info_t f16_info =
  {.binname = " f16", .type_name = "f16",  .size = 2,
   .write_str = (writer)write_str_f16, .read_str = (str_reader)read_str_f16};
static const struct primtype_info_t f32_info =
  {.binname = " f32", .type_name = "f32",  .size = 4,
   .write_str = (writer)write_str_f32, .read_str = (str_reader)read_str_f32};
static const struct primtype_info_t f64_info =
  {.binname = " f64", .type_name = "f64",  .size = 8,
   .write_str = (writer)write_str_f64, .read_str = (str_reader)read_str_f64};
static const struct primtype_info_t bool_info =
  {.binname = "bool", .type_name = "bool", .size = 1,
   .write_str = (writer)write_str_bool, .read_str = (str_reader)read_str_bool};

static const struct primtype_info_t* primtypes[] = {
  &i8_info, &i16_info, &i32_info, &i64_info,
  &u8_info, &u16_info, &u32_info, &u64_info,
  &f16_info, &f32_info, &f64_info,
  &bool_info,
  NULL // NULL-terminated
};

// General value interface.  All endian business taken care of at
// lower layers.

static int read_is_binary(FILE *f) {
  skipspaces(f);
  int c = getc(f);
  if (c == 'b') {
    int8_t bin_version;
    int ret = read_byte(f, &bin_version);

    if (ret != 0) { futhark_panic(1, "binary-input: could not read version.\n"); }

    if (bin_version != BINARY_FORMAT_VERSION) {
      futhark_panic(1, "binary-input: File uses version %i, but I only understand version %i.\n",
            bin_version, BINARY_FORMAT_VERSION);
    }

    return 1;
  }
  ungetc(c, f);
  return 0;
}

static const struct primtype_info_t* read_bin_read_type_enum(FILE *f) {
  char read_binname[4];

  int num_matched = fscanf(f, "%4c", read_binname);
  if (num_matched != 1) { futhark_panic(1, "binary-input: Couldn't read element type.\n"); }

  const struct primtype_info_t **type = primtypes;

  for (; *type != NULL; type++) {
    // I compare the 4 characters manually instead of using strncmp because
    // this allows any value to be used, also NULL bytes
    if (memcmp(read_binname, (*type)->binname, 4) == 0) {
      return *type;
    }
  }
  futhark_panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname);
  return NULL;
}

static void read_bin_ensure_scalar(FILE *f, const struct primtype_info_t *expected_type) {
  int8_t bin_dims;
  int ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != 0) {
    futhark_panic(1, "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
          bin_dims);
  }

  const struct primtype_info_t *bin_type = read_bin_read_type_enum(f);
  if (bin_type != expected_type) {
    futhark_panic(1, "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
          expected_type->type_name,
          bin_type->type_name);
  }
}

//// High-level interface

static int read_bin_array(FILE *f,
                          const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  int ret;

  int8_t bin_dims;
  ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != dims) {
    futhark_panic(1, "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
          dims, bin_dims);
  }

  const struct primtype_info_t *bin_primtype = read_bin_read_type_enum(f);
  if (expected_type != bin_primtype) {
    futhark_panic(1, "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
          dims, expected_type->type_name, dims, bin_primtype->type_name);
  }

  int64_t elem_count = 1;
  for (int i=0; i<dims; i++) {
    int64_t bin_shape;
    ret = (int)fread(&bin_shape, sizeof(bin_shape), 1, f);
    if (ret != 1) {
      futhark_panic(1, "binary-input: Couldn't read size for dimension %i of array.\n", i);
    }
    if (IS_BIG_ENDIAN) {
      flip_bytes(sizeof(bin_shape), (unsigned char*) &bin_shape);
    }
    elem_count *= bin_shape;
    shape[i] = bin_shape;
  }

  int64_t elem_size = expected_type->size;
  void* tmp = realloc(*data, (size_t)(elem_count * elem_size));
  if (tmp == NULL) {
    futhark_panic(1, "binary-input: Failed to allocate array of size %i.\n",
          elem_count * elem_size);
  }
  *data = tmp;

  int64_t num_elems_read = (int64_t)fread(*data, (size_t)elem_size, (size_t)elem_count, f);
  if (num_elems_read != elem_count) {
    futhark_panic(1, "binary-input: tried to read %i elements of an array, but only got %i elements.\n",
          elem_count, num_elems_read);
  }

  // If we're on big endian platform we must change all multibyte elements
  // from using little endian to big endian
  if (IS_BIG_ENDIAN && elem_size != 1) {
    flip_bytes((size_t)elem_size, (unsigned char*) *data);
  }

  return 0;
}

static int read_array(FILE *f, const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  if (!read_is_binary(f)) {
    return read_str_array(f, expected_type->size, (str_reader)expected_type->read_str, expected_type->type_name, data, shape, dims);
  } else {
    return read_bin_array(f, expected_type, data, shape, dims);
  }
}

static int end_of_input(FILE *f) {
  skipspaces(f);
  char token[2];
  next_token(f, token, sizeof(token));
  if (strcmp(token, "") == 0) {
    return 0;
  } else {
    return 1;
  }
}

static int write_str_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  if (rank==0) {
    elem_type->write_str(out, (const void*)data);
  } else {
    int64_t len = (int64_t)shape[0];
    int64_t slice_size = 1;

    int64_t elem_size = elem_type->size;
    for (int8_t i = 1; i < rank; i++) {
      slice_size *= shape[i];
    }

    if (len*slice_size == 0) {
      fprintf(out, "empty(");
      for (int64_t i = 0; i < rank; i++) {
        fprintf(out, "[%"PRIi64"]", shape[i]);
      }
      fprintf(out, "%s", elem_type->type_name);
      fprintf(out, ")");
    } else if (rank==1) {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        elem_type->write_str(out, (const void*) (data + i * elem_size));
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    } else {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        write_str_array(out, elem_type, data + i * slice_size * elem_size, shape+1, rank-1);
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    }
  }
  return 0;
}

static int write_bin_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  int64_t num_elems = 1;
  for (int64_t i = 0; i < rank; i++) {
    num_elems *= shape[i];
  }

  fputc('b', out);
  fputc((char)BINARY_FORMAT_VERSION, out);
  fwrite(&rank, sizeof(int8_t), 1, out);
  fwrite(elem_type->binname, 4, 1, out);
  if (shape != NULL) {
    fwrite(shape, sizeof(int64_t), (size_t)rank, out);
  }

  if (IS_BIG_ENDIAN) {
    for (int64_t i = 0; i < num_elems; i++) {
      const unsigned char *elem = data+i*elem_type->size;
      for (int64_t j = 0; j < elem_type->size; j++) {
        fwrite(&elem[elem_type->size-j], 1, 1, out);
      }
    }
  } else {
    fwrite(data, (size_t)elem_type->size, (size_t)num_elems, out);
  }

  return 0;
}

static int write_array(FILE *out, int write_binary,
                       const struct primtype_info_t *elem_type,
                       const void *data,
                       const int64_t *shape,
                       const int8_t rank) {
  if (write_binary) {
    return write_bin_array(out, elem_type, data, shape, rank);
  } else {
    return write_str_array(out, elem_type, data, shape, rank);
  }
}

static int read_scalar(FILE *f,
                       const struct primtype_info_t *expected_type, void *dest) {
  if (!read_is_binary(f)) {
    char buf[100];
    next_token(f, buf, sizeof(buf));
    return expected_type->read_str(buf, dest);
  } else {
    read_bin_ensure_scalar(f, expected_type);
    size_t elem_size = (size_t)expected_type->size;
    size_t num_elems_read = fread(dest, elem_size, 1, f);
    if (IS_BIG_ENDIAN) {
      flip_bytes(elem_size, (unsigned char*) dest);
    }
    return num_elems_read == 1 ? 0 : 1;
  }
}

static int write_scalar(FILE *out, int write_binary, const struct primtype_info_t *type, void *src) {
  if (write_binary) {
    return write_bin_array(out, type, src, NULL, 0);
  } else {
    return type->write_str(out, src);
  }
}

// End of values.h.

// Start of server.h.

// Forward declarations of things that we technically don't know until
// the application header file is included, but which we need.
struct futhark_context_config;
struct futhark_context;
char *futhark_context_get_error(struct futhark_context *ctx);
int futhark_context_sync(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value);
int futhark_get_tuning_param_count(void);
const char* futhark_get_tuning_param_name(int i);
const char* futhark_get_tuning_param_class(int i);

typedef int (*restore_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef void (*store_fn)(const void*, FILE *, struct futhark_context*, void*);
typedef int (*free_fn)(const void*, struct futhark_context*, void*);
typedef int (*project_fn)(struct futhark_context*, void*, const void*);
typedef int (*new_fn)(struct futhark_context*, void**, const void*[]);

struct field {
  const char *name;
  const struct type *type;
  project_fn project;
};

struct record {
  int num_fields;
  const struct field* fields;
  new_fn new;
};

struct type {
  const char *name;
  restore_fn restore;
  store_fn store;
  free_fn free;
  const void *aux;
  const struct record *record;
};

int free_scalar(const void *aux, struct futhark_context *ctx, void *p) {
  (void)aux;
  (void)ctx;
  (void)p;
  // Nothing to do.
  return 0;
}

#define DEF_SCALAR_TYPE(T)                                      \
  int restore_##T(const void *aux, FILE *f,                     \
                  struct futhark_context *ctx, void *p) {       \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    return read_scalar(f, &T##_info, p);                        \
  }                                                             \
                                                                \
  void store_##T(const void *aux, FILE *f,                      \
                 struct futhark_context *ctx, void *p) {        \
    (void)aux;                                                  \
    (void)ctx;                                                  \
    write_scalar(f, 1, &T##_info, p);                           \
  }                                                             \
                                                                \
  struct type type_##T =                                        \
    { .name = #T,                                               \
      .restore = restore_##T,                                   \
      .store = store_##T,                                       \
      .free = free_scalar                                       \
    }                                                           \

DEF_SCALAR_TYPE(i8);
DEF_SCALAR_TYPE(i16);
DEF_SCALAR_TYPE(i32);
DEF_SCALAR_TYPE(i64);
DEF_SCALAR_TYPE(u8);
DEF_SCALAR_TYPE(u16);
DEF_SCALAR_TYPE(u32);
DEF_SCALAR_TYPE(u64);
DEF_SCALAR_TYPE(f16);
DEF_SCALAR_TYPE(f32);
DEF_SCALAR_TYPE(f64);
DEF_SCALAR_TYPE(bool);

struct value {
  const struct type *type;
  union {
    void *v_ptr;
    int8_t  v_i8;
    int16_t v_i16;
    int32_t v_i32;
    int64_t v_i64;

    uint8_t  v_u8;
    uint16_t v_u16;
    uint32_t v_u32;
    uint64_t v_u64;

    uint16_t v_f16;
    float v_f32;
    double v_f64;

    bool v_bool;
  } value;
};

void* value_ptr(struct value *v) {
  if (v->type == &type_i8) {
    return &v->value.v_i8;
  }
  if (v->type == &type_i16) {
    return &v->value.v_i16;
  }
  if (v->type == &type_i32) {
    return &v->value.v_i32;
  }
  if (v->type == &type_i64) {
    return &v->value.v_i64;
  }
  if (v->type == &type_u8) {
    return &v->value.v_u8;
  }
  if (v->type == &type_u16) {
    return &v->value.v_u16;
  }
  if (v->type == &type_u32) {
    return &v->value.v_u32;
  }
  if (v->type == &type_u64) {
    return &v->value.v_u64;
  }
  if (v->type == &type_f16) {
    return &v->value.v_f16;
  }
  if (v->type == &type_f32) {
    return &v->value.v_f32;
  }
  if (v->type == &type_f64) {
    return &v->value.v_f64;
  }
  if (v->type == &type_bool) {
    return &v->value.v_bool;
  }
  return &v->value.v_ptr;
}

struct variable {
  // NULL name indicates free slot.  Name is owned by this struct.
  char *name;
  struct value value;
};

typedef int (*entry_point_fn)(struct futhark_context*, void**, void**);

struct entry_point {
  const char *name;
  entry_point_fn f;
  const char** tuning_params;
  const struct type **out_types;
  bool *out_unique;
  const struct type **in_types;
  bool *in_unique;
};

int entry_num_ins(struct entry_point *e) {
  int count = 0;
  while (e->in_types[count]) {
    count++;
  }
  return count;
}

int entry_num_outs(struct entry_point *e) {
  int count = 0;
  while (e->out_types[count]) {
    count++;
  }
  return count;
}

struct futhark_prog {
  // Last entry point identified by NULL name.
  struct entry_point *entry_points;
  // Last type identified by NULL name.
  const struct type **types;
};

struct server_state {
  struct futhark_prog prog;
  struct futhark_context_config *cfg;
  struct futhark_context *ctx;
  int variables_capacity;
  struct variable *variables;
};

struct variable* get_variable(struct server_state *s,
                              const char *name) {
  for (int i = 0; i < s->variables_capacity; i++) {
    if (s->variables[i].name != NULL &&
        strcmp(s->variables[i].name, name) == 0) {
      return &s->variables[i];
    }
  }

  return NULL;
}

struct variable* create_variable(struct server_state *s,
                                 const char *name,
                                 const struct type *type) {
  int found = -1;
  for (int i = 0; i < s->variables_capacity; i++) {
    if (found == -1 && s->variables[i].name == NULL) {
      found = i;
    } else if (s->variables[i].name != NULL &&
               strcmp(s->variables[i].name, name) == 0) {
      return NULL;
    }
  }

  if (found != -1) {
    // Found a free spot.
    s->variables[found].name = strdup(name);
    s->variables[found].value.type = type;
    return &s->variables[found];
  }

  // Need to grow the buffer.
  found = s->variables_capacity;
  s->variables_capacity *= 2;
  s->variables = realloc(s->variables,
                         s->variables_capacity * sizeof(struct variable));

  s->variables[found].name = strdup(name);
  s->variables[found].value.type = type;

  for (int i = found+1; i < s->variables_capacity; i++) {
    s->variables[i].name = NULL;
  }

  return &s->variables[found];
}

void drop_variable(struct variable *v) {
  free(v->name);
  v->name = NULL;
}

int arg_exists(const char *args[], int i) {
  return args[i] != NULL;
}

const char* get_arg(const char *args[], int i) {
  if (!arg_exists(args, i)) {
    futhark_panic(1, "Insufficient command args.\n");
  }
  return args[i];
}

const struct type* get_type(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.types[i]; i++) {
    if (strcmp(s->prog.types[i]->name, name) == 0) {
      return s->prog.types[i];
    }
  }

  futhark_panic(1, "Unknown type %s\n", name);
  return NULL;
}

struct entry_point* get_entry_point(struct server_state *s, const char *name) {
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    if (strcmp(s->prog.entry_points[i].name, name) == 0) {
      return &s->prog.entry_points[i];
    }
  }

  return NULL;
}

// Print the command-done marker, indicating that we are ready for
// more input.
void ok(void) {
  printf("%%%%%% OK\n");
  fflush(stdout);
}

// Print the failure marker.  Output is now an error message until the
// next ok().
void failure(void) {
  printf("%%%%%% FAILURE\n");
}

void error_check(struct server_state *s, int err) {
  if (err != 0) {
    failure();
    char *error = futhark_context_get_error(s->ctx);
    if (error != NULL) {
      puts(error);
    }
    free(error);
  }
}

void cmd_call(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);

  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  int num_ins = entry_num_ins(e);
  // +1 to avoid zero-size arrays, which is UB.
  void* outs[num_outs+1];
  void* ins[num_ins+1];

  for (int i = 0; i < num_ins; i++) {
    const char *in_name = get_arg(args, 1+num_outs+i);
    struct variable *v = get_variable(s, in_name);
    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", in_name);
      return;
    }
    if (v->value.type != e->in_types[i]) {
      failure();
      printf("Wrong input type.  Expected %s, got %s.\n",
             e->in_types[i]->name, v->value.type->name);
      return;
    }
    ins[i] = value_ptr(&v->value);
  }

  for (int i = 0; i < num_outs; i++) {
    const char *out_name = get_arg(args, 1+i);
    struct variable *v = create_variable(s, out_name, e->out_types[i]);
    if (v == NULL) {
      failure();
      printf("Variable already exists: %s\n", out_name);
      return;
    }
    outs[i] = value_ptr(&v->value);
  }

  int64_t t_start = get_wall_time();
  int err = e->f(s->ctx, outs, ins);
  err |= futhark_context_sync(s->ctx);
  int64_t t_end = get_wall_time();
  long long int elapsed_usec = t_end - t_start;
  printf("runtime: %lld\n", elapsed_usec);

  error_check(s, err);
  if (err != 0) {
    // Need to uncreate the output variables, which would otherwise be left
    // in an uninitialised state.
    for (int i = 0; i < num_outs; i++) {
      const char *out_name = get_arg(args, 1+i);
      struct variable *v = get_variable(s, out_name);
      if (v) {
        drop_variable(v);
      }
    }
  }
}

void cmd_restore(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "rb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
    return;
  }

  int bad = 0;
  int values = 0;
  for (int i = 1; arg_exists(args, i); i+=2, values++) {
    const char *vname = get_arg(args, i);
    const char *type = get_arg(args, i+1);

    const struct type *t = get_type(s, type);
    struct variable *v = create_variable(s, vname, t);

    if (v == NULL) {
      bad = 1;
      failure();
      printf("Variable already exists: %s\n", vname);
      break;
    }

    errno = 0;
    if (t->restore(t->aux, f, s->ctx, value_ptr(&v->value)) != 0) {
      bad = 1;
      failure();
      printf("Failed to restore variable %s.\n"
             "Possibly malformed data in %s (errno: %s)\n",
             vname, fname, strerror(errno));
      drop_variable(v);
      break;
    }
  }

  if (!bad && end_of_input(f) != 0) {
    failure();
    printf("Expected EOF after reading %d values from %s\n",
           values, fname);
  }

  fclose(f);

  if (!bad) {
    int err = futhark_context_sync(s->ctx);
    error_check(s, err);
  }
}

void cmd_store(struct server_state *s, const char *args[]) {
  const char *fname = get_arg(args, 0);

  FILE *f = fopen(fname, "wb");
  if (f == NULL) {
    failure();
    printf("Failed to open %s: %s\n", fname, strerror(errno));
  } else {
    for (int i = 1; arg_exists(args, i); i++) {
      const char *vname = get_arg(args, i);
      struct variable *v = get_variable(s, vname);

      if (v == NULL) {
        failure();
        printf("Unknown variable: %s\n", vname);
        return;
      }

      const struct type *t = v->value.type;
      t->store(t->aux, f, s->ctx, value_ptr(&v->value));
    }
    fclose(f);
  }
}

void cmd_free(struct server_state *s, const char *args[]) {
  for (int i = 0; arg_exists(args, i); i++) {
    const char *name = get_arg(args, i);
    struct variable *v = get_variable(s, name);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", name);
      return;
    }

    const struct type *t = v->value.type;

    int err = t->free(t->aux, s->ctx, value_ptr(&v->value));
    error_check(s, err);
    drop_variable(v);
  }
}

void cmd_rename(struct server_state *s, const char *args[]) {
  const char *oldname = get_arg(args, 0);
  const char *newname = get_arg(args, 1);
  struct variable *old = get_variable(s, oldname);
  struct variable *new = get_variable(s, newname);

  if (old == NULL) {
    failure();
    printf("Unknown variable: %s\n", oldname);
    return;
  }

  if (new != NULL) {
    failure();
    printf("Variable already exists: %s\n", newname);
    return;
  }

  free(old->name);
  old->name = strdup(newname);
}

void cmd_inputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_ins = entry_num_ins(e);
  for (int i = 0; i < num_ins; i++) {
    if (e->in_unique[i]) {
      putchar('*');
    }
    puts(e->in_types[i]->name);
  }
}

void cmd_outputs(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  int num_outs = entry_num_outs(e);
  for (int i = 0; i < num_outs; i++) {
    if (e->out_unique[i]) {
      putchar('*');
    }
    puts(e->out_types[i]->name);
  }
}

void cmd_clear(struct server_state *s, const char *args[]) {
  (void)args;
  int err = 0;
  for (int i = 0; i < s->variables_capacity; i++) {
    struct variable *v = &s->variables[i];
    if (v->name != NULL) {
      err |= v->value.type->free(v->value.type->aux, s->ctx, value_ptr(&v->value));
      drop_variable(v);
    }
  }
  err |= futhark_context_clear_caches(s->ctx);
  error_check(s, err);
}

void cmd_pause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_pause_profiling(s->ctx);
}

void cmd_unpause_profiling(struct server_state *s, const char *args[]) {
  (void)args;
  futhark_context_unpause_profiling(s->ctx);
}

void cmd_report(struct server_state *s, const char *args[]) {
  (void)args;
  char *report = futhark_context_report(s->ctx);
  if (report) {
    puts(report);
  } else {
    failure();
    report = futhark_context_get_error(s->ctx);
    if (report) {
      puts(report);
    } else {
      puts("Failed to produce profiling report.\n");
    }
  }
  free(report);
}

void cmd_set_tuning_param(struct server_state *s, const char *args[]) {
  const char *param = get_arg(args, 0);
  const char *val_s = get_arg(args, 1);
  size_t val = atol(val_s);
  int err = futhark_context_config_set_tuning_param(s->cfg, param, val);

  error_check(s, err);

  if (err != 0) {
    printf("Failed to set tuning parameter %s to %ld\n", param, (long)val);
  }
}

void cmd_tuning_params(struct server_state *s, const char *args[]) {
  const char *name = get_arg(args, 0);
  struct entry_point *e = get_entry_point(s, name);

  if (e == NULL) {
    failure();
    printf("Unknown entry point: %s\n", name);
    return;
  }

  const char **params = e->tuning_params;
  for (int i = 0; params[i] != NULL; i++) {
    printf("%s\n", params[i]);
  }
}

void cmd_tuning_param_class(struct server_state *s, const char *args[]) {
  (void)s;
  const char *param = get_arg(args, 0);

  int n = futhark_get_tuning_param_count();

  for (int i = 0; i < n; i++) {
    if (strcmp(futhark_get_tuning_param_name(i), param) == 0) {
      printf("%s\n", futhark_get_tuning_param_class(i));
      return;
    }
  }

  failure();
  printf("Unknown tuning parameter: %s\n", param);
}

void cmd_fields(struct server_state *s, const char *args[]) {
  const char *type = get_arg(args, 0);
  const struct type *t = get_type(s, type);
  const struct record *r = t->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  for (int i = 0; i < r->num_fields; i++) {
    const struct field f = r->fields[i];
    printf("%s %s\n", f.name, f.type->name);
  }
}

void cmd_project(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *from_name = get_arg(args, 1);
  const char *field_name = get_arg(args, 2);

  struct variable *from = get_variable(s, from_name);

  if (from == NULL) {
    failure();
    printf("Unknown variable: %s\n", from_name);
    return;
  }

  const struct type *from_type = from->value.type;
  const struct record *r = from_type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  const struct field *field = NULL;
  for (int i = 0; i < r->num_fields; i++) {
    if (strcmp(r->fields[i].name, field_name) == 0) {
      field = &r->fields[i];
      break;
    }
  }

  if (field == NULL) {
    failure();
    printf("No such field\n");
  }

  struct variable *to = create_variable(s, to_name, field->type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  field->project(s->ctx, value_ptr(&to->value), from->value.value.v_ptr);
}

void cmd_new(struct server_state *s, const char *args[]) {
  const char *to_name = get_arg(args, 0);
  const char *type_name = get_arg(args, 1);
  const struct type *type = get_type(s, type_name);
  struct variable *to = create_variable(s, to_name, type);

  if (to == NULL) {
    failure();
    printf("Variable already exists: %s\n", to_name);
    return;
  }

  const struct record* r = type->record;

  if (r == NULL) {
    failure();
    printf("Not a record type\n");
    return;
  }

  int num_args = 0;
  for (int i = 2; arg_exists(args, i); i++) {
    num_args++;
  }

  if (num_args != r->num_fields) {
    failure();
    printf("%d fields expected but %d values provided.\n", num_args, r->num_fields);
    return;
  }

  const void** value_ptrs = alloca(num_args * sizeof(void*));

  for (int i = 0; i < num_args; i++) {
    struct variable* v = get_variable(s, args[2+i]);

    if (v == NULL) {
      failure();
      printf("Unknown variable: %s\n", args[2+i]);
      return;
    }

    if (strcmp(v->value.type->name, r->fields[i].type->name) != 0) {
      failure();
      printf("Field %s mismatch: expected type %s, got %s\n",
             r->fields[i].name, r->fields[i].type->name, v->value.type->name);
      return;
    }

    value_ptrs[i] = value_ptr(&v->value);
  }

  r->new(s->ctx, value_ptr(&to->value), value_ptrs);
}

void cmd_entry_points(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.entry_points[i].name; i++) {
    puts(s->prog.entry_points[i].name);
  }
}

void cmd_types(struct server_state *s, const char *args[]) {
  (void)args;
  for (int i = 0; s->prog.types[i] != NULL; i++) {
    puts(s->prog.types[i]->name);
  }
}

char *next_word(char **line) {
  char *p = *line;

  while (isspace(*p)) {
    p++;
  }

  if (*p == 0) {
    return NULL;
  }

  if (*p == '"') {
    char *save = p+1;
    // Skip ahead till closing quote.
    p++;

    while (*p && *p != '"') {
      p++;
    }

    if (*p == '"') {
      *p = 0;
      *line = p+1;
      return save;
    } else {
      return NULL;
    }
  } else {
    char *save = p;
    // Skip ahead till next whitespace.

    while (*p && !isspace(*p)) {
      p++;
    }

    if (*p) {
      *p = 0;
      *line = p+1;
    } else {
      *line = p;
    }
    return save;
  }
}

void process_line(struct server_state *s, char *line) {
  int max_num_tokens = 1000;
  const char* tokens[max_num_tokens];
  int num_tokens = 0;

  while ((tokens[num_tokens] = next_word(&line)) != NULL) {
    num_tokens++;
    if (num_tokens == max_num_tokens) {
      futhark_panic(1, "Line too long.\n");
    }
  }

  const char *command = tokens[0];

  if (command == NULL) {
    failure();
    printf("Empty line\n");
  } else if (strcmp(command, "call") == 0) {
    cmd_call(s, tokens+1);
  } else if (strcmp(command, "restore") == 0) {
    cmd_restore(s, tokens+1);
  } else if (strcmp(command, "store") == 0) {
    cmd_store(s, tokens+1);
  } else if (strcmp(command, "free") == 0) {
    cmd_free(s, tokens+1);
  } else if (strcmp(command, "rename") == 0) {
    cmd_rename(s, tokens+1);
  } else if (strcmp(command, "inputs") == 0) {
    cmd_inputs(s, tokens+1);
  } else if (strcmp(command, "outputs") == 0) {
    cmd_outputs(s, tokens+1);
  } else if (strcmp(command, "clear") == 0) {
    cmd_clear(s, tokens+1);
  } else if (strcmp(command, "pause_profiling") == 0) {
    cmd_pause_profiling(s, tokens+1);
  } else if (strcmp(command, "unpause_profiling") == 0) {
    cmd_unpause_profiling(s, tokens+1);
  } else if (strcmp(command, "report") == 0) {
    cmd_report(s, tokens+1);
  } else if (strcmp(command, "set_tuning_param") == 0) {
    cmd_set_tuning_param(s, tokens+1);
  } else if (strcmp(command, "tuning_params") == 0) {
    cmd_tuning_params(s, tokens+1);
  } else if (strcmp(command, "tuning_param_class") == 0) {
    cmd_tuning_param_class(s, tokens+1);
  } else if (strcmp(command, "fields") == 0) {
    cmd_fields(s, tokens+1);
  } else if (strcmp(command, "new") == 0) {
    cmd_new(s, tokens+1);
  } else if (strcmp(command, "project") == 0) {
    cmd_project(s, tokens+1);
  } else if (strcmp(command, "entry_points") == 0) {
    cmd_entry_points(s, tokens+1);
  } else if (strcmp(command, "types") == 0) {
    cmd_types(s, tokens+1);
  } else {
    futhark_panic(1, "Unknown command: %s\n", command);
  }
}

void run_server(struct futhark_prog *prog,
                struct futhark_context_config *cfg,
                struct futhark_context *ctx) {
  char *line = NULL;
  size_t buflen = 0;
  ssize_t linelen;

  struct server_state s = {
    .cfg = cfg,
    .ctx = ctx,
    .variables_capacity = 100,
    .prog = *prog
  };

  s.variables = malloc(s.variables_capacity * sizeof(struct variable));

  for (int i = 0; i < s.variables_capacity; i++) {
    s.variables[i].name = NULL;
  }

  ok();
  while ((linelen = getline(&line, &buflen, stdin)) > 0) {
    process_line(&s, line);
    ok();
  }

  free(s.variables);
  free(line);
}

// The aux struct lets us write generic method implementations without
// code duplication.

typedef void* (*array_new_fn)(struct futhark_context *, const void*, const int64_t*);
typedef const int64_t* (*array_shape_fn)(struct futhark_context*, void*);
typedef int (*array_values_fn)(struct futhark_context*, void*, void*);
typedef int (*array_free_fn)(struct futhark_context*, void*);

struct array_aux {
  int rank;
  const struct primtype_info_t* info;
  const char *name;
  array_new_fn new;
  array_shape_fn shape;
  array_values_fn values;
  array_free_fn free;
};

int restore_array(const struct array_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *data = NULL;
  int64_t shape[aux->rank];
  if (read_array(f, aux->info, &data, shape, aux->rank) != 0) {
    return 1;
  }

  void *arr = aux->new(ctx, data, shape);
  if (arr == NULL) {
    return 1;
  }
  int err = futhark_context_sync(ctx);
  *(void**)p = arr;
  free(data);
  return err;
}

void store_array(const struct array_aux *aux, FILE *f,
                 struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  const int64_t *shape = aux->shape(ctx, arr);
  int64_t size = sizeof(aux->info->size);
  for (int i = 0; i < aux->rank; i++) {
    size *= shape[i];
  }
  int32_t *data = malloc(size);
  assert(aux->values(ctx, arr, data) == 0);
  assert(futhark_context_sync(ctx) == 0);
  assert(write_array(f, 1, aux->info, data, shape, aux->rank) == 0);
  free(data);
}

int free_array(const struct array_aux *aux,
               struct futhark_context *ctx, void *p) {
  void *arr = *(void**)p;
  return aux->free(ctx, arr);
}

typedef void* (*opaque_restore_fn)(struct futhark_context*, void*);
typedef int (*opaque_store_fn)(struct futhark_context*, const void*, void **, size_t *);
typedef int (*opaque_free_fn)(struct futhark_context*, void*);

struct opaque_aux {
  opaque_restore_fn restore;
  opaque_store_fn store;
  opaque_free_fn free;
};

int restore_opaque(const struct opaque_aux *aux, FILE *f,
                   struct futhark_context *ctx, void *p) {
  // We have a problem: we need to load data from 'f', since the
  // restore function takes a pointer, but we don't know how much we
  // need (and cannot possibly).  So we do something hacky: we read
  // *all* of the file, pass all of the data to the restore function
  // (which doesn't care if there's extra at the end), then we compute
  // how much space the the object actually takes in serialised form
  // and rewind the file to that position.  The only downside is more IO.
  size_t start = ftell(f);
  size_t size;
  char *bytes = fslurp_file(f, &size);
  void *obj = aux->restore(ctx, bytes);
  free(bytes);
  if (obj != NULL) {
    *(void**)p = obj;
    size_t obj_size;
    (void)aux->store(ctx, obj, NULL, &obj_size);
    fseek(f, start+obj_size, SEEK_SET);
    return 0;
  } else {
    fseek(f, start, SEEK_SET);
    return 1;
  }
}

void store_opaque(const struct opaque_aux *aux, FILE *f,
                  struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  size_t obj_size;
  void *data = NULL;
  (void)aux->store(ctx, obj, &data, &obj_size);
  assert(futhark_context_sync(ctx) == 0);
  fwrite(data, sizeof(char), obj_size, f);
  free(data);
}

int free_opaque(const struct opaque_aux *aux,
                struct futhark_context *ctx, void *p) {
  void *obj = *(void**)p;
  return aux->free(ctx, obj);
}

// End of server.h.

// Start of tuning.h.


int is_blank_line_or_comment(const char *s) {
  size_t i = strspn(s, " \t\n");
  return s[i] == '\0' || // Line is blank.
         strncmp(s + i, "--", 2) == 0; // Line is comment.
}

static char* load_tuning_file(const char *fname,
                              void *cfg,
                              int (*set_tuning_param)(void*, const char*, size_t)) {
  const int max_line_len = 1024;
  char* line = (char*) malloc(max_line_len);

  FILE *f = fopen(fname, "r");

  if (f == NULL) {
    snprintf(line, max_line_len, "Cannot open file: %s", strerror(errno));
    return line;
  }

  int lineno = 0;
  while (fgets(line, max_line_len, f) != NULL) {
    lineno++;
    if (is_blank_line_or_comment(line)) {
      continue;
    }
    char *eql = strstr(line, "=");
    if (eql) {
      *eql = 0;
      char *endptr;
      int value = strtol(eql+1, &endptr, 10);
      if (*endptr && *endptr != '\n') {
        snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
                 lineno);
        return line;
      }
      if (set_tuning_param(cfg, line, (size_t)value) != 0) {
        char* err = (char*) malloc(max_line_len + 50);
        snprintf(err, max_line_len + 50, "Unknown name '%s' on line %d.", line, lineno);
        free(line);
        return err;
      }
    } else {
      snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
               lineno);
      return line;
    }
  }

  free(line);

  return NULL;
}

// End of tuning.h.

const struct type type_ZMZNf32;
const struct type type_ZMZNf64;
const struct type type_ZMZNi32;
void *futhark_new_f32_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_f32_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNf32_aux = {.name ="[]f32", .rank =1, .info =&f32_info, .new =(array_new_fn) futhark_new_f32_1d_wrap, .free =(array_free_fn) futhark_free_f32_1d, .shape =(array_shape_fn) futhark_shape_f32_1d, .values =(array_values_fn) futhark_values_f32_1d};
const struct type type_ZMZNf32 = {.name ="[]f32", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNf32_aux};
void *futhark_new_f64_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_f64_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNf64_aux = {.name ="[]f64", .rank =1, .info =&f64_info, .new =(array_new_fn) futhark_new_f64_1d_wrap, .free =(array_free_fn) futhark_free_f64_1d, .shape =(array_shape_fn) futhark_shape_f64_1d, .values =(array_values_fn) futhark_values_f64_1d};
const struct type type_ZMZNf64 = {.name ="[]f64", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNf64_aux};
void *futhark_new_i32_1d_wrap(struct futhark_context *ctx, const void *p, const int64_t *shape)
{
    return futhark_new_i32_1d(ctx, p, shape[0]);
}
const struct array_aux type_ZMZNi32_aux = {.name ="[]i32", .rank =1, .info =&i32_info, .new =(array_new_fn) futhark_new_i32_1d_wrap, .free =(array_free_fn) futhark_free_i32_1d, .shape =(array_shape_fn) futhark_shape_i32_1d, .values =(array_values_fn) futhark_values_i32_1d};
const struct type type_ZMZNi32 = {.name ="[]i32", .restore =(restore_fn) restore_array, .store =(store_fn) store_array, .free =(free_fn) free_array, .aux =&type_ZMZNi32_aux};
const struct type *human_genericf32_out_types[] = {&type_ZMZNf32, NULL};
bool human_genericf32_out_unique[] = {true};
const struct type *human_genericf32_in_types[] = {&type_ZMZNi32, &type_ZMZNi32, &type_ZMZNi32, &type_ZMZNf32, NULL};
bool human_genericf32_in_unique[] = {false, false, false, false};
const char *human_genericf32_tuning_params[] = {"builtin#replicate_bool.tblock_size_29941", "builtin#replicate_i32.tblock_size_29834", "builtin#replicate_i8.tblock_size_29808", "human_genericf32.hist_L2_30312", "human_genericf32.hist_L2_30750", "human_genericf32.hist_L_30250", "human_genericf32.hist_L_30688", "human_genericf32.seghist_num_tblocks_28296", "human_genericf32.seghist_num_tblocks_28587", "human_genericf32.seghist_tblock_size_28294", "human_genericf32.seghist_tblock_size_28585", "human_genericf32.segmap_num_tblocks_28232", "human_genericf32.segmap_num_tblocks_28405", "human_genericf32.segmap_num_tblocks_28698", "human_genericf32.segmap_tblock_size_28230", "human_genericf32.segmap_tblock_size_28254", "human_genericf32.segmap_tblock_size_28324", "human_genericf32.segmap_tblock_size_28403", "human_genericf32.segmap_tblock_size_28419", "human_genericf32.segmap_tblock_size_28615", "human_genericf32.segmap_tblock_size_28696", "human_genericf32.segscan_num_tblocks_28222", "human_genericf32.segscan_num_tblocks_28238", "human_genericf32.segscan_num_tblocks_28246", "human_genericf32.segscan_num_tblocks_28395", "human_genericf32.segscan_num_tblocks_28411", "human_genericf32.segscan_num_tblocks_28688", "human_genericf32.segscan_tblock_size_28220", "human_genericf32.segscan_tblock_size_28236", "human_genericf32.segscan_tblock_size_28244", "human_genericf32.segscan_tblock_size_28393", "human_genericf32.segscan_tblock_size_28409", "human_genericf32.segscan_tblock_size_28686", NULL};
int call_human_genericf32(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f32_1d * *out0 = outs[0];
    struct futhark_i32_1d * in0 = *(struct futhark_i32_1d * *) ins[0];
    struct futhark_i32_1d * in1 = *(struct futhark_i32_1d * *) ins[1];
    struct futhark_i32_1d * in2 = *(struct futhark_i32_1d * *) ins[2];
    struct futhark_f32_1d * in3 = *(struct futhark_f32_1d * *) ins[3];
    
    return futhark_entry_human_genericf32(ctx, out0, in0, in1, in2, in3);
}
const struct type *human_genericf64_out_types[] = {&type_ZMZNf64, NULL};
bool human_genericf64_out_unique[] = {true};
const struct type *human_genericf64_in_types[] = {&type_ZMZNi32, &type_ZMZNi32, &type_ZMZNi32, &type_ZMZNf64, NULL};
bool human_genericf64_in_unique[] = {false, false, false, false};
const char *human_genericf64_tuning_params[] = {"builtin#replicate_bool.tblock_size_29941", "builtin#replicate_i32.tblock_size_29834", "builtin#replicate_i8.tblock_size_29808", "human_genericf64.hist_L2_30312", "human_genericf64.hist_L2_30750", "human_genericf64.hist_L_30250", "human_genericf64.hist_L_30688", "human_genericf64.seghist_num_tblocks_28782", "human_genericf64.seghist_num_tblocks_29073", "human_genericf64.seghist_tblock_size_28780", "human_genericf64.seghist_tblock_size_29071", "human_genericf64.segmap_num_tblocks_28714", "human_genericf64.segmap_num_tblocks_28891", "human_genericf64.segmap_num_tblocks_29184", "human_genericf64.segmap_tblock_size_28712", "human_genericf64.segmap_tblock_size_28736", "human_genericf64.segmap_tblock_size_28810", "human_genericf64.segmap_tblock_size_28889", "human_genericf64.segmap_tblock_size_28905", "human_genericf64.segmap_tblock_size_29101", "human_genericf64.segmap_tblock_size_29182", "human_genericf64.segscan_num_tblocks_28704", "human_genericf64.segscan_num_tblocks_28720", "human_genericf64.segscan_num_tblocks_28728", "human_genericf64.segscan_num_tblocks_28881", "human_genericf64.segscan_num_tblocks_28897", "human_genericf64.segscan_num_tblocks_29174", "human_genericf64.segscan_tblock_size_28702", "human_genericf64.segscan_tblock_size_28718", "human_genericf64.segscan_tblock_size_28726", "human_genericf64.segscan_tblock_size_28879", "human_genericf64.segscan_tblock_size_28895", "human_genericf64.segscan_tblock_size_29172", NULL};
int call_human_genericf64(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_f64_1d * *out0 = outs[0];
    struct futhark_i32_1d * in0 = *(struct futhark_i32_1d * *) ins[0];
    struct futhark_i32_1d * in1 = *(struct futhark_i32_1d * *) ins[1];
    struct futhark_i32_1d * in2 = *(struct futhark_i32_1d * *) ins[2];
    struct futhark_f64_1d * in3 = *(struct futhark_f64_1d * *) ins[3];
    
    return futhark_entry_human_genericf64(ctx, out0, in0, in1, in2, in3);
}
const struct type *human_generici32_out_types[] = {&type_ZMZNi32, NULL};
bool human_generici32_out_unique[] = {true};
const struct type *human_generici32_in_types[] = {&type_ZMZNi32, &type_ZMZNi32, &type_ZMZNi32, &type_ZMZNi32, NULL};
bool human_generici32_in_unique[] = {false, false, false, false};
const char *human_generici32_tuning_params[] = {"builtin#replicate_bool.tblock_size_29941", "builtin#replicate_i32.tblock_size_29834", "builtin#replicate_i8.tblock_size_29808", "human_generici32.hist_L2_30312", "human_generici32.hist_L2_30750", "human_generici32.hist_L_30250", "human_generici32.hist_L_30688", "human_generici32.seghist_num_tblocks_29268", "human_generici32.seghist_num_tblocks_29559", "human_generici32.seghist_tblock_size_29266", "human_generici32.seghist_tblock_size_29557", "human_generici32.segmap_num_tblocks_29200", "human_generici32.segmap_num_tblocks_29377", "human_generici32.segmap_num_tblocks_29670", "human_generici32.segmap_tblock_size_29198", "human_generici32.segmap_tblock_size_29222", "human_generici32.segmap_tblock_size_29296", "human_generici32.segmap_tblock_size_29375", "human_generici32.segmap_tblock_size_29391", "human_generici32.segmap_tblock_size_29587", "human_generici32.segmap_tblock_size_29668", "human_generici32.segscan_num_tblocks_29190", "human_generici32.segscan_num_tblocks_29206", "human_generici32.segscan_num_tblocks_29214", "human_generici32.segscan_num_tblocks_29367", "human_generici32.segscan_num_tblocks_29383", "human_generici32.segscan_num_tblocks_29660", "human_generici32.segscan_tblock_size_29188", "human_generici32.segscan_tblock_size_29204", "human_generici32.segscan_tblock_size_29212", "human_generici32.segscan_tblock_size_29365", "human_generici32.segscan_tblock_size_29381", "human_generici32.segscan_tblock_size_29658", NULL};
int call_human_generici32(struct futhark_context *ctx, void **outs, void **ins)
{
    struct futhark_i32_1d * *out0 = outs[0];
    struct futhark_i32_1d * in0 = *(struct futhark_i32_1d * *) ins[0];
    struct futhark_i32_1d * in1 = *(struct futhark_i32_1d * *) ins[1];
    struct futhark_i32_1d * in2 = *(struct futhark_i32_1d * *) ins[2];
    struct futhark_i32_1d * in3 = *(struct futhark_i32_1d * *) ins[3];
    
    return futhark_entry_human_generici32(ctx, out0, in0, in1, in2, in3);
}
const struct type *types[] = {&type_i8, &type_i16, &type_i32, &type_i64, &type_u8, &type_u16, &type_u32, &type_u64, &type_f16, &type_f32, &type_f64, &type_bool, &type_ZMZNf32, &type_ZMZNf64, &type_ZMZNi32, NULL};
struct entry_point entry_points[] = {{.name ="human_genericf32", .f =call_human_genericf32, .tuning_params =human_genericf32_tuning_params, .in_types =human_genericf32_in_types, .out_types =human_genericf32_out_types, .in_unique =human_genericf32_in_unique, .out_unique =human_genericf32_out_unique}, {.name ="human_genericf64", .f =call_human_genericf64, .tuning_params =human_genericf64_tuning_params, .in_types =human_genericf64_in_types, .out_types =human_genericf64_out_types, .in_unique =human_genericf64_in_unique, .out_unique =human_genericf64_out_unique}, {.name ="human_generici32", .f =call_human_generici32, .tuning_params =human_generici32_tuning_params, .in_types =human_generici32_in_types, .out_types =human_generici32_out_types, .in_unique =human_generici32_in_unique, .out_unique =human_generici32_out_unique}, {.name =NULL}};
struct futhark_prog prog = {.types =types, .entry_points =entry_points};
int parse_options(struct futhark_context_config *cfg, int argc, char *const argv[])
{
    int ch;
    static struct option long_options[] = {{"debugging", no_argument, NULL, 1}, {"log", no_argument, NULL, 2}, {"profile", no_argument, NULL, 3}, {"help", no_argument, NULL, 4}, {"print-params", no_argument, NULL, 5}, {"param", required_argument, NULL, 6}, {"tuning", required_argument, NULL, 7}, {"cache-file", required_argument, NULL, 8}, {"device", required_argument, NULL, 9}, {"default-thread-block-size", required_argument, NULL, 10}, {"default-grid-size", required_argument, NULL, 11}, {"default-group-size", required_argument, NULL, 12}, {"default-num-groups", required_argument, NULL, 13}, {"default-tile-size", required_argument, NULL, 14}, {"default-reg-tile-size", required_argument, NULL, 15}, {"default-registers", required_argument, NULL, 16}, {"default-cache", required_argument, NULL, 17}, {"default-threshold", required_argument, NULL, 18}, {"unified-memory", required_argument, NULL, 19}, {"dump-cuda", required_argument, NULL, 20}, {"load-cuda", required_argument, NULL, 21}, {"dump-ptx", required_argument, NULL, 22}, {"load-ptx", required_argument, NULL, 23}, {"nvrtc-option", required_argument, NULL, 24}, {0, 0, 0, 0}};
    static char *option_descriptions = "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n";
    
    while ((ch = getopt_long(argc, argv, ":DLPhd:", long_options, NULL)) != -1) {
        if (ch == 1 || ch == 'D')
            futhark_context_config_set_debugging(cfg, 1);
        if (ch == 2 || ch == 'L')
            futhark_context_config_set_logging(cfg, 1);
        if (ch == 3 || ch == 'P')
            futhark_context_config_set_profiling(cfg, 1);
        if (ch == 4 || ch == 'h') {
            printf("Usage: %s [OPTIONS]...\nOptions:\n\n%s\nFor more information, consult the Futhark User's Guide or the man pages.\n", fut_progname, option_descriptions);
            exit(0);
        }
        if (ch == 5) {
            int n = futhark_get_tuning_param_count();
            
            for (int i = 0; i < n; i++)
                printf("%s (%s)\n", futhark_get_tuning_param_name(i), futhark_get_tuning_param_class(i));
            exit(0);
        }
        if (ch == 6) {
            char *name = optarg;
            char *equals = strstr(optarg, "=");
            char *value_str = equals != NULL ? equals + 1 : optarg;
            int value = atoi(value_str);
            
            if (equals != NULL) {
                *equals = 0;
                if (futhark_context_config_set_tuning_param(cfg, name, value) != 0)
                    futhark_panic(1, "Unknown size: %s\n", name);
            } else
                futhark_panic(1, "Invalid argument for size option: %s\n", optarg);
        }
        if (ch == 7) {
            char *ret = load_tuning_file(optarg, cfg, (int (*)(void *, const char *, size_t)) futhark_context_config_set_tuning_param);
            
            if (ret != NULL)
                futhark_panic(1, "When loading tuning file '%s': %s\n", optarg, ret);
        }
        if (ch == 8)
            futhark_context_config_set_cache_file(cfg, optarg);
        if (ch == 9 || ch == 'd')
            futhark_context_config_set_device(cfg, optarg);
        if (ch == 10)
            futhark_context_config_set_default_thread_block_size(cfg, atoi(optarg));
        if (ch == 11)
            futhark_context_config_set_default_grid_size(cfg, atoi(optarg));
        if (ch == 12)
            futhark_context_config_set_default_group_size(cfg, atoi(optarg));
        if (ch == 13)
            futhark_context_config_set_default_num_groups(cfg, atoi(optarg));
        if (ch == 14)
            futhark_context_config_set_default_tile_size(cfg, atoi(optarg));
        if (ch == 15)
            futhark_context_config_set_default_reg_tile_size(cfg, atoi(optarg));
        if (ch == 16)
            futhark_context_config_set_default_registers(cfg, atoi(optarg));
        if (ch == 17)
            futhark_context_config_set_default_cache(cfg, atoi(optarg));
        if (ch == 18)
            futhark_context_config_set_default_threshold(cfg, atoi(optarg));
        if (ch == 19)
            futhark_context_config_set_unified_memory(cfg, atoi(optarg));
        if (ch == 20) {
            const char *prog = futhark_context_config_get_program(cfg);
            
            if (dump_file(optarg, prog, strlen(prog)) != 0) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            exit(0);
        }
        if (ch == 21) {
            size_t n;
            const char *s = slurp_file(optarg, &n);
            
            if (s == NULL) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            futhark_context_config_set_program(cfg, s);
        }
        if (ch == 22) {
            futhark_context_config_dump_ptx_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 23)
            futhark_context_config_load_ptx_from(cfg, optarg);
        if (ch == 24)
            futhark_context_config_add_nvrtc_option(cfg, optarg);
        if (ch == ':')
            futhark_panic(-1, "Missing argument for option %s\n", argv[optind - 1]);
        if (ch == '?') {
            fprintf(stderr, "Usage: %s [OPTIONS]...\nOptions:\n\n%s\n", fut_progname, "  -D/--debugging                  Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                        Print various low-overhead logging information while running.\n  -P/--profile                    Enable the collection of profiling information.\n  -h/--help                       Print help information and exit.\n  --print-params                  Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT              Set a tuning parameter to the given value.\n  --tuning FILE                   Read size=value assignments from the given file.\n  --cache-file FILE               Store program cache here.\n  -d/--device NAME                Use the first device whose name contains the given string.\n  --default-thread-block-size INT The default size of thread blocks that are launched.\n  --default-grid-size INT         The default number of thread blocks that are launched.\n  --default-group-size INT        Alias for --default-thread-block-size.\n  --default-num-groups INT        Alias for --default-num-thread-blocks.\n  --default-tile-size INT         The default tile size for two-dimensional tiling.\n  --default-reg-tile-size INT     The default register tile size for two-dimensional tiling.\n  --default-registers INT         The amount of register memory in bytes.\n  --default-cache INT             The amount of register memory in bytes.\n  --default-threshold INT         The default parallelism threshold.\n  --unified-memory INT            Whether to use unified memory\n  --dump-cuda FILE                Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE                Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE                 Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE                 Load PTX code from the indicated file.\n  --nvrtc-option OPT              Add an additional build option to the string passed to NVRTC.\n");
            futhark_panic(1, "Unknown option: %s\n", argv[optind - 1]);
        }
    }
    return optind;
}
int main(int argc, char **argv)
{
    fut_progname = argv[0];
    
    struct futhark_context_config *cfg = futhark_context_config_new();
    
    assert(cfg != NULL);
    
    int parsed_options = parse_options(cfg, argc, argv);
    
    argc -= parsed_options;
    argv += parsed_options;
    if (argc != 0)
        futhark_panic(1, "Excess non-option: %s\n", argv[0]);
    
    struct futhark_context *ctx = futhark_context_new(cfg);
    
    assert(ctx != NULL);
    futhark_context_set_logging_file(ctx, stdout);
    
    char *error = futhark_context_get_error(ctx);
    
    if (error != NULL)
        futhark_panic(1, "Error during context initialisation:\n%s", error);
    if (entry_point != NULL)
        run_server(&prog, cfg, ctx);
    futhark_context_free(ctx);
    futhark_context_config_free(cfg);
}

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_30383;
    struct memblock_device counters_mem_30821;
    struct memblock_device global_dynid_mem_29823;
    struct memblock_device global_dynid_mem_29984;
    struct memblock_device global_dynid_mem_30140;
    struct memblock_device global_dynid_mem_30449;
    struct memblock_device global_dynid_mem_30578;
    struct memblock_device global_dynid_mem_30887;
};
struct tuning_params {
    int dummy;
    int64_t *builtinzhreplicate_boolzitblock_sizze_29941;
    int64_t *builtinzhreplicate_i32zitblock_sizze_29834;
    int64_t *builtinzhreplicate_i8zitblock_sizze_29808;
    int64_t *human_genericf32zihist_L2_30312;
    int64_t *human_genericf32zihist_L2_30750;
    int64_t *human_genericf32zihist_L_30250;
    int64_t *human_genericf32zihist_L_30688;
    int64_t *human_genericf32ziseghist_num_tblocks_28296;
    int64_t *human_genericf32ziseghist_num_tblocks_28587;
    int64_t *human_genericf32ziseghist_tblock_sizze_28294;
    int64_t *human_genericf32ziseghist_tblock_sizze_28585;
    int64_t *human_genericf32zisegmap_num_tblocks_28232;
    int64_t *human_genericf32zisegmap_num_tblocks_28405;
    int64_t *human_genericf32zisegmap_num_tblocks_28698;
    int64_t *human_genericf32zisegmap_tblock_sizze_28230;
    int64_t *human_genericf32zisegmap_tblock_sizze_28254;
    int64_t *human_genericf32zisegmap_tblock_sizze_28324;
    int64_t *human_genericf32zisegmap_tblock_sizze_28403;
    int64_t *human_genericf32zisegmap_tblock_sizze_28419;
    int64_t *human_genericf32zisegmap_tblock_sizze_28615;
    int64_t *human_genericf32zisegmap_tblock_sizze_28696;
    int64_t *human_genericf32zisegscan_num_tblocks_28222;
    int64_t *human_genericf32zisegscan_num_tblocks_28238;
    int64_t *human_genericf32zisegscan_num_tblocks_28246;
    int64_t *human_genericf32zisegscan_num_tblocks_28395;
    int64_t *human_genericf32zisegscan_num_tblocks_28411;
    int64_t *human_genericf32zisegscan_num_tblocks_28688;
    int64_t *human_genericf32zisegscan_tblock_sizze_28220;
    int64_t *human_genericf32zisegscan_tblock_sizze_28236;
    int64_t *human_genericf32zisegscan_tblock_sizze_28244;
    int64_t *human_genericf32zisegscan_tblock_sizze_28393;
    int64_t *human_genericf32zisegscan_tblock_sizze_28409;
    int64_t *human_genericf32zisegscan_tblock_sizze_28686;
    int64_t *human_genericf64zihist_L2_30312;
    int64_t *human_genericf64zihist_L2_30750;
    int64_t *human_genericf64zihist_L_30250;
    int64_t *human_genericf64zihist_L_30688;
    int64_t *human_genericf64ziseghist_num_tblocks_28782;
    int64_t *human_genericf64ziseghist_num_tblocks_29073;
    int64_t *human_genericf64ziseghist_tblock_sizze_28780;
    int64_t *human_genericf64ziseghist_tblock_sizze_29071;
    int64_t *human_genericf64zisegmap_num_tblocks_28714;
    int64_t *human_genericf64zisegmap_num_tblocks_28891;
    int64_t *human_genericf64zisegmap_num_tblocks_29184;
    int64_t *human_genericf64zisegmap_tblock_sizze_28712;
    int64_t *human_genericf64zisegmap_tblock_sizze_28736;
    int64_t *human_genericf64zisegmap_tblock_sizze_28810;
    int64_t *human_genericf64zisegmap_tblock_sizze_28889;
    int64_t *human_genericf64zisegmap_tblock_sizze_28905;
    int64_t *human_genericf64zisegmap_tblock_sizze_29101;
    int64_t *human_genericf64zisegmap_tblock_sizze_29182;
    int64_t *human_genericf64zisegscan_num_tblocks_28704;
    int64_t *human_genericf64zisegscan_num_tblocks_28720;
    int64_t *human_genericf64zisegscan_num_tblocks_28728;
    int64_t *human_genericf64zisegscan_num_tblocks_28881;
    int64_t *human_genericf64zisegscan_num_tblocks_28897;
    int64_t *human_genericf64zisegscan_num_tblocks_29174;
    int64_t *human_genericf64zisegscan_tblock_sizze_28702;
    int64_t *human_genericf64zisegscan_tblock_sizze_28718;
    int64_t *human_genericf64zisegscan_tblock_sizze_28726;
    int64_t *human_genericf64zisegscan_tblock_sizze_28879;
    int64_t *human_genericf64zisegscan_tblock_sizze_28895;
    int64_t *human_genericf64zisegscan_tblock_sizze_29172;
    int64_t *human_generici32zihist_L2_30312;
    int64_t *human_generici32zihist_L2_30750;
    int64_t *human_generici32zihist_L_30250;
    int64_t *human_generici32zihist_L_30688;
    int64_t *human_generici32ziseghist_num_tblocks_29268;
    int64_t *human_generici32ziseghist_num_tblocks_29559;
    int64_t *human_generici32ziseghist_tblock_sizze_29266;
    int64_t *human_generici32ziseghist_tblock_sizze_29557;
    int64_t *human_generici32zisegmap_num_tblocks_29200;
    int64_t *human_generici32zisegmap_num_tblocks_29377;
    int64_t *human_generici32zisegmap_num_tblocks_29670;
    int64_t *human_generici32zisegmap_tblock_sizze_29198;
    int64_t *human_generici32zisegmap_tblock_sizze_29222;
    int64_t *human_generici32zisegmap_tblock_sizze_29296;
    int64_t *human_generici32zisegmap_tblock_sizze_29375;
    int64_t *human_generici32zisegmap_tblock_sizze_29391;
    int64_t *human_generici32zisegmap_tblock_sizze_29587;
    int64_t *human_generici32zisegmap_tblock_sizze_29668;
    int64_t *human_generici32zisegscan_num_tblocks_29190;
    int64_t *human_generici32zisegscan_num_tblocks_29206;
    int64_t *human_generici32zisegscan_num_tblocks_29214;
    int64_t *human_generici32zisegscan_num_tblocks_29367;
    int64_t *human_generici32zisegscan_num_tblocks_29383;
    int64_t *human_generici32zisegscan_num_tblocks_29660;
    int64_t *human_generici32zisegscan_tblock_sizze_29188;
    int64_t *human_generici32zisegscan_tblock_sizze_29204;
    int64_t *human_generici32zisegscan_tblock_sizze_29212;
    int64_t *human_generici32zisegscan_tblock_sizze_29365;
    int64_t *human_generici32zisegscan_tblock_sizze_29381;
    int64_t *human_generici32zisegscan_tblock_sizze_29658;
};
static const int num_tuning_params = 93;
static const char *tuning_param_names[] = {"builtin#replicate_bool.tblock_size_29941", "builtin#replicate_i32.tblock_size_29834", "builtin#replicate_i8.tblock_size_29808", "human_genericf32.hist_L2_30312", "human_genericf32.hist_L2_30750", "human_genericf32.hist_L_30250", "human_genericf32.hist_L_30688", "human_genericf32.seghist_num_tblocks_28296", "human_genericf32.seghist_num_tblocks_28587", "human_genericf32.seghist_tblock_size_28294", "human_genericf32.seghist_tblock_size_28585", "human_genericf32.segmap_num_tblocks_28232", "human_genericf32.segmap_num_tblocks_28405", "human_genericf32.segmap_num_tblocks_28698", "human_genericf32.segmap_tblock_size_28230", "human_genericf32.segmap_tblock_size_28254", "human_genericf32.segmap_tblock_size_28324", "human_genericf32.segmap_tblock_size_28403", "human_genericf32.segmap_tblock_size_28419", "human_genericf32.segmap_tblock_size_28615", "human_genericf32.segmap_tblock_size_28696", "human_genericf32.segscan_num_tblocks_28222", "human_genericf32.segscan_num_tblocks_28238", "human_genericf32.segscan_num_tblocks_28246", "human_genericf32.segscan_num_tblocks_28395", "human_genericf32.segscan_num_tblocks_28411", "human_genericf32.segscan_num_tblocks_28688", "human_genericf32.segscan_tblock_size_28220", "human_genericf32.segscan_tblock_size_28236", "human_genericf32.segscan_tblock_size_28244", "human_genericf32.segscan_tblock_size_28393", "human_genericf32.segscan_tblock_size_28409", "human_genericf32.segscan_tblock_size_28686", "human_genericf64.hist_L2_30312", "human_genericf64.hist_L2_30750", "human_genericf64.hist_L_30250", "human_genericf64.hist_L_30688", "human_genericf64.seghist_num_tblocks_28782", "human_genericf64.seghist_num_tblocks_29073", "human_genericf64.seghist_tblock_size_28780", "human_genericf64.seghist_tblock_size_29071", "human_genericf64.segmap_num_tblocks_28714", "human_genericf64.segmap_num_tblocks_28891", "human_genericf64.segmap_num_tblocks_29184", "human_genericf64.segmap_tblock_size_28712", "human_genericf64.segmap_tblock_size_28736", "human_genericf64.segmap_tblock_size_28810", "human_genericf64.segmap_tblock_size_28889", "human_genericf64.segmap_tblock_size_28905", "human_genericf64.segmap_tblock_size_29101", "human_genericf64.segmap_tblock_size_29182", "human_genericf64.segscan_num_tblocks_28704", "human_genericf64.segscan_num_tblocks_28720", "human_genericf64.segscan_num_tblocks_28728", "human_genericf64.segscan_num_tblocks_28881", "human_genericf64.segscan_num_tblocks_28897", "human_genericf64.segscan_num_tblocks_29174", "human_genericf64.segscan_tblock_size_28702", "human_genericf64.segscan_tblock_size_28718", "human_genericf64.segscan_tblock_size_28726", "human_genericf64.segscan_tblock_size_28879", "human_genericf64.segscan_tblock_size_28895", "human_genericf64.segscan_tblock_size_29172", "human_generici32.hist_L2_30312", "human_generici32.hist_L2_30750", "human_generici32.hist_L_30250", "human_generici32.hist_L_30688", "human_generici32.seghist_num_tblocks_29268", "human_generici32.seghist_num_tblocks_29559", "human_generici32.seghist_tblock_size_29266", "human_generici32.seghist_tblock_size_29557", "human_generici32.segmap_num_tblocks_29200", "human_generici32.segmap_num_tblocks_29377", "human_generici32.segmap_num_tblocks_29670", "human_generici32.segmap_tblock_size_29198", "human_generici32.segmap_tblock_size_29222", "human_generici32.segmap_tblock_size_29296", "human_generici32.segmap_tblock_size_29375", "human_generici32.segmap_tblock_size_29391", "human_generici32.segmap_tblock_size_29587", "human_generici32.segmap_tblock_size_29668", "human_generici32.segscan_num_tblocks_29190", "human_generici32.segscan_num_tblocks_29206", "human_generici32.segscan_num_tblocks_29214", "human_generici32.segscan_num_tblocks_29367", "human_generici32.segscan_num_tblocks_29383", "human_generici32.segscan_num_tblocks_29660", "human_generici32.segscan_tblock_size_29188", "human_generici32.segscan_tblock_size_29204", "human_generici32.segscan_tblock_size_29212", "human_generici32.segscan_tblock_size_29365", "human_generici32.segscan_tblock_size_29381", "human_generici32.segscan_tblock_size_29658", NULL};
static const char *tuning_param_vars[] = {"builtinzhreplicate_boolzitblock_sizze_29941", "builtinzhreplicate_i32zitblock_sizze_29834", "builtinzhreplicate_i8zitblock_sizze_29808", "human_genericf32zihist_L2_30312", "human_genericf32zihist_L2_30750", "human_genericf32zihist_L_30250", "human_genericf32zihist_L_30688", "human_genericf32ziseghist_num_tblocks_28296", "human_genericf32ziseghist_num_tblocks_28587", "human_genericf32ziseghist_tblock_sizze_28294", "human_genericf32ziseghist_tblock_sizze_28585", "human_genericf32zisegmap_num_tblocks_28232", "human_genericf32zisegmap_num_tblocks_28405", "human_genericf32zisegmap_num_tblocks_28698", "human_genericf32zisegmap_tblock_sizze_28230", "human_genericf32zisegmap_tblock_sizze_28254", "human_genericf32zisegmap_tblock_sizze_28324", "human_genericf32zisegmap_tblock_sizze_28403", "human_genericf32zisegmap_tblock_sizze_28419", "human_genericf32zisegmap_tblock_sizze_28615", "human_genericf32zisegmap_tblock_sizze_28696", "human_genericf32zisegscan_num_tblocks_28222", "human_genericf32zisegscan_num_tblocks_28238", "human_genericf32zisegscan_num_tblocks_28246", "human_genericf32zisegscan_num_tblocks_28395", "human_genericf32zisegscan_num_tblocks_28411", "human_genericf32zisegscan_num_tblocks_28688", "human_genericf32zisegscan_tblock_sizze_28220", "human_genericf32zisegscan_tblock_sizze_28236", "human_genericf32zisegscan_tblock_sizze_28244", "human_genericf32zisegscan_tblock_sizze_28393", "human_genericf32zisegscan_tblock_sizze_28409", "human_genericf32zisegscan_tblock_sizze_28686", "human_genericf64zihist_L2_30312", "human_genericf64zihist_L2_30750", "human_genericf64zihist_L_30250", "human_genericf64zihist_L_30688", "human_genericf64ziseghist_num_tblocks_28782", "human_genericf64ziseghist_num_tblocks_29073", "human_genericf64ziseghist_tblock_sizze_28780", "human_genericf64ziseghist_tblock_sizze_29071", "human_genericf64zisegmap_num_tblocks_28714", "human_genericf64zisegmap_num_tblocks_28891", "human_genericf64zisegmap_num_tblocks_29184", "human_genericf64zisegmap_tblock_sizze_28712", "human_genericf64zisegmap_tblock_sizze_28736", "human_genericf64zisegmap_tblock_sizze_28810", "human_genericf64zisegmap_tblock_sizze_28889", "human_genericf64zisegmap_tblock_sizze_28905", "human_genericf64zisegmap_tblock_sizze_29101", "human_genericf64zisegmap_tblock_sizze_29182", "human_genericf64zisegscan_num_tblocks_28704", "human_genericf64zisegscan_num_tblocks_28720", "human_genericf64zisegscan_num_tblocks_28728", "human_genericf64zisegscan_num_tblocks_28881", "human_genericf64zisegscan_num_tblocks_28897", "human_genericf64zisegscan_num_tblocks_29174", "human_genericf64zisegscan_tblock_sizze_28702", "human_genericf64zisegscan_tblock_sizze_28718", "human_genericf64zisegscan_tblock_sizze_28726", "human_genericf64zisegscan_tblock_sizze_28879", "human_genericf64zisegscan_tblock_sizze_28895", "human_genericf64zisegscan_tblock_sizze_29172", "human_generici32zihist_L2_30312", "human_generici32zihist_L2_30750", "human_generici32zihist_L_30250", "human_generici32zihist_L_30688", "human_generici32ziseghist_num_tblocks_29268", "human_generici32ziseghist_num_tblocks_29559", "human_generici32ziseghist_tblock_sizze_29266", "human_generici32ziseghist_tblock_sizze_29557", "human_generici32zisegmap_num_tblocks_29200", "human_generici32zisegmap_num_tblocks_29377", "human_generici32zisegmap_num_tblocks_29670", "human_generici32zisegmap_tblock_sizze_29198", "human_generici32zisegmap_tblock_sizze_29222", "human_generici32zisegmap_tblock_sizze_29296", "human_generici32zisegmap_tblock_sizze_29375", "human_generici32zisegmap_tblock_sizze_29391", "human_generici32zisegmap_tblock_sizze_29587", "human_generici32zisegmap_tblock_sizze_29668", "human_generici32zisegscan_num_tblocks_29190", "human_generici32zisegscan_num_tblocks_29206", "human_generici32zisegscan_num_tblocks_29214", "human_generici32zisegscan_num_tblocks_29367", "human_generici32zisegscan_num_tblocks_29383", "human_generici32zisegscan_num_tblocks_29660", "human_generici32zisegscan_tblock_sizze_29188", "human_generici32zisegscan_tblock_sizze_29204", "human_generici32zisegscan_tblock_sizze_29212", "human_generici32zisegscan_tblock_sizze_29365", "human_generici32zisegscan_tblock_sizze_29381", "human_generici32zisegscan_tblock_sizze_29658", NULL};
static const char *tuning_param_classes[] = {"thread_block_size", "thread_block_size", "thread_block_size", "cache", "cache", "shared_memory", "shared_memory", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "cache", "cache", "shared_memory", "shared_memory", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "cache", "cache", "shared_memory", "shared_memory", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "grid_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", "thread_block_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 1;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_tblock_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_tblocks(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global", "() {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n\n#define SHARED_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0", "000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8",
                                    "000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x37",
                                    "1B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x", "37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x", "37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x",
                                    "38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x", "384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, ", "0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, ",
                                    "0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, ", "0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000", ", 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000",
                                    ", 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000", ", 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x387620", "00, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1",
                                    "024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n/", "/ Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint", "8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALA",
                                    "R_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y)", " {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) ", "{\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  ",
                                    "foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return", " y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = ", "x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t ",
                                    "y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nS", "CALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64", "_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x",
                                    ") {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VER", "SION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return m", "ul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int",
                                    "32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t ", "a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  retur", "n __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1",
                                    ";\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, f", "loat y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {", "\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSC",
                                    "ALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float", " x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(", "uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  int32_t xb = futrts_to_bits32(x);\n  int32_t yb = futrts_to_bits32(y);\n  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futr",
                                    "ts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  re", "turn rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {\n  return ldexpf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {\n  return copysignf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}", "\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(dou",
                                    "ble x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR do", "uble futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int", "16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return x * pow((double)2.0, (double)y);\n}\n\nSCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {\n  int64_t xb = futrts_to_bits64(x);\n  int64_t yb = futrts_to_bits64(y);\n  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#e",
                                    "lse\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  r", "eturn tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x", ") {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR",
                                    "_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR", "_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 ", "x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return e",
                                    "rf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return ldexp(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return copysign(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  retu", "rn (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrt", "s_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f1",
                                    "6 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSC", "ALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCA", "LAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {\n  return futrts_ldexp32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {\n  return futrts_copysign32((float)x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  retu",
                                    "rn x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32", "_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#el", "se\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  float ret;\n  asm volatile(\"atom.global.add.f32 %0,[%1],%2;\":\"=f\"(ret):\"l\"(p),\"f\"(x):\"memory\");\n  return ret;\n#elif defined(__opencl_c_ext_fp32_global_atomic_add)\n  // use hardware-supported atomic addition on some Intel GPUs\n  return atomic_fetch_add_explicit((volatile __global atomic_float*)p,\n                                   x,\n                                   memory_order_relaxed);\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f32)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f32(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  float old = x;\n  float ret;\n  while ((old=atomic_xchg(p, ret=atomic_xchg(p, 0.0f)+old))!=0.0f);\n  return ret;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile",
                                    " __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, ", "int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint", "64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(F",
                                    "UTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n  // On OpenCL, use technique from\n  // https://pipinspace.github.io/blog/atomic-float-addition-in-opencl.html\n#elif defined(cl_nv_pragma_unroll)\n  // use hardware-supported atomic addition on Nvidia GPUs with inline\n  // PTX assembly\n  double ret;\n  asm volatile(\"atom.global.add.f64 %0,[%1],%2;\":\"=d\"(ret):\"l\"(p),\"d\"(x):\"memory\");\n  return ret;\n#elif __has_builtin(__builtin_amdgcn_global_atomic_fadd_f64)\n  // use hardware-supported atomic addition on some AMD GPUs\n  return __builtin_amdgcn_global_atomic_fadd_f64(p, x);\n#else\n  // fallback emulation:\n  // https://forums.developer.nvidia.com/t/atomicadd-float-float-atomicmul-float-float/14639/5\n  union {int64_t i; double f;} old;\n  union {int64_t i; double f;} ret;\n  old.f = x;\n  while (1) {\n    ret.i = atom_xchg((volatile __global int64_t*)p, (int64_t)0);\n    ret.f += old.f;\n    old.i = atom_xchg((volatile __global int64_t*)p, ret.i);\n    if (old.i == 0) {\n      break;\n    }\n  }\n  return ret.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  u", "nion { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do ", "{\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(v",
                                    "olatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(SHARED_MEM_PARAM                              \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {                           \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_g", "lobal_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_in", "dex + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                                                int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n ",
                                    "                                               int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \\\n      y_index =                                                         \\\n        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \\\n", "        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n  ", "                                    int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        tblock_id_1 * TR_BLOCK_DIM * muly +                             \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n ",
                                    "     if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t mulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \\\n  ", "int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_", "PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \\\n  int tblock_id_0 = get_tblock_id(0);                                   \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int tblock_id_1 = get_tblock_id(1);                                   \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int tblock_id_2 = get_tblock_id(2);                                 \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_loc",
                                    "al_id(1);    \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \\\n      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      tblock_id_2 += get_num_tblocks(2);                                \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                      ", "                             \\\n    tblock_id_1 += get_num_tblocks(1);                                  \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                             ", "                           \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }                                                                     \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                       ",
                                    "                         \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset += i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];     ", "                       \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL\nvoid builtinzhreplicate_boolzireplicate_29937(int64_t num_elems_29933, unsigned char val_29934_bits, int64_t replicate_n_29936, int64_t virt_num_tblocks_29942, int64_t num_tblocks_29943, __global unsigned char *mem_29932)\n{\n    bool val_29934 = val_29934_bits;\n    int32_t replicate_ltid_29938;\n    int32_t tblock_sizze_29940;\n    int32_t replicate_gid_29939;\n    int32_t replicate_gtid_29937;\n    int32_t phys_tblock_id_29944;\n    int32_t iterations_29945;\n    \n    replicate_ltid_29938 = get_local_id(0);\n    tblock_sizze_29940 = get_local_size(0);\n    replicate_gid_29939 = get_tblock_id(0);\n    replicate_gtid_29937 = replicate_gid_29939 * tblock_sizze_29940 + replicate_ltid_29938;\n    phys_tblock_id_29944 = get_tblock_id(0);\n    iterations_29945 = sdiv_up32(sext_i64_i32(virt_num_tblocks_29942) - phys_tblock_id_29944, sext_i64_i32(num_tblocks_29943));\n    for (int32_t i_29946 = 0; i_29946 < iterations_29945; i_29946++) {\n        int32_t virt_tblock_id_29947;\n        int64_t global_tid_29948;\n        int64_t slice_29950;\n        int64_t rep_i_29949;\n        int64_t remnant_29951;\n        \n        virt_tblock_id_29947 = phys_tblock_id_29944 + i_29946 * sext_i64_i32(num_tblocks_29943);\n        global_tid_29948 = sext_i32_i64(virt_tblock_id_29947) * sext_i32_i64(tblock_sizze_29940) + sext_i32_i64(replicate_ltid_29938);\n        slice_29950 = num_elems_29933;\n        rep_i_29949 = global_tid_29948;\n        remnant_29951 = global_tid_29948 - rep_i_29949;\n        if (slt64(global_tid_29948, replicate_n_29936)) {\n            ((__global bool *) mem_29932)[rep_i_29949] = val_29934;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_29830(int64_t num_elems_29826, int32_t val_29827, int64_t rep", "licate_n_29829, int64_t virt_num_tblocks_29835, int64_t num_tblocks_29836, __global unsigned char *mem_29825)\n{\n    int32_t replicate_ltid_29831;\n    int32_t tblock_sizze_29833;\n    int32_t replicate_gid_29832;\n    int32_t replicate_gtid_29830;\n    int32_t phys_tblock_id_29837;\n    int32_t iterations_29838;\n    \n    replicate_ltid_29831 = get_local_id(0);\n    tblock_sizze_29833 = get_local_size(0);\n    replicate_gid_29832 = get_tblock_id(0);\n    replicate_gtid_29830 = replicate_gid_29832 * tblock_sizze_29833 + replicate_ltid_29831;\n    phys_tblock_id_29837 = get_tblock_id(0);\n    iterations_29838 = sdiv_up32(sext_i64_i32(virt_num_tblocks_29835) - phys_tblock_id_29837, sext_i64_i32(num_tblocks_29836));\n    for (int32_t i_29839 = 0; i_29839 < iterations_29838; i_29839++) {\n        int32_t virt_tblock_id_29840;\n        int64_t global_tid_29841;\n        int64_t slice_29843;\n        int64_t rep_i_29842;\n        int64_t remnant_29844;\n        \n        virt_tblock_id_29840 = phys_tblock_id_29837 + i_29839 * sext_i64_i32(num_tblocks_29836);\n        global_tid_29841 = sext_i32_i64(virt_tblock_id_29840) * sext_i32_i64(tblock_sizze_29833) + sext_i32_i64(replicate_ltid_29831);\n        slice_29843 = num_elems_29826;\n        rep_i_29842 = global_tid_29841;\n        remnant_29844 = global_tid_29841 - rep_i_29842;\n        if (slt64(global_tid_29841, replicate_n_29829)) {\n            ((__global int32_t *) mem_29825)[rep_i_29842] = val_29827;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_29804(int64_t num_elems_29800, int8_t val_29801, int64_t replicate_n_29803, int64_t virt_num_tblocks_29809, int64_t num_tblocks_29810, __global unsigned char *mem_29799)\n{\n    int32_t replicate_ltid_29805;\n    int32_t tblock_sizze_29807;\n    int32_t replicate_gid_29806;\n    int32_t replicate_gtid_29804;\n    int32_t phys_tblock_id_29811;\n    int32_t iterations_29812;\n    \n    replicate_ltid",
                                    "_29805 = get_local_id(0);\n    tblock_sizze_29807 = get_local_size(0);\n    replicate_gid_29806 = get_tblock_id(0);\n    replicate_gtid_29804 = replicate_gid_29806 * tblock_sizze_29807 + replicate_ltid_29805;\n    phys_tblock_id_29811 = get_tblock_id(0);\n    iterations_29812 = sdiv_up32(sext_i64_i32(virt_num_tblocks_29809) - phys_tblock_id_29811, sext_i64_i32(num_tblocks_29810));\n    for (int32_t i_29813 = 0; i_29813 < iterations_29812; i_29813++) {\n        int32_t virt_tblock_id_29814;\n        int64_t global_tid_29815;\n        int64_t slice_29817;\n        int64_t rep_i_29816;\n        int64_t remnant_29818;\n        \n        virt_tblock_id_29814 = phys_tblock_id_29811 + i_29813 * sext_i64_i32(num_tblocks_29810);\n        global_tid_29815 = sext_i32_i64(virt_tblock_id_29814) * sext_i32_i64(tblock_sizze_29807) + sext_i32_i64(replicate_ltid_29805);\n        slice_29817 = num_elems_29800;\n        rep_i_29816 = global_tid_29815;\n        remnant_29818 = global_tid_29815 - rep_i_29816;\n        if (slt64(global_tid_29815, replicate_n_29803)) {\n            ((__global int8_t *) mem_29799)[rep_i_29816] = val_29801;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL_SIZED(human_genericf32ziseghist_global_28302_dim1, 1, 1)\nvoid human_genericf32ziseghist_global_28302(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_18678, int64_t nz2081U_18679, int64_t num_tblocks_28297, int64_t num_subhistos_30239, int32_t chk_i_30320, int64_t hist_H_chk_30321, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242)\n{\n    #define seghist_tblock_sizze_28295 (human_genericf32ziseghist_global_28302ziseghist_tblock_sizze_28295)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_", "30323;\n    int32_t tblock_sizze_30326;\n    int32_t wave_sizze_30325;\n    int32_t block_id_30324;\n    int32_t global_tid_30322;\n    int64_t phys_tid_28302;\n    int32_t subhisto_ind_30327;\n    int64_t num_chunks_30328;\n    \n    local_tid_30323 = get_local_id(0);\n    tblock_sizze_30326 = get_local_size(0);\n    wave_sizze_30325 = LOCKSTEP_WIDTH;\n    block_id_30324 = get_tblock_id(0);\n    global_tid_30322 = block_id_30324 * tblock_sizze_30326 + local_tid_30323;\n    phys_tid_28302 = sext_i32_i64(global_tid_30322);\n    subhisto_ind_30327 = squot32(global_tid_30322, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_28295 * num_tblocks_28297), sext_i64_i32(num_subhistos_30239)));\n    num_chunks_30328 = sdiv_up64(nz2081U_18679, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_28295 * num_tblocks_28297)));\n    for (int64_t chunk_i_30329 = 0; chunk_i_30329 < num_chunks_30328; chunk_i_30329++) {\n        int64_t i_30330 = chunk_i_30329 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_28295 * num_tblocks_28297)) + sext_i32_i64(global_tid_30322);\n        \n        if (slt64(i_30330, nz2081U_18679)) {\n            int64_t slice_30331;\n            int64_t gtid_28301;\n            int64_t remnant_30332;\n            \n            slice_30331 = nz2081U_18679;\n            gtid_28301 = i_30330;\n            remnant_30332 = i_30330 - gtid_28301;\n            if (slt64(i_30330, nz2081U_18679)) {\n                int32_t eta_p_28310;\n                int64_t ii_28311;\n                bool x_28312;\n                bool y_28313;\n                bool bounds_check_28314;\n                bool index_certs_28315;\n                float eta_p_28309;\n                float eq_arg1_28316;\n                bool defunc_0_eq_res_28317;\n                bool defunc_0_lt_res_28318;\n                int32_t bool_res_28319;\n                int32_t bool_res_28320;\n                \n                eta_p_28310 = ((__global int32_t *) II1_mem_29679)[gtid_28301];\n                ii_28311 = sext_i32_i64(eta_p_28310);\n                x", "_28312 = sle64((int64_t) 0, ii_28311);\n                y_28313 = slt64(ii_28311, mz2080U_18678);\n                bounds_check_28314 = x_28312 && y_28313;\n                if (!bounds_check_28314) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                            global_failure_args[0] = (int64_t) ii_28311;\n                            global_failure_args[1] = (int64_t) mz2080U_18678;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                eta_p_28309 = ((__global float *) A_mem_29680)[gtid_28301];\n                eq_arg1_28316 = ((__global float *) mem_29695)[ii_28311];\n                defunc_0_eq_res_28317 = eta_p_28309 == eq_arg1_28316;\n                defunc_0_lt_res_28318 = eta_p_28309 < eq_arg1_28316;\n                bool_res_28319 = btoi_bool_i32(defunc_0_lt_res_28318);\n                bool_res_28320 = btoi_bool_i32(defunc_0_eq_res_28317);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_30320) * hist_H_chk_30321, ii_28311) && (slt64(ii_28311, sext_i32_i64(chk_i_30320) * hist_H_chk_30321 + hist_H_chk_30321) && (sle64((int64_t) 0, ii_28311) && slt64(ii_28311, mz2080U_18678)))) {\n                        int32_t eta_p_28303;\n                        int32_t eta_p_28304;\n                        int32_t eta_p_28305;\n                        int32_t eta_p_28306;\n                        \n                        eta_p_28305 = bool_res_28319;\n                        eta_p_28306 = bool_res_28320;\n                        \n                        int32_t old_30333;\n                        \n                        old_30333 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30240)[sext_i32_i64(subhisto_ind_30327) * mz2080U_18678 + ii_28311], (int) eta_p_28305);\n          ",
                                    "              \n                        int32_t old_30334;\n                        \n                        old_30334 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30242)[sext_i32_i64(subhisto_ind_30327) * mz2080U_18678 + ii_28311], (int) eta_p_28306);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_28295\n}\nFUTHARK_KERNEL_SIZED(human_genericf32ziseghist_global_28593_dim1, 1, 1)\nvoid human_genericf32ziseghist_global_28593(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_18678, int64_t loop_dz2081Uz2088Uz2087U_27123, int64_t num_tblocks_28588, int64_t num_subhistos_30677, int32_t chk_i_30758, int64_t hist_H_chk_30759, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define seghist_tblock_sizze_28586 (human_genericf32ziseghist_global_28593ziseghist_tblock_sizze_28586)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30761;\n    int32_t tblock_sizze_30764;\n    int32_t wave_sizze_30763;\n    int32_t block_id_30762;\n    int32_t global_tid_30760;\n    int64_t phys_tid_28593;\n    int32_t subhisto_ind_30765;\n    int64_t num_chunks_30766;\n    \n    local_tid_30761 = get_local_id(0);\n    tblock_sizze_30764 = get_local_size(0);\n    wave_sizze_30763 = LOCKSTEP_WIDTH;\n    block_id_30762 = get_tblock_id(0);\n    global_tid_30760 = block_id_30762 * tblock_sizze_30764 + local_tid_30761;\n    phys_tid_28593 = sext_i32_i64(global_tid_30760);\n    subhisto_ind_30765 = squot32(global_tid_30760, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_28586 * num_tblocks_28588), sext_i64_i32(num_subhistos_30677)));\n    num_chunks_30766 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27123, sext_i32_i64(sext_i64_i32(seghist", "_tblock_sizze_28586 * num_tblocks_28588)));\n    for (int64_t chunk_i_30767 = 0; chunk_i_30767 < num_chunks_30766; chunk_i_30767++) {\n        int64_t i_30768 = chunk_i_30767 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_28586 * num_tblocks_28588)) + sext_i32_i64(global_tid_30760);\n        \n        if (slt64(i_30768, loop_dz2081Uz2088Uz2087U_27123)) {\n            int64_t slice_30769;\n            int64_t gtid_28592;\n            int64_t remnant_30770;\n            \n            slice_30769 = loop_dz2081Uz2088Uz2087U_27123;\n            gtid_28592 = i_30768;\n            remnant_30770 = i_30768 - gtid_28592;\n            if (slt64(i_30768, loop_dz2081Uz2088Uz2087U_27123)) {\n                int32_t eta_p_28601;\n                int64_t ii_28602;\n                bool x_28603;\n                bool y_28604;\n                bool bounds_check_28605;\n                bool index_certs_28606;\n                float eta_p_28600;\n                float eq_arg1_28607;\n                bool defunc_0_eq_res_28608;\n                bool defunc_0_lt_res_28609;\n                int32_t bool_res_28610;\n                int32_t bool_res_28611;\n                \n                eta_p_28601 = ((__global int32_t *) mem_param_29728)[gtid_28592];\n                ii_28602 = sext_i32_i64(eta_p_28601);\n                x_28603 = sle64((int64_t) 0, ii_28602);\n                y_28604 = slt64(ii_28602, mz2080U_18678);\n                bounds_check_28605 = x_28603 && y_28604;\n                if (!bounds_check_28605) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 10) == -1) {\n                            global_failure_args[0] = (int64_t) ii_28602;\n                            global_failure_args[1] = (int64_t) mz2080U_18678;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                eta_p_28600 = ((__global float *) mem_param_29731)[gtid_28592];\n                eq_arg1_28607 = ((__g", "lobal float *) mem_29740)[ii_28602];\n                defunc_0_eq_res_28608 = eta_p_28600 == eq_arg1_28607;\n                defunc_0_lt_res_28609 = eta_p_28600 < eq_arg1_28607;\n                bool_res_28610 = btoi_bool_i32(defunc_0_lt_res_28609);\n                bool_res_28611 = btoi_bool_i32(defunc_0_eq_res_28608);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_30758) * hist_H_chk_30759, ii_28602) && (slt64(ii_28602, sext_i32_i64(chk_i_30758) * hist_H_chk_30759 + hist_H_chk_30759) && (sle64((int64_t) 0, ii_28602) && slt64(ii_28602, mz2080U_18678)))) {\n                        int32_t eta_p_28594;\n                        int32_t eta_p_28595;\n                        int32_t eta_p_28596;\n                        int32_t eta_p_28597;\n                        \n                        eta_p_28596 = bool_res_28610;\n                        eta_p_28597 = bool_res_28611;\n                        \n                        int32_t old_30771;\n                        \n                        old_30771 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30678)[sext_i32_i64(subhisto_ind_30765) * mz2080U_18678 + ii_28602], (int) eta_p_28596);\n                        \n                        int32_t old_30772;\n                        \n                        old_30772 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30680)[sext_i32_i64(subhisto_ind_30765) * mz2080U_18678 + ii_28602], (int) eta_p_28597);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_28586\n}\nFUTHARK_KERNEL_SIZED(human_genericf32ziseghist_local_28302_dim1, 1, 1)\nvoid human_genericf32ziseghist_local_28302(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_18678, int64_t nz2081U_18679, int64_t num_sub",
                                    "histos_30239, int64_t num_tblocks_30252, int32_t hist_M_30258, int32_t chk_i_30262, int64_t num_segments_30263, int64_t hist_H_chk_30264, int64_t histo_sizze_30265, int32_t init_per_thread_30266, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242)\n{\n    #define max_tblock_sizze_30251 (human_genericf32ziseghist_local_28302zimax_tblock_sizze_30251)\n    \n    volatile __local unsigned char *subhistogram_local_mem_30282_backing_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_30282_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_30280_backing_0 = &shared_mem[subhistogram_local_mem_30282_backing_1_offset];\n    const int64_t subhistogram_local_mem_30280_backing_0_offset = subhistogram_local_mem_30282_backing_1_offset + ((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30268;\n    int32_t tblock_sizze_30271;\n    int32_t wave_sizze_30270;\n    int32_t block_id_30269;\n    int32_t global_tid_30267;\n    int64_t phys_tid_28302;\n    int32_t phys_tblock_id_30272;\n    int32_t iterations_30273;\n    \n    local_tid_30268 = get_local_id(0);\n    tblock_sizze_30271 = get_local_size(0);\n    wave_sizze_30270 = LOCKSTEP_WIDTH;\n    block_id_30269 = get_tblock_id(0);\n    global_tid_30267 = block_id_30269 * tblock_sizze_30271 + local_tid_30268;\n    phys_tid_", "28302 = sext_i32_i64(global_tid_30267);\n    phys_tblock_id_30272 = get_tblock_id(0);\n    iterations_30273 = sdiv_up32(sext_i64_i32(num_tblocks_30252 * num_segments_30263) - phys_tblock_id_30272, sext_i64_i32(num_tblocks_30252));\n    for (int32_t i_30274 = 0; i_30274 < iterations_30273; i_30274++) {\n        int32_t virt_tblock_id_30275;\n        int32_t flat_segment_id_30276;\n        int32_t gid_in_segment_30277;\n        int32_t pgtid_in_segment_30278;\n        int32_t threads_per_segment_30279;\n        __local unsigned char *subhistogram_local_mem_30280;\n        __local unsigned char *subhistogram_local_mem_30282;\n        int32_t thread_local_subhisto_i_30284;\n        int64_t num_chunks_30297;\n        \n        virt_tblock_id_30275 = phys_tblock_id_30272 + i_30274 * sext_i64_i32(num_tblocks_30252);\n        flat_segment_id_30276 = squot32(virt_tblock_id_30275, sext_i64_i32(num_tblocks_30252));\n        gid_in_segment_30277 = srem32(virt_tblock_id_30275, sext_i64_i32(num_tblocks_30252));\n        pgtid_in_segment_30278 = gid_in_segment_30277 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n        threads_per_segment_30279 = sext_i64_i32(num_tblocks_30252 * max_tblock_sizze_30251);\n        subhistogram_local_mem_30280 = (__local unsigned char *) subhistogram_local_mem_30280_backing_0;\n        subhistogram_local_mem_30282 = (__local unsigned char *) subhistogram_local_mem_30282_backing_1;\n        thread_local_subhisto_i_30284 = srem32(local_tid_30268, hist_M_30258);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_30285 = 0; local_i_30285 < init_per_thread_30266; local_i_30285++) {\n                int32_t j_30286 = local_i_30285 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n                int32_t j_offset_30287 = hist_M_30258 * sext_i64_i32(histo_sizze_30265) * gid_in_segment_30277 + j_30286;\n                int32_t local_subhisto_i_30288 = squot32(j_30286, sext_i64_i32(histo_sizze_30265));\n                in", "t32_t global_subhisto_i_30289 = squot32(j_offset_30287, sext_i64_i32(histo_sizze_30265));\n                \n                if (slt32(j_30286, hist_M_30258 * sext_i64_i32(histo_sizze_30265))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30289 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30239)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264) && slt64(sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264, mz2080U_18678)))) {\n                            int32_t tmp_30290 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(local_subhisto_i_30288) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265)))] = tmp_30290;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(local_subhisto_i_30288) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265)))] = 0;\n                        }\n                    }\n                }\n            }\n            for (int32_t local_i_30291 = 0; local_i_30291 < init_per_thread_30266; local_i_30291++) {\n                int32_t j_30292 = local_i_30291 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n                int32_t j_offset_30293 = hist_M_30258 * sext_i64_i32(histo_sizze_30265) * gid_in_segment_30277 + j_30292;\n                int32_t local_subhisto_i_30294 = squot32(j_30292, sext_i64_i32(histo_sizze_30265));\n                int32_t global_subhisto_i_30295 = squot",
                                    "32(j_offset_30293, sext_i64_i32(histo_sizze_30265));\n                \n                if (slt32(j_30292, hist_M_30258 * sext_i64_i32(histo_sizze_30265))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30295 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30239)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264) && slt64(sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264, mz2080U_18678)))) {\n                            int32_t tmp_30296 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(local_subhisto_i_30294) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265)))] = tmp_30296;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(local_subhisto_i_30294) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_30297 = sdiv_up64(nz2081U_18679, sext_i32_i64(threads_per_segment_30279));\n        for (int64_t chunk_i_30298 = 0; chunk_i_30298 < num_chunks_30297; chunk_i_30298++) {\n            int64_t i_30299 = chunk_i_30298 * sext_i32_i64(threads_per_segment_30279) + sext_i32_i64(pgtid_in_segment_30278);\n            \n            if (slt64(i_30299, nz2081U_18679)) {\n                int64_t gtid_28301;\n                int32_t eta_p_28310;\n                int64_t ii", "_28311;\n                bool x_28312;\n                bool y_28313;\n                bool bounds_check_28314;\n                bool index_certs_28315;\n                float eta_p_28309;\n                float eq_arg1_28316;\n                bool defunc_0_eq_res_28317;\n                bool defunc_0_lt_res_28318;\n                int32_t bool_res_28319;\n                int32_t bool_res_28320;\n                \n                gtid_28301 = i_30299;\n                eta_p_28310 = ((__global int32_t *) II1_mem_29679)[gtid_28301];\n                ii_28311 = sext_i32_i64(eta_p_28310);\n                x_28312 = sle64((int64_t) 0, ii_28311);\n                y_28313 = slt64(ii_28311, mz2080U_18678);\n                bounds_check_28314 = x_28312 && y_28313;\n                if (!bounds_check_28314) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                            global_failure_args[0] = (int64_t) ii_28311;\n                            global_failure_args[1] = (int64_t) mz2080U_18678;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                eta_p_28309 = ((__global float *) A_mem_29680)[gtid_28301];\n                eq_arg1_28316 = ((__global float *) mem_29695)[ii_28311];\n                defunc_0_eq_res_28317 = eta_p_28309 == eq_arg1_28316;\n                defunc_0_lt_res_28318 = eta_p_28309 < eq_arg1_28316;\n                bool_res_28319 = btoi_bool_i32(defunc_0_lt_res_28318);\n                bool_res_28320 = btoi_bool_i32(defunc_0_eq_res_28317);\n                if (chk_i_30262 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, ii_28311) && slt64(ii_28311, mz2080U_18678)) && (sle64(sext_i32_i64(chk_i_30262) * hist_H_chk_30264, ii_28311) ", "&& slt64(ii_28311, sext_i32_i64(chk_i_30262) * hist_H_chk_30264 + hist_H_chk_30264))) {\n                        int32_t eta_p_28303;\n                        int32_t eta_p_28304;\n                        int32_t eta_p_28305;\n                        int32_t eta_p_28306;\n                        \n                        eta_p_28305 = bool_res_28319;\n                        eta_p_28306 = bool_res_28320;\n                        \n                        int32_t old_30300;\n                        \n                        old_30300 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30280)[sext_i32_i64(thread_local_subhisto_i_30284) * hist_H_chk_30264 + (ii_28311 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264)], (int) eta_p_28305);\n                        \n                        int32_t old_30301;\n                        \n                        old_30301 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30282)[sext_i32_i64(thread_local_subhisto_i_30284) * hist_H_chk_30264 + (ii_28311 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264)], (int) eta_p_28306);\n                    }\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_30302 = smin64(hist_H_chk_30264, mz2080U_18678 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264);\n            int32_t histo_sizze_30303 = sext_i64_i32(trunc_H_30302);\n            \n            for (int32_t local_i_30304 = 0; local_i_30304 < init_per_thread_30266; local_i_30304++) {\n                int32_t j_30305 = local_i_30304 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n                \n                if (slt32(j_30305, histo_sizze_30303)) {\n                    int32_t eta_p_28303;\n          ",
                                    "          int32_t eta_p_28304;\n                    int32_t eta_p_28305;\n                    int32_t eta_p_28306;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_28303 = ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(j_30305)];\n                        eta_p_28304 = ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(j_30305)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_30306 = 0; subhisto_id_30306 < hist_M_30258 - 1; subhisto_id_30306++) {\n                            eta_p_28305 = ((__local int32_t *) subhistogram_local_mem_30280)[(sext_i32_i64(subhisto_id_30306) + (int64_t) 1) * hist_H_chk_30264 + sext_i32_i64(j_30305)];\n                            eta_p_28306 = ((__local int32_t *) subhistogram_local_mem_30282)[(sext_i32_i64(subhisto_id_30306) + (int64_t) 1) * hist_H_chk_30264 + sext_i32_i64(j_30305)];\n                            \n                            int32_t tmp_28307 = add32(eta_p_28303, eta_p_28305);\n                            int32_t tmp_28308 = add32(eta_p_28304, eta_p_28306);\n                            \n                            eta_p_28303 = tmp_28307;\n                            eta_p_28304 = tmp_28308;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[srem64(sext_i32_i64(virt_tblock_id_30275), num_tblocks_30252) * mz2080U_18678 + (sext_i32_i64(j_30305) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264)] = eta_p_28303;\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[srem64(sext_i32_i64(virt_tblock_id_30275), num_tblocks_30252) * mz2080U_18678 + (sext_i32_i64(j_30305) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264)] = et", "a_p_28304;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_30251\n}\nFUTHARK_KERNEL_SIZED(human_genericf32ziseghist_local_28593_dim1, 1, 1)\nvoid human_genericf32ziseghist_local_28593(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_18678, int64_t loop_dz2081Uz2088Uz2087U_27123, int64_t num_subhistos_30677, int64_t num_tblocks_30690, int32_t hist_M_30696, int32_t chk_i_30700, int64_t num_segments_30701, int64_t hist_H_chk_30702, int64_t histo_sizze_30703, int32_t init_per_thread_30704, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define max_tblock_sizze_30689 (human_genericf32ziseghist_local_28593zimax_tblock_sizze_30689)\n    \n    volatile __local unsigned char *subhistogram_local_mem_30720_backing_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_30720_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_30718_backing_0 = &shared_mem[subhistogram_local_mem_30720_backing_1_offset];\n    const int64_t subhistogram_local_mem_30718_backing_0_offset = subhistogram_local_mem_30720_backing_1_offset + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    ", "\n    int32_t local_tid_30706;\n    int32_t tblock_sizze_30709;\n    int32_t wave_sizze_30708;\n    int32_t block_id_30707;\n    int32_t global_tid_30705;\n    int64_t phys_tid_28593;\n    int32_t phys_tblock_id_30710;\n    int32_t iterations_30711;\n    \n    local_tid_30706 = get_local_id(0);\n    tblock_sizze_30709 = get_local_size(0);\n    wave_sizze_30708 = LOCKSTEP_WIDTH;\n    block_id_30707 = get_tblock_id(0);\n    global_tid_30705 = block_id_30707 * tblock_sizze_30709 + local_tid_30706;\n    phys_tid_28593 = sext_i32_i64(global_tid_30705);\n    phys_tblock_id_30710 = get_tblock_id(0);\n    iterations_30711 = sdiv_up32(sext_i64_i32(num_tblocks_30690 * num_segments_30701) - phys_tblock_id_30710, sext_i64_i32(num_tblocks_30690));\n    for (int32_t i_30712 = 0; i_30712 < iterations_30711; i_30712++) {\n        int32_t virt_tblock_id_30713;\n        int32_t flat_segment_id_30714;\n        int32_t gid_in_segment_30715;\n        int32_t pgtid_in_segment_30716;\n        int32_t threads_per_segment_30717;\n        __local unsigned char *subhistogram_local_mem_30718;\n        __local unsigned char *subhistogram_local_mem_30720;\n        int32_t thread_local_subhisto_i_30722;\n        int64_t num_chunks_30735;\n        \n        virt_tblock_id_30713 = phys_tblock_id_30710 + i_30712 * sext_i64_i32(num_tblocks_30690);\n        flat_segment_id_30714 = squot32(virt_tblock_id_30713, sext_i64_i32(num_tblocks_30690));\n        gid_in_segment_30715 = srem32(virt_tblock_id_30713, sext_i64_i32(num_tblocks_30690));\n        pgtid_in_segment_30716 = gid_in_segment_30715 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n        threads_per_segment_30717 = sext_i64_i32(num_tblocks_30690 * max_tblock_sizze_30689);\n        subhistogram_local_mem_30718 = (__local unsigned char *) subhistogram_local_mem_30718_backing_0;\n        subhistogram_local_mem_30720 = (__local unsigned char *) subhistogram_local_mem_30720_backing_1;\n        thread_local_subhisto_i_30722 = srem32(local_tid_30706, hist_M_30696);\n        /",
                                    "/ initialize histograms in shared memory\n        {\n            for (int32_t local_i_30723 = 0; local_i_30723 < init_per_thread_30704; local_i_30723++) {\n                int32_t j_30724 = local_i_30723 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                int32_t j_offset_30725 = hist_M_30696 * sext_i64_i32(histo_sizze_30703) * gid_in_segment_30715 + j_30724;\n                int32_t local_subhisto_i_30726 = squot32(j_30724, sext_i64_i32(histo_sizze_30703));\n                int32_t global_subhisto_i_30727 = squot32(j_offset_30725, sext_i64_i32(histo_sizze_30703));\n                \n                if (slt32(j_30724, hist_M_30696 * sext_i64_i32(histo_sizze_30703))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30727 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30677)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702) && slt64(sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702, mz2080U_18678)))) {\n                            int32_t tmp_30728 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(local_subhisto_i_30726) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703)))] = tmp_30728;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(local_subhisto_i_30726) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703)))] = 0;\n                        }\n                    }\n                }\n", "            }\n            for (int32_t local_i_30729 = 0; local_i_30729 < init_per_thread_30704; local_i_30729++) {\n                int32_t j_30730 = local_i_30729 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                int32_t j_offset_30731 = hist_M_30696 * sext_i64_i32(histo_sizze_30703) * gid_in_segment_30715 + j_30730;\n                int32_t local_subhisto_i_30732 = squot32(j_30730, sext_i64_i32(histo_sizze_30703));\n                int32_t global_subhisto_i_30733 = squot32(j_offset_30731, sext_i64_i32(histo_sizze_30703));\n                \n                if (slt32(j_30730, hist_M_30696 * sext_i64_i32(histo_sizze_30703))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30733 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30677)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702) && slt64(sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702, mz2080U_18678)))) {\n                            int32_t tmp_30734 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(local_subhisto_i_30732) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703)))] = tmp_30734;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(local_subhisto_i_30732) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barri", "er(CLK_LOCAL_MEM_FENCE);\n        num_chunks_30735 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27123, sext_i32_i64(threads_per_segment_30717));\n        for (int64_t chunk_i_30736 = 0; chunk_i_30736 < num_chunks_30735; chunk_i_30736++) {\n            int64_t i_30737 = chunk_i_30736 * sext_i32_i64(threads_per_segment_30717) + sext_i32_i64(pgtid_in_segment_30716);\n            \n            if (slt64(i_30737, loop_dz2081Uz2088Uz2087U_27123)) {\n                int64_t gtid_28592;\n                int32_t eta_p_28601;\n                int64_t ii_28602;\n                bool x_28603;\n                bool y_28604;\n                bool bounds_check_28605;\n                bool index_certs_28606;\n                float eta_p_28600;\n                float eq_arg1_28607;\n                bool defunc_0_eq_res_28608;\n                bool defunc_0_lt_res_28609;\n                int32_t bool_res_28610;\n                int32_t bool_res_28611;\n                \n                gtid_28592 = i_30737;\n                eta_p_28601 = ((__global int32_t *) mem_param_29728)[gtid_28592];\n                ii_28602 = sext_i32_i64(eta_p_28601);\n                x_28603 = sle64((int64_t) 0, ii_28602);\n                y_28604 = slt64(ii_28602, mz2080U_18678);\n                bounds_check_28605 = x_28603 && y_28604;\n                if (!bounds_check_28605) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                            global_failure_args[0] = (int64_t) ii_28602;\n                            global_failure_args[1] = (int64_t) mz2080U_18678;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                eta_p_28600 = ((__global float *) mem_param_29731)[gtid_28592];\n                eq_arg1_28607 = ((__global float *) mem_29740)[ii_28602];\n                defunc_0_eq_res_28608 = eta_p_28600 == eq_arg1_28607;\n             ",
                                    "   defunc_0_lt_res_28609 = eta_p_28600 < eq_arg1_28607;\n                bool_res_28610 = btoi_bool_i32(defunc_0_lt_res_28609);\n                bool_res_28611 = btoi_bool_i32(defunc_0_eq_res_28608);\n                if (chk_i_30700 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, ii_28602) && slt64(ii_28602, mz2080U_18678)) && (sle64(sext_i32_i64(chk_i_30700) * hist_H_chk_30702, ii_28602) && slt64(ii_28602, sext_i32_i64(chk_i_30700) * hist_H_chk_30702 + hist_H_chk_30702))) {\n                        int32_t eta_p_28594;\n                        int32_t eta_p_28595;\n                        int32_t eta_p_28596;\n                        int32_t eta_p_28597;\n                        \n                        eta_p_28596 = bool_res_28610;\n                        eta_p_28597 = bool_res_28611;\n                        \n                        int32_t old_30738;\n                        \n                        old_30738 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30718)[sext_i32_i64(thread_local_subhisto_i_30722) * hist_H_chk_30702 + (ii_28602 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702)], (int) eta_p_28596);\n                        \n                        int32_t old_30739;\n                        \n                        old_30739 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30720)[sext_i32_i64(thread_local_subhisto_i_30722) * hist_H_chk_30702 + (ii_28602 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702)], (int) eta_p_28597);\n                    }\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n", "            int64_t trunc_H_30740 = smin64(hist_H_chk_30702, mz2080U_18678 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702);\n            int32_t histo_sizze_30741 = sext_i64_i32(trunc_H_30740);\n            \n            for (int32_t local_i_30742 = 0; local_i_30742 < init_per_thread_30704; local_i_30742++) {\n                int32_t j_30743 = local_i_30742 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                \n                if (slt32(j_30743, histo_sizze_30741)) {\n                    int32_t eta_p_28594;\n                    int32_t eta_p_28595;\n                    int32_t eta_p_28596;\n                    int32_t eta_p_28597;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_28594 = ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(j_30743)];\n                        eta_p_28595 = ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(j_30743)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_30744 = 0; subhisto_id_30744 < hist_M_30696 - 1; subhisto_id_30744++) {\n                            eta_p_28596 = ((__local int32_t *) subhistogram_local_mem_30718)[(sext_i32_i64(subhisto_id_30744) + (int64_t) 1) * hist_H_chk_30702 + sext_i32_i64(j_30743)];\n                            eta_p_28597 = ((__local int32_t *) subhistogram_local_mem_30720)[(sext_i32_i64(subhisto_id_30744) + (int64_t) 1) * hist_H_chk_30702 + sext_i32_i64(j_30743)];\n                            \n                            int32_t tmp_28598 = add32(eta_p_28594, eta_p_28596);\n                            int32_t tmp_28599 = add32(eta_p_28595, eta_p_28597);\n                            \n                            eta_p_28594 = tmp_28598;\n                            eta_p_28595 = tmp_28599;\n                        }\n                    }\n                    // Put final bucke", "t value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[srem64(sext_i32_i64(virt_tblock_id_30713), num_tblocks_30690) * mz2080U_18678 + (sext_i32_i64(j_30743) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702)] = eta_p_28594;\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[srem64(sext_i32_i64(virt_tblock_id_30713), num_tblocks_30690) * mz2080U_18678 + (sext_i32_i64(j_30743) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702)] = eta_p_28595;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_30689\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegmap_28228_dim1, 1, 1)\nvoid human_genericf32zisegmap_28228(__global int *global_failure, int64_t mz2080U_18678, int64_t nz2081U_18679, int64_t num_tblocks_28233, int32_t virt_num_tblocks_29953, __global unsigned char *mem_29683, __global unsigned char *mem_29684)\n{\n    #define segmap_tblock_sizze_28231 (human_genericf32zisegmap_28228zisegmap_tblock_sizze_28231)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29955;\n    int32_t tblock_sizze_29958;\n    int32_t wave_sizze_29957;\n    int32_t block_id_29956;\n    int32_t global_tid_29954;\n    int64_t phys_tid_28228;\n    int32_t phys_tblock_id_29959;\n    int32_t iterations_29960;\n    \n    local_tid_29955 = get_local_id(0);\n    tblock_sizze_29958 = get_local_size(0);\n    wave_sizze_29957 = LOCKSTEP_WIDTH;\n    block_id_29956 = get_tblock_id(0);\n    global_tid_29954 = block_id_29956 * tblock_sizze_29958 + local_tid_29955;\n    phys_tid_28228 = sext_i32_i64(global_tid_29954);\n    phys_tblock_id_29959 = get_tblock_id(0);\n    iterations_29960 = sdiv_up32(virt_num_tblocks_29953 - phys_tblock_id_29959, sext_i64_i32(num_tblocks_28233));\n    for (int32_t i_29961 = 0; i_29961 < iterations_29960; i_29961++) {\n        int32_t virt_tblock_id_",
                                    "29962;\n        int64_t global_tid_29963;\n        int64_t slice_29964;\n        int64_t write_i_28227;\n        int64_t remnant_29965;\n        \n        virt_tblock_id_29962 = phys_tblock_id_29959 + i_29961 * sext_i64_i32(num_tblocks_28233);\n        global_tid_29963 = sext_i32_i64(virt_tblock_id_29962) * segmap_tblock_sizze_28231 + sext_i32_i64(local_tid_29955);\n        slice_29964 = mz2080U_18678;\n        write_i_28227 = global_tid_29963;\n        remnant_29965 = global_tid_29963 - write_i_28227;\n        if (slt64(write_i_28227, mz2080U_18678)) {\n            int64_t zv_lhs_27696;\n            int64_t tmp_27697;\n            bool cond_27700;\n            int64_t lifted_lambda_res_27701;\n            \n            zv_lhs_27696 = add64((int64_t) -1, write_i_28227);\n            tmp_27697 = smod64(zv_lhs_27696, mz2080U_18678);\n            cond_27700 = write_i_28227 == (int64_t) 0;\n            if (cond_27700) {\n                lifted_lambda_res_27701 = (int64_t) 0;\n            } else {\n                int64_t lifted_lambda_res_27698 = ((__global int64_t *) mem_29683)[tmp_27697];\n                \n                lifted_lambda_res_27701 = lifted_lambda_res_27698;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27701) && slt64(lifted_lambda_res_27701, nz2081U_18679)) {\n                ((__global bool *) mem_29684)[lifted_lambda_res_27701] = 1;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_28231\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegmap_28278_dim1, 1, 1)\nvoid human_genericf32zisegmap_28278(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_18678, int64_t nz2081U_18679, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29689, __global unsigned char *mem_29692, __global unsigned char *mem_29695)\n{\n    #define segmap_tblock_sizze_28274 (human_genericf32zisegmap_28278zisegmap_tblock_siz", "ze_28274)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30231;\n    int32_t tblock_sizze_30234;\n    int32_t wave_sizze_30233;\n    int32_t block_id_30232;\n    int32_t global_tid_30230;\n    int64_t phys_tid_28278;\n    int64_t global_tid_30235;\n    int64_t slice_30236;\n    int64_t gtid_28277;\n    int64_t remnant_30237;\n    \n    local_tid_30231 = get_local_id(0);\n    tblock_sizze_30234 = get_local_size(0);\n    wave_sizze_30233 = LOCKSTEP_WIDTH;\n    block_id_30232 = get_tblock_id(0);\n    global_tid_30230 = block_id_30232 * tblock_sizze_30234 + local_tid_30231;\n    phys_tid_28278 = sext_i32_i64(global_tid_30230);\n    global_tid_30235 = sext_i32_i64(block_id_30232) * segmap_tblock_sizze_28274 + sext_i32_i64(local_tid_30231);\n    slice_30236 = mz2080U_18678;\n    gtid_28277 = global_tid_30235;\n    remnant_30237 = global_tid_30235 - gtid_28277;\n    if (slt64(gtid_28277, mz2080U_18678)) {\n        int32_t eta_p_28280;\n        bool cond_28282;\n        float lifted_lambda_res_28283;\n        float i32_res_28291;\n        float defunc_0_div_res_28292;\n        \n        eta_p_28280 = ((__global int32_t *) shp_mem_29678)[gtid_28277];\n        cond_28282 = eta_p_28280 == 0;\n        if (cond_28282) {\n            lifted_lambda_res_28283 = 0.0F;\n        } else {\n            int32_t eta_p_28279;\n            int32_t tmp_28284;\n            int64_t tmp_28285;\n            bool x_28286;\n            bool y_28287;\n            bool bounds_check_28288;\n            bool index_certs_28289;\n            float lifted_lambda_res_f_res_28290;\n            \n            eta_p_28279 = ((__global int32_t *) mem_29692)[gtid_28277];\n            tmp_28284 = sub32(eta_p_28279, 1);\n            tmp_28285 = sext_i32_i64(tmp_28284);\n            x_28286 = sle64((int64_t) 0, tmp_28285);\n            y_28287 = slt64(tmp_28285, nz2081U_18679);\n            bounds_check_28288 = x_28286 && y_28287;\n            if (!bounds_check_28288) {\n                {\n                    if (atomic_cmpxchg_i32_globa", "l(global_failure, -1, 0) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_28285;\n                        global_failure_args[1] = (int64_t) nz2081U_18679;\n                        ;\n                    }\n                    return;\n                }\n            }\n            lifted_lambda_res_f_res_28290 = ((__global float *) mem_29689)[tmp_28285];\n            lifted_lambda_res_28283 = lifted_lambda_res_f_res_28290;\n        }\n        i32_res_28291 = sitofp_i32_f32(eta_p_28280);\n        defunc_0_div_res_28292 = lifted_lambda_res_28283 / i32_res_28291;\n        ((__global float *) mem_29695)[gtid_28277] = defunc_0_div_res_28292;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_28274\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegmap_28364_dim1, 1, 1)\nvoid human_genericf32zisegmap_28364(__global int *global_failure, int64_t mz2080U_18678, __global unsigned char *ks_mem_29677, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29695, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *mem_29703, __global unsigned char *mem_29705, __global unsigned char *mem_29707, __global unsigned char *mem_29709)\n{\n    #define segmap_tblock_sizze_28357 (human_genericf32zisegmap_28364zisegmap_tblock_sizze_28357)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30428;\n    int32_t tblock_sizze_30431;\n    int32_t wave_sizze_30430;\n    int32_t block_id_30429;\n    int32_t global_tid_30427;\n    int64_t phys_tid_28364;\n    int64_t global_tid_30432;\n    int64_t slice_30433;\n    int64_t gtid_28363;\n    int64_t remnant_30434;\n    \n    local_tid_30428 = get_local_id(0);\n    tblock_sizze_30431 = get_local_size(0);\n    wave_sizze_30430 = LOCKSTEP_WIDTH;\n    block_id_30429 = get_tblock_id(0);\n    global_tid_30427 = block_id_30429 * tblock_sizze_30431 + local_tid_30428;\n    phys_tid_28364 = sext_i32_i64(global_tid_30427);\n    global_tid_30432 = sext_i32_i64(block_id_30429) * segmap_tblo",
                                    "ck_sizze_28357 + sext_i32_i64(local_tid_30428);\n    slice_30433 = mz2080U_18678;\n    gtid_28363 = global_tid_30432;\n    remnant_30434 = global_tid_30432 - gtid_28363;\n    if (slt64(gtid_28363, mz2080U_18678)) {\n        int32_t eta_p_28365;\n        int32_t eta_p_28366;\n        int32_t eta_p_28367;\n        int32_t eta_p_28368;\n        bool cond_28370;\n        int32_t lifted_lambda_res_28371;\n        bool cond_28377;\n        float lifted_lambda_res_28378;\n        bool cond_28379;\n        int32_t lifted_lambda_res_28380;\n        int32_t lifted_lambda_res_28386;\n        \n        eta_p_28365 = ((__global int32_t *) mem_29699)[gtid_28363];\n        eta_p_28366 = ((__global int32_t *) mem_29697)[gtid_28363];\n        eta_p_28367 = ((__global int32_t *) shp_mem_29678)[gtid_28363];\n        eta_p_28368 = ((__global int32_t *) ks_mem_29677)[gtid_28363];\n        cond_28370 = eta_p_28367 == 0;\n        if (cond_28370) {\n            lifted_lambda_res_28371 = -1;\n        } else {\n            bool cond_28372;\n            int32_t lifted_lambda_res_f_res_28373;\n            \n            cond_28372 = sle32(eta_p_28368, eta_p_28365);\n            if (cond_28372) {\n                lifted_lambda_res_f_res_28373 = 0;\n            } else {\n                int32_t zlze_rhs_28374;\n                bool cond_28375;\n                int32_t lifted_lambda_res_f_res_f_res_28376;\n                \n                zlze_rhs_28374 = add32(eta_p_28365, eta_p_28366);\n                cond_28375 = sle32(eta_p_28368, zlze_rhs_28374);\n                if (cond_28375) {\n                    lifted_lambda_res_f_res_f_res_28376 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_28376 = 2;\n                }\n                lifted_lambda_res_f_res_28373 = lifted_lambda_res_f_res_f_res_28376;\n            }\n            lifted_lambda_res_28371 = lifted_lambda_res_f_res_28373;\n        }\n        cond_28377 = lifted_lambda_res_28371 == 1;\n        if (cond_28377) {\n            float eta_p_28369 = ((_", "_global float *) mem_29695)[gtid_28363];\n            \n            lifted_lambda_res_28378 = eta_p_28369;\n        } else {\n            lifted_lambda_res_28378 = 0.0F;\n        }\n        cond_28379 = lifted_lambda_res_28371 == -1;\n        if (cond_28379) {\n            lifted_lambda_res_28380 = -1;\n        } else {\n            bool cond_28381;\n            int32_t lifted_lambda_res_f_res_28382;\n            \n            cond_28381 = lifted_lambda_res_28371 == 0;\n            if (cond_28381) {\n                lifted_lambda_res_f_res_28382 = eta_p_28368;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_28383;\n                \n                if (cond_28377) {\n                    lifted_lambda_res_f_res_f_res_28383 = -1;\n                } else {\n                    int32_t zm_lhs_28384;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_28385;\n                    \n                    zm_lhs_28384 = sub32(eta_p_28368, eta_p_28365);\n                    lifted_lambda_res_f_res_f_res_f_res_28385 = sub32(zm_lhs_28384, eta_p_28366);\n                    lifted_lambda_res_f_res_f_res_28383 = lifted_lambda_res_f_res_f_res_f_res_28385;\n                }\n                lifted_lambda_res_f_res_28382 = lifted_lambda_res_f_res_f_res_28383;\n            }\n            lifted_lambda_res_28380 = lifted_lambda_res_f_res_28382;\n        }\n        if (cond_28379) {\n            lifted_lambda_res_28386 = 0;\n        } else {\n            bool cond_28387;\n            int32_t lifted_lambda_res_f_res_28388;\n            \n            cond_28387 = lifted_lambda_res_28371 == 0;\n            if (cond_28387) {\n                lifted_lambda_res_f_res_28388 = eta_p_28365;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_28389;\n                \n                if (cond_28377) {\n                    lifted_lambda_res_f_res_f_res_28389 = 0;\n                } else {\n                    int32_t zm_lhs_28390;\n                    int32_t lifted_lambda_res_f", "_res_f_res_f_res_28391;\n                    \n                    zm_lhs_28390 = sub32(eta_p_28367, eta_p_28365);\n                    lifted_lambda_res_f_res_f_res_f_res_28391 = sub32(zm_lhs_28390, eta_p_28366);\n                    lifted_lambda_res_f_res_f_res_28389 = lifted_lambda_res_f_res_f_res_f_res_28391;\n                }\n                lifted_lambda_res_f_res_28388 = lifted_lambda_res_f_res_f_res_28389;\n            }\n            lifted_lambda_res_28386 = lifted_lambda_res_f_res_28388;\n        }\n        ((__global int32_t *) mem_29703)[gtid_28363] = lifted_lambda_res_28386;\n        ((__global int32_t *) mem_29705)[gtid_28363] = lifted_lambda_res_28380;\n        ((__global float *) mem_29707)[gtid_28363] = lifted_lambda_res_28378;\n        ((__global int32_t *) mem_29709)[gtid_28363] = lifted_lambda_res_28371;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_28357\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegmap_28401_dim1, 1, 1)\nvoid human_genericf32zisegmap_28401(__global int *global_failure, int64_t nz2081U_18679, int64_t m_27087, int64_t num_tblocks_28406, int32_t virt_num_tblocks_30539, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29712, __global unsigned char *mem_29714, __global unsigned char *mem_29716, __global unsigned char *mem_29718)\n{\n    #define segmap_tblock_sizze_28404 (human_genericf32zisegmap_28401zisegmap_tblock_sizze_28404)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30541;\n    int32_t tblock_sizze_30544;\n    int32_t wave_sizze_30543;\n    int32_t block_id_30542;\n    int32_t global_tid_30540;\n    int64_t phys_tid_28401;\n    int32_t phys_tblock_id_30545;\n    int32_t iterations_30546;\n    \n    local_tid_30541 = get_local_id(0);\n    tblock_sizze_30544 = get_local_size(0);\n    wave_sizze_30543 = LOCKSTEP_WIDTH;\n    block_id_30542 = get_tblock_id(0);\n    global_tid_30540 = block_id_30542 * tblock_sizze_30544 + local_tid_30541;\n    phys_tid_28401 =",
                                    " sext_i32_i64(global_tid_30540);\n    phys_tblock_id_30545 = get_tblock_id(0);\n    iterations_30546 = sdiv_up32(virt_num_tblocks_30539 - phys_tblock_id_30545, sext_i64_i32(num_tblocks_28406));\n    for (int32_t i_30547 = 0; i_30547 < iterations_30546; i_30547++) {\n        int32_t virt_tblock_id_30548;\n        int64_t global_tid_30549;\n        int64_t slice_30550;\n        int64_t write_i_28400;\n        int64_t remnant_30551;\n        \n        virt_tblock_id_30548 = phys_tblock_id_30545 + i_30547 * sext_i64_i32(num_tblocks_28406);\n        global_tid_30549 = sext_i32_i64(virt_tblock_id_30548) * segmap_tblock_sizze_28404 + sext_i32_i64(local_tid_30541);\n        slice_30550 = nz2081U_18679;\n        write_i_28400 = global_tid_30549;\n        remnant_30551 = global_tid_30549 - write_i_28400;\n        if (slt64(write_i_28400, nz2081U_18679)) {\n            int64_t eta_p_27397;\n            float write_value_27399;\n            int32_t write_value_27400;\n            bool cond_27401;\n            int64_t lifted_lambda_res_27402;\n            \n            eta_p_27397 = ((__global int64_t *) mem_29714)[write_i_28400];\n            write_value_27399 = ((__global float *) A_mem_29680)[write_i_28400];\n            write_value_27400 = ((__global int32_t *) II1_mem_29679)[write_i_28400];\n            cond_27401 = eta_p_27397 == (int64_t) 1;\n            if (cond_27401) {\n                int64_t eta_p_27398;\n                int64_t lifted_lambda_res_t_res_28152;\n                \n                eta_p_27398 = ((__global int64_t *) mem_29712)[write_i_28400];\n                lifted_lambda_res_t_res_28152 = sub64(eta_p_27398, (int64_t) 1);\n                lifted_lambda_res_27402 = lifted_lambda_res_t_res_28152;\n            } else {\n                lifted_lambda_res_27402 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27402) && slt64(lifted_lambda_res_27402, m_27087)) {\n                ((__global float *) mem_29718)[lifted_lambda_res_27402] = write_value_27399;\n     ", "       }\n            if (sle64((int64_t) 0, lifted_lambda_res_27402) && slt64(lifted_lambda_res_27402, m_27087)) {\n                ((__global int32_t *) mem_29716)[lifted_lambda_res_27402] = write_value_27400;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_28404\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegmap_28506_dim1, 1, 1)\nvoid human_genericf32zisegmap_28506(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_18678, int64_t loop_dz2081Uz2088Uz2087U_27123, __global unsigned char *mem_param_29725, __global unsigned char *mem_param_29731, __global unsigned char *mem_29737, __global unsigned char *mem_29740)\n{\n    #define segmap_tblock_sizze_28502 (human_genericf32zisegmap_28506zisegmap_tblock_sizze_28502)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30669;\n    int32_t tblock_sizze_30672;\n    int32_t wave_sizze_30671;\n    int32_t block_id_30670;\n    int32_t global_tid_30668;\n    int64_t phys_tid_28506;\n    int64_t global_tid_30673;\n    int64_t slice_30674;\n    int64_t gtid_28505;\n    int64_t remnant_30675;\n    \n    local_tid_30669 = get_local_id(0);\n    tblock_sizze_30672 = get_local_size(0);\n    wave_sizze_30671 = LOCKSTEP_WIDTH;\n    block_id_30670 = get_tblock_id(0);\n    global_tid_30668 = block_id_30670 * tblock_sizze_30672 + local_tid_30669;\n    phys_tid_28506 = sext_i32_i64(global_tid_30668);\n    global_tid_30673 = sext_i32_i64(block_id_30670) * segmap_tblock_sizze_28502 + sext_i32_i64(local_tid_30669);\n    slice_30674 = mz2080U_18678;\n    gtid_28505 = global_tid_30673;\n    remnant_30675 = global_tid_30673 - gtid_28505;\n    if (slt64(gtid_28505, mz2080U_18678)) {\n        int32_t eta_p_28508;\n        int64_t zv_lhs_28509;\n        int64_t tmp_28510;\n        bool cond_28512;\n        int32_t lifted_lambda_res_28513;\n        bool cond_28514;\n        float defunc_0_f_res_28515;\n  ", "      \n        eta_p_28508 = ((__global int32_t *) mem_param_29725)[gtid_28505];\n        zv_lhs_28509 = add64((int64_t) -1, gtid_28505);\n        tmp_28510 = smod64(zv_lhs_28509, mz2080U_18678);\n        cond_28512 = gtid_28505 == (int64_t) 0;\n        if (cond_28512) {\n            lifted_lambda_res_28513 = 0;\n        } else {\n            int32_t lifted_lambda_res_28511 = ((__global int32_t *) mem_29737)[tmp_28510];\n            \n            lifted_lambda_res_28513 = lifted_lambda_res_28511;\n        }\n        cond_28514 = eta_p_28508 == 0;\n        if (cond_28514) {\n            defunc_0_f_res_28515 = 0.0F;\n        } else {\n            bool cond_28516;\n            float defunc_0_f_res_f_res_28517;\n            \n            cond_28516 = eta_p_28508 == 1;\n            if (cond_28516) {\n                int64_t off_28518;\n                bool x_28519;\n                bool y_28520;\n                bool bounds_check_28521;\n                bool index_certs_28522;\n                float defunc_0_f_res_f_res_t_res_28523;\n                \n                off_28518 = sext_i32_i64(lifted_lambda_res_28513);\n                x_28519 = sle64((int64_t) 0, off_28518);\n                y_28520 = slt64(off_28518, loop_dz2081Uz2088Uz2087U_27123);\n                bounds_check_28521 = x_28519 && y_28520;\n                if (!bounds_check_28521) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                            global_failure_args[0] = (int64_t) off_28518;\n                            global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27123;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                defunc_0_f_res_f_res_t_res_28523 = ((__global float *) mem_param_29731)[off_28518];\n                defunc_0_f_res_f_res_28517 = defunc_0_f_res_f_res_t_res_28523;\n            } else {\n                bool cond_28524;\n                float defu",
                                    "nc_0_f_res_f_res_f_res_28525;\n                \n                cond_28524 = eta_p_28508 == 2;\n                if (cond_28524) {\n                    int64_t off_28526;\n                    bool x_28527;\n                    bool y_28528;\n                    bool bounds_check_28529;\n                    bool index_certs_28530;\n                    float defunc_0_f_res_f_res_f_res_t_res_28531;\n                    \n                    off_28526 = sext_i32_i64(lifted_lambda_res_28513);\n                    x_28527 = sle64((int64_t) 0, off_28526);\n                    y_28528 = slt64(off_28526, loop_dz2081Uz2088Uz2087U_27123);\n                    bounds_check_28529 = x_28527 && y_28528;\n                    if (!bounds_check_28529) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                                global_failure_args[0] = (int64_t) off_28526;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27123;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    defunc_0_f_res_f_res_f_res_t_res_28531 = ((__global float *) mem_param_29731)[off_28526];\n                    defunc_0_f_res_f_res_f_res_28525 = defunc_0_f_res_f_res_f_res_t_res_28531;\n                } else {\n                    int64_t off_28532;\n                    bool x_28533;\n                    bool y_28534;\n                    bool bounds_check_28535;\n                    bool index_certs_28536;\n                    int32_t zp_rhs_28538;\n                    int32_t mid_28539;\n                    int64_t mid_28540;\n                    bool x_28541;\n                    bool y_28542;\n                    bool bounds_check_28543;\n                    bool index_certs_28544;\n                    int32_t zm_lhs_28546;\n                    int32_t last_28547;\n                    int64_t last_28548;\n   ", "                 bool x_28549;\n                    bool y_28550;\n                    bool bounds_check_28551;\n                    bool index_certs_28552;\n                    float first_28537;\n                    float mid_28545;\n                    float last_28553;\n                    bool defunc_0_lt_res_28554;\n                    bool defunc_0_eq_res_28555;\n                    bool x_28556;\n                    bool y_28557;\n                    bool cond_28558;\n                    float defunc_0_median3_res_28559;\n                    \n                    off_28532 = sext_i32_i64(lifted_lambda_res_28513);\n                    x_28533 = sle64((int64_t) 0, off_28532);\n                    y_28534 = slt64(off_28532, loop_dz2081Uz2088Uz2087U_27123);\n                    bounds_check_28535 = x_28533 && y_28534;\n                    if (!bounds_check_28535) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                                global_failure_args[0] = (int64_t) off_28532;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27123;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    zp_rhs_28538 = sdiv32(eta_p_28508, 2);\n                    mid_28539 = add32(lifted_lambda_res_28513, zp_rhs_28538);\n                    mid_28540 = sext_i32_i64(mid_28539);\n                    x_28541 = sle64((int64_t) 0, mid_28540);\n                    y_28542 = slt64(mid_28540, loop_dz2081Uz2088Uz2087U_27123);\n                    bounds_check_28543 = x_28541 && y_28542;\n                    if (!bounds_check_28543) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1) {\n                                global_failure_args[0] = (int64_t) mid_28540;\n                                global_failure_args[1] = (", "int64_t) loop_dz2081Uz2088Uz2087U_27123;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    zm_lhs_28546 = add32(eta_p_28508, lifted_lambda_res_28513);\n                    last_28547 = sub32(zm_lhs_28546, 1);\n                    last_28548 = sext_i32_i64(last_28547);\n                    x_28549 = sle64((int64_t) 0, last_28548);\n                    y_28550 = slt64(last_28548, loop_dz2081Uz2088Uz2087U_27123);\n                    bounds_check_28551 = x_28549 && y_28550;\n                    if (!bounds_check_28551) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n                                global_failure_args[0] = (int64_t) last_28548;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27123;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    first_28537 = ((__global float *) mem_param_29731)[off_28532];\n                    mid_28545 = ((__global float *) mem_param_29731)[mid_28540];\n                    last_28553 = ((__global float *) mem_param_29731)[last_28548];\n                    defunc_0_lt_res_28554 = first_28537 < mid_28545;\n                    defunc_0_eq_res_28555 = first_28537 == mid_28545;\n                    x_28556 = !defunc_0_lt_res_28554;\n                    y_28557 = defunc_0_eq_res_28555 && x_28556;\n                    cond_28558 = defunc_0_lt_res_28554 || y_28557;\n                    if (cond_28558) {\n                        bool defunc_0_lt_res_28560;\n                        bool defunc_0_eq_res_28561;\n                        bool x_28562;\n                        bool y_28563;\n                        bool cond_28564;\n                        float defunc_0_median3_res_t_res_28565;\n                        \n   ",
                                    "                     defunc_0_lt_res_28560 = mid_28545 < last_28553;\n                        defunc_0_eq_res_28561 = mid_28545 == last_28553;\n                        x_28562 = !defunc_0_lt_res_28560;\n                        y_28563 = defunc_0_eq_res_28561 && x_28562;\n                        cond_28564 = defunc_0_lt_res_28560 || y_28563;\n                        if (cond_28564) {\n                            defunc_0_median3_res_t_res_28565 = mid_28545;\n                        } else {\n                            bool defunc_0_lt_res_28566;\n                            bool defunc_0_eq_res_28567;\n                            bool x_28568;\n                            bool y_28569;\n                            bool cond_28570;\n                            float defunc_0_median3_res_t_res_f_res_28571;\n                            \n                            defunc_0_lt_res_28566 = first_28537 < last_28553;\n                            defunc_0_eq_res_28567 = first_28537 == last_28553;\n                            x_28568 = !defunc_0_lt_res_28566;\n                            y_28569 = defunc_0_eq_res_28567 && x_28568;\n                            cond_28570 = defunc_0_lt_res_28566 || y_28569;\n                            if (cond_28570) {\n                                defunc_0_median3_res_t_res_f_res_28571 = last_28553;\n                            } else {\n                                defunc_0_median3_res_t_res_f_res_28571 = first_28537;\n                            }\n                            defunc_0_median3_res_t_res_28565 = defunc_0_median3_res_t_res_f_res_28571;\n                        }\n                        defunc_0_median3_res_28559 = defunc_0_median3_res_t_res_28565;\n                    } else {\n                        bool defunc_0_lt_res_28572;\n                        bool defunc_0_eq_res_28573;\n                        bool x_28574;\n                        bool y_28575;\n                        bool cond_28576;\n                        float defunc_0_median3_res_f", "_res_28577;\n                        \n                        defunc_0_lt_res_28572 = first_28537 < last_28553;\n                        defunc_0_eq_res_28573 = first_28537 == last_28553;\n                        x_28574 = !defunc_0_lt_res_28572;\n                        y_28575 = defunc_0_eq_res_28573 && x_28574;\n                        cond_28576 = defunc_0_lt_res_28572 || y_28575;\n                        if (cond_28576) {\n                            defunc_0_median3_res_f_res_28577 = first_28537;\n                        } else {\n                            bool defunc_0_lt_res_28578;\n                            bool defunc_0_eq_res_28579;\n                            bool x_28580;\n                            bool y_28581;\n                            bool cond_28582;\n                            float defunc_0_median3_res_f_res_f_res_28583;\n                            \n                            defunc_0_lt_res_28578 = mid_28545 < last_28553;\n                            defunc_0_eq_res_28579 = mid_28545 == last_28553;\n                            x_28580 = !defunc_0_lt_res_28578;\n                            y_28581 = defunc_0_eq_res_28579 && x_28580;\n                            cond_28582 = defunc_0_lt_res_28578 || y_28581;\n                            if (cond_28582) {\n                                defunc_0_median3_res_f_res_f_res_28583 = last_28553;\n                            } else {\n                                defunc_0_median3_res_f_res_f_res_28583 = mid_28545;\n                            }\n                            defunc_0_median3_res_f_res_28577 = defunc_0_median3_res_f_res_f_res_28583;\n                        }\n                        defunc_0_median3_res_28559 = defunc_0_median3_res_f_res_28577;\n                    }\n                    defunc_0_f_res_f_res_f_res_28525 = defunc_0_median3_res_28559;\n                }\n                defunc_0_f_res_f_res_28517 = defunc_0_f_res_f_res_f_res_28525;\n            }\n            defunc_0_f_res_28515 = defunc_0_f_", "res_f_res_28517;\n        }\n        ((__global float *) mem_29740)[gtid_28505] = defunc_0_f_res_28515;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_28502\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegmap_28656_dim1, 1, 1)\nvoid human_genericf32zisegmap_28656(__global int *global_failure, int64_t mz2080U_18678, __global unsigned char *mem_param_29722, __global unsigned char *mem_param_29725, __global unsigned char *mem_param_29734, __global unsigned char *mem_29740, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *mem_29748, __global unsigned char *mem_29750, __global unsigned char *mem_29752, __global unsigned char *mem_29754)\n{\n    #define segmap_tblock_sizze_28649 (human_genericf32zisegmap_28656zisegmap_tblock_sizze_28649)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30866;\n    int32_t tblock_sizze_30869;\n    int32_t wave_sizze_30868;\n    int32_t block_id_30867;\n    int32_t global_tid_30865;\n    int64_t phys_tid_28656;\n    int64_t global_tid_30870;\n    int64_t slice_30871;\n    int64_t gtid_28655;\n    int64_t remnant_30872;\n    \n    local_tid_30866 = get_local_id(0);\n    tblock_sizze_30869 = get_local_size(0);\n    wave_sizze_30868 = LOCKSTEP_WIDTH;\n    block_id_30867 = get_tblock_id(0);\n    global_tid_30865 = block_id_30867 * tblock_sizze_30869 + local_tid_30866;\n    phys_tid_28656 = sext_i32_i64(global_tid_30865);\n    global_tid_30870 = sext_i32_i64(block_id_30867) * segmap_tblock_sizze_28649 + sext_i32_i64(local_tid_30866);\n    slice_30871 = mz2080U_18678;\n    gtid_28655 = global_tid_30870;\n    remnant_30872 = global_tid_30870 - gtid_28655;\n    if (slt64(gtid_28655, mz2080U_18678)) {\n        int32_t eta_p_28657;\n        int32_t eta_p_28658;\n        int32_t eta_p_28659;\n        int32_t eta_p_28660;\n        bool cond_28663;\n        int32_t lifted_lambda_res_28664;\n        bool cond_28670;\n        float lifted_lambda_res_28671;\n        bool cond_28672;\n        int32_t lifted_lam",
                                    "bda_res_28673;\n        int32_t lifted_lambda_res_28679;\n        \n        eta_p_28657 = ((__global int32_t *) mem_29744)[gtid_28655];\n        eta_p_28658 = ((__global int32_t *) mem_29742)[gtid_28655];\n        eta_p_28659 = ((__global int32_t *) mem_param_29725)[gtid_28655];\n        eta_p_28660 = ((__global int32_t *) mem_param_29722)[gtid_28655];\n        cond_28663 = eta_p_28659 == 0;\n        if (cond_28663) {\n            lifted_lambda_res_28664 = -1;\n        } else {\n            bool cond_28665;\n            int32_t lifted_lambda_res_f_res_28666;\n            \n            cond_28665 = sle32(eta_p_28660, eta_p_28657);\n            if (cond_28665) {\n                lifted_lambda_res_f_res_28666 = 0;\n            } else {\n                int32_t zlze_rhs_28667;\n                bool cond_28668;\n                int32_t lifted_lambda_res_f_res_f_res_28669;\n                \n                zlze_rhs_28667 = add32(eta_p_28657, eta_p_28658);\n                cond_28668 = sle32(eta_p_28660, zlze_rhs_28667);\n                if (cond_28668) {\n                    lifted_lambda_res_f_res_f_res_28669 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_28669 = 2;\n                }\n                lifted_lambda_res_f_res_28666 = lifted_lambda_res_f_res_f_res_28669;\n            }\n            lifted_lambda_res_28664 = lifted_lambda_res_f_res_28666;\n        }\n        cond_28670 = lifted_lambda_res_28664 == 1;\n        if (cond_28670) {\n            float eta_p_28662 = ((__global float *) mem_29740)[gtid_28655];\n            \n            lifted_lambda_res_28671 = eta_p_28662;\n        } else {\n            float eta_p_28661 = ((__global float *) mem_param_29734)[gtid_28655];\n            \n            lifted_lambda_res_28671 = eta_p_28661;\n        }\n        cond_28672 = lifted_lambda_res_28664 == -1;\n        if (cond_28672) {\n            lifted_lambda_res_28673 = -1;\n        } else {\n            bool cond_28674;\n            int32_t lifted_lambda_res_f_res_28675;\n        ", "    \n            cond_28674 = lifted_lambda_res_28664 == 0;\n            if (cond_28674) {\n                lifted_lambda_res_f_res_28675 = eta_p_28660;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_28676;\n                \n                if (cond_28670) {\n                    lifted_lambda_res_f_res_f_res_28676 = -1;\n                } else {\n                    int32_t zm_lhs_28677;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_28678;\n                    \n                    zm_lhs_28677 = sub32(eta_p_28660, eta_p_28657);\n                    lifted_lambda_res_f_res_f_res_f_res_28678 = sub32(zm_lhs_28677, eta_p_28658);\n                    lifted_lambda_res_f_res_f_res_28676 = lifted_lambda_res_f_res_f_res_f_res_28678;\n                }\n                lifted_lambda_res_f_res_28675 = lifted_lambda_res_f_res_f_res_28676;\n            }\n            lifted_lambda_res_28673 = lifted_lambda_res_f_res_28675;\n        }\n        if (cond_28672) {\n            lifted_lambda_res_28679 = 0;\n        } else {\n            bool cond_28680;\n            int32_t lifted_lambda_res_f_res_28681;\n            \n            cond_28680 = lifted_lambda_res_28664 == 0;\n            if (cond_28680) {\n                lifted_lambda_res_f_res_28681 = eta_p_28657;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_28682;\n                \n                if (cond_28670) {\n                    lifted_lambda_res_f_res_f_res_28682 = 0;\n                } else {\n                    int32_t zm_lhs_28683;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_28684;\n                    \n                    zm_lhs_28683 = sub32(eta_p_28659, eta_p_28657);\n                    lifted_lambda_res_f_res_f_res_f_res_28684 = sub32(zm_lhs_28683, eta_p_28658);\n                    lifted_lambda_res_f_res_f_res_28682 = lifted_lambda_res_f_res_f_res_f_res_28684;\n                }\n                lifted_lambda_res_f_res_28681 = lifted_lambda_res_f_res", "_f_res_28682;\n            }\n            lifted_lambda_res_28679 = lifted_lambda_res_f_res_28681;\n        }\n        ((__global int32_t *) mem_29748)[gtid_28655] = lifted_lambda_res_28679;\n        ((__global int32_t *) mem_29750)[gtid_28655] = lifted_lambda_res_28673;\n        ((__global float *) mem_29752)[gtid_28655] = lifted_lambda_res_28671;\n        ((__global int32_t *) mem_29754)[gtid_28655] = lifted_lambda_res_28664;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_28649\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegmap_28694_dim1, 1, 1)\nvoid human_genericf32zisegmap_28694(__global int *global_failure, int64_t loop_dz2081Uz2088Uz2087U_27123, int64_t m_27343, int64_t num_tblocks_28699, int32_t virt_num_tblocks_30977, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29757, __global unsigned char *mem_29759, __global unsigned char *mem_29761, __global unsigned char *mem_29763)\n{\n    #define segmap_tblock_sizze_28697 (human_genericf32zisegmap_28694zisegmap_tblock_sizze_28697)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30979;\n    int32_t tblock_sizze_30982;\n    int32_t wave_sizze_30981;\n    int32_t block_id_30980;\n    int32_t global_tid_30978;\n    int64_t phys_tid_28694;\n    int32_t phys_tblock_id_30983;\n    int32_t iterations_30984;\n    \n    local_tid_30979 = get_local_id(0);\n    tblock_sizze_30982 = get_local_size(0);\n    wave_sizze_30981 = LOCKSTEP_WIDTH;\n    block_id_30980 = get_tblock_id(0);\n    global_tid_30978 = block_id_30980 * tblock_sizze_30982 + local_tid_30979;\n    phys_tid_28694 = sext_i32_i64(global_tid_30978);\n    phys_tblock_id_30983 = get_tblock_id(0);\n    iterations_30984 = sdiv_up32(virt_num_tblocks_30977 - phys_tblock_id_30983, sext_i64_i32(num_tblocks_28699));\n    for (int32_t i_30985 = 0; i_30985 < iterations_30984; i_30985++) {\n        int32_t virt_tblock_id_30986;\n        int64_t global_tid_30987;\n        int64_t slice_30988;\n        int64_",
                                    "t write_i_28693;\n        int64_t remnant_30989;\n        \n        virt_tblock_id_30986 = phys_tblock_id_30983 + i_30985 * sext_i64_i32(num_tblocks_28699);\n        global_tid_30987 = sext_i32_i64(virt_tblock_id_30986) * segmap_tblock_sizze_28697 + sext_i32_i64(local_tid_30979);\n        slice_30988 = loop_dz2081Uz2088Uz2087U_27123;\n        write_i_28693 = global_tid_30987;\n        remnant_30989 = global_tid_30987 - write_i_28693;\n        if (slt64(write_i_28693, loop_dz2081Uz2088Uz2087U_27123)) {\n            int64_t eta_p_27730;\n            float write_value_27732;\n            int32_t write_value_27733;\n            bool cond_27734;\n            int64_t lifted_lambda_res_27735;\n            \n            eta_p_27730 = ((__global int64_t *) mem_29759)[write_i_28693];\n            write_value_27732 = ((__global float *) mem_param_29731)[write_i_28693];\n            write_value_27733 = ((__global int32_t *) mem_param_29728)[write_i_28693];\n            cond_27734 = eta_p_27730 == (int64_t) 1;\n            if (cond_27734) {\n                int64_t eta_p_27731;\n                int64_t lifted_lambda_res_t_res_28180;\n                \n                eta_p_27731 = ((__global int64_t *) mem_29757)[write_i_28693];\n                lifted_lambda_res_t_res_28180 = sub64(eta_p_27731, (int64_t) 1);\n                lifted_lambda_res_27735 = lifted_lambda_res_t_res_28180;\n            } else {\n                lifted_lambda_res_27735 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27735) && slt64(lifted_lambda_res_27735, m_27343)) {\n                ((__global float *) mem_29763)[lifted_lambda_res_27735] = write_value_27732;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27735) && slt64(lifted_lambda_res_27735, m_27343)) {\n                ((__global int32_t *) mem_29761)[lifted_lambda_res_27735] = write_value_27733;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #unde", "f segmap_tblock_sizze_28697\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegred_large_30337_dim1, 1, 1)\nvoid human_genericf32zisegred_large_30337(__global int *global_failure, int64_t mz2080U_18678, int64_t num_tblocks_28297, int64_t num_subhistos_30239, int64_t blocks_per_segment_30375, int64_t q_30376, int64_t num_virtblocks_30377, int64_t threads_per_segment_30378, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242, __global unsigned char *segred_tmp_mem_30379, __global unsigned char *segred_tmp_mem_30381, __global unsigned char *counters_mem_30383)\n{\n    #define seghist_tblock_sizze_28295 (human_genericf32zisegred_large_30337ziseghist_tblock_sizze_28295)\n    #define chunk_sizze_30338 (human_genericf32zisegred_large_30337zichunk_sizze_30338)\n    \n    volatile __local unsigned char *sync_arr_mem_30394_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_30394_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_30392_backing_1 = &shared_mem[sync_arr_mem_30394_backing_2_offset];\n    const int64_t red_arr_i32_mem_30392_backing_1_offset = sync_arr_mem_30394_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_28295 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28295, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30390_backing_0 = &shared_mem[red_arr_i32_mem_30392_backing_1_offset];\n    const int64_t red_arr_i32_mem_30390_backing_0_offset = red_arr_i32_mem_30392_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_28295 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28295, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30386;\n    int32_t tblock_sizze_30389;\n    int32_t wave_sizze_30388;\n    int32_t block_id_30387;\n    int32_t global_tid_30385;\n    int64_t flat_gtid_303", "37;\n    __local unsigned char *red_arr_i32_mem_30390;\n    __local unsigned char *red_arr_i32_mem_30392;\n    __local unsigned char *sync_arr_mem_30394;\n    int32_t phys_tblock_id_30396;\n    int32_t iterations_30397;\n    \n    local_tid_30386 = get_local_id(0);\n    tblock_sizze_30389 = get_local_size(0);\n    wave_sizze_30388 = LOCKSTEP_WIDTH;\n    block_id_30387 = get_tblock_id(0);\n    global_tid_30385 = block_id_30387 * tblock_sizze_30389 + local_tid_30386;\n    flat_gtid_30337 = sext_i32_i64(global_tid_30385);\n    red_arr_i32_mem_30390 = (__local unsigned char *) red_arr_i32_mem_30390_backing_0;\n    red_arr_i32_mem_30392 = (__local unsigned char *) red_arr_i32_mem_30392_backing_1;\n    sync_arr_mem_30394 = (__local unsigned char *) sync_arr_mem_30394_backing_2;\n    phys_tblock_id_30396 = get_tblock_id(0);\n    iterations_30397 = sdiv_up32(sext_i64_i32(num_virtblocks_30377) - phys_tblock_id_30396, sext_i64_i32(num_tblocks_28297));\n    for (int32_t i_30398 = 0; i_30398 < iterations_30397; i_30398++) {\n        int32_t virt_tblock_id_30399;\n        int64_t flat_segment_id_30400;\n        int64_t global_tid_30401;\n        int64_t slice_30402;\n        int64_t bucket_id_30335;\n        int64_t remnant_30403;\n        int64_t subhistogram_id_30336;\n        int32_t eta_p_block_res_acc_30404;\n        int32_t eta_p_block_res_acc_30405;\n        int32_t eta_p_28303;\n        int32_t eta_p_28304;\n        int32_t eta_p_28305;\n        int32_t eta_p_28306;\n        int64_t tblock_id_in_segment_30412;\n        int64_t block_base_offset_30413;\n        int32_t offset_30416;\n        int32_t skip_waves_30417;\n        int32_t eta_p_30406;\n        int32_t eta_p_30407;\n        int32_t eta_p_30408;\n        int32_t eta_p_30409;\n        \n        virt_tblock_id_30399 = phys_tblock_id_30396 + i_30398 * sext_i64_i32(num_tblocks_28297);\n        flat_segment_id_30400 = squot64(sext_i32_i64(virt_tblock_id_30399), blocks_per_segment_30375);\n        global_tid_30401 = srem64(sext_i32_i64(virt_tblock_id_30399) * ",
                                    "seghist_tblock_sizze_28295 + sext_i32_i64(local_tid_30386), threads_per_segment_30378);\n        slice_30402 = mz2080U_18678;\n        bucket_id_30335 = flat_segment_id_30400;\n        remnant_30403 = flat_segment_id_30400 - bucket_id_30335;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_30404 = 0;\n            eta_p_block_res_acc_30405 = 0;\n        }\n        tblock_id_in_segment_30412 = squot64(global_tid_30401, seghist_tblock_sizze_28295);\n        block_base_offset_30413 = tblock_id_in_segment_30412 * q_30376 * seghist_tblock_sizze_28295;\n        for (int64_t i_30414 = 0; i_30414 < q_30376; i_30414++) {\n            int64_t block_offset_30415 = block_base_offset_30413 + i_30414 * seghist_tblock_sizze_28295;\n            \n            subhistogram_id_30336 = global_tid_30401 + threads_per_segment_30378 * i_30414;\n            if (slt64(subhistogram_id_30336, num_subhistos_30239)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_28303 = eta_p_block_res_acc_30404;\n                        eta_p_28304 = eta_p_block_res_acc_30405;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_28305 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[subhistogram_id_30336 * mz2080U_18678 + bucket_id_30335];\n                        eta_p_28306 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[subhistogram_id_30336 * mz2080U_18678 + bucket_id_30335];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_28307 = add32(eta_p_28303, eta_p_28305);\n                        int32_t tmp_28308 = add32(eta_p_28304, eta_p_28306);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_3040", "4 = tmp_28307;\n                            eta_p_block_res_acc_30405 = tmp_28308;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_block_res_acc_30404;\n            ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_block_res_acc_30405;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_30417 = 1;\n        offset_30416 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_30386, sext_i64_i32(seghist_tblock_sizze_28295))) {\n                eta_p_30406 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                eta_p_30407 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n            }\n        }\n        offset_30416 = 1;\n        while (slt32(offset_30416, wave_sizze_30388)) {\n            if (slt32(local_tid_30386 + offset_30416, sext_i64_i32(seghist_tblock_sizze_28295)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) & (2 * offset_30416 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_30408 = ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                    eta_p_30409 = ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                    int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                    \n                    eta_p_30406 = tmp_30410;\n                    eta_p_30407 = ", "tmp_30411;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                    ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                }\n            }\n            offset_30416 *= 2;\n        }\n        while (slt32(skip_waves_30417, squot32(sext_i64_i32(seghist_tblock_sizze_28295) + wave_sizze_30388 - 1, wave_sizze_30388))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_30416 = skip_waves_30417 * wave_sizze_30388;\n            if (slt32(local_tid_30386 + offset_30416, sext_i64_i32(seghist_tblock_sizze_28295)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) == 0 && (squot32(local_tid_30386, wave_sizze_30388) & (2 * skip_waves_30417 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_30408 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                    eta_p_30409 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                    int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                    \n                    eta_p_30406 = tmp_30410;\n                    eta_p_30407 = tmp_30411;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                    ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                }\n            }\n            skip_waves_30417 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCA",
                                    "L_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_30386) == (int64_t) 0) {\n                eta_p_block_res_acc_30404 = eta_p_30406;\n                eta_p_block_res_acc_30405 = eta_p_30407;\n            } else {\n                eta_p_block_res_acc_30404 = 0;\n                eta_p_block_res_acc_30405 = 0;\n            }\n        }\n        if (blocks_per_segment_30375 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_30386 == 0) {\n                    ((__global int32_t *) mem_29699)[bucket_id_30335] = eta_p_block_res_acc_30404;\n                    ((__global int32_t *) mem_29697)[bucket_id_30335] = eta_p_block_res_acc_30405;\n                }\n            }\n        } else {\n            int32_t old_counter_30418;\n            bool is_last_block_30419;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_30386 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_30379)[sext_i32_i64(virt_tblock_id_30399)] = eta_p_block_res_acc_30404;\n                    mem_fence_global();\n                    ((__global int32_t *) segred_tmp_mem_30381)[sext_i32_i64(virt_tblock_id_30399)] = eta_p_block_res_acc_30405;\n                    mem_fence_global();\n                    old_counter_30418 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30383)[srem64(flat_segment_id_30400, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_30394)[(int64_t) 0] = old_counter_30418 == sext_i64_i32(blocks_per_segment_30375 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_30419 = ((__local bool *) sync_arr_mem_30394)[(int64_t) 0];\n            if (is_last_block_30419) {\n                if (local_tid_30386 == 0) {\n                    old_coun", "ter_30418 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30383)[srem64(flat_segment_id_30400, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_30375));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_30420 = sdiv_up64(blocks_per_segment_30375, seghist_tblock_sizze_28295);\n                    \n                    eta_p_28303 = 0;\n                    eta_p_28304 = 0;\n                    for (int64_t i_30421 = 0; i_30421 < read_per_thread_30420; i_30421++) {\n                        int64_t block_res_id_30422 = sext_i32_i64(local_tid_30386) * read_per_thread_30420 + i_30421;\n                        int64_t index_of_block_res_30423 = flat_segment_id_30400 * blocks_per_segment_30375 + block_res_id_30422;\n                        \n                        if (slt64(block_res_id_30422, blocks_per_segment_30375)) {\n                            eta_p_28305 = ((__global int32_t *) segred_tmp_mem_30379)[index_of_block_res_30423];\n                            eta_p_28306 = ((__global int32_t *) segred_tmp_mem_30381)[index_of_block_res_30423];\n                            \n                            int32_t tmp_28307 = add32(eta_p_28303, eta_p_28305);\n                            int32_t tmp_28308 = add32(eta_p_28304, eta_p_28306);\n                            \n                            eta_p_28303 = tmp_28307;\n                            eta_p_28304 = tmp_28308;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_28303;\n                ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_28304;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_30424;\n                    int32_t skip_waves_30425 = 1;\n                    int32_t e", "ta_p_30406;\n                    int32_t eta_p_30407;\n                    int32_t eta_p_30408;\n                    int32_t eta_p_30409;\n                    \n                    offset_30424 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_30386, sext_i64_i32(seghist_tblock_sizze_28295))) {\n                            eta_p_30406 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            eta_p_30407 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                        }\n                    }\n                    offset_30424 = 1;\n                    while (slt32(offset_30424, wave_sizze_30388)) {\n                        if (slt32(local_tid_30386 + offset_30424, sext_i64_i32(seghist_tblock_sizze_28295)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) & (2 * offset_30424 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_30408 = ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                                eta_p_30409 = ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                                int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                                \n                                eta_p_30406 = tmp_30410;\n                                eta_p_30407 = tmp_30411;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __lo",
                                    "cal int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                            }\n                        }\n                        offset_30424 *= 2;\n                    }\n                    while (slt32(skip_waves_30425, squot32(sext_i64_i32(seghist_tblock_sizze_28295) + wave_sizze_30388 - 1, wave_sizze_30388))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_30424 = skip_waves_30425 * wave_sizze_30388;\n                        if (slt32(local_tid_30386 + offset_30424, sext_i64_i32(seghist_tblock_sizze_28295)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) == 0 && (squot32(local_tid_30386, wave_sizze_30388) & (2 * skip_waves_30425 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_30408 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                                eta_p_30409 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                                int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                                \n                                eta_p_30406 = tmp_30410;\n                                eta_p_30407 = tmp_30411;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                                ((__local int32_t *) red_arr_i32_mem_30392)[", "sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                            }\n                        }\n                        skip_waves_30425 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_30386 == 0) {\n                            ((__global int32_t *) mem_29699)[bucket_id_30335] = eta_p_30406;\n                            ((__global int32_t *) mem_29697)[bucket_id_30335] = eta_p_30407;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_28295\n    #undef chunk_sizze_30338\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegred_large_30775_dim1, 1, 1)\nvoid human_genericf32zisegred_large_30775(__global int *global_failure, int64_t mz2080U_18678, int64_t num_tblocks_28588, int64_t num_subhistos_30677, int64_t blocks_per_segment_30813, int64_t q_30814, int64_t num_virtblocks_30815, int64_t threads_per_segment_30816, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680, __global unsigned char *segred_tmp_mem_30817, __global unsigned char *segred_tmp_mem_30819, __global unsigned char *counters_mem_30821)\n{\n    #define seghist_tblock_sizze_28586 (human_genericf32zisegred_large_30775ziseghist_tblock_sizze_28586)\n    #define chunk_sizze_30776 (human_genericf32zisegred_large_30775zichunk_sizze_30776)\n    \n    volatile __local unsigned char *sync_arr_mem_30832_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_30832_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_30830_backing_1 = &shared_mem[sync_arr_mem_30832_backing_2_offset];\n    const int64_t red_arr_i32_mem_30830_backing_1_offset = sync_arr", "_mem_30832_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_28586 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28586, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30828_backing_0 = &shared_mem[red_arr_i32_mem_30830_backing_1_offset];\n    const int64_t red_arr_i32_mem_30828_backing_0_offset = red_arr_i32_mem_30830_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_28586 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28586, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30824;\n    int32_t tblock_sizze_30827;\n    int32_t wave_sizze_30826;\n    int32_t block_id_30825;\n    int32_t global_tid_30823;\n    int64_t flat_gtid_30775;\n    __local unsigned char *red_arr_i32_mem_30828;\n    __local unsigned char *red_arr_i32_mem_30830;\n    __local unsigned char *sync_arr_mem_30832;\n    int32_t phys_tblock_id_30834;\n    int32_t iterations_30835;\n    \n    local_tid_30824 = get_local_id(0);\n    tblock_sizze_30827 = get_local_size(0);\n    wave_sizze_30826 = LOCKSTEP_WIDTH;\n    block_id_30825 = get_tblock_id(0);\n    global_tid_30823 = block_id_30825 * tblock_sizze_30827 + local_tid_30824;\n    flat_gtid_30775 = sext_i32_i64(global_tid_30823);\n    red_arr_i32_mem_30828 = (__local unsigned char *) red_arr_i32_mem_30828_backing_0;\n    red_arr_i32_mem_30830 = (__local unsigned char *) red_arr_i32_mem_30830_backing_1;\n    sync_arr_mem_30832 = (__local unsigned char *) sync_arr_mem_30832_backing_2;\n    phys_tblock_id_30834 = get_tblock_id(0);\n    iterations_30835 = sdiv_up32(sext_i64_i32(num_virtblocks_30815) - phys_tblock_id_30834, sext_i64_i32(num_tblocks_28588));\n    for (int32_t i_30836 = 0; i_30836 < iterations_30835; i_30836++) {\n        int32_t virt_tblock_id_30837;\n        int64_t flat_segment_id_30838;\n        int64_t global_tid_30839;\n        int64_t slice_30840;\n        int64_t bucket_id_30773;\n        int64_t remnant_30841;\n        int64_t s",
                                    "ubhistogram_id_30774;\n        int32_t eta_p_block_res_acc_30842;\n        int32_t eta_p_block_res_acc_30843;\n        int32_t eta_p_28594;\n        int32_t eta_p_28595;\n        int32_t eta_p_28596;\n        int32_t eta_p_28597;\n        int64_t tblock_id_in_segment_30850;\n        int64_t block_base_offset_30851;\n        int32_t offset_30854;\n        int32_t skip_waves_30855;\n        int32_t eta_p_30844;\n        int32_t eta_p_30845;\n        int32_t eta_p_30846;\n        int32_t eta_p_30847;\n        \n        virt_tblock_id_30837 = phys_tblock_id_30834 + i_30836 * sext_i64_i32(num_tblocks_28588);\n        flat_segment_id_30838 = squot64(sext_i32_i64(virt_tblock_id_30837), blocks_per_segment_30813);\n        global_tid_30839 = srem64(sext_i32_i64(virt_tblock_id_30837) * seghist_tblock_sizze_28586 + sext_i32_i64(local_tid_30824), threads_per_segment_30816);\n        slice_30840 = mz2080U_18678;\n        bucket_id_30773 = flat_segment_id_30838;\n        remnant_30841 = flat_segment_id_30838 - bucket_id_30773;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_30842 = 0;\n            eta_p_block_res_acc_30843 = 0;\n        }\n        tblock_id_in_segment_30850 = squot64(global_tid_30839, seghist_tblock_sizze_28586);\n        block_base_offset_30851 = tblock_id_in_segment_30850 * q_30814 * seghist_tblock_sizze_28586;\n        for (int64_t i_30852 = 0; i_30852 < q_30814; i_30852++) {\n            int64_t block_offset_30853 = block_base_offset_30851 + i_30852 * seghist_tblock_sizze_28586;\n            \n            subhistogram_id_30774 = global_tid_30839 + threads_per_segment_30816 * i_30852;\n            if (slt64(subhistogram_id_30774, num_subhistos_30677)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_28594 = eta_p_block_res_acc_30842;\n                        eta_p_28595 = eta_p_block_res_acc_30843;\n                    }\n          ", "          // load next value(s)\n                    {\n                        eta_p_28596 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[subhistogram_id_30774 * mz2080U_18678 + bucket_id_30773];\n                        eta_p_28597 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[subhistogram_id_30774 * mz2080U_18678 + bucket_id_30773];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_28598 = add32(eta_p_28594, eta_p_28596);\n                        int32_t tmp_28599 = add32(eta_p_28595, eta_p_28597);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_30842 = tmp_28598;\n                            eta_p_block_res_acc_30843 = tmp_28599;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_block_res_acc_30842;\n            ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_block_res_acc_30843;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_30855 = 1;\n        offset_30854 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_30824, sext_i64_i32(seghist_tblock_sizze_28586))) {\n                eta_p_30844 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                eta_p_30845 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n            }\n        }\n        offset_30854 = 1;\n        while (slt32(offset_30854, wave_sizze_30826)) {\n            if (slt32(local_tid_30824 + offset_30854, sext_i64_i32(seghist_tblock_sizze_28586)) &&", " ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) & (2 * offset_30854 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_30846 = ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                    eta_p_30847 = ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                    int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                    \n                    eta_p_30844 = tmp_30848;\n                    eta_p_30845 = tmp_30849;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                    ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                }\n            }\n            offset_30854 *= 2;\n        }\n        while (slt32(skip_waves_30855, squot32(sext_i64_i32(seghist_tblock_sizze_28586) + wave_sizze_30826 - 1, wave_sizze_30826))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_30854 = skip_waves_30855 * wave_sizze_30826;\n            if (slt32(local_tid_30824 + offset_30854, sext_i64_i32(seghist_tblock_sizze_28586)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) == 0 && (squot32(local_tid_30824, wave_sizze_30826) & (2 * skip_waves_30855 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_30846 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                    eta_p_30847 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n         ",
                                    "       }\n                // apply reduction operation\n                {\n                    int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                    int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                    \n                    eta_p_30844 = tmp_30848;\n                    eta_p_30845 = tmp_30849;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                    ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                }\n            }\n            skip_waves_30855 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_30824) == (int64_t) 0) {\n                eta_p_block_res_acc_30842 = eta_p_30844;\n                eta_p_block_res_acc_30843 = eta_p_30845;\n            } else {\n                eta_p_block_res_acc_30842 = 0;\n                eta_p_block_res_acc_30843 = 0;\n            }\n        }\n        if (blocks_per_segment_30813 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_30824 == 0) {\n                    ((__global int32_t *) mem_29744)[bucket_id_30773] = eta_p_block_res_acc_30842;\n                    ((__global int32_t *) mem_29742)[bucket_id_30773] = eta_p_block_res_acc_30843;\n                }\n            }\n        } else {\n            int32_t old_counter_30856;\n            bool is_last_block_30857;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_30824 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_30817)[sext_i32_i64(virt_tblock_id_30837)] = eta_p_block_res_acc_30842;\n                    mem_fence_global();\n           ", "         ((__global int32_t *) segred_tmp_mem_30819)[sext_i32_i64(virt_tblock_id_30837)] = eta_p_block_res_acc_30843;\n                    mem_fence_global();\n                    old_counter_30856 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30821)[srem64(flat_segment_id_30838, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_30832)[(int64_t) 0] = old_counter_30856 == sext_i64_i32(blocks_per_segment_30813 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_30857 = ((__local bool *) sync_arr_mem_30832)[(int64_t) 0];\n            if (is_last_block_30857) {\n                if (local_tid_30824 == 0) {\n                    old_counter_30856 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30821)[srem64(flat_segment_id_30838, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_30813));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_30858 = sdiv_up64(blocks_per_segment_30813, seghist_tblock_sizze_28586);\n                    \n                    eta_p_28594 = 0;\n                    eta_p_28595 = 0;\n                    for (int64_t i_30859 = 0; i_30859 < read_per_thread_30858; i_30859++) {\n                        int64_t block_res_id_30860 = sext_i32_i64(local_tid_30824) * read_per_thread_30858 + i_30859;\n                        int64_t index_of_block_res_30861 = flat_segment_id_30838 * blocks_per_segment_30813 + block_res_id_30860;\n                        \n                        if (slt64(block_res_id_30860, blocks_per_segment_30813)) {\n                            eta_p_28596 = ((__global int32_t *) segred_tmp_mem_30817)[index_of_block_res_30861];\n                            eta_p_28597 = ((__global int32_t *) segred_tmp_mem_30819)[index_of_block_res_30861];\n                            \n                            int32_t tmp", "_28598 = add32(eta_p_28594, eta_p_28596);\n                            int32_t tmp_28599 = add32(eta_p_28595, eta_p_28597);\n                            \n                            eta_p_28594 = tmp_28598;\n                            eta_p_28595 = tmp_28599;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_28594;\n                ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_28595;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_30862;\n                    int32_t skip_waves_30863 = 1;\n                    int32_t eta_p_30844;\n                    int32_t eta_p_30845;\n                    int32_t eta_p_30846;\n                    int32_t eta_p_30847;\n                    \n                    offset_30862 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_30824, sext_i64_i32(seghist_tblock_sizze_28586))) {\n                            eta_p_30844 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                            eta_p_30845 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                        }\n                    }\n                    offset_30862 = 1;\n                    while (slt32(offset_30862, wave_sizze_30826)) {\n                        if (slt32(local_tid_30824 + offset_30862, sext_i64_i32(seghist_tblock_sizze_28586)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) & (2 * offset_30862 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_30846 = ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid",
                                    "_30824 + offset_30862)];\n                                eta_p_30847 = ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                                int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                                \n                                eta_p_30844 = tmp_30848;\n                                eta_p_30845 = tmp_30849;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                            }\n                        }\n                        offset_30862 *= 2;\n                    }\n                    while (slt32(skip_waves_30863, squot32(sext_i64_i32(seghist_tblock_sizze_28586) + wave_sizze_30826 - 1, wave_sizze_30826))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_30862 = skip_waves_30863 * wave_sizze_30826;\n                        if (slt32(local_tid_30824 + offset_30862, sext_i64_i32(seghist_tblock_sizze_28586)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) == 0 && (squot32(local_tid_30824, wave_sizze_30826) & (2 * skip_waves_30863 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_30846 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                                eta_p_30847 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_3082", "4 + offset_30862)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                                int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                                \n                                eta_p_30844 = tmp_30848;\n                                eta_p_30845 = tmp_30849;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                                ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                            }\n                        }\n                        skip_waves_30863 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_30824 == 0) {\n                            ((__global int32_t *) mem_29744)[bucket_id_30773] = eta_p_30844;\n                            ((__global int32_t *) mem_29742)[bucket_id_30773] = eta_p_30845;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_28586\n    #undef chunk_sizze_30776\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegred_small_30337_dim1, 1, 1)\nvoid human_genericf32zisegred_small_30337(__global int *global_failure, int64_t mz2080U_18678, int64_t num_tblocks_28297, int64_t num_subhistos_30239, int64_t segment_sizze_nonzzero_30339, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_", "subhistos_mem_30242)\n{\n    #define seghist_tblock_sizze_28295 (human_genericf32zisegred_small_30337ziseghist_tblock_sizze_28295)\n    \n    volatile __local unsigned char *red_arr_i32_mem_30348_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_30348_backing_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_28295 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28295, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30346_backing_0 = &shared_mem[red_arr_i32_mem_30348_backing_1_offset];\n    const int64_t red_arr_i32_mem_30346_backing_0_offset = red_arr_i32_mem_30348_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_28295 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28295, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30342;\n    int32_t tblock_sizze_30345;\n    int32_t wave_sizze_30344;\n    int32_t block_id_30343;\n    int32_t global_tid_30341;\n    int64_t flat_gtid_30337;\n    __local unsigned char *red_arr_i32_mem_30346;\n    __local unsigned char *red_arr_i32_mem_30348;\n    int32_t phys_tblock_id_30350;\n    int32_t iterations_30351;\n    \n    local_tid_30342 = get_local_id(0);\n    tblock_sizze_30345 = get_local_size(0);\n    wave_sizze_30344 = LOCKSTEP_WIDTH;\n    block_id_30343 = get_tblock_id(0);\n    global_tid_30341 = block_id_30343 * tblock_sizze_30345 + local_tid_30342;\n    flat_gtid_30337 = sext_i32_i64(global_tid_30341);\n    red_arr_i32_mem_30346 = (__local unsigned char *) red_arr_i32_mem_30346_backing_0;\n    red_arr_i32_mem_30348 = (__local unsigned char *) red_arr_i32_mem_30348_backing_1;\n    phys_tblock_id_30350 = get_tblock_id(0);\n    iterations_30351 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_18678, squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339))) - phys_tblock_id_30350, sext_i64_i32(num_tblocks_28297));\n    for (int32_t i_30352 = 0; i_30352 < iterations_30351; i_30352++) {\n        int32_t virt_tblo",
                                    "ck_id_30353;\n        int64_t slice_30354;\n        int64_t bucket_id_30335;\n        int64_t remnant_30355;\n        int64_t subhistogram_id_30336;\n        \n        virt_tblock_id_30353 = phys_tblock_id_30350 + i_30352 * sext_i64_i32(num_tblocks_28297);\n        slice_30354 = mz2080U_18678;\n        bucket_id_30335 = squot64(sext_i32_i64(local_tid_30342), segment_sizze_nonzzero_30339) + sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339);\n        remnant_30355 = squot64(sext_i32_i64(local_tid_30342), segment_sizze_nonzzero_30339) + sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339) - bucket_id_30335;\n        subhistogram_id_30336 = srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_30239) && (slt64(bucket_id_30335, mz2080U_18678) && slt64(sext_i32_i64(local_tid_30342), num_subhistos_30239 * squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_30356 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[subhistogram_id_30336 * mz2080U_18678 + bucket_id_30335];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = tmp_30356;\n                    \n                    int32_t tmp_30357 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[subhistogram_id_30336 * mz2080U_18678 + bucket_id_30335];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = tmp_30357;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = 0;\n            }\n        }\n    ", "    barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_30239)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_28303;\n                int32_t eta_p_28304;\n                int32_t eta_p_28305;\n                int32_t eta_p_28306;\n                int32_t eta_p_30358;\n                int32_t eta_p_30359;\n                int32_t eta_p_30360;\n                int32_t eta_p_30361;\n                bool ltid_in_bounds_30364 = slt64(sext_i32_i64(local_tid_30342), num_subhistos_30239 * squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339));\n                int32_t skip_threads_30365;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_30364) {\n                        eta_p_28305 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)];\n                        eta_p_28306 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)];\n                        if ((local_tid_30342 - squot32(local_tid_30342, 32) * 32) == 0) {\n                            eta_p_28303 = eta_p_28305;\n                            eta_p_28304 = eta_p_28306;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30365 = 1;\n                    while (slt32(skip_threads_30365, 32)) {\n                        bool thread_active_30366 = sle32(skip_threads_30365, local_tid_30342 - squot32(local_tid_30342, 32) * 32) && ltid_in_bounds_30364;\n                        \n                        if (thread_active_30366) {\n                            // read operands\n                            {\n                                eta_p_28303 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30365)];\n                          ", "      eta_p_28304 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30365)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_30367 = slt64(srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239), sext_i32_i64(local_tid_30342) - sext_i32_i64(local_tid_30342 - skip_threads_30365));\n                            \n                            if (thread_active_30366 && inactive_30367) {\n                                eta_p_28303 = eta_p_28305;\n                                eta_p_28304 = eta_p_28306;\n                            }\n                            if (thread_active_30366) {\n                                if (!inactive_30367) {\n                                    int32_t tmp_28307 = add32(eta_p_28303, eta_p_28305);\n                                    int32_t tmp_28308 = add32(eta_p_28304, eta_p_28306);\n                                    \n                                    eta_p_28303 = tmp_28307;\n                                    eta_p_28304 = tmp_28308;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_30344, skip_threads_30365)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30366) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_28303;\n                                eta_p_28305 = eta_p_28303;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_28304;\n                                eta_p_28306 = eta_p_28304;\n                            }\n                        }\n                        i",
                                    "f (sle32(wave_sizze_30344, skip_threads_30365)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30365 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_30342 - squot32(local_tid_30342, 32) * 32) == 31 && ltid_in_bounds_30364) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(squot32(local_tid_30342, 32))] = eta_p_28303;\n                        ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(squot32(local_tid_30342, 32))] = eta_p_28304;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_30368;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364) {\n                            eta_p_30360 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)];\n                            eta_p_30361 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)];\n                            if ((local_tid_30342 - squot32(local_tid_30342, 32) * 32) == 0) {\n                                eta_p_30358 = eta_p_30360;\n                                eta_p_30359 = eta_p_30361;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_30368 = 1;\n                        while (slt32(skip_threads_30368, 32)) {\n                            bool thread_active_30369 = sle32(skip_threads_", "30368, local_tid_30342 - squot32(local_tid_30342, 32) * 32) && (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364);\n                            \n                            if (thread_active_30369) {\n                                // read operands\n                                {\n                                    eta_p_30358 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30368)];\n                                    eta_p_30359 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30368)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_30370 = slt64(srem64(sext_i32_i64(local_tid_30342 * 32 + 32 - 1), num_subhistos_30239), sext_i32_i64(local_tid_30342 * 32 + 32 - 1) - sext_i32_i64((local_tid_30342 - skip_threads_30368) * 32 + 32 - 1));\n                                \n                                if (thread_active_30369 && inactive_30370) {\n                                    eta_p_30358 = eta_p_30360;\n                                    eta_p_30359 = eta_p_30361;\n                                }\n                                if (thread_active_30369) {\n                                    if (!inactive_30370) {\n                                        int32_t tmp_30362 = add32(eta_p_30358, eta_p_30360);\n                                        int32_t tmp_30363 = add32(eta_p_30359, eta_p_30361);\n                                        \n                                        eta_p_30358 = tmp_30362;\n                                        eta_p_30359 = tmp_30363;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_30344, skip_threads_30368)) {\n                                barrier(CLK_LOCAL_M", "EM_FENCE);\n                            }\n                            if (thread_active_30369) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_30358;\n                                    eta_p_30360 = eta_p_30358;\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_30359;\n                                    eta_p_30361 = eta_p_30359;\n                                }\n                            }\n                            if (sle32(wave_sizze_30344, skip_threads_30368)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_30368 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_30371 = squot32(local_tid_30342, 32) == 0 || !ltid_in_bounds_30364;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_30371) {\n                            eta_p_28305 = eta_p_28303;\n                            eta_p_28306 = eta_p_28304;\n                            eta_p_28303 = ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(squot32(local_tid_30342, 32)) - (int64_t) 1];\n                            eta_p_28304 = ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(squot32(local_tid_30342, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_30372 = slt64(srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239), sext_i32_i64(local_tid_30342) - sext_i32_i64(squot32(local_tid_30342, 32) * 32 -",
                                    " 1));\n                        \n                        if (!no_carry_in_30371) {\n                            if (inactive_30372) {\n                                eta_p_28303 = eta_p_28305;\n                                eta_p_28304 = eta_p_28306;\n                            }\n                        }\n                        if (!no_carry_in_30371) {\n                            if (!inactive_30372) {\n                                int32_t tmp_28307 = add32(eta_p_28303, eta_p_28305);\n                                int32_t tmp_28308 = add32(eta_p_28304, eta_p_28306);\n                                \n                                eta_p_28303 = tmp_28307;\n                                eta_p_28304 = tmp_28308;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_30371) {\n                            ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_28303;\n                            ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_28304;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364) {\n                        ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_28305;\n                        ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_28306;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid", "_30342), mz2080U_18678) && slt64(sext_i32_i64(local_tid_30342), squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339))) {\n                int32_t tmp_30373 = ((__local int32_t *) red_arr_i32_mem_30346)[(sext_i32_i64(local_tid_30342) + (int64_t) 1) * segment_sizze_nonzzero_30339 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29699)[sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid_30342)] = tmp_30373;\n                \n                int32_t tmp_30374 = ((__local int32_t *) red_arr_i32_mem_30348)[(sext_i32_i64(local_tid_30342) + (int64_t) 1) * segment_sizze_nonzzero_30339 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29697)[sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid_30342)] = tmp_30374;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_28295\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegred_small_30775_dim1, 1, 1)\nvoid human_genericf32zisegred_small_30775(__global int *global_failure, int64_t mz2080U_18678, int64_t num_tblocks_28588, int64_t num_subhistos_30677, int64_t segment_sizze_nonzzero_30777, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define seghist_tblock_sizze_28586 (human_genericf32zisegred_small_30775ziseghist_tblock_sizze_28586)\n    \n    volatile __local unsigned char *red_arr_i32_mem_30786_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_30786_backing_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_28586 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28586, (int64_t) 8), (int64_t) 8));\n    volatile __loc", "al unsigned char *red_arr_i32_mem_30784_backing_0 = &shared_mem[red_arr_i32_mem_30786_backing_1_offset];\n    const int64_t red_arr_i32_mem_30784_backing_0_offset = red_arr_i32_mem_30786_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_28586 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28586, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30780;\n    int32_t tblock_sizze_30783;\n    int32_t wave_sizze_30782;\n    int32_t block_id_30781;\n    int32_t global_tid_30779;\n    int64_t flat_gtid_30775;\n    __local unsigned char *red_arr_i32_mem_30784;\n    __local unsigned char *red_arr_i32_mem_30786;\n    int32_t phys_tblock_id_30788;\n    int32_t iterations_30789;\n    \n    local_tid_30780 = get_local_id(0);\n    tblock_sizze_30783 = get_local_size(0);\n    wave_sizze_30782 = LOCKSTEP_WIDTH;\n    block_id_30781 = get_tblock_id(0);\n    global_tid_30779 = block_id_30781 * tblock_sizze_30783 + local_tid_30780;\n    flat_gtid_30775 = sext_i32_i64(global_tid_30779);\n    red_arr_i32_mem_30784 = (__local unsigned char *) red_arr_i32_mem_30784_backing_0;\n    red_arr_i32_mem_30786 = (__local unsigned char *) red_arr_i32_mem_30786_backing_1;\n    phys_tblock_id_30788 = get_tblock_id(0);\n    iterations_30789 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_18678, squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777))) - phys_tblock_id_30788, sext_i64_i32(num_tblocks_28588));\n    for (int32_t i_30790 = 0; i_30790 < iterations_30789; i_30790++) {\n        int32_t virt_tblock_id_30791;\n        int64_t slice_30792;\n        int64_t bucket_id_30773;\n        int64_t remnant_30793;\n        int64_t subhistogram_id_30774;\n        \n        virt_tblock_id_30791 = phys_tblock_id_30788 + i_30790 * sext_i64_i32(num_tblocks_28588);\n        slice_30792 = mz2080U_18678;\n        bucket_id_30773 = squot64(sext_i32_i64(local_tid_30780), segment_sizze_nonzzero_30777) + sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock",
                                    "_sizze_28586, segment_sizze_nonzzero_30777);\n        remnant_30793 = squot64(sext_i32_i64(local_tid_30780), segment_sizze_nonzzero_30777) + sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777) - bucket_id_30773;\n        subhistogram_id_30774 = srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_30677) && (slt64(bucket_id_30773, mz2080U_18678) && slt64(sext_i32_i64(local_tid_30780), num_subhistos_30677 * squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_30794 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[subhistogram_id_30774 * mz2080U_18678 + bucket_id_30773];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = tmp_30794;\n                    \n                    int32_t tmp_30795 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[subhistogram_id_30774 * mz2080U_18678 + bucket_id_30773];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = tmp_30795;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_30677)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_28594;\n                int32_t eta_p_28595;\n                int32_t eta_p_28596;\n                int32_t eta_p_28597;\n                int32_t eta_p_30796;\n                int32_t eta_p_30797;\n                int32_t eta_p_30798;\n                int32_t", " eta_p_30799;\n                bool ltid_in_bounds_30802 = slt64(sext_i32_i64(local_tid_30780), num_subhistos_30677 * squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777));\n                int32_t skip_threads_30803;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_30802) {\n                        eta_p_28596 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)];\n                        eta_p_28597 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)];\n                        if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == 0) {\n                            eta_p_28594 = eta_p_28596;\n                            eta_p_28595 = eta_p_28597;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30803 = 1;\n                    while (slt32(skip_threads_30803, 32)) {\n                        bool thread_active_30804 = sle32(skip_threads_30803, local_tid_30780 - squot32(local_tid_30780, 32) * 32) && ltid_in_bounds_30802;\n                        \n                        if (thread_active_30804) {\n                            // read operands\n                            {\n                                eta_p_28594 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30803)];\n                                eta_p_28595 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30803)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_30805 = slt64(srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677), sext_i32_i64(local_tid_30780) - sext_i32_i64(local_tid_30780 ", "- skip_threads_30803));\n                            \n                            if (thread_active_30804 && inactive_30805) {\n                                eta_p_28594 = eta_p_28596;\n                                eta_p_28595 = eta_p_28597;\n                            }\n                            if (thread_active_30804) {\n                                if (!inactive_30805) {\n                                    int32_t tmp_28598 = add32(eta_p_28594, eta_p_28596);\n                                    int32_t tmp_28599 = add32(eta_p_28595, eta_p_28597);\n                                    \n                                    eta_p_28594 = tmp_28598;\n                                    eta_p_28595 = tmp_28599;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_30782, skip_threads_30803)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30804) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_28594;\n                                eta_p_28596 = eta_p_28594;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_28595;\n                                eta_p_28597 = eta_p_28595;\n                            }\n                        }\n                        if (sle32(wave_sizze_30782, skip_threads_30803)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30803 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == ",
                                    "31 && ltid_in_bounds_30802) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(squot32(local_tid_30780, 32))] = eta_p_28594;\n                        ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(squot32(local_tid_30780, 32))] = eta_p_28595;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_30806;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802) {\n                            eta_p_30798 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)];\n                            eta_p_30799 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)];\n                            if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == 0) {\n                                eta_p_30796 = eta_p_30798;\n                                eta_p_30797 = eta_p_30799;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_30806 = 1;\n                        while (slt32(skip_threads_30806, 32)) {\n                            bool thread_active_30807 = sle32(skip_threads_30806, local_tid_30780 - squot32(local_tid_30780, 32) * 32) && (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802);\n                            \n                            if (thread_active_30807) {\n                                // read operands\n                                {\n                                    eta_p_30796 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_", "threads_30806)];\n                                    eta_p_30797 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30806)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_30808 = slt64(srem64(sext_i32_i64(local_tid_30780 * 32 + 32 - 1), num_subhistos_30677), sext_i32_i64(local_tid_30780 * 32 + 32 - 1) - sext_i32_i64((local_tid_30780 - skip_threads_30806) * 32 + 32 - 1));\n                                \n                                if (thread_active_30807 && inactive_30808) {\n                                    eta_p_30796 = eta_p_30798;\n                                    eta_p_30797 = eta_p_30799;\n                                }\n                                if (thread_active_30807) {\n                                    if (!inactive_30808) {\n                                        int32_t tmp_30800 = add32(eta_p_30796, eta_p_30798);\n                                        int32_t tmp_30801 = add32(eta_p_30797, eta_p_30799);\n                                        \n                                        eta_p_30796 = tmp_30800;\n                                        eta_p_30797 = tmp_30801;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_30782, skip_threads_30806)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_30807) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_30796;\n                                    eta_p_30798 = eta_p_30796;\n                                    ((volatile __local int32_t *) re", "d_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_30797;\n                                    eta_p_30799 = eta_p_30797;\n                                }\n                            }\n                            if (sle32(wave_sizze_30782, skip_threads_30806)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_30806 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_30809 = squot32(local_tid_30780, 32) == 0 || !ltid_in_bounds_30802;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_30809) {\n                            eta_p_28596 = eta_p_28594;\n                            eta_p_28597 = eta_p_28595;\n                            eta_p_28594 = ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(squot32(local_tid_30780, 32)) - (int64_t) 1];\n                            eta_p_28595 = ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(squot32(local_tid_30780, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_30810 = slt64(srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677), sext_i32_i64(local_tid_30780) - sext_i32_i64(squot32(local_tid_30780, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_30809) {\n                            if (inactive_30810) {\n                                eta_p_28594 = eta_p_28596;\n                                eta_p_28595 = eta_p_28597;\n                            }\n                        }\n                        if (!no_carry_in_30809) {\n                            if (!inactive_30810) {\n                                int32_",
                                    "t tmp_28598 = add32(eta_p_28594, eta_p_28596);\n                                int32_t tmp_28599 = add32(eta_p_28595, eta_p_28597);\n                                \n                                eta_p_28594 = tmp_28598;\n                                eta_p_28595 = tmp_28599;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_30809) {\n                            ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_28594;\n                            ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_28595;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802) {\n                        ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_28596;\n                        ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_28597;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777) + sext_i32_i64(local_tid_30780), mz2080U_18678) && slt64(sext_i32_i64(local_tid_30780), squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777))) {\n                int32_t tmp_30811 = ((__local int32_t *) red_arr_i32_mem_30784)[(sext_i32_i64(local_tid_30780) + (int64_t) 1) * segment_sizze_nonzzero_30777 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29744)[sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_28586", ", segment_sizze_nonzzero_30777) + sext_i32_i64(local_tid_30780)] = tmp_30811;\n                \n                int32_t tmp_30812 = ((__local int32_t *) red_arr_i32_mem_30786)[(sext_i32_i64(local_tid_30780) + (int64_t) 1) * segment_sizze_nonzzero_30777 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29742)[sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777) + sext_i32_i64(local_tid_30780)] = tmp_30812;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_28586\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegscan_28226_dim1, 1, 1)\nvoid human_genericf32zisegscan_28226(__global int *global_failure, int64_t mz2080U_18678, int64_t num_tblocks_28223, int64_t num_virt_blocks_29795, int64_t num_virt_threads_29796, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29683, __global unsigned char *status_flags_mem_29797, __global unsigned char *aggregates_mem_29819, __global unsigned char *incprefixes_mem_29821, __global unsigned char *global_dynid_mem_29823)\n{\n    #define segscan_tblock_sizze_28221 (human_genericf32zisegscan_28226zisegscan_tblock_sizze_28221)\n    #define chunk_sizze_29794 (human_genericf32zisegscan_28226zichunk_sizze_29794)\n    \n    volatile __local unsigned char *local_mem_29853_backing_0 = &shared_mem[0];\n    const int64_t local_mem_29853_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28221), chunk_sizze_29794 * segscan_tblock_sizze_28221 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28221), chunk_sizze_29794 * segscan_tblock_sizze_28221 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29846;\n    int32_t tblock_sizze_29849;\n    int32_t wave_sizze_29848;\n    int3", "2_t block_id_29847;\n    int32_t global_tid_29845;\n    int64_t phys_tid_28226;\n    int32_t chunk_sizze_32b_29850;\n    int64_t byte_offsets_29851;\n    int64_t warp_byte_offset_29852;\n    __local unsigned char *local_mem_29853;\n    int64_t trans_arr_len_29854;\n    int64_t phys_block_id_29860;\n    int64_t virtloop_bound_29861;\n    \n    local_tid_29846 = get_local_id(0);\n    tblock_sizze_29849 = get_local_size(0);\n    wave_sizze_29848 = LOCKSTEP_WIDTH;\n    block_id_29847 = get_tblock_id(0);\n    global_tid_29845 = block_id_29847 * tblock_sizze_29849 + local_tid_29846;\n    phys_tid_28226 = sext_i32_i64(global_tid_29845);\n    chunk_sizze_32b_29850 = sext_i64_i32(chunk_sizze_29794);\n    byte_offsets_29851 = segscan_tblock_sizze_28221 * (int64_t) 8;\n    warp_byte_offset_29852 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_29853 = (__local unsigned char *) local_mem_29853_backing_0;\n    trans_arr_len_29854 = chunk_sizze_29794 * segscan_tblock_sizze_28221;\n    phys_block_id_29860 = get_tblock_id(0);\n    virtloop_bound_29861 = sdiv_up64(num_virt_blocks_29795 - phys_block_id_29860, num_tblocks_28223);\n    for (int64_t virtloop_i_29862 = 0; virtloop_i_29862 < virtloop_bound_29861; virtloop_i_29862++) {\n        int64_t dynamic_id_29863;\n        int64_t block_offset_29864;\n        int64_t sgm_idx_29865;\n        int32_t boundary_29866;\n        int32_t segsizze_compact_29867;\n        int64_t private_mem_29868[chunk_sizze_29794];\n        int64_t thd_offset_29870;\n        int64_t acc_29886;\n        int64_t prefix_29896;\n        bool block_new_sgm_29897;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_29846 == 0) {\n                dynamic_id_29863 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_29823)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_29853)[(int64_t) 0] = dynamic_id_29",
                                    "863;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_29863 == num_virt_blocks_29795 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_29823)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_29863 = ((__local int32_t *) local_mem_29853)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_29864 = dynamic_id_29863 * chunk_sizze_29794 * segscan_tblock_sizze_28221;\n        sgm_idx_29865 = smod64(block_offset_29864, mz2080U_18678);\n        boundary_29866 = sext_i64_i32(smin64(chunk_sizze_29794 * segscan_tblock_sizze_28221, mz2080U_18678 - sgm_idx_29865));\n        segsizze_compact_29867 = sext_i64_i32(smin64(chunk_sizze_29794 * segscan_tblock_sizze_28221, mz2080U_18678));\n        thd_offset_29870 = block_offset_29864 + sext_i32_i64(local_tid_29846);\n        // Load and map\n        {\n            for (int64_t i_29871 = 0; i_29871 < chunk_sizze_29794; i_29871++) {\n                int64_t virt_tid_29872 = thd_offset_29870 + i_29871 * segscan_tblock_sizze_28221;\n                int64_t slice_29873 = mz2080U_18678;\n                int64_t gtid_28225 = virt_tid_29872;\n                int64_t remnant_29874 = virt_tid_29872 - gtid_28225;\n                \n                if (slt64(virt_tid_29872, mz2080U_18678)) {\n                    int32_t eta_p_27704 = ((__global int32_t *) shp_mem_29678)[gtid_28225];\n                    int64_t i32_res_27705 = sext_i32_i64(eta_p_27704);\n                    \n                    private_mem_29868[i_29871] = i32_res_27705;\n                } else {\n                    private_mem_29868[i_29871] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_29875 = 0; i_29875 < chunk_sizze_29794; i_29875++) {\n", "                int64_t sharedIdx_29876 = sext_i32_i64(local_tid_29846) + i_29875 * segscan_tblock_sizze_28221;\n                int64_t tmp_29877 = private_mem_29868[i_29875];\n                \n                ((__local int64_t *) local_mem_29853)[sharedIdx_29876] = tmp_29877;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_29878 = 0; i_29878 < chunk_sizze_29794; i_29878++) {\n                int64_t sharedIdx_29879 = sext_i32_i64(local_tid_29846) * chunk_sizze_29794 + i_29878;\n                int64_t tmp_29880 = ((__local int64_t *) local_mem_29853)[sharedIdx_29879];\n                \n                private_mem_29868[i_29878] = tmp_29880;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_29881 = 0; i_29881 < chunk_sizze_29794 - (int64_t) 1; i_29881++) {\n                int64_t eta_p_27379;\n                int64_t eta_p_27380;\n                \n                eta_p_27379 = private_mem_29868[i_29881];\n                eta_p_27380 = private_mem_29868[i_29881 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27381 = add64(eta_p_27379, eta_p_27380);\n                \n                private_mem_29868[i_29881 + (int64_t) 1] = defunc_0_op_res_27381;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_29882 = private_mem_29868[chunk_sizze_29794 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = tmp_29882;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_29883;\n            int64_t eta_p_29884;\n            int64_t eta_p_29887;\n            int64_t eta_p_29888;\n            bool ltid_in_bounds_29890 = slt64(sext_i32_i64(local_tid_29846), num_virt_threads_29796);\n            int32_t skip_threads_29891;\n            \n            // read input for in-block scan\n ", "           {\n                if (ltid_in_bounds_29890) {\n                    eta_p_29884 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                    if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                        eta_p_29883 = eta_p_29884;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_29891 = 1;\n                while (slt32(skip_threads_29891, 32)) {\n                    bool thread_active_29892 = sle32(skip_threads_29891, local_tid_29846 - squot32(local_tid_29846, 32) * 32) && ltid_in_bounds_29890;\n                    \n                    if (thread_active_29892) {\n                        // read operands\n                        {\n                            eta_p_29883 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29891)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_29892) {\n                            int64_t defunc_0_op_res_29885 = add64(eta_p_29883, eta_p_29884);\n                            \n                            eta_p_29883 = defunc_0_op_res_29885;\n                        }\n                    }\n                    if (sle32(wave_sizze_29848, skip_threads_29891)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_29892) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29883;\n                            eta_p_29884 = eta_p_29883;\n                        }\n                    }\n                    if (sle32(wave_sizze_29848, skip_threads_29891)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }",
                                    "\n                    skip_threads_29891 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 31 && ltid_in_bounds_29890) {\n                    ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(squot32(local_tid_29846, 32))] = eta_p_29883;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_29893;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_29846, 32) == 0 && ltid_in_bounds_29890) {\n                        eta_p_29888 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                        if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                            eta_p_29887 = eta_p_29888;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_29893 = 1;\n                    while (slt32(skip_threads_29893, 32)) {\n                        bool thread_active_29894 = sle32(skip_threads_29893, local_tid_29846 - squot32(local_tid_29846, 32) * 32) && (squot32(local_tid_29846, 32) == 0 && ltid_in_bounds_29890);\n                        \n                        if (thread_active_29894) {\n                            // read operands\n                            {\n                                eta_p_29887 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29893)];\n                            }\n                        }\n                        // perform operation\n                        {\n                     ", "       if (thread_active_29894) {\n                                int64_t defunc_0_op_res_29889 = add64(eta_p_29887, eta_p_29888);\n                                \n                                eta_p_29887 = defunc_0_op_res_29889;\n                            }\n                        }\n                        if (sle32(wave_sizze_29848, skip_threads_29893)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_29894) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29887;\n                                eta_p_29888 = eta_p_29887;\n                            }\n                        }\n                        if (sle32(wave_sizze_29848, skip_threads_29893)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_29893 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_29895 = squot32(local_tid_29846, 32) == 0 || !ltid_in_bounds_29890;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_29895) {\n                        eta_p_29884 = eta_p_29883;\n                        eta_p_29883 = ((__local int64_t *) local_mem_29853)[sext_i32_i64(squot32(local_tid_29846, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_29895) {\n                        int64_t defunc_0_op_res_29885 = add64(eta_p_29883, eta_p_29884);\n                        \n                        eta_p_29883 = defunc_0_op_res_29885;\n                    }\n                }\n                // write final result\n            ", "    {\n                    if (!no_carry_in_29895) {\n                        ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29883;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_29846, 32) == 0 && ltid_in_bounds_29890) {\n                    ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29884;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_29846 == 0) {\n                acc_29886 = ((__local int64_t *) local_mem_29853)[segscan_tblock_sizze_28221 - (int64_t) 1];\n            } else {\n                acc_29886 = ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_29896 = (int64_t) 0;\n        block_new_sgm_29897 = sgm_idx_29865 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_29897 && local_tid_29846 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863] = acc_29886;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 2;\n                acc_29886 = (int64_t) 0;\n            }\n            if (!block_new_sgm_29897 && slt32(local_tid_29846, wave_sizze_29848)) {\n                if (local_tid_29846 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_29819)[dynamic_id_29863] = acc_29886;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 1;\n                    \n                    int8_t tmp_29898 = ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863 - (int64_t) 1];\n           ",
                                    "         \n                    ((volatile __local int8_t *) local_mem_29853)[(int64_t) 0] = tmp_29898;\n                }\n                mem_fence_local();\n                \n                int8_t status_29899 = ((__local int8_t *) local_mem_29853)[(int64_t) 0];\n                \n                if (status_29899 == (int8_t) 2) {\n                    if (local_tid_29846 == 0) {\n                        prefix_29896 = ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_29900 = sext_i64_i32(dynamic_id_29863 - sext_i32_i64(wave_sizze_29848));\n                    \n                    while (slt32(wave_sizze_29848 * -1, readOffset_29900)) {\n                        int32_t read_i_29901 = readOffset_29900 + local_tid_29846;\n                        int64_t aggr_29902 = (int64_t) 0;\n                        int8_t flag_29903 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_29901)) {\n                            flag_29903 = ((volatile __global int8_t *) status_flags_mem_29797)[sext_i32_i64(read_i_29901)];\n                            if (flag_29903 == (int8_t) 2) {\n                                aggr_29902 = ((volatile __global int64_t *) incprefixes_mem_29821)[sext_i32_i64(read_i_29901)];\n                            } else if (flag_29903 == (int8_t) 1) {\n                                aggr_29902 = ((volatile __global int64_t *) aggregates_mem_29819)[sext_i32_i64(read_i_29901)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)] = aggr_29902;\n                        ((__local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = flag_29903;\n                        flag_29903 = ((__local int8_t *) local_mem_29853)[sext_i32_i64(wave_sizze_29848) - (int64_t) 1];\n                        if (slt8(flag_29903, (int8_t) 2", ")) {\n                            int8_t flg_x_29907;\n                            int8_t flg_y_29908;\n                            int64_t eta_p_29904;\n                            int64_t eta_p_29905;\n                            int32_t skip_threads_29909;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_29908 = ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                                eta_p_29905 = ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)];\n                                if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                                    eta_p_29904 = eta_p_29905;\n                                    flg_x_29907 = flg_y_29908;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_29909 = 1;\n                                while (slt32(skip_threads_29909, 32)) {\n                                    if (sle32(skip_threads_29909, local_tid_29846 - squot32(local_tid_29846, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_29907 = ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29909)];\n                                            eta_p_29904 = ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + (sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29909))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_29908 == (int8_t) 2 || flg_y_29908 == (int8_t) 0) {\n          ", "                                      flg_x_29907 = flg_y_29908;\n                                                eta_p_29904 = eta_p_29905;\n                                            } else {\n                                                int64_t defunc_0_op_res_29906 = add64(eta_p_29904, eta_p_29905);\n                                                \n                                                eta_p_29904 = defunc_0_op_res_29906;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = flg_x_29907;\n                                            flg_y_29908 = flg_x_29907;\n                                            ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)] = eta_p_29904;\n                                            eta_p_29905 = eta_p_29904;\n                                        }\n                                    }\n                                    skip_threads_29909 *= 2;\n                                }\n                            }\n                        }\n                        flag_29903 = ((__local int8_t *) local_mem_29853)[sext_i32_i64(wave_sizze_29848) - (int64_t) 1];\n                        aggr_29902 = ((__local int64_t *) local_mem_29853)[(int64_t) 4 + (sext_i32_i64(wave_sizze_29848) - (int64_t) 1)];\n                        if (flag_29903 == (int8_t) 2) {\n                            readOffset_29900 = wave_sizze_29848 * -1;\n                        } else if (flag_29903 == (int8_t) 1) {\n                            readOffset_29900 -= wave_sizze_29848;\n                        }\n                        if (slt8((int8_t) 0, flag_29903)) {\n                            int64_t eta_p_29910 = aggr_29902;\n                            int64_t eta_p_29911 = pr",
                                    "efix_29896;\n                            int64_t defunc_0_op_res_29912 = add64(eta_p_29910, eta_p_29911);\n                            \n                            prefix_29896 = defunc_0_op_res_29912;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_29846 == 0) {\n                    if (boundary_29866 == sext_i64_i32(segscan_tblock_sizze_28221 * chunk_sizze_29794)) {\n                        int64_t eta_p_29913 = prefix_29896;\n                        int64_t eta_p_29914 = acc_29886;\n                        int64_t defunc_0_op_res_29915 = add64(eta_p_29913, eta_p_29914);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863] = defunc_0_op_res_29915;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_29853)[(int64_t) 4] = prefix_29896;\n                    acc_29886 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_29863 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_29896 = ((__local int64_t *) local_mem_29853)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_29916;\n            int64_t eta_p_29917;\n            int64_t eta_p_29919 = prefix_29896;\n            int64_t eta_p_29920 = acc_29886;\n            \n            if (slt32(local_tid_29846 * chunk_sizze_32b_29850, boundary_29866) && !block_new_sgm_29897) {\n                int64_t defunc_0_op_res_29921 = add64(eta_p_29919, eta_p_29920);\n                \n                eta_p_29916 = defunc_0_op_res_29921;\n            } else {\n                eta_p_29916 = acc_29886;\n            }\n            \n            int32_t stopping_point_299", "22 = segsizze_compact_29867 - srem32(local_tid_29846 * chunk_sizze_32b_29850 - 1 + segsizze_compact_29867 - boundary_29866, segsizze_compact_29867);\n            \n            for (int64_t i_29923 = 0; i_29923 < chunk_sizze_29794; i_29923++) {\n                if (slt32(sext_i64_i32(i_29923), stopping_point_29922 - 1)) {\n                    eta_p_29917 = private_mem_29868[i_29923];\n                    \n                    int64_t defunc_0_op_res_29918 = add64(eta_p_29916, eta_p_29917);\n                    \n                    private_mem_29868[i_29923] = defunc_0_op_res_29918;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_29924 = 0; i_29924 < chunk_sizze_29794; i_29924++) {\n                int64_t sharedIdx_29925 = sext_i32_i64(local_tid_29846) * chunk_sizze_29794 + i_29924;\n                int64_t tmp_29926 = private_mem_29868[i_29924];\n                \n                ((__local int64_t *) local_mem_29853)[sharedIdx_29925] = tmp_29926;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_29927 = 0; i_29927 < chunk_sizze_29794; i_29927++) {\n                int64_t flat_idx_29928 = thd_offset_29870 + i_29927 * segscan_tblock_sizze_28221;\n                int64_t slice_29929 = mz2080U_18678;\n                int64_t gtid_28225 = flat_idx_29928;\n                int64_t remnant_29930 = flat_idx_29928 - gtid_28225;\n                \n                if (slt64(flat_idx_29928, mz2080U_18678)) {\n                    int64_t tmp_29931 = ((__local int64_t *) local_mem_29853)[flat_idx_29928 - block_offset_29864];\n                    \n                    ((__global int64_t *) mem_29683)[gtid_28225] = tmp_29931;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28221\n    #undef chunk_sizze_29794\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegscan_", "28242_dim1, 1, 1)\nvoid human_genericf32zisegscan_28242(__global int *global_failure, int64_t nz2081U_18679, int64_t num_tblocks_28239, int64_t num_virt_blocks_29972, int64_t num_virt_threads_29973, __global unsigned char *A_mem_29680, __global unsigned char *mem_29684, __global unsigned char *mem_29687, __global unsigned char *mem_29689, __global unsigned char *status_flags_mem_29974, __global unsigned char *aggregates_mem_29976, __global unsigned char *incprefixes_mem_29978, __global unsigned char *aggregates_mem_29980, __global unsigned char *incprefixes_mem_29982, __global unsigned char *global_dynid_mem_29984)\n{\n    #define segscan_tblock_sizze_28237 (human_genericf32zisegscan_28242zisegscan_tblock_sizze_28237)\n    #define chunk_sizze_29971 (human_genericf32zisegscan_28242zichunk_sizze_29971)\n    \n    volatile __local unsigned char *local_mem_29996_backing_0 = &shared_mem[0];\n    const int64_t local_mem_29996_backing_0_offset = 0 + (smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_28237, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_28237), smax64(chunk_sizze_29971 * segscan_tblock_sizze_28237, chunk_sizze_29971 * segscan_tblock_sizze_28237 * (int64_t) 4)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_28237, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_28237), smax64(chunk_sizze_29971 * segscan_tblock_sizze_28237, chunk_sizze_29971 * segscan_tblock_sizze_28237 * (int64_t) 4)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29987;\n    int32_t tblock_sizze_29990;\n    int32_t wave_sizze_29989;\n    int32_t block_id_29988;\n    int32_t global_tid_29986;\n    int64_t phys_tid_28242;\n    int32_t chunk_sizze_32b_29991;\n    int64_t byte_offsets_29992;\n    int64_t byte_offsets_29993;\n    int64_t warp_byte_offset_29994;\n    int64_t warp_byte_offset_29995;\n    __local unsigned char *local_mem_29996;\n    int64_t trans_arr_len_2",
                                    "9997;\n    int64_t phys_block_id_30006;\n    int64_t virtloop_bound_30007;\n    \n    local_tid_29987 = get_local_id(0);\n    tblock_sizze_29990 = get_local_size(0);\n    wave_sizze_29989 = LOCKSTEP_WIDTH;\n    block_id_29988 = get_tblock_id(0);\n    global_tid_29986 = block_id_29988 * tblock_sizze_29990 + local_tid_29987;\n    phys_tid_28242 = sext_i32_i64(global_tid_29986);\n    chunk_sizze_32b_29991 = sext_i64_i32(chunk_sizze_29971);\n    byte_offsets_29992 = segscan_tblock_sizze_28237;\n    byte_offsets_29993 = sdiv_up64(byte_offsets_29992, (int64_t) 4) * (int64_t) 4 + segscan_tblock_sizze_28237 * (int64_t) 4;\n    warp_byte_offset_29994 = (int64_t) 64;\n    warp_byte_offset_29995 = sdiv_up64(warp_byte_offset_29994, (int64_t) 4) * (int64_t) 4 + (int64_t) 128;\n    // Allocate reusable shared memory\n    { }\n    local_mem_29996 = (__local unsigned char *) local_mem_29996_backing_0;\n    trans_arr_len_29997 = chunk_sizze_29971 * segscan_tblock_sizze_28237;\n    phys_block_id_30006 = get_tblock_id(0);\n    virtloop_bound_30007 = sdiv_up64(num_virt_blocks_29972 - phys_block_id_30006, num_tblocks_28239);\n    for (int64_t virtloop_i_30008 = 0; virtloop_i_30008 < virtloop_bound_30007; virtloop_i_30008++) {\n        int64_t dynamic_id_30009;\n        int64_t block_offset_30010;\n        int64_t sgm_idx_30011;\n        int32_t boundary_30012;\n        int32_t segsizze_compact_30013;\n        bool private_mem_30014[chunk_sizze_29971];\n        float private_mem_30016[chunk_sizze_29971];\n        int64_t thd_offset_30018;\n        bool acc_30045;\n        float acc_30046;\n        bool prefix_30060;\n        float prefix_30061;\n        bool block_new_sgm_30062;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_29987 == 0) {\n                dynamic_id_30009 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_29984)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__", "local int64_t *) local_mem_29996)[(int64_t) 0] = dynamic_id_30009;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30009 == num_virt_blocks_29972 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_29984)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30009 = ((__local int32_t *) local_mem_29996)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30010 = dynamic_id_30009 * chunk_sizze_29971 * segscan_tblock_sizze_28237;\n        sgm_idx_30011 = smod64(block_offset_30010, nz2081U_18679);\n        boundary_30012 = sext_i64_i32(smin64(chunk_sizze_29971 * segscan_tblock_sizze_28237, nz2081U_18679 - sgm_idx_30011));\n        segsizze_compact_30013 = sext_i64_i32(smin64(chunk_sizze_29971 * segscan_tblock_sizze_28237, nz2081U_18679));\n        thd_offset_30018 = block_offset_30010 + sext_i32_i64(local_tid_29987);\n        // Load and map\n        {\n            for (int64_t i_30019 = 0; i_30019 < chunk_sizze_29971; i_30019++) {\n                int64_t virt_tid_30020 = thd_offset_30018 + i_30019 * segscan_tblock_sizze_28237;\n                int64_t slice_30021 = nz2081U_18679;\n                int64_t gtid_28241 = virt_tid_30020;\n                int64_t remnant_30022 = virt_tid_30020 - gtid_28241;\n                \n                if (slt64(virt_tid_30020, nz2081U_18679)) {\n                    bool x_26937 = ((__global bool *) mem_29684)[gtid_28241];\n                    float x_26938 = ((__global float *) A_mem_29680)[gtid_28241];\n                    \n                    private_mem_30014[i_30019] = x_26937;\n                    private_mem_30016[i_30019] = x_26938;\n                } else {\n                    private_mem_30014[i_30019] = 0;\n                    private_mem_30016[i_30019] = 0.0F;\n                }\n            }\n        }\n     ", "   barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30023 = 0; i_30023 < chunk_sizze_29971; i_30023++) {\n                int64_t sharedIdx_30024 = sext_i32_i64(local_tid_29987) + i_30023 * segscan_tblock_sizze_28237;\n                bool tmp_30025 = private_mem_30014[i_30023];\n                \n                ((__local bool *) local_mem_29996)[sharedIdx_30024] = tmp_30025;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30026 = 0; i_30026 < chunk_sizze_29971; i_30026++) {\n                int64_t sharedIdx_30027 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30026;\n                bool tmp_30028 = ((__local bool *) local_mem_29996)[sharedIdx_30027];\n                \n                private_mem_30014[i_30026] = tmp_30028;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30029 = 0; i_30029 < chunk_sizze_29971; i_30029++) {\n                int64_t sharedIdx_30030 = sext_i32_i64(local_tid_29987) + i_30029 * segscan_tblock_sizze_28237;\n                float tmp_30031 = private_mem_30016[i_30029];\n                \n                ((__local float *) local_mem_29996)[sharedIdx_30030] = tmp_30031;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30032 = 0; i_30032 < chunk_sizze_29971; i_30032++) {\n                int64_t sharedIdx_30033 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30032;\n                float tmp_30034 = ((__local float *) local_mem_29996)[sharedIdx_30033];\n                \n                private_mem_30016[i_30032] = tmp_30034;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30035 = 0; i_30035 < chunk_sizze_29971 - (int64_t) 1; i_30035++) {\n                bool eta_p_26930;\n                bool eta_p_26932;\n                \n                eta_p_26930 = private_mem_30014[i_30035];\n                eta_p_2693",
                                    "2 = private_mem_30014[i_30035 + (int64_t) 1];\n                \n                float eta_p_26931;\n                float eta_p_26933;\n                \n                eta_p_26931 = private_mem_30016[i_30035];\n                eta_p_26933 = private_mem_30016[i_30035 + (int64_t) 1];\n                \n                bool tmp_26934 = eta_p_26930 || eta_p_26932;\n                float tmp_26935;\n                \n                if (eta_p_26932) {\n                    tmp_26935 = eta_p_26933;\n                } else {\n                    float defunc_0_op_res_26936 = eta_p_26931 + eta_p_26933;\n                    \n                    tmp_26935 = defunc_0_op_res_26936;\n                }\n                private_mem_30014[i_30035 + (int64_t) 1] = tmp_26934;\n                private_mem_30016[i_30035 + (int64_t) 1] = tmp_26935;\n            }\n        }\n        // Publish results in shared memory\n        {\n            bool tmp_30036 = private_mem_30014[chunk_sizze_29971 - (int64_t) 1];\n            \n            ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = tmp_30036;\n            \n            float tmp_30037 = private_mem_30016[chunk_sizze_29971 - (int64_t) 1];\n            \n            ((__local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = tmp_30037;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            bool eta_p_30038;\n            float eta_p_30039;\n            bool eta_p_30040;\n            float eta_p_30041;\n            bool eta_p_30047;\n            float eta_p_30048;\n            bool eta_p_30049;\n            float eta_p_30050;\n            bool ltid_in_bounds_30054 = slt64(sext_i32_i64(local_tid_29987), num_virt_threads_29973);\n            int32_t skip_threads_30055;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30054) {\n                    eta_p_30040 = ((volatile __local bool *) local", "_mem_29996)[sext_i32_i64(local_tid_29987)];\n                    eta_p_30041 = ((volatile __local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)];\n                    if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                        eta_p_30038 = eta_p_30040;\n                        eta_p_30039 = eta_p_30041;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30055 = 1;\n                while (slt32(skip_threads_30055, 32)) {\n                    bool thread_active_30056 = sle32(skip_threads_30055, local_tid_29987 - squot32(local_tid_29987, 32) * 32) && ltid_in_bounds_30054;\n                    \n                    if (thread_active_30056) {\n                        // read operands\n                        {\n                            eta_p_30038 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30055)];\n                            eta_p_30039 = ((volatile __local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30055))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30056) {\n                            bool tmp_30042 = eta_p_30038 || eta_p_30040;\n                            float tmp_30043;\n                            \n                            if (eta_p_30040) {\n                                tmp_30043 = eta_p_30041;\n                            } else {\n                                float defunc_0_op_res_30044 = eta_p_30039 + eta_p_30041;\n                                \n                                tmp_30043 = defunc_0_op_res_30044;\n                            }\n                            eta_p_30038 = tmp_30042;\n                            et", "a_p_30039 = tmp_30043;\n                        }\n                    }\n                    if (sle32(wave_sizze_29989, skip_threads_30055)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30056) {\n                        // write result\n                        {\n                            ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30038;\n                            eta_p_30040 = eta_p_30038;\n                            ((volatile __local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30039;\n                            eta_p_30041 = eta_p_30039;\n                        }\n                    }\n                    if (sle32(wave_sizze_29989, skip_threads_30055)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30055 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 31 && ltid_in_bounds_30054) {\n                    ((volatile __local bool *) local_mem_29996)[sext_i32_i64(squot32(local_tid_29987, 32))] = eta_p_30038;\n                    ((volatile __local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(squot32(local_tid_29987, 32))] = eta_p_30039;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30057;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_29987, 32) == 0 && ltid_in_bounds_30054) {\n                        eta_p_30049 = ((volatile __local bool *) local_mem_29996)[sext_i",
                                    "32_i64(local_tid_29987)];\n                        eta_p_30050 = ((volatile __local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)];\n                        if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                            eta_p_30047 = eta_p_30049;\n                            eta_p_30048 = eta_p_30050;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30057 = 1;\n                    while (slt32(skip_threads_30057, 32)) {\n                        bool thread_active_30058 = sle32(skip_threads_30057, local_tid_29987 - squot32(local_tid_29987, 32) * 32) && (squot32(local_tid_29987, 32) == 0 && ltid_in_bounds_30054);\n                        \n                        if (thread_active_30058) {\n                            // read operands\n                            {\n                                eta_p_30047 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30057)];\n                                eta_p_30048 = ((volatile __local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30057))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30058) {\n                                bool tmp_30051 = eta_p_30047 || eta_p_30049;\n                                float tmp_30052;\n                                \n                                if (eta_p_30049) {\n                                    tmp_30052 = eta_p_30050;\n                                } else {\n                                    float defunc_0_op_res_30053 = eta_p_30048 + eta_p_30050;\n                                    \n                                   ", " tmp_30052 = defunc_0_op_res_30053;\n                                }\n                                eta_p_30047 = tmp_30051;\n                                eta_p_30048 = tmp_30052;\n                            }\n                        }\n                        if (sle32(wave_sizze_29989, skip_threads_30057)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30058) {\n                            // write result\n                            {\n                                ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30047;\n                                eta_p_30049 = eta_p_30047;\n                                ((volatile __local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30048;\n                                eta_p_30050 = eta_p_30048;\n                            }\n                        }\n                        if (sle32(wave_sizze_29989, skip_threads_30057)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30057 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30059 = squot32(local_tid_29987, 32) == 0 || !ltid_in_bounds_30054;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30059) {\n                        eta_p_30040 = eta_p_30038;\n                        eta_p_30041 = eta_p_30039;\n                        eta_p_30038 = ((__local bool *) local_mem_29996)[sext_i32_i64(squot32(local_tid_29987, 32)) - (int64_t) 1];\n                        eta_p_30039 = ((__local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (sext_i32_i64(squot32(local_tid_29987, 32)) - (int64_t) 1)];\n       ", "             }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30059) {\n                        bool tmp_30042 = eta_p_30038 || eta_p_30040;\n                        float tmp_30043;\n                        \n                        if (eta_p_30040) {\n                            tmp_30043 = eta_p_30041;\n                        } else {\n                            float defunc_0_op_res_30044 = eta_p_30039 + eta_p_30041;\n                            \n                            tmp_30043 = defunc_0_op_res_30044;\n                        }\n                        eta_p_30038 = tmp_30042;\n                        eta_p_30039 = tmp_30043;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30059) {\n                        ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30038;\n                        ((__local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30039;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_29987, 32) == 0 && ltid_in_bounds_30054) {\n                    ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30040;\n                    ((__local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30041;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_29987 == 0) {\n                acc_30045 = ((__local bool *) local_mem_29996)[segscan_tblock_sizze_28237 - (int64_t) 1];\n                acc_30046 = ((__local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (segscan_tblock_sizze_28237 - (int64_t) 1)];\n",
                                    "            } else {\n                acc_30045 = ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - (int64_t) 1];\n                acc_30046 = ((__local float *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (sext_i32_i64(local_tid_29987) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30060 = 0;\n        prefix_30061 = 0.0F;\n        block_new_sgm_30062 = sgm_idx_30011 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30062 && local_tid_29987 == 0) {\n                ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009] = acc_30045;\n                ((volatile __global float *) incprefixes_mem_29982)[dynamic_id_30009] = acc_30046;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 2;\n                acc_30045 = 0;\n                acc_30046 = 0.0F;\n            }\n            if (!block_new_sgm_30062 && slt32(local_tid_29987, wave_sizze_29989)) {\n                if (local_tid_29987 == 0) {\n                    ((volatile __global bool *) aggregates_mem_29976)[dynamic_id_30009] = acc_30045;\n                    ((volatile __global float *) aggregates_mem_29980)[dynamic_id_30009] = acc_30046;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 1;\n                    \n                    int8_t tmp_30063 = ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_29996)[(int64_t) 0] = tmp_30063;\n                }\n                mem_fence_local();\n                \n                int8_t status_30064 = ((__local int8_t *) local_mem_29996)[(int64_t) 0];\n                \n                if (status_30064 == (int8_t) 2) {\n                    if (local_tid_29987 == 0) {\n        ", "                prefix_30060 = ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009 - (int64_t) 1];\n                        prefix_30061 = ((volatile __global float *) incprefixes_mem_29982)[dynamic_id_30009 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30065 = sext_i64_i32(dynamic_id_30009 - sext_i32_i64(wave_sizze_29989));\n                    \n                    while (slt32(wave_sizze_29989 * -1, readOffset_30065)) {\n                        int32_t read_i_30066 = readOffset_30065 + local_tid_29987;\n                        bool aggr_30067 = 0;\n                        float aggr_30068 = 0.0F;\n                        int8_t flag_30069 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30066)) {\n                            flag_30069 = ((volatile __global int8_t *) status_flags_mem_29974)[sext_i32_i64(read_i_30066)];\n                            if (flag_30069 == (int8_t) 2) {\n                                aggr_30067 = ((volatile __global bool *) incprefixes_mem_29978)[sext_i32_i64(read_i_30066)];\n                                aggr_30068 = ((volatile __global float *) incprefixes_mem_29982)[sext_i32_i64(read_i_30066)];\n                            } else if (flag_30069 == (int8_t) 1) {\n                                aggr_30067 = ((volatile __global bool *) aggregates_mem_29976)[sext_i32_i64(read_i_30066)];\n                                aggr_30068 = ((volatile __global float *) aggregates_mem_29980)[sext_i32_i64(read_i_30066)];\n                            }\n                        }\n                        ((__local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)] = aggr_30067;\n                        ((__local float *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = aggr_30068;\n                        ((__local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = flag_30069;\n        ", "                flag_30069 = ((__local int8_t *) local_mem_29996)[sext_i32_i64(wave_sizze_29989) - (int64_t) 1];\n                        if (slt8(flag_30069, (int8_t) 2)) {\n                            int8_t flg_x_30077;\n                            int8_t flg_y_30078;\n                            bool eta_p_30070;\n                            float eta_p_30071;\n                            bool eta_p_30072;\n                            float eta_p_30073;\n                            int32_t skip_threads_30079;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30078 = ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)];\n                                eta_p_30072 = ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)];\n                                eta_p_30073 = ((volatile __local float *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + sext_i32_i64(local_tid_29987)];\n                                if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                                    eta_p_30070 = eta_p_30072;\n                                    eta_p_30071 = eta_p_30073;\n                                    flg_x_30077 = flg_y_30078;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30079 = 1;\n                                while (slt32(skip_threads_30079, 32)) {\n                                    if (sle32(skip_threads_30079, local_tid_29987 - squot32(local_tid_29987, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30077 = ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)",
                                    " - sext_i32_i64(skip_threads_30079)];\n                                            eta_p_30070 = ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30079))];\n                                            eta_p_30071 = ((volatile __local float *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30079))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30078 == (int8_t) 2 || flg_y_30078 == (int8_t) 0) {\n                                                flg_x_30077 = flg_y_30078;\n                                                eta_p_30070 = eta_p_30072;\n                                                eta_p_30071 = eta_p_30073;\n                                            } else {\n                                                bool tmp_30074 = eta_p_30070 || eta_p_30072;\n                                                float tmp_30075;\n                                                \n                                                if (eta_p_30072) {\n                                                    tmp_30075 = eta_p_30073;\n                                                } else {\n                                                    float defunc_0_op_res_30076 = eta_p_30071 + eta_p_30073;\n                                                    \n                                                    tmp_30075 = defunc_0_op_res_30076;\n                                                }\n                                                eta_p_30070 = tmp_30074;\n                                                eta_p_30071 = tmp_30075;\n                                            }\n                                        }\n                                        // write result\n                               ", "         {\n                                            ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = flg_x_30077;\n                                            flg_y_30078 = flg_x_30077;\n                                            ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)] = eta_p_30070;\n                                            eta_p_30072 = eta_p_30070;\n                                            ((volatile __local float *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30071;\n                                            eta_p_30073 = eta_p_30071;\n                                        }\n                                    }\n                                    skip_threads_30079 *= 2;\n                                }\n                            }\n                        }\n                        flag_30069 = ((__local int8_t *) local_mem_29996)[sext_i32_i64(wave_sizze_29989) - (int64_t) 1];\n                        aggr_30067 = ((__local bool *) local_mem_29996)[(int64_t) 32 + (sext_i32_i64(wave_sizze_29989) - (int64_t) 1)];\n                        aggr_30068 = ((__local float *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + (sext_i32_i64(wave_sizze_29989) - (int64_t) 1)];\n                        if (flag_30069 == (int8_t) 2) {\n                            readOffset_30065 = wave_sizze_29989 * -1;\n                        } else if (flag_30069 == (int8_t) 1) {\n                            readOffset_30065 -= wave_sizze_29989;\n                        }\n                        if (slt8((int8_t) 0, flag_30069)) {\n                            bool eta_p_30080 = aggr_30067;\n                            float eta_p_30081 = aggr_30068;\n                            bool eta_p_30082 = prefix_30060;\n                            float eta_p_30083 = prefix_30061;\n                            bool tmp_30084 = eta_p_30080 || eta_p_300", "82;\n                            float tmp_30085;\n                            \n                            if (eta_p_30082) {\n                                tmp_30085 = eta_p_30083;\n                            } else {\n                                float defunc_0_op_res_30086 = eta_p_30081 + eta_p_30083;\n                                \n                                tmp_30085 = defunc_0_op_res_30086;\n                            }\n                            prefix_30060 = tmp_30084;\n                            prefix_30061 = tmp_30085;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_29987 == 0) {\n                    if (boundary_30012 == sext_i64_i32(segscan_tblock_sizze_28237 * chunk_sizze_29971)) {\n                        bool eta_p_30087 = prefix_30060;\n                        float eta_p_30088 = prefix_30061;\n                        bool eta_p_30089 = acc_30045;\n                        float eta_p_30090 = acc_30046;\n                        bool tmp_30091 = eta_p_30087 || eta_p_30089;\n                        float tmp_30092;\n                        \n                        if (eta_p_30089) {\n                            tmp_30092 = eta_p_30090;\n                        } else {\n                            float defunc_0_op_res_30093 = eta_p_30088 + eta_p_30090;\n                            \n                            tmp_30092 = defunc_0_op_res_30093;\n                        }\n                        ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009] = tmp_30091;\n                        ((volatile __global float *) incprefixes_mem_29982)[dynamic_id_30009] = tmp_30092;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 2;\n                    }\n                    ((__local bool *) local_mem_29996)[(int64_t) 32] = prefix_30060;\n                    ((__local ",
                                    "float *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4)] = prefix_30061;\n                    acc_30045 = 0;\n                    acc_30046 = 0.0F;\n                }\n            }\n            if (!(dynamic_id_30009 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30060 = ((__local bool *) local_mem_29996)[(int64_t) 32];\n                prefix_30061 = ((__local float *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            bool eta_p_30094;\n            bool eta_p_30096;\n            bool eta_p_30101 = prefix_30060;\n            bool eta_p_30103 = acc_30045;\n            float eta_p_30095;\n            float eta_p_30097;\n            float eta_p_30102 = prefix_30061;\n            float eta_p_30104 = acc_30046;\n            \n            if (slt32(local_tid_29987 * chunk_sizze_32b_29991, boundary_30012) && !block_new_sgm_30062) {\n                bool tmp_30105 = eta_p_30101 || eta_p_30103;\n                float tmp_30106;\n                \n                if (eta_p_30103) {\n                    tmp_30106 = eta_p_30104;\n                } else {\n                    float defunc_0_op_res_30107 = eta_p_30102 + eta_p_30104;\n                    \n                    tmp_30106 = defunc_0_op_res_30107;\n                }\n                eta_p_30094 = tmp_30105;\n                eta_p_30095 = tmp_30106;\n            } else {\n                eta_p_30094 = acc_30045;\n                eta_p_30095 = acc_30046;\n            }\n            \n            int32_t stopping_point_30108 = segsizze_compact_30013 - srem32(local_tid_29987 * chunk_sizze_32b_29991 - 1 + segsizze_compact_30013 - boundary_30012, segsizze_compact_30013);\n            \n            for (int64_t i_30109 = 0; i_30109 < chunk_sizze_29971; i_30109++) {\n                if (slt32(sext_i64_i32(i_30109), stopping_point_30108 - 1)) {\n                    eta_p_30", "096 = private_mem_30014[i_30109];\n                    eta_p_30097 = private_mem_30016[i_30109];\n                    \n                    bool tmp_30098 = eta_p_30094 || eta_p_30096;\n                    float tmp_30099;\n                    \n                    if (eta_p_30096) {\n                        tmp_30099 = eta_p_30097;\n                    } else {\n                        float defunc_0_op_res_30100 = eta_p_30095 + eta_p_30097;\n                        \n                        tmp_30099 = defunc_0_op_res_30100;\n                    }\n                    private_mem_30014[i_30109] = tmp_30098;\n                    private_mem_30016[i_30109] = tmp_30099;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30110 = 0; i_30110 < chunk_sizze_29971; i_30110++) {\n                int64_t sharedIdx_30111 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30110;\n                bool tmp_30112 = private_mem_30014[i_30110];\n                \n                ((__local bool *) local_mem_29996)[sharedIdx_30111] = tmp_30112;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30113 = 0; i_30113 < chunk_sizze_29971; i_30113++) {\n                int64_t flat_idx_30114 = thd_offset_30018 + i_30113 * segscan_tblock_sizze_28237;\n                int64_t slice_30115 = nz2081U_18679;\n                int64_t gtid_28241 = flat_idx_30114;\n                int64_t remnant_30116 = flat_idx_30114 - gtid_28241;\n                \n                if (slt64(flat_idx_30114, nz2081U_18679)) {\n                    bool tmp_30117 = ((__local bool *) local_mem_29996)[flat_idx_30114 - block_offset_30010];\n                    \n                    ((__global bool *) mem_29687)[gtid_28241] = tmp_30117;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30118 = 0; i_30118 < chunk_sizze_29971; i_30118++) {\n            ", "    int64_t sharedIdx_30119 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30118;\n                float tmp_30120 = private_mem_30016[i_30118];\n                \n                ((__local float *) local_mem_29996)[sharedIdx_30119] = tmp_30120;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30121 = 0; i_30121 < chunk_sizze_29971; i_30121++) {\n                int64_t flat_idx_30122 = thd_offset_30018 + i_30121 * segscan_tblock_sizze_28237;\n                int64_t slice_30123 = nz2081U_18679;\n                int64_t gtid_28241 = flat_idx_30122;\n                int64_t remnant_30124 = flat_idx_30122 - gtid_28241;\n                \n                if (slt64(flat_idx_30122, nz2081U_18679)) {\n                    float tmp_30125 = ((__local float *) local_mem_29996)[flat_idx_30122 - block_offset_30010];\n                    \n                    ((__global float *) mem_29689)[gtid_28241] = tmp_30125;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28237\n    #undef chunk_sizze_29971\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegscan_28250_dim1, 1, 1)\nvoid human_genericf32zisegscan_28250(__global int *global_failure, int64_t mz2080U_18678, int64_t num_tblocks_28247, int64_t num_virt_blocks_30132, int64_t num_virt_threads_30133, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29692, __global unsigned char *status_flags_mem_30134, __global unsigned char *aggregates_mem_30136, __global unsigned char *incprefixes_mem_30138, __global unsigned char *global_dynid_mem_30140)\n{\n    #define segscan_tblock_sizze_28245 (human_genericf32zisegscan_28250zisegscan_tblock_sizze_28245)\n    #define chunk_sizze_30131 (human_genericf32zisegscan_28250zichunk_sizze_30131)\n    \n    volatile __local unsigned char *local_mem_30150_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30150_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, ",
                                    "(int64_t) 4 * segscan_tblock_sizze_28245), chunk_sizze_30131 * segscan_tblock_sizze_28245 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28245), chunk_sizze_30131 * segscan_tblock_sizze_28245 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30143;\n    int32_t tblock_sizze_30146;\n    int32_t wave_sizze_30145;\n    int32_t block_id_30144;\n    int32_t global_tid_30142;\n    int64_t phys_tid_28250;\n    int32_t chunk_sizze_32b_30147;\n    int64_t byte_offsets_30148;\n    int64_t warp_byte_offset_30149;\n    __local unsigned char *local_mem_30150;\n    int64_t trans_arr_len_30151;\n    int64_t phys_block_id_30157;\n    int64_t virtloop_bound_30158;\n    \n    local_tid_30143 = get_local_id(0);\n    tblock_sizze_30146 = get_local_size(0);\n    wave_sizze_30145 = LOCKSTEP_WIDTH;\n    block_id_30144 = get_tblock_id(0);\n    global_tid_30142 = block_id_30144 * tblock_sizze_30146 + local_tid_30143;\n    phys_tid_28250 = sext_i32_i64(global_tid_30142);\n    chunk_sizze_32b_30147 = sext_i64_i32(chunk_sizze_30131);\n    byte_offsets_30148 = segscan_tblock_sizze_28245 * (int64_t) 4;\n    warp_byte_offset_30149 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30150 = (__local unsigned char *) local_mem_30150_backing_0;\n    trans_arr_len_30151 = chunk_sizze_30131 * segscan_tblock_sizze_28245;\n    phys_block_id_30157 = get_tblock_id(0);\n    virtloop_bound_30158 = sdiv_up64(num_virt_blocks_30132 - phys_block_id_30157, num_tblocks_28247);\n    for (int64_t virtloop_i_30159 = 0; virtloop_i_30159 < virtloop_bound_30158; virtloop_i_30159++) {\n        int64_t dynamic_id_30160;\n        int64_t block_offset_30161;\n        int64_t sgm_idx_30162;\n        int32_t boundary_30163;\n        int32_t segsizze_compact_30164;\n        int32_t private_mem_30165[chunk_sizze_30131];\n        int64_t thd_offset_30167;\n        int32_t acc_30183;\n        int32_t pref", "ix_30193;\n        bool block_new_sgm_30194;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30143 == 0) {\n                dynamic_id_30160 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30140)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30150)[(int64_t) 0] = dynamic_id_30160;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30160 == num_virt_blocks_30132 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30140)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30160 = ((__local int32_t *) local_mem_30150)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30161 = dynamic_id_30160 * chunk_sizze_30131 * segscan_tblock_sizze_28245;\n        sgm_idx_30162 = smod64(block_offset_30161, mz2080U_18678);\n        boundary_30163 = sext_i64_i32(smin64(chunk_sizze_30131 * segscan_tblock_sizze_28245, mz2080U_18678 - sgm_idx_30162));\n        segsizze_compact_30164 = sext_i64_i32(smin64(chunk_sizze_30131 * segscan_tblock_sizze_28245, mz2080U_18678));\n        thd_offset_30167 = block_offset_30161 + sext_i32_i64(local_tid_30143);\n        // Load and map\n        {\n            for (int64_t i_30168 = 0; i_30168 < chunk_sizze_30131; i_30168++) {\n                int64_t virt_tid_30169 = thd_offset_30167 + i_30168 * segscan_tblock_sizze_28245;\n                int64_t slice_30170 = mz2080U_18678;\n                int64_t gtid_28249 = virt_tid_30169;\n                int64_t remnant_30171 = virt_tid_30169 - gtid_28249;\n                \n                if (slt64(virt_tid_30169, mz2080U_18678)) {\n                    int32_t x_27657 = ((__global int32_t *) shp_mem_29678)[gtid_2824", "9];\n                    \n                    private_mem_30165[i_30168] = x_27657;\n                } else {\n                    private_mem_30165[i_30168] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30172 = 0; i_30172 < chunk_sizze_30131; i_30172++) {\n                int64_t sharedIdx_30173 = sext_i32_i64(local_tid_30143) + i_30172 * segscan_tblock_sizze_28245;\n                int32_t tmp_30174 = private_mem_30165[i_30172];\n                \n                ((__local int32_t *) local_mem_30150)[sharedIdx_30173] = tmp_30174;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30175 = 0; i_30175 < chunk_sizze_30131; i_30175++) {\n                int64_t sharedIdx_30176 = sext_i32_i64(local_tid_30143) * chunk_sizze_30131 + i_30175;\n                int32_t tmp_30177 = ((__local int32_t *) local_mem_30150)[sharedIdx_30176];\n                \n                private_mem_30165[i_30175] = tmp_30177;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30178 = 0; i_30178 < chunk_sizze_30131 - (int64_t) 1; i_30178++) {\n                int32_t eta_p_27654;\n                int32_t eta_p_27655;\n                \n                eta_p_27654 = private_mem_30165[i_30178];\n                eta_p_27655 = private_mem_30165[i_30178 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_27656 = add32(eta_p_27654, eta_p_27655);\n                \n                private_mem_30165[i_30178 + (int64_t) 1] = defunc_0_op_res_27656;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_30179 = private_mem_30165[chunk_sizze_30131 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = tmp_30179;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan resu",
                                    "lts (with warp scan)\n        {\n            int32_t eta_p_30180;\n            int32_t eta_p_30181;\n            int32_t eta_p_30184;\n            int32_t eta_p_30185;\n            bool ltid_in_bounds_30187 = slt64(sext_i32_i64(local_tid_30143), num_virt_threads_30133);\n            int32_t skip_threads_30188;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30187) {\n                    eta_p_30181 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                    if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                        eta_p_30180 = eta_p_30181;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30188 = 1;\n                while (slt32(skip_threads_30188, 32)) {\n                    bool thread_active_30189 = sle32(skip_threads_30188, local_tid_30143 - squot32(local_tid_30143, 32) * 32) && ltid_in_bounds_30187;\n                    \n                    if (thread_active_30189) {\n                        // read operands\n                        {\n                            eta_p_30180 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30188)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30189) {\n                            int32_t defunc_0_op_res_30182 = add32(eta_p_30180, eta_p_30181);\n                            \n                            eta_p_30180 = defunc_0_op_res_30182;\n                        }\n                    }\n                    if (sle32(wave_sizze_30145, skip_threads_30188)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30189) {\n                        // write result\n                        {\n       ", "                     ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30180;\n                            eta_p_30181 = eta_p_30180;\n                        }\n                    }\n                    if (sle32(wave_sizze_30145, skip_threads_30188)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30188 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 31 && ltid_in_bounds_30187) {\n                    ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(squot32(local_tid_30143, 32))] = eta_p_30180;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30190;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187) {\n                        eta_p_30185 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                        if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                            eta_p_30184 = eta_p_30185;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30190 = 1;\n                    while (slt32(skip_threads_30190, 32)) {\n                        bool thread_active_30191 = sle32(skip_threads_30190, local_tid_30143 - squot32(local_tid_30143, 32) * 32) && (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187);\n                        \n                        if (thread_active_30191) {\n                    ", "        // read operands\n                            {\n                                eta_p_30184 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30190)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30191) {\n                                int32_t defunc_0_op_res_30186 = add32(eta_p_30184, eta_p_30185);\n                                \n                                eta_p_30184 = defunc_0_op_res_30186;\n                            }\n                        }\n                        if (sle32(wave_sizze_30145, skip_threads_30190)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30191) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30184;\n                                eta_p_30185 = eta_p_30184;\n                            }\n                        }\n                        if (sle32(wave_sizze_30145, skip_threads_30190)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30190 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30192 = squot32(local_tid_30143, 32) == 0 || !ltid_in_bounds_30187;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30192) {\n                        eta_p_30181 = eta_p_30180;\n                        eta_p_30180 = ((__local int32_t *) local_mem_30150)[sext_i32_i64(squot32(local_tid_30143, 32)) - (int64_t) 1];\n                    }\n                }\n   ",
                                    "             // perform operation\n                {\n                    if (!no_carry_in_30192) {\n                        int32_t defunc_0_op_res_30182 = add32(eta_p_30180, eta_p_30181);\n                        \n                        eta_p_30180 = defunc_0_op_res_30182;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30192) {\n                        ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30180;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187) {\n                    ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30181;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30143 == 0) {\n                acc_30183 = ((__local int32_t *) local_mem_30150)[segscan_tblock_sizze_28245 - (int64_t) 1];\n            } else {\n                acc_30183 = ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30193 = 0;\n        block_new_sgm_30194 = sgm_idx_30162 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30194 && local_tid_30143 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160] = acc_30183;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 2;\n                acc_30183 = 0;\n            }\n            if (!block_new_sgm_30194 && slt32(local_tid_30143, wave_sizze_30145)) {\n                if (local_tid_30143 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem", "_30136)[dynamic_id_30160] = acc_30183;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 1;\n                    \n                    int8_t tmp_30195 = ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30150)[(int64_t) 0] = tmp_30195;\n                }\n                mem_fence_local();\n                \n                int8_t status_30196 = ((__local int8_t *) local_mem_30150)[(int64_t) 0];\n                \n                if (status_30196 == (int8_t) 2) {\n                    if (local_tid_30143 == 0) {\n                        prefix_30193 = ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30197 = sext_i64_i32(dynamic_id_30160 - sext_i32_i64(wave_sizze_30145));\n                    \n                    while (slt32(wave_sizze_30145 * -1, readOffset_30197)) {\n                        int32_t read_i_30198 = readOffset_30197 + local_tid_30143;\n                        int32_t aggr_30199 = 0;\n                        int8_t flag_30200 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30198)) {\n                            flag_30200 = ((volatile __global int8_t *) status_flags_mem_30134)[sext_i32_i64(read_i_30198)];\n                            if (flag_30200 == (int8_t) 2) {\n                                aggr_30199 = ((volatile __global int32_t *) incprefixes_mem_30138)[sext_i32_i64(read_i_30198)];\n                            } else if (flag_30200 == (int8_t) 1) {\n                                aggr_30199 = ((volatile __global int32_t *) aggregates_mem_30136)[sext_i32_i64(read_i_30198)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_30150)[(int64_t", ") 8 + sext_i32_i64(local_tid_30143)] = aggr_30199;\n                        ((__local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = flag_30200;\n                        flag_30200 = ((__local int8_t *) local_mem_30150)[sext_i32_i64(wave_sizze_30145) - (int64_t) 1];\n                        if (slt8(flag_30200, (int8_t) 2)) {\n                            int8_t flg_x_30204;\n                            int8_t flg_y_30205;\n                            int32_t eta_p_30201;\n                            int32_t eta_p_30202;\n                            int32_t skip_threads_30206;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30205 = ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                                eta_p_30202 = ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8 + sext_i32_i64(local_tid_30143)];\n                                if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                                    eta_p_30201 = eta_p_30202;\n                                    flg_x_30204 = flg_y_30205;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30206 = 1;\n                                while (slt32(skip_threads_30206, 32)) {\n                                    if (sle32(skip_threads_30206, local_tid_30143 - squot32(local_tid_30143, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30204 = ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30206)];\n                                            eta_p_30201 = ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8",
                                    " + (sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30206))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30205 == (int8_t) 2 || flg_y_30205 == (int8_t) 0) {\n                                                flg_x_30204 = flg_y_30205;\n                                                eta_p_30201 = eta_p_30202;\n                                            } else {\n                                                int32_t defunc_0_op_res_30203 = add32(eta_p_30201, eta_p_30202);\n                                                \n                                                eta_p_30201 = defunc_0_op_res_30203;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = flg_x_30204;\n                                            flg_y_30205 = flg_x_30204;\n                                            ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8 + sext_i32_i64(local_tid_30143)] = eta_p_30201;\n                                            eta_p_30202 = eta_p_30201;\n                                        }\n                                    }\n                                    skip_threads_30206 *= 2;\n                                }\n                            }\n                        }\n                        flag_30200 = ((__local int8_t *) local_mem_30150)[sext_i32_i64(wave_sizze_30145) - (int64_t) 1];\n                        aggr_30199 = ((__local int32_t *) local_mem_30150)[(int64_t) 8 + (sext_i32_i64(wave_sizze_30145) - (int64_t) 1)];\n                        if (flag_30200 == (int8_t) 2) {\n                            readOffset_30197 = wave_sizze_30145 * ", "-1;\n                        } else if (flag_30200 == (int8_t) 1) {\n                            readOffset_30197 -= wave_sizze_30145;\n                        }\n                        if (slt8((int8_t) 0, flag_30200)) {\n                            int32_t eta_p_30207 = aggr_30199;\n                            int32_t eta_p_30208 = prefix_30193;\n                            int32_t defunc_0_op_res_30209 = add32(eta_p_30207, eta_p_30208);\n                            \n                            prefix_30193 = defunc_0_op_res_30209;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30143 == 0) {\n                    if (boundary_30163 == sext_i64_i32(segscan_tblock_sizze_28245 * chunk_sizze_30131)) {\n                        int32_t eta_p_30210 = prefix_30193;\n                        int32_t eta_p_30211 = acc_30183;\n                        int32_t defunc_0_op_res_30212 = add32(eta_p_30210, eta_p_30211);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160] = defunc_0_op_res_30212;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_30150)[(int64_t) 8] = prefix_30193;\n                    acc_30183 = 0;\n                }\n            }\n            if (!(dynamic_id_30160 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30193 = ((__local int32_t *) local_mem_30150)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_30213;\n            int32_t eta_p_30214;\n            int32_t eta_p_30216 = prefix_30193;\n            int32_t eta_p_30217 = acc_30183;\n            \n            if (slt32(local_tid_30143 * chunk_sizze_32b_30147", ", boundary_30163) && !block_new_sgm_30194) {\n                int32_t defunc_0_op_res_30218 = add32(eta_p_30216, eta_p_30217);\n                \n                eta_p_30213 = defunc_0_op_res_30218;\n            } else {\n                eta_p_30213 = acc_30183;\n            }\n            \n            int32_t stopping_point_30219 = segsizze_compact_30164 - srem32(local_tid_30143 * chunk_sizze_32b_30147 - 1 + segsizze_compact_30164 - boundary_30163, segsizze_compact_30164);\n            \n            for (int64_t i_30220 = 0; i_30220 < chunk_sizze_30131; i_30220++) {\n                if (slt32(sext_i64_i32(i_30220), stopping_point_30219 - 1)) {\n                    eta_p_30214 = private_mem_30165[i_30220];\n                    \n                    int32_t defunc_0_op_res_30215 = add32(eta_p_30213, eta_p_30214);\n                    \n                    private_mem_30165[i_30220] = defunc_0_op_res_30215;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30221 = 0; i_30221 < chunk_sizze_30131; i_30221++) {\n                int64_t sharedIdx_30222 = sext_i32_i64(local_tid_30143) * chunk_sizze_30131 + i_30221;\n                int32_t tmp_30223 = private_mem_30165[i_30221];\n                \n                ((__local int32_t *) local_mem_30150)[sharedIdx_30222] = tmp_30223;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30224 = 0; i_30224 < chunk_sizze_30131; i_30224++) {\n                int64_t flat_idx_30225 = thd_offset_30167 + i_30224 * segscan_tblock_sizze_28245;\n                int64_t slice_30226 = mz2080U_18678;\n                int64_t gtid_28249 = flat_idx_30225;\n                int64_t remnant_30227 = flat_idx_30225 - gtid_28249;\n                \n                if (slt64(flat_idx_30225, mz2080U_18678)) {\n                    int32_t tmp_30228 = ((__local int32_t *) local_mem_30150)[flat_idx_30225 - block_offset_30161];\n          ",
                                    "          \n                    ((__global int32_t *) mem_29692)[gtid_28249] = tmp_30228;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28245\n    #undef chunk_sizze_30131\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegscan_28399_dim1, 1, 1)\nvoid human_genericf32zisegscan_28399(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_18678, int64_t nz2081U_18679, int64_t num_tblocks_28396, int64_t num_virt_blocks_30441, int64_t num_virt_threads_30442, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *mem_29709, __global unsigned char *mem_29712, __global unsigned char *mem_29714, __global unsigned char *status_flags_mem_30443, __global unsigned char *aggregates_mem_30445, __global unsigned char *incprefixes_mem_30447, __global unsigned char *global_dynid_mem_30449)\n{\n    #define segscan_tblock_sizze_28394 (human_genericf32zisegscan_28399zisegscan_tblock_sizze_28394)\n    #define chunk_sizze_30440 (human_genericf32zisegscan_28399zichunk_sizze_30440)\n    \n    volatile __local unsigned char *local_mem_30459_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30459_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28394), chunk_sizze_30440 * segscan_tblock_sizze_28394 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28394), chunk_sizze_30440 * segscan_tblock_sizze_28394 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30452;\n    int32_t tblock_sizze_30455;\n    int32_t wave_sizze_30454;\n ", "   int32_t block_id_30453;\n    int32_t global_tid_30451;\n    int64_t phys_tid_28399;\n    int32_t chunk_sizze_32b_30456;\n    int64_t byte_offsets_30457;\n    int64_t warp_byte_offset_30458;\n    __local unsigned char *local_mem_30459;\n    int64_t trans_arr_len_30460;\n    int64_t phys_block_id_30466;\n    int64_t virtloop_bound_30467;\n    \n    local_tid_30452 = get_local_id(0);\n    tblock_sizze_30455 = get_local_size(0);\n    wave_sizze_30454 = LOCKSTEP_WIDTH;\n    block_id_30453 = get_tblock_id(0);\n    global_tid_30451 = block_id_30453 * tblock_sizze_30455 + local_tid_30452;\n    phys_tid_28399 = sext_i32_i64(global_tid_30451);\n    chunk_sizze_32b_30456 = sext_i64_i32(chunk_sizze_30440);\n    byte_offsets_30457 = segscan_tblock_sizze_28394 * (int64_t) 8;\n    warp_byte_offset_30458 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30459 = (__local unsigned char *) local_mem_30459_backing_0;\n    trans_arr_len_30460 = chunk_sizze_30440 * segscan_tblock_sizze_28394;\n    phys_block_id_30466 = get_tblock_id(0);\n    virtloop_bound_30467 = sdiv_up64(num_virt_blocks_30441 - phys_block_id_30466, num_tblocks_28396);\n    for (int64_t virtloop_i_30468 = 0; virtloop_i_30468 < virtloop_bound_30467; virtloop_i_30468++) {\n        int64_t dynamic_id_30469;\n        int64_t block_offset_30470;\n        int64_t sgm_idx_30471;\n        int32_t boundary_30472;\n        int32_t segsizze_compact_30473;\n        int64_t private_mem_30474[chunk_sizze_30440];\n        int64_t thd_offset_30476;\n        int64_t acc_30492;\n        int64_t prefix_30502;\n        bool block_new_sgm_30503;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30452 == 0) {\n                dynamic_id_30469 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30449)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30459)[(int64_t) 0] = dynami", "c_id_30469;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30469 == num_virt_blocks_30441 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30449)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30469 = ((__local int32_t *) local_mem_30459)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30470 = dynamic_id_30469 * chunk_sizze_30440 * segscan_tblock_sizze_28394;\n        sgm_idx_30471 = smod64(block_offset_30470, nz2081U_18679);\n        boundary_30472 = sext_i64_i32(smin64(chunk_sizze_30440 * segscan_tblock_sizze_28394, nz2081U_18679 - sgm_idx_30471));\n        segsizze_compact_30473 = sext_i64_i32(smin64(chunk_sizze_30440 * segscan_tblock_sizze_28394, nz2081U_18679));\n        thd_offset_30476 = block_offset_30470 + sext_i32_i64(local_tid_30452);\n        // Load and map\n        {\n            for (int64_t i_30477 = 0; i_30477 < chunk_sizze_30440; i_30477++) {\n                int64_t virt_tid_30478 = thd_offset_30476 + i_30477 * segscan_tblock_sizze_28394;\n                int64_t slice_30479 = nz2081U_18679;\n                int64_t gtid_28398 = virt_tid_30478;\n                int64_t remnant_30480 = virt_tid_30478 - gtid_28398;\n                \n                if (slt64(virt_tid_30478, nz2081U_18679)) {\n                    int32_t eta_p_27407 = ((__global int32_t *) II1_mem_29679)[gtid_28398];\n                    int64_t ii_27408 = sext_i32_i64(eta_p_27407);\n                    bool x_27409 = sle64((int64_t) 0, ii_27408);\n                    bool y_27410 = slt64(ii_27408, mz2080U_18678);\n                    bool bounds_check_27411 = x_27409 && y_27410;\n                    bool index_certs_27412;\n                    \n                    if (!bounds_check_27411) {\n                        {\n                            if (atomi",
                                    "c_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                                global_failure_args[0] = (int64_t) ii_27408;\n                                global_failure_args[1] = (int64_t) mz2080U_18678;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int32_t zeze_lhs_27413 = ((__global int32_t *) mem_29709)[ii_27408];\n                    bool cond_27414 = zeze_lhs_27413 == -1;\n                    bool defunc_0_p_res_27415;\n                    \n                    if (cond_27414) {\n                        defunc_0_p_res_27415 = 0;\n                    } else {\n                        float eta_p_27406 = ((__global float *) A_mem_29680)[gtid_28398];\n                        bool cond_27416 = zeze_lhs_27413 == 0;\n                        bool defunc_0_p_res_f_res_27417;\n                        \n                        if (cond_27416) {\n                            float lt_arg1_28149 = ((__global float *) mem_29695)[ii_27408];\n                            bool defunc_0_lt_res_28150 = eta_p_27406 < lt_arg1_28149;\n                            \n                            defunc_0_p_res_f_res_27417 = defunc_0_lt_res_28150;\n                        } else {\n                            bool cond_27420 = zeze_lhs_27413 == 1;\n                            bool defunc_0_p_res_f_res_f_res_27421;\n                            \n                            if (cond_27420) {\n                                defunc_0_p_res_f_res_f_res_27421 = 0;\n                            } else {\n                                float lt_arg1_27422 = ((__global float *) mem_29695)[ii_27408];\n                                bool defunc_0_lt_res_27423 = eta_p_27406 < lt_arg1_27422;\n                                bool cond_27424 = !defunc_0_lt_res_27423;\n                                bool defunc_0_eq_res_27425 ", "= eta_p_27406 == lt_arg1_27422;\n                                bool defunc_0_p_res_f_res_f_res_f_res_t_res_27426 = !defunc_0_eq_res_27425;\n                                bool x_27427 = cond_27424 && defunc_0_p_res_f_res_f_res_f_res_t_res_27426;\n                                \n                                defunc_0_p_res_f_res_f_res_27421 = x_27427;\n                            }\n                            defunc_0_p_res_f_res_27417 = defunc_0_p_res_f_res_f_res_27421;\n                        }\n                        defunc_0_p_res_27415 = defunc_0_p_res_f_res_27417;\n                    }\n                    \n                    int64_t defunc_0_f_res_27428 = btoi_bool_i64(defunc_0_p_res_27415);\n                    \n                    ((__global int64_t *) mem_29714)[gtid_28398] = defunc_0_f_res_27428;\n                    private_mem_30474[i_30477] = defunc_0_f_res_27428;\n                } else {\n                    private_mem_30474[i_30477] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30481 = 0; i_30481 < chunk_sizze_30440; i_30481++) {\n                int64_t sharedIdx_30482 = sext_i32_i64(local_tid_30452) + i_30481 * segscan_tblock_sizze_28394;\n                int64_t tmp_30483 = private_mem_30474[i_30481];\n                \n                ((__local int64_t *) local_mem_30459)[sharedIdx_30482] = tmp_30483;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30484 = 0; i_30484 < chunk_sizze_30440; i_30484++) {\n                int64_t sharedIdx_30485 = sext_i32_i64(local_tid_30452) * chunk_sizze_30440 + i_30484;\n                int64_t tmp_30486 = ((__local int64_t *) local_mem_30459)[sharedIdx_30485];\n                \n                private_mem_30474[i_30484] = tmp_30486;\n            }\n            barr", "ier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30487 = 0; i_30487 < chunk_sizze_30440 - (int64_t) 1; i_30487++) {\n                int64_t eta_p_27073;\n                int64_t eta_p_27074;\n                \n                eta_p_27073 = private_mem_30474[i_30487];\n                eta_p_27074 = private_mem_30474[i_30487 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27075 = add64(eta_p_27073, eta_p_27074);\n                \n                private_mem_30474[i_30487 + (int64_t) 1] = defunc_0_op_res_27075;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_30488 = private_mem_30474[chunk_sizze_30440 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = tmp_30488;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_30489;\n            int64_t eta_p_30490;\n            int64_t eta_p_30493;\n            int64_t eta_p_30494;\n            bool ltid_in_bounds_30496 = slt64(sext_i32_i64(local_tid_30452), num_virt_threads_30442);\n            int32_t skip_threads_30497;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30496) {\n                    eta_p_30490 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)];\n                    if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 0) {\n                        eta_p_30489 = eta_p_30490;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30497 = 1;\n                while (slt32(skip_threads_30497, 32)) {\n                    bool thread_active_30498 = sle32(skip_threads_30497, local_tid_30452 - squot32(local_tid_30452, 32) * 32) && ltid_in_bounds_30496;\n                    \n        ",
                                    "            if (thread_active_30498) {\n                        // read operands\n                        {\n                            eta_p_30489 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30497)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30498) {\n                            int64_t defunc_0_op_res_30491 = add64(eta_p_30489, eta_p_30490);\n                            \n                            eta_p_30489 = defunc_0_op_res_30491;\n                        }\n                    }\n                    if (sle32(wave_sizze_30454, skip_threads_30497)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30498) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30489;\n                            eta_p_30490 = eta_p_30489;\n                        }\n                    }\n                    if (sle32(wave_sizze_30454, skip_threads_30497)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30497 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 31 && ltid_in_bounds_30496) {\n                    ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(squot32(local_tid_30452, 32))] = eta_p_30489;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30499;\n                \n                // read input", " for in-block scan\n                {\n                    if (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496) {\n                        eta_p_30494 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)];\n                        if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 0) {\n                            eta_p_30493 = eta_p_30494;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30499 = 1;\n                    while (slt32(skip_threads_30499, 32)) {\n                        bool thread_active_30500 = sle32(skip_threads_30499, local_tid_30452 - squot32(local_tid_30452, 32) * 32) && (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496);\n                        \n                        if (thread_active_30500) {\n                            // read operands\n                            {\n                                eta_p_30493 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30499)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30500) {\n                                int64_t defunc_0_op_res_30495 = add64(eta_p_30493, eta_p_30494);\n                                \n                                eta_p_30493 = defunc_0_op_res_30495;\n                            }\n                        }\n                        if (sle32(wave_sizze_30454, skip_threads_30499)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30500) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30493;\n             ", "                   eta_p_30494 = eta_p_30493;\n                            }\n                        }\n                        if (sle32(wave_sizze_30454, skip_threads_30499)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30499 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30501 = squot32(local_tid_30452, 32) == 0 || !ltid_in_bounds_30496;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30501) {\n                        eta_p_30490 = eta_p_30489;\n                        eta_p_30489 = ((__local int64_t *) local_mem_30459)[sext_i32_i64(squot32(local_tid_30452, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30501) {\n                        int64_t defunc_0_op_res_30491 = add64(eta_p_30489, eta_p_30490);\n                        \n                        eta_p_30489 = defunc_0_op_res_30491;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30501) {\n                        ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30489;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496) {\n                    ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30490;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30452 == 0) {\n                acc_30492 = ((__local int64_t ",
                                    "*) local_mem_30459)[segscan_tblock_sizze_28394 - (int64_t) 1];\n            } else {\n                acc_30492 = ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30502 = (int64_t) 0;\n        block_new_sgm_30503 = sgm_idx_30471 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30503 && local_tid_30452 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469] = acc_30492;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 2;\n                acc_30492 = (int64_t) 0;\n            }\n            if (!block_new_sgm_30503 && slt32(local_tid_30452, wave_sizze_30454)) {\n                if (local_tid_30452 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_30445)[dynamic_id_30469] = acc_30492;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 1;\n                    \n                    int8_t tmp_30504 = ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30459)[(int64_t) 0] = tmp_30504;\n                }\n                mem_fence_local();\n                \n                int8_t status_30505 = ((__local int8_t *) local_mem_30459)[(int64_t) 0];\n                \n                if (status_30505 == (int8_t) 2) {\n                    if (local_tid_30452 == 0) {\n                        prefix_30502 = ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30506 = sext_i64_i32(dynamic_id_30469 - sext_i32_i64(wave_sizze_30454));\n                    \n                    while (sl", "t32(wave_sizze_30454 * -1, readOffset_30506)) {\n                        int32_t read_i_30507 = readOffset_30506 + local_tid_30452;\n                        int64_t aggr_30508 = (int64_t) 0;\n                        int8_t flag_30509 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30507)) {\n                            flag_30509 = ((volatile __global int8_t *) status_flags_mem_30443)[sext_i32_i64(read_i_30507)];\n                            if (flag_30509 == (int8_t) 2) {\n                                aggr_30508 = ((volatile __global int64_t *) incprefixes_mem_30447)[sext_i32_i64(read_i_30507)];\n                            } else if (flag_30509 == (int8_t) 1) {\n                                aggr_30508 = ((volatile __global int64_t *) aggregates_mem_30445)[sext_i32_i64(read_i_30507)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)] = aggr_30508;\n                        ((__local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = flag_30509;\n                        flag_30509 = ((__local int8_t *) local_mem_30459)[sext_i32_i64(wave_sizze_30454) - (int64_t) 1];\n                        if (slt8(flag_30509, (int8_t) 2)) {\n                            int8_t flg_x_30513;\n                            int8_t flg_y_30514;\n                            int64_t eta_p_30510;\n                            int64_t eta_p_30511;\n                            int32_t skip_threads_30515;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30514 = ((volatile __local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)];\n                                eta_p_30511 = ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)];\n                                if ((local_tid_30452 - squot32(local_tid_3", "0452, 32) * 32) == 0) {\n                                    eta_p_30510 = eta_p_30511;\n                                    flg_x_30513 = flg_y_30514;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30515 = 1;\n                                while (slt32(skip_threads_30515, 32)) {\n                                    if (sle32(skip_threads_30515, local_tid_30452 - squot32(local_tid_30452, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30513 = ((volatile __local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30515)];\n                                            eta_p_30510 = ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + (sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30515))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30514 == (int8_t) 2 || flg_y_30514 == (int8_t) 0) {\n                                                flg_x_30513 = flg_y_30514;\n                                                eta_p_30510 = eta_p_30511;\n                                            } else {\n                                                int64_t defunc_0_op_res_30512 = add64(eta_p_30510, eta_p_30511);\n                                                \n                                                eta_p_30510 = defunc_0_op_res_30512;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30",
                                    "459)[sext_i32_i64(local_tid_30452)] = flg_x_30513;\n                                            flg_y_30514 = flg_x_30513;\n                                            ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)] = eta_p_30510;\n                                            eta_p_30511 = eta_p_30510;\n                                        }\n                                    }\n                                    skip_threads_30515 *= 2;\n                                }\n                            }\n                        }\n                        flag_30509 = ((__local int8_t *) local_mem_30459)[sext_i32_i64(wave_sizze_30454) - (int64_t) 1];\n                        aggr_30508 = ((__local int64_t *) local_mem_30459)[(int64_t) 4 + (sext_i32_i64(wave_sizze_30454) - (int64_t) 1)];\n                        if (flag_30509 == (int8_t) 2) {\n                            readOffset_30506 = wave_sizze_30454 * -1;\n                        } else if (flag_30509 == (int8_t) 1) {\n                            readOffset_30506 -= wave_sizze_30454;\n                        }\n                        if (slt8((int8_t) 0, flag_30509)) {\n                            int64_t eta_p_30516 = aggr_30508;\n                            int64_t eta_p_30517 = prefix_30502;\n                            int64_t defunc_0_op_res_30518 = add64(eta_p_30516, eta_p_30517);\n                            \n                            prefix_30502 = defunc_0_op_res_30518;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30452 == 0) {\n                    if (boundary_30472 == sext_i64_i32(segscan_tblock_sizze_28394 * chunk_sizze_30440)) {\n                        int64_t eta_p_30519 = prefix_30502;\n                        int64_t eta_p_30520 = acc_30492;\n                        int64_t defunc_0_op_res_30521 = add64(eta_p_30519, eta_p_30520);\n                        \n                     ", "   ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469] = defunc_0_op_res_30521;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_30459)[(int64_t) 4] = prefix_30502;\n                    acc_30492 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_30469 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30502 = ((__local int64_t *) local_mem_30459)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_30522;\n            int64_t eta_p_30523;\n            int64_t eta_p_30525 = prefix_30502;\n            int64_t eta_p_30526 = acc_30492;\n            \n            if (slt32(local_tid_30452 * chunk_sizze_32b_30456, boundary_30472) && !block_new_sgm_30503) {\n                int64_t defunc_0_op_res_30527 = add64(eta_p_30525, eta_p_30526);\n                \n                eta_p_30522 = defunc_0_op_res_30527;\n            } else {\n                eta_p_30522 = acc_30492;\n            }\n            \n            int32_t stopping_point_30528 = segsizze_compact_30473 - srem32(local_tid_30452 * chunk_sizze_32b_30456 - 1 + segsizze_compact_30473 - boundary_30472, segsizze_compact_30473);\n            \n            for (int64_t i_30529 = 0; i_30529 < chunk_sizze_30440; i_30529++) {\n                if (slt32(sext_i64_i32(i_30529), stopping_point_30528 - 1)) {\n                    eta_p_30523 = private_mem_30474[i_30529];\n                    \n                    int64_t defunc_0_op_res_30524 = add64(eta_p_30522, eta_p_30523);\n                    \n                    private_mem_30474[i_30529] = defunc_0_op_res_30524;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n    ", "    {\n            for (int64_t i_30530 = 0; i_30530 < chunk_sizze_30440; i_30530++) {\n                int64_t sharedIdx_30531 = sext_i32_i64(local_tid_30452) * chunk_sizze_30440 + i_30530;\n                int64_t tmp_30532 = private_mem_30474[i_30530];\n                \n                ((__local int64_t *) local_mem_30459)[sharedIdx_30531] = tmp_30532;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30533 = 0; i_30533 < chunk_sizze_30440; i_30533++) {\n                int64_t flat_idx_30534 = thd_offset_30476 + i_30533 * segscan_tblock_sizze_28394;\n                int64_t slice_30535 = nz2081U_18679;\n                int64_t gtid_28398 = flat_idx_30534;\n                int64_t remnant_30536 = flat_idx_30534 - gtid_28398;\n                \n                if (slt64(flat_idx_30534, nz2081U_18679)) {\n                    int64_t tmp_30537 = ((__local int64_t *) local_mem_30459)[flat_idx_30534 - block_offset_30470];\n                    \n                    ((__global int64_t *) mem_29712)[gtid_28398] = tmp_30537;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28394\n    #undef chunk_sizze_30440\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegscan_28415_dim1, 1, 1)\nvoid human_genericf32zisegscan_28415(__global int *global_failure, int64_t mz2080U_18678, int64_t num_tblocks_28412, int64_t num_virt_blocks_30570, int64_t num_virt_threads_30571, __global unsigned char *mem_param_29725, __global unsigned char *mem_29737, __global unsigned char *status_flags_mem_30572, __global unsigned char *aggregates_mem_30574, __global unsigned char *incprefixes_mem_30576, __global unsigned char *global_dynid_mem_30578)\n{\n    #define segscan_tblock_sizze_28410 (human_genericf32zisegscan_28415zisegscan_tblock_sizze_28410)\n    #define chunk_sizze_30569 (human_genericf32zisegscan_28415zichunk_sizze_30569)\n    \n    volatile __local unsigned char *local_mem_30588_backi",
                                    "ng_0 = &shared_mem[0];\n    const int64_t local_mem_30588_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28410), chunk_sizze_30569 * segscan_tblock_sizze_28410 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28410), chunk_sizze_30569 * segscan_tblock_sizze_28410 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30581;\n    int32_t tblock_sizze_30584;\n    int32_t wave_sizze_30583;\n    int32_t block_id_30582;\n    int32_t global_tid_30580;\n    int64_t phys_tid_28415;\n    int32_t chunk_sizze_32b_30585;\n    int64_t byte_offsets_30586;\n    int64_t warp_byte_offset_30587;\n    __local unsigned char *local_mem_30588;\n    int64_t trans_arr_len_30589;\n    int64_t phys_block_id_30595;\n    int64_t virtloop_bound_30596;\n    \n    local_tid_30581 = get_local_id(0);\n    tblock_sizze_30584 = get_local_size(0);\n    wave_sizze_30583 = LOCKSTEP_WIDTH;\n    block_id_30582 = get_tblock_id(0);\n    global_tid_30580 = block_id_30582 * tblock_sizze_30584 + local_tid_30581;\n    phys_tid_28415 = sext_i32_i64(global_tid_30580);\n    chunk_sizze_32b_30585 = sext_i64_i32(chunk_sizze_30569);\n    byte_offsets_30586 = segscan_tblock_sizze_28410 * (int64_t) 4;\n    warp_byte_offset_30587 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30588 = (__local unsigned char *) local_mem_30588_backing_0;\n    trans_arr_len_30589 = chunk_sizze_30569 * segscan_tblock_sizze_28410;\n    phys_block_id_30595 = get_tblock_id(0);\n    virtloop_bound_30596 = sdiv_up64(num_virt_blocks_30570 - phys_block_id_30595, num_tblocks_28412);\n    for (int64_t virtloop_i_30597 = 0; virtloop_i_30597 < virtloop_bound_30596; virtloop_i_30597++) {\n        int64_t dynamic_id_30598;\n        int64_t block_offset_30599;\n        int64_t sgm_idx_30600;\n        int32_t boundary_30601;\n        int32_t segsizze_compact_30602;\n        int32_t private_m", "em_30603[chunk_sizze_30569];\n        int64_t thd_offset_30605;\n        int32_t acc_30621;\n        int32_t prefix_30631;\n        bool block_new_sgm_30632;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30581 == 0) {\n                dynamic_id_30598 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30578)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30588)[(int64_t) 0] = dynamic_id_30598;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30598 == num_virt_blocks_30570 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30578)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30598 = ((__local int32_t *) local_mem_30588)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30599 = dynamic_id_30598 * chunk_sizze_30569 * segscan_tblock_sizze_28410;\n        sgm_idx_30600 = smod64(block_offset_30599, mz2080U_18678);\n        boundary_30601 = sext_i64_i32(smin64(chunk_sizze_30569 * segscan_tblock_sizze_28410, mz2080U_18678 - sgm_idx_30600));\n        segsizze_compact_30602 = sext_i64_i32(smin64(chunk_sizze_30569 * segscan_tblock_sizze_28410, mz2080U_18678));\n        thd_offset_30605 = block_offset_30599 + sext_i32_i64(local_tid_30581);\n        // Load and map\n        {\n            for (int64_t i_30606 = 0; i_30606 < chunk_sizze_30569; i_30606++) {\n                int64_t virt_tid_30607 = thd_offset_30605 + i_30606 * segscan_tblock_sizze_28410;\n                int64_t slice_30608 = mz2080U_18678;\n                int64_t gtid_28414 = virt_tid_30607;\n                int64_t remnant_30609 = virt_tid_30607 - gtid_28414;\n                \n                if (slt64(virt_tid", "_30607, mz2080U_18678)) {\n                    int32_t x_27134 = ((__global int32_t *) mem_param_29725)[gtid_28414];\n                    \n                    private_mem_30603[i_30606] = x_27134;\n                } else {\n                    private_mem_30603[i_30606] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30610 = 0; i_30610 < chunk_sizze_30569; i_30610++) {\n                int64_t sharedIdx_30611 = sext_i32_i64(local_tid_30581) + i_30610 * segscan_tblock_sizze_28410;\n                int32_t tmp_30612 = private_mem_30603[i_30610];\n                \n                ((__local int32_t *) local_mem_30588)[sharedIdx_30611] = tmp_30612;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30613 = 0; i_30613 < chunk_sizze_30569; i_30613++) {\n                int64_t sharedIdx_30614 = sext_i32_i64(local_tid_30581) * chunk_sizze_30569 + i_30613;\n                int32_t tmp_30615 = ((__local int32_t *) local_mem_30588)[sharedIdx_30614];\n                \n                private_mem_30603[i_30613] = tmp_30615;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30616 = 0; i_30616 < chunk_sizze_30569 - (int64_t) 1; i_30616++) {\n                int32_t eta_p_27131;\n                int32_t eta_p_27132;\n                \n                eta_p_27131 = private_mem_30603[i_30616];\n                eta_p_27132 = private_mem_30603[i_30616 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_27133 = add32(eta_p_27131, eta_p_27132);\n                \n                private_mem_30603[i_30616 + (int64_t) 1] = defunc_0_op_res_27133;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_30617 = private_mem_30603[chunk_sizze_30569 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_30588)[sext",
                                    "_i32_i64(local_tid_30581)] = tmp_30617;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_30618;\n            int32_t eta_p_30619;\n            int32_t eta_p_30622;\n            int32_t eta_p_30623;\n            bool ltid_in_bounds_30625 = slt64(sext_i32_i64(local_tid_30581), num_virt_threads_30571);\n            int32_t skip_threads_30626;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30625) {\n                    eta_p_30619 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)];\n                    if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                        eta_p_30618 = eta_p_30619;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30626 = 1;\n                while (slt32(skip_threads_30626, 32)) {\n                    bool thread_active_30627 = sle32(skip_threads_30626, local_tid_30581 - squot32(local_tid_30581, 32) * 32) && ltid_in_bounds_30625;\n                    \n                    if (thread_active_30627) {\n                        // read operands\n                        {\n                            eta_p_30618 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30626)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30627) {\n                            int32_t defunc_0_op_res_30620 = add32(eta_p_30618, eta_p_30619);\n                            \n                            eta_p_30618 = defunc_0_op_res_30620;\n                        }\n                    }\n                    if (sle32(wave_sizze_30583, skip_threads_30626)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n        ", "            if (thread_active_30627) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30618;\n                            eta_p_30619 = eta_p_30618;\n                        }\n                    }\n                    if (sle32(wave_sizze_30583, skip_threads_30626)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30626 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 31 && ltid_in_bounds_30625) {\n                    ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(squot32(local_tid_30581, 32))] = eta_p_30618;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30628;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30581, 32) == 0 && ltid_in_bounds_30625) {\n                        eta_p_30623 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)];\n                        if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                            eta_p_30622 = eta_p_30623;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30628 = 1;\n                    while (slt32(skip_threads_30628, 32)) {\n                        bool thread_active_30629 = sle32(skip_threads_30628, local_tid_30581 - squot32(local_tid_30581, 32) * 32) && (squot32(local_tid_30581, 32) == 0 && ltid_in", "_bounds_30625);\n                        \n                        if (thread_active_30629) {\n                            // read operands\n                            {\n                                eta_p_30622 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30628)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30629) {\n                                int32_t defunc_0_op_res_30624 = add32(eta_p_30622, eta_p_30623);\n                                \n                                eta_p_30622 = defunc_0_op_res_30624;\n                            }\n                        }\n                        if (sle32(wave_sizze_30583, skip_threads_30628)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30629) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30622;\n                                eta_p_30623 = eta_p_30622;\n                            }\n                        }\n                        if (sle32(wave_sizze_30583, skip_threads_30628)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30628 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30630 = squot32(local_tid_30581, 32) == 0 || !ltid_in_bounds_30625;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30630) {\n                        eta_p_30619 = eta_p_30618;\n                        eta_p_30618 = ((__local int32_t *) local_m",
                                    "em_30588)[sext_i32_i64(squot32(local_tid_30581, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30630) {\n                        int32_t defunc_0_op_res_30620 = add32(eta_p_30618, eta_p_30619);\n                        \n                        eta_p_30618 = defunc_0_op_res_30620;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30630) {\n                        ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30618;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30581, 32) == 0 && ltid_in_bounds_30625) {\n                    ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30619;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30581 == 0) {\n                acc_30621 = ((__local int32_t *) local_mem_30588)[segscan_tblock_sizze_28410 - (int64_t) 1];\n            } else {\n                acc_30621 = ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30631 = 0;\n        block_new_sgm_30632 = sgm_idx_30600 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30632 && local_tid_30581 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598] = acc_30621;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 2;\n                acc_30621 = 0;\n            }\n            if (!block_new_sgm_30632 && slt32(local_tid_30581, wave_sizze_30583))", " {\n                if (local_tid_30581 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_30574)[dynamic_id_30598] = acc_30621;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 1;\n                    \n                    int8_t tmp_30633 = ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30588)[(int64_t) 0] = tmp_30633;\n                }\n                mem_fence_local();\n                \n                int8_t status_30634 = ((__local int8_t *) local_mem_30588)[(int64_t) 0];\n                \n                if (status_30634 == (int8_t) 2) {\n                    if (local_tid_30581 == 0) {\n                        prefix_30631 = ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30635 = sext_i64_i32(dynamic_id_30598 - sext_i32_i64(wave_sizze_30583));\n                    \n                    while (slt32(wave_sizze_30583 * -1, readOffset_30635)) {\n                        int32_t read_i_30636 = readOffset_30635 + local_tid_30581;\n                        int32_t aggr_30637 = 0;\n                        int8_t flag_30638 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30636)) {\n                            flag_30638 = ((volatile __global int8_t *) status_flags_mem_30572)[sext_i32_i64(read_i_30636)];\n                            if (flag_30638 == (int8_t) 2) {\n                                aggr_30637 = ((volatile __global int32_t *) incprefixes_mem_30576)[sext_i32_i64(read_i_30636)];\n                            } else if (flag_30638 == (int8_t) 1) {\n                                aggr_30637 = ((volatile __global int32_t *) aggregates_mem_30574)[sext_i32_i64(read_i_30636)];\n              ", "              }\n                        }\n                        ((__local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)] = aggr_30637;\n                        ((__local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = flag_30638;\n                        flag_30638 = ((__local int8_t *) local_mem_30588)[sext_i32_i64(wave_sizze_30583) - (int64_t) 1];\n                        if (slt8(flag_30638, (int8_t) 2)) {\n                            int8_t flg_x_30642;\n                            int8_t flg_y_30643;\n                            int32_t eta_p_30639;\n                            int32_t eta_p_30640;\n                            int32_t skip_threads_30644;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30643 = ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)];\n                                eta_p_30640 = ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)];\n                                if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                                    eta_p_30639 = eta_p_30640;\n                                    flg_x_30642 = flg_y_30643;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30644 = 1;\n                                while (slt32(skip_threads_30644, 32)) {\n                                    if (sle32(skip_threads_30644, local_tid_30581 - squot32(local_tid_30581, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30642 = ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30644)];\n    ",
                                    "                                        eta_p_30639 = ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + (sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30644))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30643 == (int8_t) 2 || flg_y_30643 == (int8_t) 0) {\n                                                flg_x_30642 = flg_y_30643;\n                                                eta_p_30639 = eta_p_30640;\n                                            } else {\n                                                int32_t defunc_0_op_res_30641 = add32(eta_p_30639, eta_p_30640);\n                                                \n                                                eta_p_30639 = defunc_0_op_res_30641;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = flg_x_30642;\n                                            flg_y_30643 = flg_x_30642;\n                                            ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)] = eta_p_30639;\n                                            eta_p_30640 = eta_p_30639;\n                                        }\n                                    }\n                                    skip_threads_30644 *= 2;\n                                }\n                            }\n                        }\n                        flag_30638 = ((__local int8_t *) local_mem_30588)[sext_i32_i64(wave_sizze_30583) - (int64_t) 1];\n                        aggr_30637 = ((__local int32_t *) local_mem_30588)[(int64_t) 8 + (sext_i32_i64(wave_sizze_30583) - (int64_t) 1)];\n          ", "              if (flag_30638 == (int8_t) 2) {\n                            readOffset_30635 = wave_sizze_30583 * -1;\n                        } else if (flag_30638 == (int8_t) 1) {\n                            readOffset_30635 -= wave_sizze_30583;\n                        }\n                        if (slt8((int8_t) 0, flag_30638)) {\n                            int32_t eta_p_30645 = aggr_30637;\n                            int32_t eta_p_30646 = prefix_30631;\n                            int32_t defunc_0_op_res_30647 = add32(eta_p_30645, eta_p_30646);\n                            \n                            prefix_30631 = defunc_0_op_res_30647;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30581 == 0) {\n                    if (boundary_30601 == sext_i64_i32(segscan_tblock_sizze_28410 * chunk_sizze_30569)) {\n                        int32_t eta_p_30648 = prefix_30631;\n                        int32_t eta_p_30649 = acc_30621;\n                        int32_t defunc_0_op_res_30650 = add32(eta_p_30648, eta_p_30649);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598] = defunc_0_op_res_30650;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_30588)[(int64_t) 8] = prefix_30631;\n                    acc_30621 = 0;\n                }\n            }\n            if (!(dynamic_id_30598 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30631 = ((__local int32_t *) local_mem_30588)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_30651;\n            int32_t eta_p_30652;\n            int32_t eta_p_30654 = prefix_30631;\n       ", "     int32_t eta_p_30655 = acc_30621;\n            \n            if (slt32(local_tid_30581 * chunk_sizze_32b_30585, boundary_30601) && !block_new_sgm_30632) {\n                int32_t defunc_0_op_res_30656 = add32(eta_p_30654, eta_p_30655);\n                \n                eta_p_30651 = defunc_0_op_res_30656;\n            } else {\n                eta_p_30651 = acc_30621;\n            }\n            \n            int32_t stopping_point_30657 = segsizze_compact_30602 - srem32(local_tid_30581 * chunk_sizze_32b_30585 - 1 + segsizze_compact_30602 - boundary_30601, segsizze_compact_30602);\n            \n            for (int64_t i_30658 = 0; i_30658 < chunk_sizze_30569; i_30658++) {\n                if (slt32(sext_i64_i32(i_30658), stopping_point_30657 - 1)) {\n                    eta_p_30652 = private_mem_30603[i_30658];\n                    \n                    int32_t defunc_0_op_res_30653 = add32(eta_p_30651, eta_p_30652);\n                    \n                    private_mem_30603[i_30658] = defunc_0_op_res_30653;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30659 = 0; i_30659 < chunk_sizze_30569; i_30659++) {\n                int64_t sharedIdx_30660 = sext_i32_i64(local_tid_30581) * chunk_sizze_30569 + i_30659;\n                int32_t tmp_30661 = private_mem_30603[i_30659];\n                \n                ((__local int32_t *) local_mem_30588)[sharedIdx_30660] = tmp_30661;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30662 = 0; i_30662 < chunk_sizze_30569; i_30662++) {\n                int64_t flat_idx_30663 = thd_offset_30605 + i_30662 * segscan_tblock_sizze_28410;\n                int64_t slice_30664 = mz2080U_18678;\n                int64_t gtid_28414 = flat_idx_30663;\n                int64_t remnant_30665 = flat_idx_30663 - gtid_28414;\n                \n                if (slt64(flat_idx_30663, mz2080U_18678)) {\n              ",
                                    "      int32_t tmp_30666 = ((__local int32_t *) local_mem_30588)[flat_idx_30663 - block_offset_30599];\n                    \n                    ((__global int32_t *) mem_29737)[gtid_28414] = tmp_30666;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28410\n    #undef chunk_sizze_30569\n}\nFUTHARK_KERNEL_SIZED(human_genericf32zisegscan_28692_dim1, 1, 1)\nvoid human_genericf32zisegscan_28692(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_18678, int64_t loop_dz2081Uz2088Uz2087U_27123, int64_t num_tblocks_28689, int64_t num_virt_blocks_30879, int64_t num_virt_threads_30880, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *mem_29754, __global unsigned char *mem_29757, __global unsigned char *mem_29759, __global unsigned char *status_flags_mem_30881, __global unsigned char *aggregates_mem_30883, __global unsigned char *incprefixes_mem_30885, __global unsigned char *global_dynid_mem_30887)\n{\n    #define segscan_tblock_sizze_28687 (human_genericf32zisegscan_28692zisegscan_tblock_sizze_28687)\n    #define chunk_sizze_30878 (human_genericf32zisegscan_28692zichunk_sizze_30878)\n    \n    volatile __local unsigned char *local_mem_30897_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30897_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28687), chunk_sizze_30878 * segscan_tblock_sizze_28687 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28687), chunk_sizze_30878 * segscan_tblock_sizze_28687 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure =", " 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30890;\n    int32_t tblock_sizze_30893;\n    int32_t wave_sizze_30892;\n    int32_t block_id_30891;\n    int32_t global_tid_30889;\n    int64_t phys_tid_28692;\n    int32_t chunk_sizze_32b_30894;\n    int64_t byte_offsets_30895;\n    int64_t warp_byte_offset_30896;\n    __local unsigned char *local_mem_30897;\n    int64_t trans_arr_len_30898;\n    int64_t phys_block_id_30904;\n    int64_t virtloop_bound_30905;\n    \n    local_tid_30890 = get_local_id(0);\n    tblock_sizze_30893 = get_local_size(0);\n    wave_sizze_30892 = LOCKSTEP_WIDTH;\n    block_id_30891 = get_tblock_id(0);\n    global_tid_30889 = block_id_30891 * tblock_sizze_30893 + local_tid_30890;\n    phys_tid_28692 = sext_i32_i64(global_tid_30889);\n    chunk_sizze_32b_30894 = sext_i64_i32(chunk_sizze_30878);\n    byte_offsets_30895 = segscan_tblock_sizze_28687 * (int64_t) 8;\n    warp_byte_offset_30896 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30897 = (__local unsigned char *) local_mem_30897_backing_0;\n    trans_arr_len_30898 = chunk_sizze_30878 * segscan_tblock_sizze_28687;\n    phys_block_id_30904 = get_tblock_id(0);\n    virtloop_bound_30905 = sdiv_up64(num_virt_blocks_30879 - phys_block_id_30904, num_tblocks_28689);\n    for (int64_t virtloop_i_30906 = 0; virtloop_i_30906 < virtloop_bound_30905; virtloop_i_30906++) {\n        int64_t dynamic_id_30907;\n        int64_t block_offset_30908;\n        int64_t sgm_idx_30909;\n        int32_t boundary_30910;\n        int32_t segsizze_compact_30911;\n        int64_t private_mem_30912[chunk_sizze_30878];\n        int64_t thd_offset_30914;\n        int64_t acc_30930;\n        int64_t prefix_30940;\n        bool block_new_sgm_30941;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30890 == 0) {\n                dynamic_id_30907 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30887)[(int64_t) 0], (int) 1);\n           ", "     // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30897)[(int64_t) 0] = dynamic_id_30907;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30907 == num_virt_blocks_30879 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30887)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30907 = ((__local int32_t *) local_mem_30897)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30908 = dynamic_id_30907 * chunk_sizze_30878 * segscan_tblock_sizze_28687;\n        sgm_idx_30909 = smod64(block_offset_30908, loop_dz2081Uz2088Uz2087U_27123);\n        boundary_30910 = sext_i64_i32(smin64(chunk_sizze_30878 * segscan_tblock_sizze_28687, loop_dz2081Uz2088Uz2087U_27123 - sgm_idx_30909));\n        segsizze_compact_30911 = sext_i64_i32(smin64(chunk_sizze_30878 * segscan_tblock_sizze_28687, loop_dz2081Uz2088Uz2087U_27123));\n        thd_offset_30914 = block_offset_30908 + sext_i32_i64(local_tid_30890);\n        // Load and map\n        {\n            for (int64_t i_30915 = 0; i_30915 < chunk_sizze_30878; i_30915++) {\n                int64_t virt_tid_30916 = thd_offset_30914 + i_30915 * segscan_tblock_sizze_28687;\n                int64_t slice_30917 = loop_dz2081Uz2088Uz2087U_27123;\n                int64_t gtid_28691 = virt_tid_30916;\n                int64_t remnant_30918 = virt_tid_30916 - gtid_28691;\n                \n                if (slt64(virt_tid_30916, loop_dz2081Uz2088Uz2087U_27123)) {\n                    int32_t eta_p_27740 = ((__global int32_t *) mem_param_29728)[gtid_28691];\n                    int64_t ii_27741 = sext_i32_i64(eta_p_27740);\n                    bool x_27742 = sle64((int64_t) 0, ii_27741);\n                    bool y_27743 = slt64(ii_27741, mz2080U_18678);\n                   ",
                                    " bool bounds_check_27744 = x_27742 && y_27743;\n                    bool index_certs_27745;\n                    \n                    if (!bounds_check_27744) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 11) == -1) {\n                                global_failure_args[0] = (int64_t) ii_27741;\n                                global_failure_args[1] = (int64_t) mz2080U_18678;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int32_t zeze_lhs_27746 = ((__global int32_t *) mem_29754)[ii_27741];\n                    bool cond_27747 = zeze_lhs_27746 == -1;\n                    bool defunc_0_p_res_27748;\n                    \n                    if (cond_27747) {\n                        defunc_0_p_res_27748 = 0;\n                    } else {\n                        float eta_p_27739 = ((__global float *) mem_param_29731)[gtid_28691];\n                        bool cond_27749 = zeze_lhs_27746 == 0;\n                        bool defunc_0_p_res_f_res_27750;\n                        \n                        if (cond_27749) {\n                            float lt_arg1_28177 = ((__global float *) mem_29740)[ii_27741];\n                            bool defunc_0_lt_res_28178 = eta_p_27739 < lt_arg1_28177;\n                            \n                            defunc_0_p_res_f_res_27750 = defunc_0_lt_res_28178;\n                        } else {\n                            bool cond_27753 = zeze_lhs_27746 == 1;\n                            bool defunc_0_p_res_f_res_f_res_27754;\n                            \n                            if (cond_27753) {\n                                defunc_0_p_res_f_res_f_res_27754 = 0;\n                            } else {\n                                float lt_arg1_27755 = ((__global float *) mem_29740)[ii_2774", "1];\n                                bool defunc_0_lt_res_27756 = eta_p_27739 < lt_arg1_27755;\n                                bool cond_27757 = !defunc_0_lt_res_27756;\n                                bool defunc_0_eq_res_27758 = eta_p_27739 == lt_arg1_27755;\n                                bool defunc_0_p_res_f_res_f_res_f_res_t_res_27759 = !defunc_0_eq_res_27758;\n                                bool x_27760 = cond_27757 && defunc_0_p_res_f_res_f_res_f_res_t_res_27759;\n                                \n                                defunc_0_p_res_f_res_f_res_27754 = x_27760;\n                            }\n                            defunc_0_p_res_f_res_27750 = defunc_0_p_res_f_res_f_res_27754;\n                        }\n                        defunc_0_p_res_27748 = defunc_0_p_res_f_res_27750;\n                    }\n                    \n                    int64_t defunc_0_f_res_27761 = btoi_bool_i64(defunc_0_p_res_27748);\n                    \n                    ((__global int64_t *) mem_29759)[gtid_28691] = defunc_0_f_res_27761;\n                    private_mem_30912[i_30915] = defunc_0_f_res_27761;\n                } else {\n                    private_mem_30912[i_30915] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30919 = 0; i_30919 < chunk_sizze_30878; i_30919++) {\n                int64_t sharedIdx_30920 = sext_i32_i64(local_tid_30890) + i_30919 * segscan_tblock_sizze_28687;\n                int64_t tmp_30921 = private_mem_30912[i_30919];\n                \n                ((__local int64_t *) local_mem_30897)[sharedIdx_30920] = tmp_30921;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30922 = 0; i_30922 < chunk_sizze_30878; i_30922++) {\n                int64_t sharedIdx_30923 = sext_i32_i64(local_tid_30890)", " * chunk_sizze_30878 + i_30922;\n                int64_t tmp_30924 = ((__local int64_t *) local_mem_30897)[sharedIdx_30923];\n                \n                private_mem_30912[i_30922] = tmp_30924;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30925 = 0; i_30925 < chunk_sizze_30878 - (int64_t) 1; i_30925++) {\n                int64_t eta_p_27329;\n                int64_t eta_p_27330;\n                \n                eta_p_27329 = private_mem_30912[i_30925];\n                eta_p_27330 = private_mem_30912[i_30925 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27331 = add64(eta_p_27329, eta_p_27330);\n                \n                private_mem_30912[i_30925 + (int64_t) 1] = defunc_0_op_res_27331;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_30926 = private_mem_30912[chunk_sizze_30878 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = tmp_30926;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_30927;\n            int64_t eta_p_30928;\n            int64_t eta_p_30931;\n            int64_t eta_p_30932;\n            bool ltid_in_bounds_30934 = slt64(sext_i32_i64(local_tid_30890), num_virt_threads_30880);\n            int32_t skip_threads_30935;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30934) {\n                    eta_p_30928 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)];\n                    if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                        eta_p_30927 = eta_p_30928;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30935 = 1;\n         ",
                                    "       while (slt32(skip_threads_30935, 32)) {\n                    bool thread_active_30936 = sle32(skip_threads_30935, local_tid_30890 - squot32(local_tid_30890, 32) * 32) && ltid_in_bounds_30934;\n                    \n                    if (thread_active_30936) {\n                        // read operands\n                        {\n                            eta_p_30927 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30935)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30936) {\n                            int64_t defunc_0_op_res_30929 = add64(eta_p_30927, eta_p_30928);\n                            \n                            eta_p_30927 = defunc_0_op_res_30929;\n                        }\n                    }\n                    if (sle32(wave_sizze_30892, skip_threads_30935)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30936) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30927;\n                            eta_p_30928 = eta_p_30927;\n                        }\n                    }\n                    if (sle32(wave_sizze_30892, skip_threads_30935)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30935 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 31 && ltid_in_bounds_30934) {\n                    ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(squot32(local_tid_30890, 32))] = eta_p_30927;\n                }\n            }\n            b", "arrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30937;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934) {\n                        eta_p_30932 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)];\n                        if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                            eta_p_30931 = eta_p_30932;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30937 = 1;\n                    while (slt32(skip_threads_30937, 32)) {\n                        bool thread_active_30938 = sle32(skip_threads_30937, local_tid_30890 - squot32(local_tid_30890, 32) * 32) && (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934);\n                        \n                        if (thread_active_30938) {\n                            // read operands\n                            {\n                                eta_p_30931 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30937)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30938) {\n                                int64_t defunc_0_op_res_30933 = add64(eta_p_30931, eta_p_30932);\n                                \n                                eta_p_30931 = defunc_0_op_res_30933;\n                            }\n                        }\n                        if (sle32(wave_sizze_30892, skip_threads_30937)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_a", "ctive_30938) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30931;\n                                eta_p_30932 = eta_p_30931;\n                            }\n                        }\n                        if (sle32(wave_sizze_30892, skip_threads_30937)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30937 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30939 = squot32(local_tid_30890, 32) == 0 || !ltid_in_bounds_30934;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30939) {\n                        eta_p_30928 = eta_p_30927;\n                        eta_p_30927 = ((__local int64_t *) local_mem_30897)[sext_i32_i64(squot32(local_tid_30890, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30939) {\n                        int64_t defunc_0_op_res_30929 = add64(eta_p_30927, eta_p_30928);\n                        \n                        eta_p_30927 = defunc_0_op_res_30929;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30939) {\n                        ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30927;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934) {\n                    ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_ti",
                                    "d_30890)] = eta_p_30928;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30890 == 0) {\n                acc_30930 = ((__local int64_t *) local_mem_30897)[segscan_tblock_sizze_28687 - (int64_t) 1];\n            } else {\n                acc_30930 = ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30940 = (int64_t) 0;\n        block_new_sgm_30941 = sgm_idx_30909 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30941 && local_tid_30890 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_30907] = acc_30930;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 2;\n                acc_30930 = (int64_t) 0;\n            }\n            if (!block_new_sgm_30941 && slt32(local_tid_30890, wave_sizze_30892)) {\n                if (local_tid_30890 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_30883)[dynamic_id_30907] = acc_30930;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 1;\n                    \n                    int8_t tmp_30942 = ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30897)[(int64_t) 0] = tmp_30942;\n                }\n                mem_fence_local();\n                \n                int8_t status_30943 = ((__local int8_t *) local_mem_30897)[(int64_t) 0];\n                \n                if (status_30943 == (int8_t) 2) {\n                    if (local_tid_30890 == 0) {\n                        prefix_30940 = ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_3090", "7 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30944 = sext_i64_i32(dynamic_id_30907 - sext_i32_i64(wave_sizze_30892));\n                    \n                    while (slt32(wave_sizze_30892 * -1, readOffset_30944)) {\n                        int32_t read_i_30945 = readOffset_30944 + local_tid_30890;\n                        int64_t aggr_30946 = (int64_t) 0;\n                        int8_t flag_30947 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30945)) {\n                            flag_30947 = ((volatile __global int8_t *) status_flags_mem_30881)[sext_i32_i64(read_i_30945)];\n                            if (flag_30947 == (int8_t) 2) {\n                                aggr_30946 = ((volatile __global int64_t *) incprefixes_mem_30885)[sext_i32_i64(read_i_30945)];\n                            } else if (flag_30947 == (int8_t) 1) {\n                                aggr_30946 = ((volatile __global int64_t *) aggregates_mem_30883)[sext_i32_i64(read_i_30945)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)] = aggr_30946;\n                        ((__local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = flag_30947;\n                        flag_30947 = ((__local int8_t *) local_mem_30897)[sext_i32_i64(wave_sizze_30892) - (int64_t) 1];\n                        if (slt8(flag_30947, (int8_t) 2)) {\n                            int8_t flg_x_30951;\n                            int8_t flg_y_30952;\n                            int64_t eta_p_30948;\n                            int64_t eta_p_30949;\n                            int32_t skip_threads_30953;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30952 = ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local", "_tid_30890)];\n                                eta_p_30949 = ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)];\n                                if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                                    eta_p_30948 = eta_p_30949;\n                                    flg_x_30951 = flg_y_30952;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30953 = 1;\n                                while (slt32(skip_threads_30953, 32)) {\n                                    if (sle32(skip_threads_30953, local_tid_30890 - squot32(local_tid_30890, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30951 = ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30953)];\n                                            eta_p_30948 = ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + (sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30953))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30952 == (int8_t) 2 || flg_y_30952 == (int8_t) 0) {\n                                                flg_x_30951 = flg_y_30952;\n                                                eta_p_30948 = eta_p_30949;\n                                            } else {\n                                                int64_t defunc_0_op_res_30950 = add64(eta_p_30948, eta_p_30949);\n                                                \n                                                eta_p_30948 = defunc_0_op_res_30950;\n                                            ",
                                    "}\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = flg_x_30951;\n                                            flg_y_30952 = flg_x_30951;\n                                            ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)] = eta_p_30948;\n                                            eta_p_30949 = eta_p_30948;\n                                        }\n                                    }\n                                    skip_threads_30953 *= 2;\n                                }\n                            }\n                        }\n                        flag_30947 = ((__local int8_t *) local_mem_30897)[sext_i32_i64(wave_sizze_30892) - (int64_t) 1];\n                        aggr_30946 = ((__local int64_t *) local_mem_30897)[(int64_t) 4 + (sext_i32_i64(wave_sizze_30892) - (int64_t) 1)];\n                        if (flag_30947 == (int8_t) 2) {\n                            readOffset_30944 = wave_sizze_30892 * -1;\n                        } else if (flag_30947 == (int8_t) 1) {\n                            readOffset_30944 -= wave_sizze_30892;\n                        }\n                        if (slt8((int8_t) 0, flag_30947)) {\n                            int64_t eta_p_30954 = aggr_30946;\n                            int64_t eta_p_30955 = prefix_30940;\n                            int64_t defunc_0_op_res_30956 = add64(eta_p_30954, eta_p_30955);\n                            \n                            prefix_30940 = defunc_0_op_res_30956;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30890 == 0) {\n                    if (boundary_30910 == sext_i64_i32(segscan_tblock_sizze_28687 * chunk_sizze_30878)) {\n                        i", "nt64_t eta_p_30957 = prefix_30940;\n                        int64_t eta_p_30958 = acc_30930;\n                        int64_t defunc_0_op_res_30959 = add64(eta_p_30957, eta_p_30958);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_30907] = defunc_0_op_res_30959;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_30897)[(int64_t) 4] = prefix_30940;\n                    acc_30930 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_30907 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30940 = ((__local int64_t *) local_mem_30897)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_30960;\n            int64_t eta_p_30961;\n            int64_t eta_p_30963 = prefix_30940;\n            int64_t eta_p_30964 = acc_30930;\n            \n            if (slt32(local_tid_30890 * chunk_sizze_32b_30894, boundary_30910) && !block_new_sgm_30941) {\n                int64_t defunc_0_op_res_30965 = add64(eta_p_30963, eta_p_30964);\n                \n                eta_p_30960 = defunc_0_op_res_30965;\n            } else {\n                eta_p_30960 = acc_30930;\n            }\n            \n            int32_t stopping_point_30966 = segsizze_compact_30911 - srem32(local_tid_30890 * chunk_sizze_32b_30894 - 1 + segsizze_compact_30911 - boundary_30910, segsizze_compact_30911);\n            \n            for (int64_t i_30967 = 0; i_30967 < chunk_sizze_30878; i_30967++) {\n                if (slt32(sext_i64_i32(i_30967), stopping_point_30966 - 1)) {\n                    eta_p_30961 = private_mem_30912[i_30967];\n                    \n                    int64_t defunc_0_op_res_30962 = add64(eta_p_30960, eta_p_3096", "1);\n                    \n                    private_mem_30912[i_30967] = defunc_0_op_res_30962;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30968 = 0; i_30968 < chunk_sizze_30878; i_30968++) {\n                int64_t sharedIdx_30969 = sext_i32_i64(local_tid_30890) * chunk_sizze_30878 + i_30968;\n                int64_t tmp_30970 = private_mem_30912[i_30968];\n                \n                ((__local int64_t *) local_mem_30897)[sharedIdx_30969] = tmp_30970;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30971 = 0; i_30971 < chunk_sizze_30878; i_30971++) {\n                int64_t flat_idx_30972 = thd_offset_30914 + i_30971 * segscan_tblock_sizze_28687;\n                int64_t slice_30973 = loop_dz2081Uz2088Uz2087U_27123;\n                int64_t gtid_28691 = flat_idx_30972;\n                int64_t remnant_30974 = flat_idx_30972 - gtid_28691;\n                \n                if (slt64(flat_idx_30972, loop_dz2081Uz2088Uz2087U_27123)) {\n                    int64_t tmp_30975 = ((__local int64_t *) local_mem_30897)[flat_idx_30972 - block_offset_30908];\n                    \n                    ((__global int64_t *) mem_29757)[gtid_28691] = tmp_30975;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28687\n    #undef chunk_sizze_30878\n}\nFUTHARK_KERNEL_SIZED(human_genericf64ziseghist_global_28788_dim1, 1, 1)\nvoid human_genericf64ziseghist_global_28788(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_21995, int64_t nz2081U_21996, int64_t num_tblocks_28783, int64_t num_subhistos_30239, int32_t chk_i_30320, int64_t hist_H_chk_30321, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *de",
                                    "func_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242)\n{\n    #define seghist_tblock_sizze_28781 (human_genericf64ziseghist_global_28788ziseghist_tblock_sizze_28781)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30323;\n    int32_t tblock_sizze_30326;\n    int32_t wave_sizze_30325;\n    int32_t block_id_30324;\n    int32_t global_tid_30322;\n    int64_t phys_tid_28788;\n    int32_t subhisto_ind_30327;\n    int64_t num_chunks_30328;\n    \n    local_tid_30323 = get_local_id(0);\n    tblock_sizze_30326 = get_local_size(0);\n    wave_sizze_30325 = LOCKSTEP_WIDTH;\n    block_id_30324 = get_tblock_id(0);\n    global_tid_30322 = block_id_30324 * tblock_sizze_30326 + local_tid_30323;\n    phys_tid_28788 = sext_i32_i64(global_tid_30322);\n    subhisto_ind_30327 = squot32(global_tid_30322, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_28781 * num_tblocks_28783), sext_i64_i32(num_subhistos_30239)));\n    num_chunks_30328 = sdiv_up64(nz2081U_21996, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_28781 * num_tblocks_28783)));\n    for (int64_t chunk_i_30329 = 0; chunk_i_30329 < num_chunks_30328; chunk_i_30329++) {\n        int64_t i_30330 = chunk_i_30329 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_28781 * num_tblocks_28783)) + sext_i32_i64(global_tid_30322);\n        \n        if (slt64(i_30330, nz2081U_21996)) {\n            int64_t slice_30331;\n            int64_t gtid_28787;\n            int64_t remnant_30332;\n            \n            slice_30331 = nz2081U_21996;\n            gtid_28787 = i_30330;\n            remnant_30332 = i_30330 - gtid_28787;\n            if (slt64(i_30330, nz2081U_21996)) {\n                int32_t eta_p_28796;\n                int64_t ii_28797;\n                bool x_28798;\n                bool y_28799;\n                bool bounds_check_28800;\n                bool index_certs_28801;\n                double eta_p_28795;\n                double eq_arg1_28802;\n                bool defunc_0_eq_res_28803;\n         ", "       bool defunc_0_lt_res_28804;\n                int32_t bool_res_28805;\n                int32_t bool_res_28806;\n                \n                eta_p_28796 = ((__global int32_t *) II1_mem_29679)[gtid_28787];\n                ii_28797 = sext_i32_i64(eta_p_28796);\n                x_28798 = sle64((int64_t) 0, ii_28797);\n                y_28799 = slt64(ii_28797, mz2080U_21995);\n                bounds_check_28800 = x_28798 && y_28799;\n                if (!bounds_check_28800) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 14) == -1) {\n                            global_failure_args[0] = (int64_t) ii_28797;\n                            global_failure_args[1] = (int64_t) mz2080U_21995;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                eta_p_28795 = ((__global double *) A_mem_29680)[gtid_28787];\n                eq_arg1_28802 = ((__global double *) mem_29695)[ii_28797];\n                defunc_0_eq_res_28803 = eta_p_28795 == eq_arg1_28802;\n                defunc_0_lt_res_28804 = eta_p_28795 < eq_arg1_28802;\n                bool_res_28805 = btoi_bool_i32(defunc_0_lt_res_28804);\n                bool_res_28806 = btoi_bool_i32(defunc_0_eq_res_28803);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_30320) * hist_H_chk_30321, ii_28797) && (slt64(ii_28797, sext_i32_i64(chk_i_30320) * hist_H_chk_30321 + hist_H_chk_30321) && (sle64((int64_t) 0, ii_28797) && slt64(ii_28797, mz2080U_21995)))) {\n                        int32_t eta_p_28789;\n                        int32_t eta_p_28790;\n                        int32_t eta_p_28791;\n                        int32_t eta_p_28792;\n                        \n                        eta_p_28791 = bool_res_28805;\n                        eta_p_28792 = bool_res_28806;\n                       ", " \n                        int32_t old_30333;\n                        \n                        old_30333 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30240)[sext_i32_i64(subhisto_ind_30327) * mz2080U_21995 + ii_28797], (int) eta_p_28791);\n                        \n                        int32_t old_30334;\n                        \n                        old_30334 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30242)[sext_i32_i64(subhisto_ind_30327) * mz2080U_21995 + ii_28797], (int) eta_p_28792);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_28781\n}\nFUTHARK_KERNEL_SIZED(human_genericf64ziseghist_global_29079_dim1, 1, 1)\nvoid human_genericf64ziseghist_global_29079(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_21995, int64_t loop_dz2081Uz2088Uz2087U_27125, int64_t num_tblocks_29074, int64_t num_subhistos_30677, int32_t chk_i_30758, int64_t hist_H_chk_30759, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define seghist_tblock_sizze_29072 (human_genericf64ziseghist_global_29079ziseghist_tblock_sizze_29072)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30761;\n    int32_t tblock_sizze_30764;\n    int32_t wave_sizze_30763;\n    int32_t block_id_30762;\n    int32_t global_tid_30760;\n    int64_t phys_tid_29079;\n    int32_t subhisto_ind_30765;\n    int64_t num_chunks_30766;\n    \n    local_tid_30761 = get_local_id(0);\n    tblock_sizze_30764 = get_local_size(0);\n    wave_sizze_30763 = LOCKSTEP_WIDTH;\n    block_id_30762 = get_tblock_id(0);\n    global_tid_30760 = block_id_30762 * tblock_sizze_30764 + local_tid_30761;\n    phys_tid_29079 = sext",
                                    "_i32_i64(global_tid_30760);\n    subhisto_ind_30765 = squot32(global_tid_30760, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_29072 * num_tblocks_29074), sext_i64_i32(num_subhistos_30677)));\n    num_chunks_30766 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_29072 * num_tblocks_29074)));\n    for (int64_t chunk_i_30767 = 0; chunk_i_30767 < num_chunks_30766; chunk_i_30767++) {\n        int64_t i_30768 = chunk_i_30767 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_29072 * num_tblocks_29074)) + sext_i32_i64(global_tid_30760);\n        \n        if (slt64(i_30768, loop_dz2081Uz2088Uz2087U_27125)) {\n            int64_t slice_30769;\n            int64_t gtid_29078;\n            int64_t remnant_30770;\n            \n            slice_30769 = loop_dz2081Uz2088Uz2087U_27125;\n            gtid_29078 = i_30768;\n            remnant_30770 = i_30768 - gtid_29078;\n            if (slt64(i_30768, loop_dz2081Uz2088Uz2087U_27125)) {\n                int32_t eta_p_29087;\n                int64_t ii_29088;\n                bool x_29089;\n                bool y_29090;\n                bool bounds_check_29091;\n                bool index_certs_29092;\n                double eta_p_29086;\n                double eq_arg1_29093;\n                bool defunc_0_eq_res_29094;\n                bool defunc_0_lt_res_29095;\n                int32_t bool_res_29096;\n                int32_t bool_res_29097;\n                \n                eta_p_29087 = ((__global int32_t *) mem_param_29728)[gtid_29078];\n                ii_29088 = sext_i32_i64(eta_p_29087);\n                x_29089 = sle64((int64_t) 0, ii_29088);\n                y_29090 = slt64(ii_29088, mz2080U_21995);\n                bounds_check_29091 = x_29089 && y_29090;\n                if (!bounds_check_29091) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 22) == -1) {\n                            global_failure_args[0] = (int64_t) ii_29088;\n                            global_", "failure_args[1] = (int64_t) mz2080U_21995;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                eta_p_29086 = ((__global double *) mem_param_29731)[gtid_29078];\n                eq_arg1_29093 = ((__global double *) mem_29740)[ii_29088];\n                defunc_0_eq_res_29094 = eta_p_29086 == eq_arg1_29093;\n                defunc_0_lt_res_29095 = eta_p_29086 < eq_arg1_29093;\n                bool_res_29096 = btoi_bool_i32(defunc_0_lt_res_29095);\n                bool_res_29097 = btoi_bool_i32(defunc_0_eq_res_29094);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_30758) * hist_H_chk_30759, ii_29088) && (slt64(ii_29088, sext_i32_i64(chk_i_30758) * hist_H_chk_30759 + hist_H_chk_30759) && (sle64((int64_t) 0, ii_29088) && slt64(ii_29088, mz2080U_21995)))) {\n                        int32_t eta_p_29080;\n                        int32_t eta_p_29081;\n                        int32_t eta_p_29082;\n                        int32_t eta_p_29083;\n                        \n                        eta_p_29082 = bool_res_29096;\n                        eta_p_29083 = bool_res_29097;\n                        \n                        int32_t old_30771;\n                        \n                        old_30771 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30678)[sext_i32_i64(subhisto_ind_30765) * mz2080U_21995 + ii_29088], (int) eta_p_29082);\n                        \n                        int32_t old_30772;\n                        \n                        old_30772 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30680)[sext_i32_i64(subhisto_ind_30765) * mz2080U_21995 + ii_29088], (int) eta_p_29083);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_t", "block_sizze_29072\n}\nFUTHARK_KERNEL_SIZED(human_genericf64ziseghist_local_28788_dim1, 1, 1)\nvoid human_genericf64ziseghist_local_28788(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_21995, int64_t nz2081U_21996, int64_t num_subhistos_30239, int64_t num_tblocks_30252, int32_t hist_M_30258, int32_t chk_i_30262, int64_t num_segments_30263, int64_t hist_H_chk_30264, int64_t histo_sizze_30265, int32_t init_per_thread_30266, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242)\n{\n    #define max_tblock_sizze_30251 (human_genericf64ziseghist_local_28788zimax_tblock_sizze_30251)\n    \n    volatile __local unsigned char *subhistogram_local_mem_30282_backing_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_30282_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_30280_backing_0 = &shared_mem[subhistogram_local_mem_30282_backing_1_offset];\n    const int64_t subhistogram_local_mem_30280_backing_0_offset = subhistogram_local_mem_30282_backing_1_offset + ((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30268;\n    int32_t tblock_sizze_30271;\n    int32_t wave_sizze_30270;\n    int32_t block_id_30269;\n    int32_t global_tid_30267;\n    int64_t phys_tid_28788;\n    int32_t phys_tblock_id_3027",
                                    "2;\n    int32_t iterations_30273;\n    \n    local_tid_30268 = get_local_id(0);\n    tblock_sizze_30271 = get_local_size(0);\n    wave_sizze_30270 = LOCKSTEP_WIDTH;\n    block_id_30269 = get_tblock_id(0);\n    global_tid_30267 = block_id_30269 * tblock_sizze_30271 + local_tid_30268;\n    phys_tid_28788 = sext_i32_i64(global_tid_30267);\n    phys_tblock_id_30272 = get_tblock_id(0);\n    iterations_30273 = sdiv_up32(sext_i64_i32(num_tblocks_30252 * num_segments_30263) - phys_tblock_id_30272, sext_i64_i32(num_tblocks_30252));\n    for (int32_t i_30274 = 0; i_30274 < iterations_30273; i_30274++) {\n        int32_t virt_tblock_id_30275;\n        int32_t flat_segment_id_30276;\n        int32_t gid_in_segment_30277;\n        int32_t pgtid_in_segment_30278;\n        int32_t threads_per_segment_30279;\n        __local unsigned char *subhistogram_local_mem_30280;\n        __local unsigned char *subhistogram_local_mem_30282;\n        int32_t thread_local_subhisto_i_30284;\n        int64_t num_chunks_30297;\n        \n        virt_tblock_id_30275 = phys_tblock_id_30272 + i_30274 * sext_i64_i32(num_tblocks_30252);\n        flat_segment_id_30276 = squot32(virt_tblock_id_30275, sext_i64_i32(num_tblocks_30252));\n        gid_in_segment_30277 = srem32(virt_tblock_id_30275, sext_i64_i32(num_tblocks_30252));\n        pgtid_in_segment_30278 = gid_in_segment_30277 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n        threads_per_segment_30279 = sext_i64_i32(num_tblocks_30252 * max_tblock_sizze_30251);\n        subhistogram_local_mem_30280 = (__local unsigned char *) subhistogram_local_mem_30280_backing_0;\n        subhistogram_local_mem_30282 = (__local unsigned char *) subhistogram_local_mem_30282_backing_1;\n        thread_local_subhisto_i_30284 = srem32(local_tid_30268, hist_M_30258);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_30285 = 0; local_i_30285 < init_per_thread_30266; local_i_30285++) {\n                int32_t j_30286 = local_i_30285 * sext_i", "64_i32(max_tblock_sizze_30251) + local_tid_30268;\n                int32_t j_offset_30287 = hist_M_30258 * sext_i64_i32(histo_sizze_30265) * gid_in_segment_30277 + j_30286;\n                int32_t local_subhisto_i_30288 = squot32(j_30286, sext_i64_i32(histo_sizze_30265));\n                int32_t global_subhisto_i_30289 = squot32(j_offset_30287, sext_i64_i32(histo_sizze_30265));\n                \n                if (slt32(j_30286, hist_M_30258 * sext_i64_i32(histo_sizze_30265))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30289 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30239)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264) && slt64(sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264, mz2080U_21995)))) {\n                            int32_t tmp_30290 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(local_subhisto_i_30288) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265)))] = tmp_30290;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(local_subhisto_i_30288) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265)))] = 0;\n                        }\n                    }\n                }\n            }\n            for (int32_t local_i_30291 = 0; local_i_30291 < init_per_thread_30266; local_i_30291++) {\n                int32_t j_30292 = local_i_30291 * sext_i64_i32(max_tblock_sizze_30251) + loca", "l_tid_30268;\n                int32_t j_offset_30293 = hist_M_30258 * sext_i64_i32(histo_sizze_30265) * gid_in_segment_30277 + j_30292;\n                int32_t local_subhisto_i_30294 = squot32(j_30292, sext_i64_i32(histo_sizze_30265));\n                int32_t global_subhisto_i_30295 = squot32(j_offset_30293, sext_i64_i32(histo_sizze_30265));\n                \n                if (slt32(j_30292, hist_M_30258 * sext_i64_i32(histo_sizze_30265))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30295 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30239)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264) && slt64(sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264, mz2080U_21995)))) {\n                            int32_t tmp_30296 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(local_subhisto_i_30294) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265)))] = tmp_30296;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(local_subhisto_i_30294) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_30297 = sdiv_up64(nz2081U_21996, sext_i32_i64(threads_per_segment_30279));\n        for (int64_t chunk_i_30298 = 0; chunk_i_30298 < num_chunks_30297; chunk_i_30298++)",
                                    " {\n            int64_t i_30299 = chunk_i_30298 * sext_i32_i64(threads_per_segment_30279) + sext_i32_i64(pgtid_in_segment_30278);\n            \n            if (slt64(i_30299, nz2081U_21996)) {\n                int64_t gtid_28787;\n                int32_t eta_p_28796;\n                int64_t ii_28797;\n                bool x_28798;\n                bool y_28799;\n                bool bounds_check_28800;\n                bool index_certs_28801;\n                double eta_p_28795;\n                double eq_arg1_28802;\n                bool defunc_0_eq_res_28803;\n                bool defunc_0_lt_res_28804;\n                int32_t bool_res_28805;\n                int32_t bool_res_28806;\n                \n                gtid_28787 = i_30299;\n                eta_p_28796 = ((__global int32_t *) II1_mem_29679)[gtid_28787];\n                ii_28797 = sext_i32_i64(eta_p_28796);\n                x_28798 = sle64((int64_t) 0, ii_28797);\n                y_28799 = slt64(ii_28797, mz2080U_21995);\n                bounds_check_28800 = x_28798 && y_28799;\n                if (!bounds_check_28800) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 13) == -1) {\n                            global_failure_args[0] = (int64_t) ii_28797;\n                            global_failure_args[1] = (int64_t) mz2080U_21995;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                eta_p_28795 = ((__global double *) A_mem_29680)[gtid_28787];\n                eq_arg1_28802 = ((__global double *) mem_29695)[ii_28797];\n                defunc_0_eq_res_28803 = eta_p_28795 == eq_arg1_28802;\n                defunc_0_lt_res_28804 = eta_p_28795 < eq_arg1_28802;\n                bool_res_28805 = btoi_bool_i32(defunc_0_lt_res_28804);\n                bool_res_28806 = btoi_bool_i32(defunc_0_eq_res_28803);\n                if (chk_i_30262 == 0) {\n      ", "              // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, ii_28797) && slt64(ii_28797, mz2080U_21995)) && (sle64(sext_i32_i64(chk_i_30262) * hist_H_chk_30264, ii_28797) && slt64(ii_28797, sext_i32_i64(chk_i_30262) * hist_H_chk_30264 + hist_H_chk_30264))) {\n                        int32_t eta_p_28789;\n                        int32_t eta_p_28790;\n                        int32_t eta_p_28791;\n                        int32_t eta_p_28792;\n                        \n                        eta_p_28791 = bool_res_28805;\n                        eta_p_28792 = bool_res_28806;\n                        \n                        int32_t old_30300;\n                        \n                        old_30300 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30280)[sext_i32_i64(thread_local_subhisto_i_30284) * hist_H_chk_30264 + (ii_28797 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264)], (int) eta_p_28791);\n                        \n                        int32_t old_30301;\n                        \n                        old_30301 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30282)[sext_i32_i64(thread_local_subhisto_i_30284) * hist_H_chk_30264 + (ii_28797 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264)], (int) eta_p_28792);\n                    }\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_30302 = smin64(hist_H_chk_30264, mz2080U_21995 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264);\n            int32_t histo_sizze_30303 = sext_i64_i32(trunc_H_30302);\n            \n            for (int32_t local_i_30304", " = 0; local_i_30304 < init_per_thread_30266; local_i_30304++) {\n                int32_t j_30305 = local_i_30304 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n                \n                if (slt32(j_30305, histo_sizze_30303)) {\n                    int32_t eta_p_28789;\n                    int32_t eta_p_28790;\n                    int32_t eta_p_28791;\n                    int32_t eta_p_28792;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_28789 = ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(j_30305)];\n                        eta_p_28790 = ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(j_30305)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_30306 = 0; subhisto_id_30306 < hist_M_30258 - 1; subhisto_id_30306++) {\n                            eta_p_28791 = ((__local int32_t *) subhistogram_local_mem_30280)[(sext_i32_i64(subhisto_id_30306) + (int64_t) 1) * hist_H_chk_30264 + sext_i32_i64(j_30305)];\n                            eta_p_28792 = ((__local int32_t *) subhistogram_local_mem_30282)[(sext_i32_i64(subhisto_id_30306) + (int64_t) 1) * hist_H_chk_30264 + sext_i32_i64(j_30305)];\n                            \n                            int32_t tmp_28793 = add32(eta_p_28789, eta_p_28791);\n                            int32_t tmp_28794 = add32(eta_p_28790, eta_p_28792);\n                            \n                            eta_p_28789 = tmp_28793;\n                            eta_p_28790 = tmp_28794;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[srem64(sext_i32_i64(virt_tblock_id_30275), num_tblocks_30252) * mz2080U_21995 + (sext_i32_i64(j_30305) + sext_i3",
                                    "2_i64(chk_i_30262) * hist_H_chk_30264)] = eta_p_28789;\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[srem64(sext_i32_i64(virt_tblock_id_30275), num_tblocks_30252) * mz2080U_21995 + (sext_i32_i64(j_30305) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264)] = eta_p_28790;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_30251\n}\nFUTHARK_KERNEL_SIZED(human_genericf64ziseghist_local_29079_dim1, 1, 1)\nvoid human_genericf64ziseghist_local_29079(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_21995, int64_t loop_dz2081Uz2088Uz2087U_27125, int64_t num_subhistos_30677, int64_t num_tblocks_30690, int32_t hist_M_30696, int32_t chk_i_30700, int64_t num_segments_30701, int64_t hist_H_chk_30702, int64_t histo_sizze_30703, int32_t init_per_thread_30704, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define max_tblock_sizze_30689 (human_genericf64ziseghist_local_29079zimax_tblock_sizze_30689)\n    \n    volatile __local unsigned char *subhistogram_local_mem_30720_backing_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_30720_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_30718_backing_0 = &shared_mem[subhistogram_local_mem_30720_backing_1_offset];\n    const int64_t subhistogram_local_mem_30718_backing_0_offset = subhistogram_local_mem_30720_backing_1_offset + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist", "_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30706;\n    int32_t tblock_sizze_30709;\n    int32_t wave_sizze_30708;\n    int32_t block_id_30707;\n    int32_t global_tid_30705;\n    int64_t phys_tid_29079;\n    int32_t phys_tblock_id_30710;\n    int32_t iterations_30711;\n    \n    local_tid_30706 = get_local_id(0);\n    tblock_sizze_30709 = get_local_size(0);\n    wave_sizze_30708 = LOCKSTEP_WIDTH;\n    block_id_30707 = get_tblock_id(0);\n    global_tid_30705 = block_id_30707 * tblock_sizze_30709 + local_tid_30706;\n    phys_tid_29079 = sext_i32_i64(global_tid_30705);\n    phys_tblock_id_30710 = get_tblock_id(0);\n    iterations_30711 = sdiv_up32(sext_i64_i32(num_tblocks_30690 * num_segments_30701) - phys_tblock_id_30710, sext_i64_i32(num_tblocks_30690));\n    for (int32_t i_30712 = 0; i_30712 < iterations_30711; i_30712++) {\n        int32_t virt_tblock_id_30713;\n        int32_t flat_segment_id_30714;\n        int32_t gid_in_segment_30715;\n        int32_t pgtid_in_segment_30716;\n        int32_t threads_per_segment_30717;\n        __local unsigned char *subhistogram_local_mem_30718;\n        __local unsigned char *subhistogram_local_mem_30720;\n        int32_t thread_local_subhisto_i_30722;\n        int64_t num_chunks_30735;\n        \n        virt_tblock_id_30713 = phys_tblock_id_30710 + i_30712 * sext_i64_i32(num_tblocks_30690);\n        flat_segment_id_30714 = squot32(virt_tblock_id_30713, sext_i64_i32(num_tblocks_30690));\n        gid_in_segment_30715 = srem32(virt_tblock_id_30713, sext_i64_i32(num_tblocks_30690));\n        pgtid_in_segment_30716 = gid_in_segment_30715 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n        threads_per_segment_30717 = sext_i64_i32(num_tblocks_30690 * max_tblock_sizze_30689);\n   ", "     subhistogram_local_mem_30718 = (__local unsigned char *) subhistogram_local_mem_30718_backing_0;\n        subhistogram_local_mem_30720 = (__local unsigned char *) subhistogram_local_mem_30720_backing_1;\n        thread_local_subhisto_i_30722 = srem32(local_tid_30706, hist_M_30696);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_30723 = 0; local_i_30723 < init_per_thread_30704; local_i_30723++) {\n                int32_t j_30724 = local_i_30723 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                int32_t j_offset_30725 = hist_M_30696 * sext_i64_i32(histo_sizze_30703) * gid_in_segment_30715 + j_30724;\n                int32_t local_subhisto_i_30726 = squot32(j_30724, sext_i64_i32(histo_sizze_30703));\n                int32_t global_subhisto_i_30727 = squot32(j_offset_30725, sext_i64_i32(histo_sizze_30703));\n                \n                if (slt32(j_30724, hist_M_30696 * sext_i64_i32(histo_sizze_30703))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30727 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30677)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702) && slt64(sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702, mz2080U_21995)))) {\n                            int32_t tmp_30728 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(local_subhisto_i_30726) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703)))] = tmp_30728;\n          ",
                                    "              } else {\n                            ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(local_subhisto_i_30726) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703)))] = 0;\n                        }\n                    }\n                }\n            }\n            for (int32_t local_i_30729 = 0; local_i_30729 < init_per_thread_30704; local_i_30729++) {\n                int32_t j_30730 = local_i_30729 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                int32_t j_offset_30731 = hist_M_30696 * sext_i64_i32(histo_sizze_30703) * gid_in_segment_30715 + j_30730;\n                int32_t local_subhisto_i_30732 = squot32(j_30730, sext_i64_i32(histo_sizze_30703));\n                int32_t global_subhisto_i_30733 = squot32(j_offset_30731, sext_i64_i32(histo_sizze_30703));\n                \n                if (slt32(j_30730, hist_M_30696 * sext_i64_i32(histo_sizze_30703))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30733 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30677)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702) && slt64(sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702, mz2080U_21995)))) {\n                            int32_t tmp_30734 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(local_subhisto_i_30732) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703)))] = tmp_30734;\n                        } else {\n              ", "              ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(local_subhisto_i_30732) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_30735 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, sext_i32_i64(threads_per_segment_30717));\n        for (int64_t chunk_i_30736 = 0; chunk_i_30736 < num_chunks_30735; chunk_i_30736++) {\n            int64_t i_30737 = chunk_i_30736 * sext_i32_i64(threads_per_segment_30717) + sext_i32_i64(pgtid_in_segment_30716);\n            \n            if (slt64(i_30737, loop_dz2081Uz2088Uz2087U_27125)) {\n                int64_t gtid_29078;\n                int32_t eta_p_29087;\n                int64_t ii_29088;\n                bool x_29089;\n                bool y_29090;\n                bool bounds_check_29091;\n                bool index_certs_29092;\n                double eta_p_29086;\n                double eq_arg1_29093;\n                bool defunc_0_eq_res_29094;\n                bool defunc_0_lt_res_29095;\n                int32_t bool_res_29096;\n                int32_t bool_res_29097;\n                \n                gtid_29078 = i_30737;\n                eta_p_29087 = ((__global int32_t *) mem_param_29728)[gtid_29078];\n                ii_29088 = sext_i32_i64(eta_p_29087);\n                x_29089 = sle64((int64_t) 0, ii_29088);\n                y_29090 = slt64(ii_29088, mz2080U_21995);\n                bounds_check_29091 = x_29089 && y_29090;\n                if (!bounds_check_29091) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 21) == -1) {\n                            global_failure_args[0] = (int64_t) ii_29088;\n                            global_failure_args[1] = (int64_t) mz2080U_21995;\n                            ;\n                        }\n                        local_failure = 1;\n                 ", "       goto error_0;\n                    }\n                }\n                eta_p_29086 = ((__global double *) mem_param_29731)[gtid_29078];\n                eq_arg1_29093 = ((__global double *) mem_29740)[ii_29088];\n                defunc_0_eq_res_29094 = eta_p_29086 == eq_arg1_29093;\n                defunc_0_lt_res_29095 = eta_p_29086 < eq_arg1_29093;\n                bool_res_29096 = btoi_bool_i32(defunc_0_lt_res_29095);\n                bool_res_29097 = btoi_bool_i32(defunc_0_eq_res_29094);\n                if (chk_i_30700 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, ii_29088) && slt64(ii_29088, mz2080U_21995)) && (sle64(sext_i32_i64(chk_i_30700) * hist_H_chk_30702, ii_29088) && slt64(ii_29088, sext_i32_i64(chk_i_30700) * hist_H_chk_30702 + hist_H_chk_30702))) {\n                        int32_t eta_p_29080;\n                        int32_t eta_p_29081;\n                        int32_t eta_p_29082;\n                        int32_t eta_p_29083;\n                        \n                        eta_p_29082 = bool_res_29096;\n                        eta_p_29083 = bool_res_29097;\n                        \n                        int32_t old_30738;\n                        \n                        old_30738 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30718)[sext_i32_i64(thread_local_subhisto_i_30722) * hist_H_chk_30702 + (ii_29088 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702)], (int) eta_p_29082);\n                        \n                        int32_t old_30739;\n                        \n                        old_30739 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30720)[sext_i32_i64(thread_local_subhisto_i_30722) * hist_H_chk_30702 + (ii_29088 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702)], (int) eta_p_29083);\n                    }\n                }\n            }\n",
                                    "        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_30740 = smin64(hist_H_chk_30702, mz2080U_21995 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702);\n            int32_t histo_sizze_30741 = sext_i64_i32(trunc_H_30740);\n            \n            for (int32_t local_i_30742 = 0; local_i_30742 < init_per_thread_30704; local_i_30742++) {\n                int32_t j_30743 = local_i_30742 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                \n                if (slt32(j_30743, histo_sizze_30741)) {\n                    int32_t eta_p_29080;\n                    int32_t eta_p_29081;\n                    int32_t eta_p_29082;\n                    int32_t eta_p_29083;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_29080 = ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(j_30743)];\n                        eta_p_29081 = ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(j_30743)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_30744 = 0; subhisto_id_30744 < hist_M_30696 - 1; subhisto_id_30744++) {\n                            eta_p_29082 = ((__local int32_t *) subhistogram_local_mem_30718)[(sext_i32_i64(subhisto_id_30744) + (int64_t) 1) * hist_H_chk_30702 + sext_i32_i64(j_30743)];\n                            eta_p_29083 = ((__local int32_t *) subhistogram_local_mem_30720)[(sext_i32_i64(subhisto_id_30744) + (int64_t) 1) * hist_H_chk_30702 + sext_i32_i64(j_30743)];\n                            \n                            int32_t tmp_29084 = add32(eta_p_29080, eta_p_29082);\n  ", "                          int32_t tmp_29085 = add32(eta_p_29081, eta_p_29083);\n                            \n                            eta_p_29080 = tmp_29084;\n                            eta_p_29081 = tmp_29085;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[srem64(sext_i32_i64(virt_tblock_id_30713), num_tblocks_30690) * mz2080U_21995 + (sext_i32_i64(j_30743) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702)] = eta_p_29080;\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[srem64(sext_i32_i64(virt_tblock_id_30713), num_tblocks_30690) * mz2080U_21995 + (sext_i32_i64(j_30743) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702)] = eta_p_29081;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_30689\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegmap_28710_dim1, 1, 1)\nvoid human_genericf64zisegmap_28710(__global int *global_failure, int64_t mz2080U_21995, int64_t nz2081U_21996, int64_t num_tblocks_28715, int32_t virt_num_tblocks_29953, __global unsigned char *mem_29683, __global unsigned char *mem_29684)\n{\n    #define segmap_tblock_sizze_28713 (human_genericf64zisegmap_28710zisegmap_tblock_sizze_28713)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29955;\n    int32_t tblock_sizze_29958;\n    int32_t wave_sizze_29957;\n    int32_t block_id_29956;\n    int32_t global_tid_29954;\n    int64_t phys_tid_28710;\n    int32_t phys_tblock_id_29959;\n    int32_t iterations_29960;\n    \n    local_tid_29955 = get_local_id(0);\n    tblock_sizze_29958 = get_local_size(0);\n    wave_sizze_29957 = LOCKSTEP_WIDTH;\n    block_id_29956 = get_tblock_id(0);\n    global_tid_29954 = block_id_29956 * tblock_sizze_29958 + local_tid_29955;\n    phys_tid_2", "8710 = sext_i32_i64(global_tid_29954);\n    phys_tblock_id_29959 = get_tblock_id(0);\n    iterations_29960 = sdiv_up32(virt_num_tblocks_29953 - phys_tblock_id_29959, sext_i64_i32(num_tblocks_28715));\n    for (int32_t i_29961 = 0; i_29961 < iterations_29960; i_29961++) {\n        int32_t virt_tblock_id_29962;\n        int64_t global_tid_29963;\n        int64_t slice_29964;\n        int64_t write_i_28709;\n        int64_t remnant_29965;\n        \n        virt_tblock_id_29962 = phys_tblock_id_29959 + i_29961 * sext_i64_i32(num_tblocks_28715);\n        global_tid_29963 = sext_i32_i64(virt_tblock_id_29962) * segmap_tblock_sizze_28713 + sext_i32_i64(local_tid_29955);\n        slice_29964 = mz2080U_21995;\n        write_i_28709 = global_tid_29963;\n        remnant_29965 = global_tid_29963 - write_i_28709;\n        if (slt64(write_i_28709, mz2080U_21995)) {\n            int64_t zv_lhs_27704;\n            int64_t tmp_27705;\n            bool cond_27708;\n            int64_t lifted_lambda_res_27709;\n            \n            zv_lhs_27704 = add64((int64_t) -1, write_i_28709);\n            tmp_27705 = smod64(zv_lhs_27704, mz2080U_21995);\n            cond_27708 = write_i_28709 == (int64_t) 0;\n            if (cond_27708) {\n                lifted_lambda_res_27709 = (int64_t) 0;\n            } else {\n                int64_t lifted_lambda_res_27706 = ((__global int64_t *) mem_29683)[tmp_27705];\n                \n                lifted_lambda_res_27709 = lifted_lambda_res_27706;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27709) && slt64(lifted_lambda_res_27709, nz2081U_21996)) {\n                ((__global bool *) mem_29684)[lifted_lambda_res_27709] = 1;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_28713\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegmap_28762_dim1, 1, 1)\nvoid human_genericf64zisegmap_28762(__global int *global_failure, int failure_is_an_option, __global int64_t *g",
                                    "lobal_failure_args, int64_t mz2080U_21995, int64_t nz2081U_21996, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29689, __global unsigned char *mem_29692, __global unsigned char *mem_29695)\n{\n    #define segmap_tblock_sizze_28758 (human_genericf64zisegmap_28762zisegmap_tblock_sizze_28758)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30231;\n    int32_t tblock_sizze_30234;\n    int32_t wave_sizze_30233;\n    int32_t block_id_30232;\n    int32_t global_tid_30230;\n    int64_t phys_tid_28762;\n    int64_t global_tid_30235;\n    int64_t slice_30236;\n    int64_t gtid_28761;\n    int64_t remnant_30237;\n    \n    local_tid_30231 = get_local_id(0);\n    tblock_sizze_30234 = get_local_size(0);\n    wave_sizze_30233 = LOCKSTEP_WIDTH;\n    block_id_30232 = get_tblock_id(0);\n    global_tid_30230 = block_id_30232 * tblock_sizze_30234 + local_tid_30231;\n    phys_tid_28762 = sext_i32_i64(global_tid_30230);\n    global_tid_30235 = sext_i32_i64(block_id_30232) * segmap_tblock_sizze_28758 + sext_i32_i64(local_tid_30231);\n    slice_30236 = mz2080U_21995;\n    gtid_28761 = global_tid_30235;\n    remnant_30237 = global_tid_30235 - gtid_28761;\n    if (slt64(gtid_28761, mz2080U_21995)) {\n        int32_t eta_p_28764;\n        bool cond_28766;\n        double lifted_lambda_res_28767;\n        float i32_res_28775;\n        float f64_res_28776;\n        float f32_arg0_28777;\n        double f32_res_28778;\n        \n        eta_p_28764 = ((__global int32_t *) shp_mem_29678)[gtid_28761];\n        cond_28766 = eta_p_28764 == 0;\n        if (cond_28766) {\n            lifted_lambda_res_28767 = 0.0;\n        } else {\n            int32_t eta_p_28763;\n            int32_t tmp_28768;\n            int64_t tmp_28769;\n            bool x_28770;\n            bool y_28771;\n            bool bounds_check_28772;\n            bool index_certs_28773;\n            double lifted_lambda_res_f_res_28774;\n            \n            eta_p_28763 = ((__global int32_t *) mem_29692)[gtid_28761];\n          ", "  tmp_28768 = sub32(eta_p_28763, 1);\n            tmp_28769 = sext_i32_i64(tmp_28768);\n            x_28770 = sle64((int64_t) 0, tmp_28769);\n            y_28771 = slt64(tmp_28769, nz2081U_21996);\n            bounds_check_28772 = x_28770 && y_28771;\n            if (!bounds_check_28772) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 12) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_28769;\n                        global_failure_args[1] = (int64_t) nz2081U_21996;\n                        ;\n                    }\n                    return;\n                }\n            }\n            lifted_lambda_res_f_res_28774 = ((__global double *) mem_29689)[tmp_28769];\n            lifted_lambda_res_28767 = lifted_lambda_res_f_res_28774;\n        }\n        i32_res_28775 = sitofp_i32_f32(eta_p_28764);\n        f64_res_28776 = fpconv_f64_f32(lifted_lambda_res_28767);\n        f32_arg0_28777 = f64_res_28776 / i32_res_28775;\n        f32_res_28778 = fpconv_f32_f64(f32_arg0_28777);\n        ((__global double *) mem_29695)[gtid_28761] = f32_res_28778;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_28758\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegmap_28850_dim1, 1, 1)\nvoid human_genericf64zisegmap_28850(__global int *global_failure, int64_t mz2080U_21995, __global unsigned char *ks_mem_29677, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29695, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *mem_29703, __global unsigned char *mem_29705, __global unsigned char *mem_29707, __global unsigned char *mem_29709)\n{\n    #define segmap_tblock_sizze_28843 (human_genericf64zisegmap_28850zisegmap_tblock_sizze_28843)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30428;\n    int32_t tblock_sizze_30431;\n    int32_t wave_sizze_30430;\n    int32_t block_id_30429;\n    int32_t global_tid_30427;\n    int64_t phys_tid_28850;\n    int64_t global_", "tid_30432;\n    int64_t slice_30433;\n    int64_t gtid_28849;\n    int64_t remnant_30434;\n    \n    local_tid_30428 = get_local_id(0);\n    tblock_sizze_30431 = get_local_size(0);\n    wave_sizze_30430 = LOCKSTEP_WIDTH;\n    block_id_30429 = get_tblock_id(0);\n    global_tid_30427 = block_id_30429 * tblock_sizze_30431 + local_tid_30428;\n    phys_tid_28850 = sext_i32_i64(global_tid_30427);\n    global_tid_30432 = sext_i32_i64(block_id_30429) * segmap_tblock_sizze_28843 + sext_i32_i64(local_tid_30428);\n    slice_30433 = mz2080U_21995;\n    gtid_28849 = global_tid_30432;\n    remnant_30434 = global_tid_30432 - gtid_28849;\n    if (slt64(gtid_28849, mz2080U_21995)) {\n        int32_t eta_p_28851;\n        int32_t eta_p_28852;\n        int32_t eta_p_28853;\n        int32_t eta_p_28854;\n        bool cond_28856;\n        int32_t lifted_lambda_res_28857;\n        bool cond_28863;\n        double lifted_lambda_res_28864;\n        bool cond_28865;\n        int32_t lifted_lambda_res_28866;\n        int32_t lifted_lambda_res_28872;\n        \n        eta_p_28851 = ((__global int32_t *) mem_29699)[gtid_28849];\n        eta_p_28852 = ((__global int32_t *) mem_29697)[gtid_28849];\n        eta_p_28853 = ((__global int32_t *) shp_mem_29678)[gtid_28849];\n        eta_p_28854 = ((__global int32_t *) ks_mem_29677)[gtid_28849];\n        cond_28856 = eta_p_28853 == 0;\n        if (cond_28856) {\n            lifted_lambda_res_28857 = -1;\n        } else {\n            bool cond_28858;\n            int32_t lifted_lambda_res_f_res_28859;\n            \n            cond_28858 = sle32(eta_p_28854, eta_p_28851);\n            if (cond_28858) {\n                lifted_lambda_res_f_res_28859 = 0;\n            } else {\n                int32_t zlze_rhs_28860;\n                bool cond_28861;\n                int32_t lifted_lambda_res_f_res_f_res_28862;\n                \n                zlze_rhs_28860 = add32(eta_p_28851, eta_p_28852);\n                cond_28861 = sle32(eta_p_28854, zlze_rhs_28860);\n                if (cond_28861) {\n     ",
                                    "               lifted_lambda_res_f_res_f_res_28862 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_28862 = 2;\n                }\n                lifted_lambda_res_f_res_28859 = lifted_lambda_res_f_res_f_res_28862;\n            }\n            lifted_lambda_res_28857 = lifted_lambda_res_f_res_28859;\n        }\n        cond_28863 = lifted_lambda_res_28857 == 1;\n        if (cond_28863) {\n            double eta_p_28855 = ((__global double *) mem_29695)[gtid_28849];\n            \n            lifted_lambda_res_28864 = eta_p_28855;\n        } else {\n            lifted_lambda_res_28864 = 0.0;\n        }\n        cond_28865 = lifted_lambda_res_28857 == -1;\n        if (cond_28865) {\n            lifted_lambda_res_28866 = -1;\n        } else {\n            bool cond_28867;\n            int32_t lifted_lambda_res_f_res_28868;\n            \n            cond_28867 = lifted_lambda_res_28857 == 0;\n            if (cond_28867) {\n                lifted_lambda_res_f_res_28868 = eta_p_28854;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_28869;\n                \n                if (cond_28863) {\n                    lifted_lambda_res_f_res_f_res_28869 = -1;\n                } else {\n                    int32_t zm_lhs_28870;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_28871;\n                    \n                    zm_lhs_28870 = sub32(eta_p_28854, eta_p_28851);\n                    lifted_lambda_res_f_res_f_res_f_res_28871 = sub32(zm_lhs_28870, eta_p_28852);\n                    lifted_lambda_res_f_res_f_res_28869 = lifted_lambda_res_f_res_f_res_f_res_28871;\n                }\n                lifted_lambda_res_f_res_28868 = lifted_lambda_res_f_res_f_res_28869;\n            }\n            lifted_lambda_res_28866 = lifted_lambda_res_f_res_28868;\n        }\n        if (cond_28865) {\n            lifted_lambda_res_28872 = 0;\n        } else {\n            bool cond_28873;\n            int32_t lifted_lambda_res_f_res_28874;\n            \n   ", "         cond_28873 = lifted_lambda_res_28857 == 0;\n            if (cond_28873) {\n                lifted_lambda_res_f_res_28874 = eta_p_28851;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_28875;\n                \n                if (cond_28863) {\n                    lifted_lambda_res_f_res_f_res_28875 = 0;\n                } else {\n                    int32_t zm_lhs_28876;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_28877;\n                    \n                    zm_lhs_28876 = sub32(eta_p_28853, eta_p_28851);\n                    lifted_lambda_res_f_res_f_res_f_res_28877 = sub32(zm_lhs_28876, eta_p_28852);\n                    lifted_lambda_res_f_res_f_res_28875 = lifted_lambda_res_f_res_f_res_f_res_28877;\n                }\n                lifted_lambda_res_f_res_28874 = lifted_lambda_res_f_res_f_res_28875;\n            }\n            lifted_lambda_res_28872 = lifted_lambda_res_f_res_28874;\n        }\n        ((__global int32_t *) mem_29703)[gtid_28849] = lifted_lambda_res_28872;\n        ((__global int32_t *) mem_29705)[gtid_28849] = lifted_lambda_res_28866;\n        ((__global double *) mem_29707)[gtid_28849] = lifted_lambda_res_28864;\n        ((__global int32_t *) mem_29709)[gtid_28849] = lifted_lambda_res_28857;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_28843\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegmap_28887_dim1, 1, 1)\nvoid human_genericf64zisegmap_28887(__global int *global_failure, int64_t nz2081U_21996, int64_t m_27089, int64_t num_tblocks_28892, int32_t virt_num_tblocks_30539, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29712, __global unsigned char *mem_29714, __global unsigned char *mem_29716, __global unsigned char *mem_29718)\n{\n    #define segmap_tblock_sizze_28890 (human_genericf64zisegmap_28887zisegmap_tblock_sizze_28890)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30541;\n    int32_t tblock_sizze", "_30544;\n    int32_t wave_sizze_30543;\n    int32_t block_id_30542;\n    int32_t global_tid_30540;\n    int64_t phys_tid_28887;\n    int32_t phys_tblock_id_30545;\n    int32_t iterations_30546;\n    \n    local_tid_30541 = get_local_id(0);\n    tblock_sizze_30544 = get_local_size(0);\n    wave_sizze_30543 = LOCKSTEP_WIDTH;\n    block_id_30542 = get_tblock_id(0);\n    global_tid_30540 = block_id_30542 * tblock_sizze_30544 + local_tid_30541;\n    phys_tid_28887 = sext_i32_i64(global_tid_30540);\n    phys_tblock_id_30545 = get_tblock_id(0);\n    iterations_30546 = sdiv_up32(virt_num_tblocks_30539 - phys_tblock_id_30545, sext_i64_i32(num_tblocks_28892));\n    for (int32_t i_30547 = 0; i_30547 < iterations_30546; i_30547++) {\n        int32_t virt_tblock_id_30548;\n        int64_t global_tid_30549;\n        int64_t slice_30550;\n        int64_t write_i_28886;\n        int64_t remnant_30551;\n        \n        virt_tblock_id_30548 = phys_tblock_id_30545 + i_30547 * sext_i64_i32(num_tblocks_28892);\n        global_tid_30549 = sext_i32_i64(virt_tblock_id_30548) * segmap_tblock_sizze_28890 + sext_i32_i64(local_tid_30541);\n        slice_30550 = nz2081U_21996;\n        write_i_28886 = global_tid_30549;\n        remnant_30551 = global_tid_30549 - write_i_28886;\n        if (slt64(write_i_28886, nz2081U_21996)) {\n            int64_t eta_p_27397;\n            double write_value_27399;\n            int32_t write_value_27400;\n            bool cond_27401;\n            int64_t lifted_lambda_res_27402;\n            \n            eta_p_27397 = ((__global int64_t *) mem_29714)[write_i_28886];\n            write_value_27399 = ((__global double *) A_mem_29680)[write_i_28886];\n            write_value_27400 = ((__global int32_t *) II1_mem_29679)[write_i_28886];\n            cond_27401 = eta_p_27397 == (int64_t) 1;\n            if (cond_27401) {\n                int64_t eta_p_27398;\n                int64_t lifted_lambda_res_t_res_28162;\n                \n                eta_p_27398 = ((__global int64_t *) mem_29712)[write_i_288",
                                    "86];\n                lifted_lambda_res_t_res_28162 = sub64(eta_p_27398, (int64_t) 1);\n                lifted_lambda_res_27402 = lifted_lambda_res_t_res_28162;\n            } else {\n                lifted_lambda_res_27402 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27402) && slt64(lifted_lambda_res_27402, m_27089)) {\n                ((__global double *) mem_29718)[lifted_lambda_res_27402] = write_value_27399;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27402) && slt64(lifted_lambda_res_27402, m_27089)) {\n                ((__global int32_t *) mem_29716)[lifted_lambda_res_27402] = write_value_27400;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_28890\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegmap_28992_dim1, 1, 1)\nvoid human_genericf64zisegmap_28992(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_21995, int64_t loop_dz2081Uz2088Uz2087U_27125, __global unsigned char *mem_param_29725, __global unsigned char *mem_param_29731, __global unsigned char *mem_29737, __global unsigned char *mem_29740)\n{\n    #define segmap_tblock_sizze_28988 (human_genericf64zisegmap_28992zisegmap_tblock_sizze_28988)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30669;\n    int32_t tblock_sizze_30672;\n    int32_t wave_sizze_30671;\n    int32_t block_id_30670;\n    int32_t global_tid_30668;\n    int64_t phys_tid_28992;\n    int64_t global_tid_30673;\n    int64_t slice_30674;\n    int64_t gtid_28991;\n    int64_t remnant_30675;\n    \n    local_tid_30669 = get_local_id(0);\n    tblock_sizze_30672 = get_local_size(0);\n    wave_sizze_30671 = LOCKSTEP_WIDTH;\n    block_id_30670 = get_tblock_id(0);\n    global_tid_30668 = block_id_30670 * tblock_sizze_30672 + local_tid_30669;\n    phys_tid_28992 = sext_i32_i64(global_tid_30668);\n    global_tid_30673 = sext_i32_i64(", "block_id_30670) * segmap_tblock_sizze_28988 + sext_i32_i64(local_tid_30669);\n    slice_30674 = mz2080U_21995;\n    gtid_28991 = global_tid_30673;\n    remnant_30675 = global_tid_30673 - gtid_28991;\n    if (slt64(gtid_28991, mz2080U_21995)) {\n        int32_t eta_p_28994;\n        int64_t zv_lhs_28995;\n        int64_t tmp_28996;\n        bool cond_28998;\n        int32_t lifted_lambda_res_28999;\n        bool cond_29000;\n        double defunc_0_f_res_29001;\n        \n        eta_p_28994 = ((__global int32_t *) mem_param_29725)[gtid_28991];\n        zv_lhs_28995 = add64((int64_t) -1, gtid_28991);\n        tmp_28996 = smod64(zv_lhs_28995, mz2080U_21995);\n        cond_28998 = gtid_28991 == (int64_t) 0;\n        if (cond_28998) {\n            lifted_lambda_res_28999 = 0;\n        } else {\n            int32_t lifted_lambda_res_28997 = ((__global int32_t *) mem_29737)[tmp_28996];\n            \n            lifted_lambda_res_28999 = lifted_lambda_res_28997;\n        }\n        cond_29000 = eta_p_28994 == 0;\n        if (cond_29000) {\n            defunc_0_f_res_29001 = 0.0;\n        } else {\n            bool cond_29002;\n            double defunc_0_f_res_f_res_29003;\n            \n            cond_29002 = eta_p_28994 == 1;\n            if (cond_29002) {\n                int64_t off_29004;\n                bool x_29005;\n                bool y_29006;\n                bool bounds_check_29007;\n                bool index_certs_29008;\n                double defunc_0_f_res_f_res_t_res_29009;\n                \n                off_29004 = sext_i32_i64(lifted_lambda_res_28999);\n                x_29005 = sle64((int64_t) 0, off_29004);\n                y_29006 = slt64(off_29004, loop_dz2081Uz2088Uz2087U_27125);\n                bounds_check_29007 = x_29005 && y_29006;\n                if (!bounds_check_29007) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 16) == -1) {\n                            global_failure_args[0] = (int64_t) off_29004;\n                        ", "    global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                defunc_0_f_res_f_res_t_res_29009 = ((__global double *) mem_param_29731)[off_29004];\n                defunc_0_f_res_f_res_29003 = defunc_0_f_res_f_res_t_res_29009;\n            } else {\n                bool cond_29010;\n                double defunc_0_f_res_f_res_f_res_29011;\n                \n                cond_29010 = eta_p_28994 == 2;\n                if (cond_29010) {\n                    int64_t off_29012;\n                    bool x_29013;\n                    bool y_29014;\n                    bool bounds_check_29015;\n                    bool index_certs_29016;\n                    double defunc_0_f_res_f_res_f_res_t_res_29017;\n                    \n                    off_29012 = sext_i32_i64(lifted_lambda_res_28999);\n                    x_29013 = sle64((int64_t) 0, off_29012);\n                    y_29014 = slt64(off_29012, loop_dz2081Uz2088Uz2087U_27125);\n                    bounds_check_29015 = x_29013 && y_29014;\n                    if (!bounds_check_29015) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 17) == -1) {\n                                global_failure_args[0] = (int64_t) off_29012;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    defunc_0_f_res_f_res_f_res_t_res_29017 = ((__global double *) mem_param_29731)[off_29012];\n                    defunc_0_f_res_f_res_f_res_29011 = defunc_0_f_res_f_res_f_res_t_res_29017;\n                } else {\n                    int64_t off_29018;\n                    bool x_29019;\n                    bool y_29020;\n                    bool bou",
                                    "nds_check_29021;\n                    bool index_certs_29022;\n                    int32_t zp_rhs_29024;\n                    int32_t mid_29025;\n                    int64_t mid_29026;\n                    bool x_29027;\n                    bool y_29028;\n                    bool bounds_check_29029;\n                    bool index_certs_29030;\n                    int32_t zm_lhs_29032;\n                    int32_t last_29033;\n                    int64_t last_29034;\n                    bool x_29035;\n                    bool y_29036;\n                    bool bounds_check_29037;\n                    bool index_certs_29038;\n                    double first_29023;\n                    double mid_29031;\n                    double last_29039;\n                    bool defunc_0_lt_res_29040;\n                    bool defunc_0_eq_res_29041;\n                    bool x_29042;\n                    bool y_29043;\n                    bool cond_29044;\n                    double defunc_0_median3_res_29045;\n                    \n                    off_29018 = sext_i32_i64(lifted_lambda_res_28999);\n                    x_29019 = sle64((int64_t) 0, off_29018);\n                    y_29020 = slt64(off_29018, loop_dz2081Uz2088Uz2087U_27125);\n                    bounds_check_29021 = x_29019 && y_29020;\n                    if (!bounds_check_29021) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 18) == -1) {\n                                global_failure_args[0] = (int64_t) off_29018;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    zp_rhs_29024 = sdiv32(eta_p_28994, 2);\n                    mid_29025 = add32(lifted_lambda_res_28999, zp_rhs_29024);\n                    mid_29026 = sext_i32_i64(mid_29025);\n                    x_29027 = sle", "64((int64_t) 0, mid_29026);\n                    y_29028 = slt64(mid_29026, loop_dz2081Uz2088Uz2087U_27125);\n                    bounds_check_29029 = x_29027 && y_29028;\n                    if (!bounds_check_29029) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 19) == -1) {\n                                global_failure_args[0] = (int64_t) mid_29026;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    zm_lhs_29032 = add32(eta_p_28994, lifted_lambda_res_28999);\n                    last_29033 = sub32(zm_lhs_29032, 1);\n                    last_29034 = sext_i32_i64(last_29033);\n                    x_29035 = sle64((int64_t) 0, last_29034);\n                    y_29036 = slt64(last_29034, loop_dz2081Uz2088Uz2087U_27125);\n                    bounds_check_29037 = x_29035 && y_29036;\n                    if (!bounds_check_29037) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 20) == -1) {\n                                global_failure_args[0] = (int64_t) last_29034;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    first_29023 = ((__global double *) mem_param_29731)[off_29018];\n                    mid_29031 = ((__global double *) mem_param_29731)[mid_29026];\n                    last_29039 = ((__global double *) mem_param_29731)[last_29034];\n                    defunc_0_lt_res_29040 = first_29023 < mid_29031;\n                    defunc_0_eq_res_29041 = first_29023 == mid_29031;\n                    x_29042 = !defunc_0_lt_res_29040;\n         ", "           y_29043 = defunc_0_eq_res_29041 && x_29042;\n                    cond_29044 = defunc_0_lt_res_29040 || y_29043;\n                    if (cond_29044) {\n                        bool defunc_0_lt_res_29046;\n                        bool defunc_0_eq_res_29047;\n                        bool x_29048;\n                        bool y_29049;\n                        bool cond_29050;\n                        double defunc_0_median3_res_t_res_29051;\n                        \n                        defunc_0_lt_res_29046 = mid_29031 < last_29039;\n                        defunc_0_eq_res_29047 = mid_29031 == last_29039;\n                        x_29048 = !defunc_0_lt_res_29046;\n                        y_29049 = defunc_0_eq_res_29047 && x_29048;\n                        cond_29050 = defunc_0_lt_res_29046 || y_29049;\n                        if (cond_29050) {\n                            defunc_0_median3_res_t_res_29051 = mid_29031;\n                        } else {\n                            bool defunc_0_lt_res_29052;\n                            bool defunc_0_eq_res_29053;\n                            bool x_29054;\n                            bool y_29055;\n                            bool cond_29056;\n                            double defunc_0_median3_res_t_res_f_res_29057;\n                            \n                            defunc_0_lt_res_29052 = first_29023 < last_29039;\n                            defunc_0_eq_res_29053 = first_29023 == last_29039;\n                            x_29054 = !defunc_0_lt_res_29052;\n                            y_29055 = defunc_0_eq_res_29053 && x_29054;\n                            cond_29056 = defunc_0_lt_res_29052 || y_29055;\n                            if (cond_29056) {\n                                defunc_0_median3_res_t_res_f_res_29057 = last_29039;\n                            } else {\n                                defunc_0_median3_res_t_res_f_res_29057 = first_29023;\n                            }\n                            defunc_0_median",
                                    "3_res_t_res_29051 = defunc_0_median3_res_t_res_f_res_29057;\n                        }\n                        defunc_0_median3_res_29045 = defunc_0_median3_res_t_res_29051;\n                    } else {\n                        bool defunc_0_lt_res_29058;\n                        bool defunc_0_eq_res_29059;\n                        bool x_29060;\n                        bool y_29061;\n                        bool cond_29062;\n                        double defunc_0_median3_res_f_res_29063;\n                        \n                        defunc_0_lt_res_29058 = first_29023 < last_29039;\n                        defunc_0_eq_res_29059 = first_29023 == last_29039;\n                        x_29060 = !defunc_0_lt_res_29058;\n                        y_29061 = defunc_0_eq_res_29059 && x_29060;\n                        cond_29062 = defunc_0_lt_res_29058 || y_29061;\n                        if (cond_29062) {\n                            defunc_0_median3_res_f_res_29063 = first_29023;\n                        } else {\n                            bool defunc_0_lt_res_29064;\n                            bool defunc_0_eq_res_29065;\n                            bool x_29066;\n                            bool y_29067;\n                            bool cond_29068;\n                            double defunc_0_median3_res_f_res_f_res_29069;\n                            \n                            defunc_0_lt_res_29064 = mid_29031 < last_29039;\n                            defunc_0_eq_res_29065 = mid_29031 == last_29039;\n                            x_29066 = !defunc_0_lt_res_29064;\n                            y_29067 = defunc_0_eq_res_29065 && x_29066;\n                            cond_29068 = defunc_0_lt_res_29064 || y_29067;\n                            if (cond_29068) {\n                                defunc_0_median3_res_f_res_f_res_29069 = last_29039;\n                            } else {\n                                defunc_0_median3_res_f_res_f_res_29069 = mid_29031;\n                            }\n ", "                           defunc_0_median3_res_f_res_29063 = defunc_0_median3_res_f_res_f_res_29069;\n                        }\n                        defunc_0_median3_res_29045 = defunc_0_median3_res_f_res_29063;\n                    }\n                    defunc_0_f_res_f_res_f_res_29011 = defunc_0_median3_res_29045;\n                }\n                defunc_0_f_res_f_res_29003 = defunc_0_f_res_f_res_f_res_29011;\n            }\n            defunc_0_f_res_29001 = defunc_0_f_res_f_res_29003;\n        }\n        ((__global double *) mem_29740)[gtid_28991] = defunc_0_f_res_29001;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_28988\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegmap_29142_dim1, 1, 1)\nvoid human_genericf64zisegmap_29142(__global int *global_failure, int64_t mz2080U_21995, __global unsigned char *mem_param_29722, __global unsigned char *mem_param_29725, __global unsigned char *mem_param_29734, __global unsigned char *mem_29740, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *mem_29748, __global unsigned char *mem_29750, __global unsigned char *mem_29752, __global unsigned char *mem_29754)\n{\n    #define segmap_tblock_sizze_29135 (human_genericf64zisegmap_29142zisegmap_tblock_sizze_29135)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30866;\n    int32_t tblock_sizze_30869;\n    int32_t wave_sizze_30868;\n    int32_t block_id_30867;\n    int32_t global_tid_30865;\n    int64_t phys_tid_29142;\n    int64_t global_tid_30870;\n    int64_t slice_30871;\n    int64_t gtid_29141;\n    int64_t remnant_30872;\n    \n    local_tid_30866 = get_local_id(0);\n    tblock_sizze_30869 = get_local_size(0);\n    wave_sizze_30868 = LOCKSTEP_WIDTH;\n    block_id_30867 = get_tblock_id(0);\n    global_tid_30865 = block_id_30867 * tblock_sizze_30869 + local_tid_30866;\n    phys_tid_29142 = sext_i32_i64(global_tid_30865);\n    global_tid_30870 = sext_i32_i64(block_id_30867) * segmap_tblock_sizze_29135 + sext_i32_i64(", "local_tid_30866);\n    slice_30871 = mz2080U_21995;\n    gtid_29141 = global_tid_30870;\n    remnant_30872 = global_tid_30870 - gtid_29141;\n    if (slt64(gtid_29141, mz2080U_21995)) {\n        int32_t eta_p_29143;\n        int32_t eta_p_29144;\n        int32_t eta_p_29145;\n        int32_t eta_p_29146;\n        bool cond_29149;\n        int32_t lifted_lambda_res_29150;\n        bool cond_29156;\n        double lifted_lambda_res_29157;\n        bool cond_29158;\n        int32_t lifted_lambda_res_29159;\n        int32_t lifted_lambda_res_29165;\n        \n        eta_p_29143 = ((__global int32_t *) mem_29744)[gtid_29141];\n        eta_p_29144 = ((__global int32_t *) mem_29742)[gtid_29141];\n        eta_p_29145 = ((__global int32_t *) mem_param_29725)[gtid_29141];\n        eta_p_29146 = ((__global int32_t *) mem_param_29722)[gtid_29141];\n        cond_29149 = eta_p_29145 == 0;\n        if (cond_29149) {\n            lifted_lambda_res_29150 = -1;\n        } else {\n            bool cond_29151;\n            int32_t lifted_lambda_res_f_res_29152;\n            \n            cond_29151 = sle32(eta_p_29146, eta_p_29143);\n            if (cond_29151) {\n                lifted_lambda_res_f_res_29152 = 0;\n            } else {\n                int32_t zlze_rhs_29153;\n                bool cond_29154;\n                int32_t lifted_lambda_res_f_res_f_res_29155;\n                \n                zlze_rhs_29153 = add32(eta_p_29143, eta_p_29144);\n                cond_29154 = sle32(eta_p_29146, zlze_rhs_29153);\n                if (cond_29154) {\n                    lifted_lambda_res_f_res_f_res_29155 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_29155 = 2;\n                }\n                lifted_lambda_res_f_res_29152 = lifted_lambda_res_f_res_f_res_29155;\n            }\n            lifted_lambda_res_29150 = lifted_lambda_res_f_res_29152;\n        }\n        cond_29156 = lifted_lambda_res_29150 == 1;\n        if (cond_29156) {\n            double eta_p_29148 = ((__global double *) mem_2",
                                    "9740)[gtid_29141];\n            \n            lifted_lambda_res_29157 = eta_p_29148;\n        } else {\n            double eta_p_29147 = ((__global double *) mem_param_29734)[gtid_29141];\n            \n            lifted_lambda_res_29157 = eta_p_29147;\n        }\n        cond_29158 = lifted_lambda_res_29150 == -1;\n        if (cond_29158) {\n            lifted_lambda_res_29159 = -1;\n        } else {\n            bool cond_29160;\n            int32_t lifted_lambda_res_f_res_29161;\n            \n            cond_29160 = lifted_lambda_res_29150 == 0;\n            if (cond_29160) {\n                lifted_lambda_res_f_res_29161 = eta_p_29146;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_29162;\n                \n                if (cond_29156) {\n                    lifted_lambda_res_f_res_f_res_29162 = -1;\n                } else {\n                    int32_t zm_lhs_29163;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_29164;\n                    \n                    zm_lhs_29163 = sub32(eta_p_29146, eta_p_29143);\n                    lifted_lambda_res_f_res_f_res_f_res_29164 = sub32(zm_lhs_29163, eta_p_29144);\n                    lifted_lambda_res_f_res_f_res_29162 = lifted_lambda_res_f_res_f_res_f_res_29164;\n                }\n                lifted_lambda_res_f_res_29161 = lifted_lambda_res_f_res_f_res_29162;\n            }\n            lifted_lambda_res_29159 = lifted_lambda_res_f_res_29161;\n        }\n        if (cond_29158) {\n            lifted_lambda_res_29165 = 0;\n        } else {\n            bool cond_29166;\n            int32_t lifted_lambda_res_f_res_29167;\n            \n            cond_29166 = lifted_lambda_res_29150 == 0;\n            if (cond_29166) {\n                lifted_lambda_res_f_res_29167 = eta_p_29143;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_29168;\n                \n                if (cond_29156) {\n                    lifted_lambda_res_f_res_f_res_29168 = 0;\n                } else {\n       ", "             int32_t zm_lhs_29169;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_29170;\n                    \n                    zm_lhs_29169 = sub32(eta_p_29145, eta_p_29143);\n                    lifted_lambda_res_f_res_f_res_f_res_29170 = sub32(zm_lhs_29169, eta_p_29144);\n                    lifted_lambda_res_f_res_f_res_29168 = lifted_lambda_res_f_res_f_res_f_res_29170;\n                }\n                lifted_lambda_res_f_res_29167 = lifted_lambda_res_f_res_f_res_29168;\n            }\n            lifted_lambda_res_29165 = lifted_lambda_res_f_res_29167;\n        }\n        ((__global int32_t *) mem_29748)[gtid_29141] = lifted_lambda_res_29165;\n        ((__global int32_t *) mem_29750)[gtid_29141] = lifted_lambda_res_29159;\n        ((__global double *) mem_29752)[gtid_29141] = lifted_lambda_res_29157;\n        ((__global int32_t *) mem_29754)[gtid_29141] = lifted_lambda_res_29150;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_29135\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegmap_29180_dim1, 1, 1)\nvoid human_genericf64zisegmap_29180(__global int *global_failure, int64_t loop_dz2081Uz2088Uz2087U_27125, int64_t m_27345, int64_t num_tblocks_29185, int32_t virt_num_tblocks_30977, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29757, __global unsigned char *mem_29759, __global unsigned char *mem_29761, __global unsigned char *mem_29763)\n{\n    #define segmap_tblock_sizze_29183 (human_genericf64zisegmap_29180zisegmap_tblock_sizze_29183)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30979;\n    int32_t tblock_sizze_30982;\n    int32_t wave_sizze_30981;\n    int32_t block_id_30980;\n    int32_t global_tid_30978;\n    int64_t phys_tid_29180;\n    int32_t phys_tblock_id_30983;\n    int32_t iterations_30984;\n    \n    local_tid_30979 = get_local_id(0);\n    tblock_sizze_30982 = get_local_size(0);\n    wave_sizze_30981 = LOCKSTEP_WIDTH;\n    block_id_30980 = get_tblock", "_id(0);\n    global_tid_30978 = block_id_30980 * tblock_sizze_30982 + local_tid_30979;\n    phys_tid_29180 = sext_i32_i64(global_tid_30978);\n    phys_tblock_id_30983 = get_tblock_id(0);\n    iterations_30984 = sdiv_up32(virt_num_tblocks_30977 - phys_tblock_id_30983, sext_i64_i32(num_tblocks_29185));\n    for (int32_t i_30985 = 0; i_30985 < iterations_30984; i_30985++) {\n        int32_t virt_tblock_id_30986;\n        int64_t global_tid_30987;\n        int64_t slice_30988;\n        int64_t write_i_29179;\n        int64_t remnant_30989;\n        \n        virt_tblock_id_30986 = phys_tblock_id_30983 + i_30985 * sext_i64_i32(num_tblocks_29185);\n        global_tid_30987 = sext_i32_i64(virt_tblock_id_30986) * segmap_tblock_sizze_29183 + sext_i32_i64(local_tid_30979);\n        slice_30988 = loop_dz2081Uz2088Uz2087U_27125;\n        write_i_29179 = global_tid_30987;\n        remnant_30989 = global_tid_30987 - write_i_29179;\n        if (slt64(write_i_29179, loop_dz2081Uz2088Uz2087U_27125)) {\n            int64_t eta_p_27740;\n            double write_value_27742;\n            int32_t write_value_27743;\n            bool cond_27744;\n            int64_t lifted_lambda_res_27745;\n            \n            eta_p_27740 = ((__global int64_t *) mem_29759)[write_i_29179];\n            write_value_27742 = ((__global double *) mem_param_29731)[write_i_29179];\n            write_value_27743 = ((__global int32_t *) mem_param_29728)[write_i_29179];\n            cond_27744 = eta_p_27740 == (int64_t) 1;\n            if (cond_27744) {\n                int64_t eta_p_27741;\n                int64_t lifted_lambda_res_t_res_28190;\n                \n                eta_p_27741 = ((__global int64_t *) mem_29757)[write_i_29179];\n                lifted_lambda_res_t_res_28190 = sub64(eta_p_27741, (int64_t) 1);\n                lifted_lambda_res_27745 = lifted_lambda_res_t_res_28190;\n            } else {\n                lifted_lambda_res_27745 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_277",
                                    "45) && slt64(lifted_lambda_res_27745, m_27345)) {\n                ((__global double *) mem_29763)[lifted_lambda_res_27745] = write_value_27742;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27745) && slt64(lifted_lambda_res_27745, m_27345)) {\n                ((__global int32_t *) mem_29761)[lifted_lambda_res_27745] = write_value_27743;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_29183\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegred_large_30337_dim1, 1, 1)\nvoid human_genericf64zisegred_large_30337(__global int *global_failure, int64_t mz2080U_21995, int64_t num_tblocks_28783, int64_t num_subhistos_30239, int64_t blocks_per_segment_30375, int64_t q_30376, int64_t num_virtblocks_30377, int64_t threads_per_segment_30378, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242, __global unsigned char *segred_tmp_mem_30379, __global unsigned char *segred_tmp_mem_30381, __global unsigned char *counters_mem_30383)\n{\n    #define seghist_tblock_sizze_28781 (human_genericf64zisegred_large_30337ziseghist_tblock_sizze_28781)\n    #define chunk_sizze_30338 (human_genericf64zisegred_large_30337zichunk_sizze_30338)\n    \n    volatile __local unsigned char *sync_arr_mem_30394_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_30394_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_30392_backing_1 = &shared_mem[sync_arr_mem_30394_backing_2_offset];\n    const int64_t red_arr_i32_mem_30392_backing_1_offset = sync_arr_mem_30394_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_28781 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28781, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30390_backing_0 = &shared_mem[red_arr_i32_mem_30392_backi", "ng_1_offset];\n    const int64_t red_arr_i32_mem_30390_backing_0_offset = red_arr_i32_mem_30392_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_28781 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28781, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30386;\n    int32_t tblock_sizze_30389;\n    int32_t wave_sizze_30388;\n    int32_t block_id_30387;\n    int32_t global_tid_30385;\n    int64_t flat_gtid_30337;\n    __local unsigned char *red_arr_i32_mem_30390;\n    __local unsigned char *red_arr_i32_mem_30392;\n    __local unsigned char *sync_arr_mem_30394;\n    int32_t phys_tblock_id_30396;\n    int32_t iterations_30397;\n    \n    local_tid_30386 = get_local_id(0);\n    tblock_sizze_30389 = get_local_size(0);\n    wave_sizze_30388 = LOCKSTEP_WIDTH;\n    block_id_30387 = get_tblock_id(0);\n    global_tid_30385 = block_id_30387 * tblock_sizze_30389 + local_tid_30386;\n    flat_gtid_30337 = sext_i32_i64(global_tid_30385);\n    red_arr_i32_mem_30390 = (__local unsigned char *) red_arr_i32_mem_30390_backing_0;\n    red_arr_i32_mem_30392 = (__local unsigned char *) red_arr_i32_mem_30392_backing_1;\n    sync_arr_mem_30394 = (__local unsigned char *) sync_arr_mem_30394_backing_2;\n    phys_tblock_id_30396 = get_tblock_id(0);\n    iterations_30397 = sdiv_up32(sext_i64_i32(num_virtblocks_30377) - phys_tblock_id_30396, sext_i64_i32(num_tblocks_28783));\n    for (int32_t i_30398 = 0; i_30398 < iterations_30397; i_30398++) {\n        int32_t virt_tblock_id_30399;\n        int64_t flat_segment_id_30400;\n        int64_t global_tid_30401;\n        int64_t slice_30402;\n        int64_t bucket_id_30335;\n        int64_t remnant_30403;\n        int64_t subhistogram_id_30336;\n        int32_t eta_p_block_res_acc_30404;\n        int32_t eta_p_block_res_acc_30405;\n        int32_t eta_p_28789;\n        int32_t eta_p_28790;\n        int32_t eta_p_28791;\n        int32_t eta_p_28792;\n        int64_t tblock_id_in_segment_30412;\n        int64_", "t block_base_offset_30413;\n        int32_t offset_30416;\n        int32_t skip_waves_30417;\n        int32_t eta_p_30406;\n        int32_t eta_p_30407;\n        int32_t eta_p_30408;\n        int32_t eta_p_30409;\n        \n        virt_tblock_id_30399 = phys_tblock_id_30396 + i_30398 * sext_i64_i32(num_tblocks_28783);\n        flat_segment_id_30400 = squot64(sext_i32_i64(virt_tblock_id_30399), blocks_per_segment_30375);\n        global_tid_30401 = srem64(sext_i32_i64(virt_tblock_id_30399) * seghist_tblock_sizze_28781 + sext_i32_i64(local_tid_30386), threads_per_segment_30378);\n        slice_30402 = mz2080U_21995;\n        bucket_id_30335 = flat_segment_id_30400;\n        remnant_30403 = flat_segment_id_30400 - bucket_id_30335;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_30404 = 0;\n            eta_p_block_res_acc_30405 = 0;\n        }\n        tblock_id_in_segment_30412 = squot64(global_tid_30401, seghist_tblock_sizze_28781);\n        block_base_offset_30413 = tblock_id_in_segment_30412 * q_30376 * seghist_tblock_sizze_28781;\n        for (int64_t i_30414 = 0; i_30414 < q_30376; i_30414++) {\n            int64_t block_offset_30415 = block_base_offset_30413 + i_30414 * seghist_tblock_sizze_28781;\n            \n            subhistogram_id_30336 = global_tid_30401 + threads_per_segment_30378 * i_30414;\n            if (slt64(subhistogram_id_30336, num_subhistos_30239)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_28789 = eta_p_block_res_acc_30404;\n                        eta_p_28790 = eta_p_block_res_acc_30405;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_28791 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[subhistogram_id_30336 * mz2080U_21995 + bucket_id_30335];\n                        eta_p_28792 = ((__global int32_t *) defunc_0_map",
                                    "_res_subhistos_mem_30242)[subhistogram_id_30336 * mz2080U_21995 + bucket_id_30335];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_28793 = add32(eta_p_28789, eta_p_28791);\n                        int32_t tmp_28794 = add32(eta_p_28790, eta_p_28792);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_30404 = tmp_28793;\n                            eta_p_block_res_acc_30405 = tmp_28794;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_block_res_acc_30404;\n            ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_block_res_acc_30405;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_30417 = 1;\n        offset_30416 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_30386, sext_i64_i32(seghist_tblock_sizze_28781))) {\n                eta_p_30406 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                eta_p_30407 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n            }\n        }\n        offset_30416 = 1;\n        while (slt32(offset_30416, wave_sizze_30388)) {\n            if (slt32(local_tid_30386 + offset_30416, sext_i64_i32(seghist_tblock_sizze_28781)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) & (2 * offset_30416 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_30408 = ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_ti", "d_30386 + offset_30416)];\n                    eta_p_30409 = ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                    int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                    \n                    eta_p_30406 = tmp_30410;\n                    eta_p_30407 = tmp_30411;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                    ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                }\n            }\n            offset_30416 *= 2;\n        }\n        while (slt32(skip_waves_30417, squot32(sext_i64_i32(seghist_tblock_sizze_28781) + wave_sizze_30388 - 1, wave_sizze_30388))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_30416 = skip_waves_30417 * wave_sizze_30388;\n            if (slt32(local_tid_30386 + offset_30416, sext_i64_i32(seghist_tblock_sizze_28781)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) == 0 && (squot32(local_tid_30386, wave_sizze_30388) & (2 * skip_waves_30417 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_30408 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                    eta_p_30409 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                    int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                    \n                    eta_p_30406 = tmp_30410", ";\n                    eta_p_30407 = tmp_30411;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                    ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                }\n            }\n            skip_waves_30417 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_30386) == (int64_t) 0) {\n                eta_p_block_res_acc_30404 = eta_p_30406;\n                eta_p_block_res_acc_30405 = eta_p_30407;\n            } else {\n                eta_p_block_res_acc_30404 = 0;\n                eta_p_block_res_acc_30405 = 0;\n            }\n        }\n        if (blocks_per_segment_30375 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_30386 == 0) {\n                    ((__global int32_t *) mem_29699)[bucket_id_30335] = eta_p_block_res_acc_30404;\n                    ((__global int32_t *) mem_29697)[bucket_id_30335] = eta_p_block_res_acc_30405;\n                }\n            }\n        } else {\n            int32_t old_counter_30418;\n            bool is_last_block_30419;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_30386 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_30379)[sext_i32_i64(virt_tblock_id_30399)] = eta_p_block_res_acc_30404;\n                    mem_fence_global();\n                    ((__global int32_t *) segred_tmp_mem_30381)[sext_i32_i64(virt_tblock_id_30399)] = eta_p_block_res_acc_30405;\n                    mem_fence_global();\n                    old_counter_30418 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30383)[srem64(flat_se",
                                    "gment_id_30400, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_30394)[(int64_t) 0] = old_counter_30418 == sext_i64_i32(blocks_per_segment_30375 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_30419 = ((__local bool *) sync_arr_mem_30394)[(int64_t) 0];\n            if (is_last_block_30419) {\n                if (local_tid_30386 == 0) {\n                    old_counter_30418 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30383)[srem64(flat_segment_id_30400, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_30375));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_30420 = sdiv_up64(blocks_per_segment_30375, seghist_tblock_sizze_28781);\n                    \n                    eta_p_28789 = 0;\n                    eta_p_28790 = 0;\n                    for (int64_t i_30421 = 0; i_30421 < read_per_thread_30420; i_30421++) {\n                        int64_t block_res_id_30422 = sext_i32_i64(local_tid_30386) * read_per_thread_30420 + i_30421;\n                        int64_t index_of_block_res_30423 = flat_segment_id_30400 * blocks_per_segment_30375 + block_res_id_30422;\n                        \n                        if (slt64(block_res_id_30422, blocks_per_segment_30375)) {\n                            eta_p_28791 = ((__global int32_t *) segred_tmp_mem_30379)[index_of_block_res_30423];\n                            eta_p_28792 = ((__global int32_t *) segred_tmp_mem_30381)[index_of_block_res_30423];\n                            \n                            int32_t tmp_28793 = add32(eta_p_28789, eta_p_28791);\n                            int32_t tmp_28794 = add32(eta_p_28790, eta_p_28792);\n                            \n                            eta_p_28789 = tmp_28793;\n                            eta_p_28790 = tmp_28794;\n                        ", "}\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_28789;\n                ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_28790;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_30424;\n                    int32_t skip_waves_30425 = 1;\n                    int32_t eta_p_30406;\n                    int32_t eta_p_30407;\n                    int32_t eta_p_30408;\n                    int32_t eta_p_30409;\n                    \n                    offset_30424 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_30386, sext_i64_i32(seghist_tblock_sizze_28781))) {\n                            eta_p_30406 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            eta_p_30407 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                        }\n                    }\n                    offset_30424 = 1;\n                    while (slt32(offset_30424, wave_sizze_30388)) {\n                        if (slt32(local_tid_30386 + offset_30424, sext_i64_i32(seghist_tblock_sizze_28781)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) & (2 * offset_30424 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_30408 = ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                                eta_p_30409 = ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            }\n                            // apply reduction operation\n                        ", "    {\n                                int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                                int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                                \n                                eta_p_30406 = tmp_30410;\n                                eta_p_30407 = tmp_30411;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                            }\n                        }\n                        offset_30424 *= 2;\n                    }\n                    while (slt32(skip_waves_30425, squot32(sext_i64_i32(seghist_tblock_sizze_28781) + wave_sizze_30388 - 1, wave_sizze_30388))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_30424 = skip_waves_30425 * wave_sizze_30388;\n                        if (slt32(local_tid_30386 + offset_30424, sext_i64_i32(seghist_tblock_sizze_28781)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) == 0 && (squot32(local_tid_30386, wave_sizze_30388) & (2 * skip_waves_30425 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_30408 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                                eta_p_30409 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                                int32_t tmp_30411 = add32(et",
                                    "a_p_30407, eta_p_30409);\n                                \n                                eta_p_30406 = tmp_30410;\n                                eta_p_30407 = tmp_30411;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                                ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                            }\n                        }\n                        skip_waves_30425 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_30386 == 0) {\n                            ((__global int32_t *) mem_29699)[bucket_id_30335] = eta_p_30406;\n                            ((__global int32_t *) mem_29697)[bucket_id_30335] = eta_p_30407;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_28781\n    #undef chunk_sizze_30338\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegred_large_30775_dim1, 1, 1)\nvoid human_genericf64zisegred_large_30775(__global int *global_failure, int64_t mz2080U_21995, int64_t num_tblocks_29074, int64_t num_subhistos_30677, int64_t blocks_per_segment_30813, int64_t q_30814, int64_t num_virtblocks_30815, int64_t threads_per_segment_30816, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680, __global unsigned char *segred_tmp_mem_30817, __global unsigned char *segred_tmp_mem_30819, __global unsigned char *counters_mem_30821)\n{\n    #define seghist_tblock_sizze_29072 (human", "_genericf64zisegred_large_30775ziseghist_tblock_sizze_29072)\n    #define chunk_sizze_30776 (human_genericf64zisegred_large_30775zichunk_sizze_30776)\n    \n    volatile __local unsigned char *sync_arr_mem_30832_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_30832_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_30830_backing_1 = &shared_mem[sync_arr_mem_30832_backing_2_offset];\n    const int64_t red_arr_i32_mem_30830_backing_1_offset = sync_arr_mem_30832_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_29072 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29072, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30828_backing_0 = &shared_mem[red_arr_i32_mem_30830_backing_1_offset];\n    const int64_t red_arr_i32_mem_30828_backing_0_offset = red_arr_i32_mem_30830_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_29072 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29072, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30824;\n    int32_t tblock_sizze_30827;\n    int32_t wave_sizze_30826;\n    int32_t block_id_30825;\n    int32_t global_tid_30823;\n    int64_t flat_gtid_30775;\n    __local unsigned char *red_arr_i32_mem_30828;\n    __local unsigned char *red_arr_i32_mem_30830;\n    __local unsigned char *sync_arr_mem_30832;\n    int32_t phys_tblock_id_30834;\n    int32_t iterations_30835;\n    \n    local_tid_30824 = get_local_id(0);\n    tblock_sizze_30827 = get_local_size(0);\n    wave_sizze_30826 = LOCKSTEP_WIDTH;\n    block_id_30825 = get_tblock_id(0);\n    global_tid_30823 = block_id_30825 * tblock_sizze_30827 + local_tid_30824;\n    flat_gtid_30775 = sext_i32_i64(global_tid_30823);\n    red_arr_i32_mem_30828 = (__local unsigned char *) red_arr_i32_mem_30828_backing_0;\n    red_arr_i32_mem_30830 = (__local unsigned char *) red_arr_i32_mem_30830_backing_1;\n    sync_arr_mem_30832 = (__local unsigned char *) sync_a", "rr_mem_30832_backing_2;\n    phys_tblock_id_30834 = get_tblock_id(0);\n    iterations_30835 = sdiv_up32(sext_i64_i32(num_virtblocks_30815) - phys_tblock_id_30834, sext_i64_i32(num_tblocks_29074));\n    for (int32_t i_30836 = 0; i_30836 < iterations_30835; i_30836++) {\n        int32_t virt_tblock_id_30837;\n        int64_t flat_segment_id_30838;\n        int64_t global_tid_30839;\n        int64_t slice_30840;\n        int64_t bucket_id_30773;\n        int64_t remnant_30841;\n        int64_t subhistogram_id_30774;\n        int32_t eta_p_block_res_acc_30842;\n        int32_t eta_p_block_res_acc_30843;\n        int32_t eta_p_29080;\n        int32_t eta_p_29081;\n        int32_t eta_p_29082;\n        int32_t eta_p_29083;\n        int64_t tblock_id_in_segment_30850;\n        int64_t block_base_offset_30851;\n        int32_t offset_30854;\n        int32_t skip_waves_30855;\n        int32_t eta_p_30844;\n        int32_t eta_p_30845;\n        int32_t eta_p_30846;\n        int32_t eta_p_30847;\n        \n        virt_tblock_id_30837 = phys_tblock_id_30834 + i_30836 * sext_i64_i32(num_tblocks_29074);\n        flat_segment_id_30838 = squot64(sext_i32_i64(virt_tblock_id_30837), blocks_per_segment_30813);\n        global_tid_30839 = srem64(sext_i32_i64(virt_tblock_id_30837) * seghist_tblock_sizze_29072 + sext_i32_i64(local_tid_30824), threads_per_segment_30816);\n        slice_30840 = mz2080U_21995;\n        bucket_id_30773 = flat_segment_id_30838;\n        remnant_30841 = flat_segment_id_30838 - bucket_id_30773;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_30842 = 0;\n            eta_p_block_res_acc_30843 = 0;\n        }\n        tblock_id_in_segment_30850 = squot64(global_tid_30839, seghist_tblock_sizze_29072);\n        block_base_offset_30851 = tblock_id_in_segment_30850 * q_30814 * seghist_tblock_sizze_29072;\n        for (int64_t i_30852 = 0; i_30852 < q_30814; i_30852++) {\n            int64_t block_offset_30853 = block_base_offset_30851 + i_30852 * s",
                                    "eghist_tblock_sizze_29072;\n            \n            subhistogram_id_30774 = global_tid_30839 + threads_per_segment_30816 * i_30852;\n            if (slt64(subhistogram_id_30774, num_subhistos_30677)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_29080 = eta_p_block_res_acc_30842;\n                        eta_p_29081 = eta_p_block_res_acc_30843;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_29082 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[subhistogram_id_30774 * mz2080U_21995 + bucket_id_30773];\n                        eta_p_29083 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[subhistogram_id_30774 * mz2080U_21995 + bucket_id_30773];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_29084 = add32(eta_p_29080, eta_p_29082);\n                        int32_t tmp_29085 = add32(eta_p_29081, eta_p_29083);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_30842 = tmp_29084;\n                            eta_p_block_res_acc_30843 = tmp_29085;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_block_res_acc_30842;\n            ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_block_res_acc_30843;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_30855 = 1;\n        offset_30854 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_30824, sext", "_i64_i32(seghist_tblock_sizze_29072))) {\n                eta_p_30844 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                eta_p_30845 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n            }\n        }\n        offset_30854 = 1;\n        while (slt32(offset_30854, wave_sizze_30826)) {\n            if (slt32(local_tid_30824 + offset_30854, sext_i64_i32(seghist_tblock_sizze_29072)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) & (2 * offset_30854 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_30846 = ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                    eta_p_30847 = ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                    int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                    \n                    eta_p_30844 = tmp_30848;\n                    eta_p_30845 = tmp_30849;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                    ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                }\n            }\n            offset_30854 *= 2;\n        }\n        while (slt32(skip_waves_30855, squot32(sext_i64_i32(seghist_tblock_sizze_29072) + wave_sizze_30826 - 1, wave_sizze_30826))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_30854 = skip_waves_30855 * wave_sizze_30826;\n            if (slt32(local_tid_30824 + offset_30854, sext_i64_i32(seghist_tblock_sizze_29072)) && ((", "local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) == 0 && (squot32(local_tid_30824, wave_sizze_30826) & (2 * skip_waves_30855 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_30846 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                    eta_p_30847 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                    int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                    \n                    eta_p_30844 = tmp_30848;\n                    eta_p_30845 = tmp_30849;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                    ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                }\n            }\n            skip_waves_30855 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_30824) == (int64_t) 0) {\n                eta_p_block_res_acc_30842 = eta_p_30844;\n                eta_p_block_res_acc_30843 = eta_p_30845;\n            } else {\n                eta_p_block_res_acc_30842 = 0;\n                eta_p_block_res_acc_30843 = 0;\n            }\n        }\n        if (blocks_per_segment_30813 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_30824 == 0) {\n                    ((__global int32_t *) mem_29744)[bucket_id_30773] = eta_p_block_res_acc_30842;\n                    ((__global int32_t *) mem_29742)[bucket_id",
                                    "_30773] = eta_p_block_res_acc_30843;\n                }\n            }\n        } else {\n            int32_t old_counter_30856;\n            bool is_last_block_30857;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_30824 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_30817)[sext_i32_i64(virt_tblock_id_30837)] = eta_p_block_res_acc_30842;\n                    mem_fence_global();\n                    ((__global int32_t *) segred_tmp_mem_30819)[sext_i32_i64(virt_tblock_id_30837)] = eta_p_block_res_acc_30843;\n                    mem_fence_global();\n                    old_counter_30856 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30821)[srem64(flat_segment_id_30838, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_30832)[(int64_t) 0] = old_counter_30856 == sext_i64_i32(blocks_per_segment_30813 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_30857 = ((__local bool *) sync_arr_mem_30832)[(int64_t) 0];\n            if (is_last_block_30857) {\n                if (local_tid_30824 == 0) {\n                    old_counter_30856 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30821)[srem64(flat_segment_id_30838, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_30813));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_30858 = sdiv_up64(blocks_per_segment_30813, seghist_tblock_sizze_29072);\n                    \n                    eta_p_29080 = 0;\n                    eta_p_29081 = 0;\n                    for (int64_t i_30859 = 0; i_30859 < read_per_thread_30858; i_30859++) {\n                        int64_t block_res_id_30860 = sext_i32_i64(local_tid_30824) * read_per_thread_30858 + i_30859;\n                        int64_t index_of_bloc", "k_res_30861 = flat_segment_id_30838 * blocks_per_segment_30813 + block_res_id_30860;\n                        \n                        if (slt64(block_res_id_30860, blocks_per_segment_30813)) {\n                            eta_p_29082 = ((__global int32_t *) segred_tmp_mem_30817)[index_of_block_res_30861];\n                            eta_p_29083 = ((__global int32_t *) segred_tmp_mem_30819)[index_of_block_res_30861];\n                            \n                            int32_t tmp_29084 = add32(eta_p_29080, eta_p_29082);\n                            int32_t tmp_29085 = add32(eta_p_29081, eta_p_29083);\n                            \n                            eta_p_29080 = tmp_29084;\n                            eta_p_29081 = tmp_29085;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_29080;\n                ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_29081;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_30862;\n                    int32_t skip_waves_30863 = 1;\n                    int32_t eta_p_30844;\n                    int32_t eta_p_30845;\n                    int32_t eta_p_30846;\n                    int32_t eta_p_30847;\n                    \n                    offset_30862 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_30824, sext_i64_i32(seghist_tblock_sizze_29072))) {\n                            eta_p_30844 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                            eta_p_30845 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                        }\n                    }\n                    offset_30862 = 1;\n          ", "          while (slt32(offset_30862, wave_sizze_30826)) {\n                        if (slt32(local_tid_30824 + offset_30862, sext_i64_i32(seghist_tblock_sizze_29072)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) & (2 * offset_30862 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_30846 = ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                                eta_p_30847 = ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                                int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                                \n                                eta_p_30844 = tmp_30848;\n                                eta_p_30845 = tmp_30849;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                            }\n                        }\n                        offset_30862 *= 2;\n                    }\n                    while (slt32(skip_waves_30863, squot32(sext_i64_i32(seghist_tblock_sizze_29072) + wave_sizze_30826 - 1, wave_sizze_30826))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_30862 = skip_waves_30863 * wave_sizze_30826;\n                        if (slt32(local_tid_30824 + offset_30862, sext_i64_i32(seghist_tblock_sizze_29072)) && ((local_tid_30824 - s",
                                    "quot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) == 0 && (squot32(local_tid_30824, wave_sizze_30826) & (2 * skip_waves_30863 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_30846 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                                eta_p_30847 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                                int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                                \n                                eta_p_30844 = tmp_30848;\n                                eta_p_30845 = tmp_30849;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                                ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                            }\n                        }\n                        skip_waves_30863 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_30824 == 0) {\n                            ((__global int32_t *) mem_29744)[bucket_id_30773] = eta_p_30844;\n                            ((__global int32_t *) mem_29742)[bucket_id_30773] = eta_p_30845;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seg", "hist_tblock_sizze_29072\n    #undef chunk_sizze_30776\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegred_small_30337_dim1, 1, 1)\nvoid human_genericf64zisegred_small_30337(__global int *global_failure, int64_t mz2080U_21995, int64_t num_tblocks_28783, int64_t num_subhistos_30239, int64_t segment_sizze_nonzzero_30339, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242)\n{\n    #define seghist_tblock_sizze_28781 (human_genericf64zisegred_small_30337ziseghist_tblock_sizze_28781)\n    \n    volatile __local unsigned char *red_arr_i32_mem_30348_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_30348_backing_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_28781 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28781, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30346_backing_0 = &shared_mem[red_arr_i32_mem_30348_backing_1_offset];\n    const int64_t red_arr_i32_mem_30346_backing_0_offset = red_arr_i32_mem_30348_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_28781 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28781, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30342;\n    int32_t tblock_sizze_30345;\n    int32_t wave_sizze_30344;\n    int32_t block_id_30343;\n    int32_t global_tid_30341;\n    int64_t flat_gtid_30337;\n    __local unsigned char *red_arr_i32_mem_30346;\n    __local unsigned char *red_arr_i32_mem_30348;\n    int32_t phys_tblock_id_30350;\n    int32_t iterations_30351;\n    \n    local_tid_30342 = get_local_id(0);\n    tblock_sizze_30345 = get_local_size(0);\n    wave_sizze_30344 = LOCKSTEP_WIDTH;\n    block_id_30343 = get_tblock_id(0);\n    global_tid_30341 = block_id_30343 * tblock_sizze_30345 + local_tid_30342;\n    flat_gtid_30337 = sext_i32_i64(global_tid_30341);\n    red_arr_i32_mem_30346", " = (__local unsigned char *) red_arr_i32_mem_30346_backing_0;\n    red_arr_i32_mem_30348 = (__local unsigned char *) red_arr_i32_mem_30348_backing_1;\n    phys_tblock_id_30350 = get_tblock_id(0);\n    iterations_30351 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_21995, squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339))) - phys_tblock_id_30350, sext_i64_i32(num_tblocks_28783));\n    for (int32_t i_30352 = 0; i_30352 < iterations_30351; i_30352++) {\n        int32_t virt_tblock_id_30353;\n        int64_t slice_30354;\n        int64_t bucket_id_30335;\n        int64_t remnant_30355;\n        int64_t subhistogram_id_30336;\n        \n        virt_tblock_id_30353 = phys_tblock_id_30350 + i_30352 * sext_i64_i32(num_tblocks_28783);\n        slice_30354 = mz2080U_21995;\n        bucket_id_30335 = squot64(sext_i32_i64(local_tid_30342), segment_sizze_nonzzero_30339) + sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339);\n        remnant_30355 = squot64(sext_i32_i64(local_tid_30342), segment_sizze_nonzzero_30339) + sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339) - bucket_id_30335;\n        subhistogram_id_30336 = srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_30239) && (slt64(bucket_id_30335, mz2080U_21995) && slt64(sext_i32_i64(local_tid_30342), num_subhistos_30239 * squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_30356 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[subhistogram_id_30336 * mz2080U_21995 + bucket_id_30335];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = tmp_30356;\n                    \n                    int32_t tmp_30357 = ((__global int32_t ",
                                    "*) defunc_0_map_res_subhistos_mem_30242)[subhistogram_id_30336 * mz2080U_21995 + bucket_id_30335];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = tmp_30357;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_30239)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_28789;\n                int32_t eta_p_28790;\n                int32_t eta_p_28791;\n                int32_t eta_p_28792;\n                int32_t eta_p_30358;\n                int32_t eta_p_30359;\n                int32_t eta_p_30360;\n                int32_t eta_p_30361;\n                bool ltid_in_bounds_30364 = slt64(sext_i32_i64(local_tid_30342), num_subhistos_30239 * squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339));\n                int32_t skip_threads_30365;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_30364) {\n                        eta_p_28791 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)];\n                        eta_p_28792 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)];\n                        if ((local_tid_30342 - squot32(local_tid_30342, 32) * 32) == 0) {\n                            eta_p_28789 = eta_p_28791;\n                            eta_p_28790 = eta_p_28792;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30365 = 1;\n                    while (slt32(skip_threads_30365, 32)) {\n           ", "             bool thread_active_30366 = sle32(skip_threads_30365, local_tid_30342 - squot32(local_tid_30342, 32) * 32) && ltid_in_bounds_30364;\n                        \n                        if (thread_active_30366) {\n                            // read operands\n                            {\n                                eta_p_28789 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30365)];\n                                eta_p_28790 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30365)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_30367 = slt64(srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239), sext_i32_i64(local_tid_30342) - sext_i32_i64(local_tid_30342 - skip_threads_30365));\n                            \n                            if (thread_active_30366 && inactive_30367) {\n                                eta_p_28789 = eta_p_28791;\n                                eta_p_28790 = eta_p_28792;\n                            }\n                            if (thread_active_30366) {\n                                if (!inactive_30367) {\n                                    int32_t tmp_28793 = add32(eta_p_28789, eta_p_28791);\n                                    int32_t tmp_28794 = add32(eta_p_28790, eta_p_28792);\n                                    \n                                    eta_p_28789 = tmp_28793;\n                                    eta_p_28790 = tmp_28794;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_30344, skip_threads_30365)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30366) {\n                            // write result\n    ", "                        {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_28789;\n                                eta_p_28791 = eta_p_28789;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_28790;\n                                eta_p_28792 = eta_p_28790;\n                            }\n                        }\n                        if (sle32(wave_sizze_30344, skip_threads_30365)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30365 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_30342 - squot32(local_tid_30342, 32) * 32) == 31 && ltid_in_bounds_30364) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(squot32(local_tid_30342, 32))] = eta_p_28789;\n                        ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(squot32(local_tid_30342, 32))] = eta_p_28790;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_30368;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364) {\n                            eta_p_30360 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)];\n                            eta_p_30361 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)];\n                            if ((local_tid_30342 - squot32(local_tid_30342, 32)",
                                    " * 32) == 0) {\n                                eta_p_30358 = eta_p_30360;\n                                eta_p_30359 = eta_p_30361;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_30368 = 1;\n                        while (slt32(skip_threads_30368, 32)) {\n                            bool thread_active_30369 = sle32(skip_threads_30368, local_tid_30342 - squot32(local_tid_30342, 32) * 32) && (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364);\n                            \n                            if (thread_active_30369) {\n                                // read operands\n                                {\n                                    eta_p_30358 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30368)];\n                                    eta_p_30359 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30368)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_30370 = slt64(srem64(sext_i32_i64(local_tid_30342 * 32 + 32 - 1), num_subhistos_30239), sext_i32_i64(local_tid_30342 * 32 + 32 - 1) - sext_i32_i64((local_tid_30342 - skip_threads_30368) * 32 + 32 - 1));\n                                \n                                if (thread_active_30369 && inactive_30370) {\n                                    eta_p_30358 = eta_p_30360;\n                                    eta_p_30359 = eta_p_30361;\n                                }\n                                if (thread_active_30369) {\n                                    if (!inactive_30370) {\n                                        int32_t tmp_30362 = add32(eta_p_30358, eta_p_30360);\n         ", "                               int32_t tmp_30363 = add32(eta_p_30359, eta_p_30361);\n                                        \n                                        eta_p_30358 = tmp_30362;\n                                        eta_p_30359 = tmp_30363;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_30344, skip_threads_30368)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_30369) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_30358;\n                                    eta_p_30360 = eta_p_30358;\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_30359;\n                                    eta_p_30361 = eta_p_30359;\n                                }\n                            }\n                            if (sle32(wave_sizze_30344, skip_threads_30368)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_30368 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_30371 = squot32(local_tid_30342, 32) == 0 || !ltid_in_bounds_30364;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_30371) {\n                            eta_p_28791 = eta_p_28789;\n                            eta_p_28792 = eta_p_28790;\n                            eta_p_28789 = ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(squot32", "(local_tid_30342, 32)) - (int64_t) 1];\n                            eta_p_28790 = ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(squot32(local_tid_30342, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_30372 = slt64(srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239), sext_i32_i64(local_tid_30342) - sext_i32_i64(squot32(local_tid_30342, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_30371) {\n                            if (inactive_30372) {\n                                eta_p_28789 = eta_p_28791;\n                                eta_p_28790 = eta_p_28792;\n                            }\n                        }\n                        if (!no_carry_in_30371) {\n                            if (!inactive_30372) {\n                                int32_t tmp_28793 = add32(eta_p_28789, eta_p_28791);\n                                int32_t tmp_28794 = add32(eta_p_28790, eta_p_28792);\n                                \n                                eta_p_28789 = tmp_28793;\n                                eta_p_28790 = tmp_28794;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_30371) {\n                            ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_28789;\n                            ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_28790;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364) {\n                        ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_ti",
                                    "d_30342)] = eta_p_28791;\n                        ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_28792;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid_30342), mz2080U_21995) && slt64(sext_i32_i64(local_tid_30342), squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339))) {\n                int32_t tmp_30373 = ((__local int32_t *) red_arr_i32_mem_30346)[(sext_i32_i64(local_tid_30342) + (int64_t) 1) * segment_sizze_nonzzero_30339 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29699)[sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid_30342)] = tmp_30373;\n                \n                int32_t tmp_30374 = ((__local int32_t *) red_arr_i32_mem_30348)[(sext_i32_i64(local_tid_30342) + (int64_t) 1) * segment_sizze_nonzzero_30339 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29697)[sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid_30342)] = tmp_30374;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_28781\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegred_small_30775_dim1, 1, 1)\nvoid human_genericf64zisegred_small_30775(__global int *global_failure, int64_t mz2080U_21995, int64_t num_tblocks_29074, int64_t num_subhistos_30677, int64_t segment_sizze_nonzzero_30777, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *defunc_0_map_res_subhistos_mem_30678", ", __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define seghist_tblock_sizze_29072 (human_genericf64zisegred_small_30775ziseghist_tblock_sizze_29072)\n    \n    volatile __local unsigned char *red_arr_i32_mem_30786_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_30786_backing_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_29072 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29072, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30784_backing_0 = &shared_mem[red_arr_i32_mem_30786_backing_1_offset];\n    const int64_t red_arr_i32_mem_30784_backing_0_offset = red_arr_i32_mem_30786_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_29072 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29072, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30780;\n    int32_t tblock_sizze_30783;\n    int32_t wave_sizze_30782;\n    int32_t block_id_30781;\n    int32_t global_tid_30779;\n    int64_t flat_gtid_30775;\n    __local unsigned char *red_arr_i32_mem_30784;\n    __local unsigned char *red_arr_i32_mem_30786;\n    int32_t phys_tblock_id_30788;\n    int32_t iterations_30789;\n    \n    local_tid_30780 = get_local_id(0);\n    tblock_sizze_30783 = get_local_size(0);\n    wave_sizze_30782 = LOCKSTEP_WIDTH;\n    block_id_30781 = get_tblock_id(0);\n    global_tid_30779 = block_id_30781 * tblock_sizze_30783 + local_tid_30780;\n    flat_gtid_30775 = sext_i32_i64(global_tid_30779);\n    red_arr_i32_mem_30784 = (__local unsigned char *) red_arr_i32_mem_30784_backing_0;\n    red_arr_i32_mem_30786 = (__local unsigned char *) red_arr_i32_mem_30786_backing_1;\n    phys_tblock_id_30788 = get_tblock_id(0);\n    iterations_30789 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_21995, squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777))) - phys_tblock_id_30788, sext_i64_i32(num_tblocks_29074));\n    for (int32_t i_30790 = 0; i_30790 < iterations_30", "789; i_30790++) {\n        int32_t virt_tblock_id_30791;\n        int64_t slice_30792;\n        int64_t bucket_id_30773;\n        int64_t remnant_30793;\n        int64_t subhistogram_id_30774;\n        \n        virt_tblock_id_30791 = phys_tblock_id_30788 + i_30790 * sext_i64_i32(num_tblocks_29074);\n        slice_30792 = mz2080U_21995;\n        bucket_id_30773 = squot64(sext_i32_i64(local_tid_30780), segment_sizze_nonzzero_30777) + sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777);\n        remnant_30793 = squot64(sext_i32_i64(local_tid_30780), segment_sizze_nonzzero_30777) + sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777) - bucket_id_30773;\n        subhistogram_id_30774 = srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_30677) && (slt64(bucket_id_30773, mz2080U_21995) && slt64(sext_i32_i64(local_tid_30780), num_subhistos_30677 * squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_30794 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[subhistogram_id_30774 * mz2080U_21995 + bucket_id_30773];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = tmp_30794;\n                    \n                    int32_t tmp_30795 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[subhistogram_id_30774 * mz2080U_21995 + bucket_id_30773];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = tmp_30795;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_ti",
                                    "d_30780)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_30677)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_29080;\n                int32_t eta_p_29081;\n                int32_t eta_p_29082;\n                int32_t eta_p_29083;\n                int32_t eta_p_30796;\n                int32_t eta_p_30797;\n                int32_t eta_p_30798;\n                int32_t eta_p_30799;\n                bool ltid_in_bounds_30802 = slt64(sext_i32_i64(local_tid_30780), num_subhistos_30677 * squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777));\n                int32_t skip_threads_30803;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_30802) {\n                        eta_p_29082 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)];\n                        eta_p_29083 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)];\n                        if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == 0) {\n                            eta_p_29080 = eta_p_29082;\n                            eta_p_29081 = eta_p_29083;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30803 = 1;\n                    while (slt32(skip_threads_30803, 32)) {\n                        bool thread_active_30804 = sle32(skip_threads_30803, local_tid_30780 - squot32(local_tid_30780, 32) * 32) && ltid_in_bounds_30802;\n                        \n                        if (thread_active_30804) {\n                            // read operands\n                            {\n                                eta_p_29080 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_", "threads_30803)];\n                                eta_p_29081 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30803)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_30805 = slt64(srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677), sext_i32_i64(local_tid_30780) - sext_i32_i64(local_tid_30780 - skip_threads_30803));\n                            \n                            if (thread_active_30804 && inactive_30805) {\n                                eta_p_29080 = eta_p_29082;\n                                eta_p_29081 = eta_p_29083;\n                            }\n                            if (thread_active_30804) {\n                                if (!inactive_30805) {\n                                    int32_t tmp_29084 = add32(eta_p_29080, eta_p_29082);\n                                    int32_t tmp_29085 = add32(eta_p_29081, eta_p_29083);\n                                    \n                                    eta_p_29080 = tmp_29084;\n                                    eta_p_29081 = tmp_29085;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_30782, skip_threads_30803)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30804) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_29080;\n                                eta_p_29082 = eta_p_29080;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_29081;\n                                eta_p_29083 = eta_p_29081;\n                            }\n        ", "                }\n                        if (sle32(wave_sizze_30782, skip_threads_30803)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30803 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == 31 && ltid_in_bounds_30802) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(squot32(local_tid_30780, 32))] = eta_p_29080;\n                        ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(squot32(local_tid_30780, 32))] = eta_p_29081;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_30806;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802) {\n                            eta_p_30798 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)];\n                            eta_p_30799 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)];\n                            if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == 0) {\n                                eta_p_30796 = eta_p_30798;\n                                eta_p_30797 = eta_p_30799;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_30806 = 1;\n                        while (slt32(skip_threads_30806, 32)) {\n                            boo",
                                    "l thread_active_30807 = sle32(skip_threads_30806, local_tid_30780 - squot32(local_tid_30780, 32) * 32) && (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802);\n                            \n                            if (thread_active_30807) {\n                                // read operands\n                                {\n                                    eta_p_30796 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30806)];\n                                    eta_p_30797 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30806)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_30808 = slt64(srem64(sext_i32_i64(local_tid_30780 * 32 + 32 - 1), num_subhistos_30677), sext_i32_i64(local_tid_30780 * 32 + 32 - 1) - sext_i32_i64((local_tid_30780 - skip_threads_30806) * 32 + 32 - 1));\n                                \n                                if (thread_active_30807 && inactive_30808) {\n                                    eta_p_30796 = eta_p_30798;\n                                    eta_p_30797 = eta_p_30799;\n                                }\n                                if (thread_active_30807) {\n                                    if (!inactive_30808) {\n                                        int32_t tmp_30800 = add32(eta_p_30796, eta_p_30798);\n                                        int32_t tmp_30801 = add32(eta_p_30797, eta_p_30799);\n                                        \n                                        eta_p_30796 = tmp_30800;\n                                        eta_p_30797 = tmp_30801;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_30782, skip_threads_30806)) {\n        ", "                        barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_30807) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_30796;\n                                    eta_p_30798 = eta_p_30796;\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_30797;\n                                    eta_p_30799 = eta_p_30797;\n                                }\n                            }\n                            if (sle32(wave_sizze_30782, skip_threads_30806)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_30806 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_30809 = squot32(local_tid_30780, 32) == 0 || !ltid_in_bounds_30802;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_30809) {\n                            eta_p_29082 = eta_p_29080;\n                            eta_p_29083 = eta_p_29081;\n                            eta_p_29080 = ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(squot32(local_tid_30780, 32)) - (int64_t) 1];\n                            eta_p_29081 = ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(squot32(local_tid_30780, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_30810 = slt64(srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677), sext_i32_i64(local_tid_30780) - sext_", "i32_i64(squot32(local_tid_30780, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_30809) {\n                            if (inactive_30810) {\n                                eta_p_29080 = eta_p_29082;\n                                eta_p_29081 = eta_p_29083;\n                            }\n                        }\n                        if (!no_carry_in_30809) {\n                            if (!inactive_30810) {\n                                int32_t tmp_29084 = add32(eta_p_29080, eta_p_29082);\n                                int32_t tmp_29085 = add32(eta_p_29081, eta_p_29083);\n                                \n                                eta_p_29080 = tmp_29084;\n                                eta_p_29081 = tmp_29085;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_30809) {\n                            ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_29080;\n                            ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_29081;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802) {\n                        ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_29082;\n                        ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_29083;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29072, segment_siz",
                                    "ze_nonzzero_30777) + sext_i32_i64(local_tid_30780), mz2080U_21995) && slt64(sext_i32_i64(local_tid_30780), squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777))) {\n                int32_t tmp_30811 = ((__local int32_t *) red_arr_i32_mem_30784)[(sext_i32_i64(local_tid_30780) + (int64_t) 1) * segment_sizze_nonzzero_30777 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29744)[sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777) + sext_i32_i64(local_tid_30780)] = tmp_30811;\n                \n                int32_t tmp_30812 = ((__local int32_t *) red_arr_i32_mem_30786)[(sext_i32_i64(local_tid_30780) + (int64_t) 1) * segment_sizze_nonzzero_30777 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29742)[sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777) + sext_i32_i64(local_tid_30780)] = tmp_30812;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_29072\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegscan_28708_dim1, 1, 1)\nvoid human_genericf64zisegscan_28708(__global int *global_failure, int64_t mz2080U_21995, int64_t num_tblocks_28705, int64_t num_virt_blocks_29795, int64_t num_virt_threads_29796, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29683, __global unsigned char *status_flags_mem_29797, __global unsigned char *aggregates_mem_29819, __global unsigned char *incprefixes_mem_29821, __global unsigned char *global_dynid_mem_29823)\n{\n    #define segscan_tblock_sizze_28703 (human_genericf64zisegscan_28708zisegscan_tblock_sizze_28703)\n    #define chunk_sizze_29794 (human_genericf64zisegscan_28708zichunk_sizze_29794)\n    \n    volatile __local unsigned char *local_mem_29853_backing_0 = &shared_mem[0];\n    const int64_t local_mem_29853_backing_0_offset = 0", " + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28703), chunk_sizze_29794 * segscan_tblock_sizze_28703 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28703), chunk_sizze_29794 * segscan_tblock_sizze_28703 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29846;\n    int32_t tblock_sizze_29849;\n    int32_t wave_sizze_29848;\n    int32_t block_id_29847;\n    int32_t global_tid_29845;\n    int64_t phys_tid_28708;\n    int32_t chunk_sizze_32b_29850;\n    int64_t byte_offsets_29851;\n    int64_t warp_byte_offset_29852;\n    __local unsigned char *local_mem_29853;\n    int64_t trans_arr_len_29854;\n    int64_t phys_block_id_29860;\n    int64_t virtloop_bound_29861;\n    \n    local_tid_29846 = get_local_id(0);\n    tblock_sizze_29849 = get_local_size(0);\n    wave_sizze_29848 = LOCKSTEP_WIDTH;\n    block_id_29847 = get_tblock_id(0);\n    global_tid_29845 = block_id_29847 * tblock_sizze_29849 + local_tid_29846;\n    phys_tid_28708 = sext_i32_i64(global_tid_29845);\n    chunk_sizze_32b_29850 = sext_i64_i32(chunk_sizze_29794);\n    byte_offsets_29851 = segscan_tblock_sizze_28703 * (int64_t) 8;\n    warp_byte_offset_29852 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_29853 = (__local unsigned char *) local_mem_29853_backing_0;\n    trans_arr_len_29854 = chunk_sizze_29794 * segscan_tblock_sizze_28703;\n    phys_block_id_29860 = get_tblock_id(0);\n    virtloop_bound_29861 = sdiv_up64(num_virt_blocks_29795 - phys_block_id_29860, num_tblocks_28705);\n    for (int64_t virtloop_i_29862 = 0; virtloop_i_29862 < virtloop_bound_29861; virtloop_i_29862++) {\n        int64_t dynamic_id_29863;\n        int64_t block_offset_29864;\n        int64_t sgm_idx_29865;\n        int32_t boundary_29866;\n        int32_t segsizze_compact_29867;\n        int64_t private_mem_29868[chunk_sizze_29794];\n        int64_t thd_offset_29870;\n        int64_", "t acc_29886;\n        int64_t prefix_29896;\n        bool block_new_sgm_29897;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_29846 == 0) {\n                dynamic_id_29863 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_29823)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_29853)[(int64_t) 0] = dynamic_id_29863;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_29863 == num_virt_blocks_29795 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_29823)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_29863 = ((__local int32_t *) local_mem_29853)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_29864 = dynamic_id_29863 * chunk_sizze_29794 * segscan_tblock_sizze_28703;\n        sgm_idx_29865 = smod64(block_offset_29864, mz2080U_21995);\n        boundary_29866 = sext_i64_i32(smin64(chunk_sizze_29794 * segscan_tblock_sizze_28703, mz2080U_21995 - sgm_idx_29865));\n        segsizze_compact_29867 = sext_i64_i32(smin64(chunk_sizze_29794 * segscan_tblock_sizze_28703, mz2080U_21995));\n        thd_offset_29870 = block_offset_29864 + sext_i32_i64(local_tid_29846);\n        // Load and map\n        {\n            for (int64_t i_29871 = 0; i_29871 < chunk_sizze_29794; i_29871++) {\n                int64_t virt_tid_29872 = thd_offset_29870 + i_29871 * segscan_tblock_sizze_28703;\n                int64_t slice_29873 = mz2080U_21995;\n                int64_t gtid_28707 = virt_tid_29872;\n                int64_t remnant_29874 = virt_tid_29872 - gtid_28707;\n                \n                if (slt64(virt_tid_29872, mz2080U_21995)) {\n                    int32_t eta_p_27712 = ((__globa",
                                    "l int32_t *) shp_mem_29678)[gtid_28707];\n                    int64_t i32_res_27713 = sext_i32_i64(eta_p_27712);\n                    \n                    private_mem_29868[i_29871] = i32_res_27713;\n                } else {\n                    private_mem_29868[i_29871] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_29875 = 0; i_29875 < chunk_sizze_29794; i_29875++) {\n                int64_t sharedIdx_29876 = sext_i32_i64(local_tid_29846) + i_29875 * segscan_tblock_sizze_28703;\n                int64_t tmp_29877 = private_mem_29868[i_29875];\n                \n                ((__local int64_t *) local_mem_29853)[sharedIdx_29876] = tmp_29877;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_29878 = 0; i_29878 < chunk_sizze_29794; i_29878++) {\n                int64_t sharedIdx_29879 = sext_i32_i64(local_tid_29846) * chunk_sizze_29794 + i_29878;\n                int64_t tmp_29880 = ((__local int64_t *) local_mem_29853)[sharedIdx_29879];\n                \n                private_mem_29868[i_29878] = tmp_29880;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_29881 = 0; i_29881 < chunk_sizze_29794 - (int64_t) 1; i_29881++) {\n                int64_t eta_p_27379;\n                int64_t eta_p_27380;\n                \n                eta_p_27379 = private_mem_29868[i_29881];\n                eta_p_27380 = private_mem_29868[i_29881 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27381 = add64(eta_p_27379, eta_p_27380);\n                \n                private_mem_29868[i_29881 + (int64_t) 1] = defunc_0_op_res_27381;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_29882 = private_mem_29868[chunk_sizze_29794 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem", "_29853)[sext_i32_i64(local_tid_29846)] = tmp_29882;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_29883;\n            int64_t eta_p_29884;\n            int64_t eta_p_29887;\n            int64_t eta_p_29888;\n            bool ltid_in_bounds_29890 = slt64(sext_i32_i64(local_tid_29846), num_virt_threads_29796);\n            int32_t skip_threads_29891;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_29890) {\n                    eta_p_29884 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                    if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                        eta_p_29883 = eta_p_29884;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_29891 = 1;\n                while (slt32(skip_threads_29891, 32)) {\n                    bool thread_active_29892 = sle32(skip_threads_29891, local_tid_29846 - squot32(local_tid_29846, 32) * 32) && ltid_in_bounds_29890;\n                    \n                    if (thread_active_29892) {\n                        // read operands\n                        {\n                            eta_p_29883 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29891)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_29892) {\n                            int64_t defunc_0_op_res_29885 = add64(eta_p_29883, eta_p_29884);\n                            \n                            eta_p_29883 = defunc_0_op_res_29885;\n                        }\n                    }\n                    if (sle32(wave_sizze_29848, skip_threads_29891)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                  ", "  }\n                    if (thread_active_29892) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29883;\n                            eta_p_29884 = eta_p_29883;\n                        }\n                    }\n                    if (sle32(wave_sizze_29848, skip_threads_29891)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_29891 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 31 && ltid_in_bounds_29890) {\n                    ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(squot32(local_tid_29846, 32))] = eta_p_29883;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_29893;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_29846, 32) == 0 && ltid_in_bounds_29890) {\n                        eta_p_29888 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                        if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                            eta_p_29887 = eta_p_29888;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_29893 = 1;\n                    while (slt32(skip_threads_29893, 32)) {\n                        bool thread_active_29894 = sle32(skip_threads_29893, local_tid_29846 - squot32(local_tid_29846, 32) * 32) && (squot32(local_tid_29846, 32) == ",
                                    "0 && ltid_in_bounds_29890);\n                        \n                        if (thread_active_29894) {\n                            // read operands\n                            {\n                                eta_p_29887 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29893)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_29894) {\n                                int64_t defunc_0_op_res_29889 = add64(eta_p_29887, eta_p_29888);\n                                \n                                eta_p_29887 = defunc_0_op_res_29889;\n                            }\n                        }\n                        if (sle32(wave_sizze_29848, skip_threads_29893)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_29894) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29887;\n                                eta_p_29888 = eta_p_29887;\n                            }\n                        }\n                        if (sle32(wave_sizze_29848, skip_threads_29893)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_29893 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_29895 = squot32(local_tid_29846, 32) == 0 || !ltid_in_bounds_29890;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_29895) {\n                        eta_p_29884 = eta_p_29883;\n                        eta_p_29883 = ((__local int64_", "t *) local_mem_29853)[sext_i32_i64(squot32(local_tid_29846, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_29895) {\n                        int64_t defunc_0_op_res_29885 = add64(eta_p_29883, eta_p_29884);\n                        \n                        eta_p_29883 = defunc_0_op_res_29885;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_29895) {\n                        ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29883;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_29846, 32) == 0 && ltid_in_bounds_29890) {\n                    ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29884;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_29846 == 0) {\n                acc_29886 = ((__local int64_t *) local_mem_29853)[segscan_tblock_sizze_28703 - (int64_t) 1];\n            } else {\n                acc_29886 = ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_29896 = (int64_t) 0;\n        block_new_sgm_29897 = sgm_idx_29865 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_29897 && local_tid_29846 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863] = acc_29886;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 2;\n                acc_29886 = (int64_t) 0;\n            }\n            if (!block_new_sgm_29897 && slt32(loc", "al_tid_29846, wave_sizze_29848)) {\n                if (local_tid_29846 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_29819)[dynamic_id_29863] = acc_29886;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 1;\n                    \n                    int8_t tmp_29898 = ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_29853)[(int64_t) 0] = tmp_29898;\n                }\n                mem_fence_local();\n                \n                int8_t status_29899 = ((__local int8_t *) local_mem_29853)[(int64_t) 0];\n                \n                if (status_29899 == (int8_t) 2) {\n                    if (local_tid_29846 == 0) {\n                        prefix_29896 = ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_29900 = sext_i64_i32(dynamic_id_29863 - sext_i32_i64(wave_sizze_29848));\n                    \n                    while (slt32(wave_sizze_29848 * -1, readOffset_29900)) {\n                        int32_t read_i_29901 = readOffset_29900 + local_tid_29846;\n                        int64_t aggr_29902 = (int64_t) 0;\n                        int8_t flag_29903 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_29901)) {\n                            flag_29903 = ((volatile __global int8_t *) status_flags_mem_29797)[sext_i32_i64(read_i_29901)];\n                            if (flag_29903 == (int8_t) 2) {\n                                aggr_29902 = ((volatile __global int64_t *) incprefixes_mem_29821)[sext_i32_i64(read_i_29901)];\n                            } else if (flag_29903 == (int8_t) 1) {\n                                aggr_29902 = ((volatile __global int64_t *) aggregates_mem_29819)[s",
                                    "ext_i32_i64(read_i_29901)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)] = aggr_29902;\n                        ((__local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = flag_29903;\n                        flag_29903 = ((__local int8_t *) local_mem_29853)[sext_i32_i64(wave_sizze_29848) - (int64_t) 1];\n                        if (slt8(flag_29903, (int8_t) 2)) {\n                            int8_t flg_x_29907;\n                            int8_t flg_y_29908;\n                            int64_t eta_p_29904;\n                            int64_t eta_p_29905;\n                            int32_t skip_threads_29909;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_29908 = ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                                eta_p_29905 = ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)];\n                                if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                                    eta_p_29904 = eta_p_29905;\n                                    flg_x_29907 = flg_y_29908;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_29909 = 1;\n                                while (slt32(skip_threads_29909, 32)) {\n                                    if (sle32(skip_threads_29909, local_tid_29846 - squot32(local_tid_29846, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_29907 = ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)", " - sext_i32_i64(skip_threads_29909)];\n                                            eta_p_29904 = ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + (sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29909))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_29908 == (int8_t) 2 || flg_y_29908 == (int8_t) 0) {\n                                                flg_x_29907 = flg_y_29908;\n                                                eta_p_29904 = eta_p_29905;\n                                            } else {\n                                                int64_t defunc_0_op_res_29906 = add64(eta_p_29904, eta_p_29905);\n                                                \n                                                eta_p_29904 = defunc_0_op_res_29906;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = flg_x_29907;\n                                            flg_y_29908 = flg_x_29907;\n                                            ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)] = eta_p_29904;\n                                            eta_p_29905 = eta_p_29904;\n                                        }\n                                    }\n                                    skip_threads_29909 *= 2;\n                                }\n                            }\n                        }\n                        flag_29903 = ((__local int8_t *) local_mem_29853)[sext_i32_i64(wave_sizze_29848) - (int64_t) 1];\n                        aggr_29902 = ((__local int64_t *) local_mem_29853)[(int64_t) 4 + (sext_i32_i64(wav", "e_sizze_29848) - (int64_t) 1)];\n                        if (flag_29903 == (int8_t) 2) {\n                            readOffset_29900 = wave_sizze_29848 * -1;\n                        } else if (flag_29903 == (int8_t) 1) {\n                            readOffset_29900 -= wave_sizze_29848;\n                        }\n                        if (slt8((int8_t) 0, flag_29903)) {\n                            int64_t eta_p_29910 = aggr_29902;\n                            int64_t eta_p_29911 = prefix_29896;\n                            int64_t defunc_0_op_res_29912 = add64(eta_p_29910, eta_p_29911);\n                            \n                            prefix_29896 = defunc_0_op_res_29912;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_29846 == 0) {\n                    if (boundary_29866 == sext_i64_i32(segscan_tblock_sizze_28703 * chunk_sizze_29794)) {\n                        int64_t eta_p_29913 = prefix_29896;\n                        int64_t eta_p_29914 = acc_29886;\n                        int64_t defunc_0_op_res_29915 = add64(eta_p_29913, eta_p_29914);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863] = defunc_0_op_res_29915;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_29853)[(int64_t) 4] = prefix_29896;\n                    acc_29886 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_29863 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_29896 = ((__local int64_t *) local_mem_29853)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_29916;\n            int64_t eta_p_29917;\n   ",
                                    "         int64_t eta_p_29919 = prefix_29896;\n            int64_t eta_p_29920 = acc_29886;\n            \n            if (slt32(local_tid_29846 * chunk_sizze_32b_29850, boundary_29866) && !block_new_sgm_29897) {\n                int64_t defunc_0_op_res_29921 = add64(eta_p_29919, eta_p_29920);\n                \n                eta_p_29916 = defunc_0_op_res_29921;\n            } else {\n                eta_p_29916 = acc_29886;\n            }\n            \n            int32_t stopping_point_29922 = segsizze_compact_29867 - srem32(local_tid_29846 * chunk_sizze_32b_29850 - 1 + segsizze_compact_29867 - boundary_29866, segsizze_compact_29867);\n            \n            for (int64_t i_29923 = 0; i_29923 < chunk_sizze_29794; i_29923++) {\n                if (slt32(sext_i64_i32(i_29923), stopping_point_29922 - 1)) {\n                    eta_p_29917 = private_mem_29868[i_29923];\n                    \n                    int64_t defunc_0_op_res_29918 = add64(eta_p_29916, eta_p_29917);\n                    \n                    private_mem_29868[i_29923] = defunc_0_op_res_29918;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_29924 = 0; i_29924 < chunk_sizze_29794; i_29924++) {\n                int64_t sharedIdx_29925 = sext_i32_i64(local_tid_29846) * chunk_sizze_29794 + i_29924;\n                int64_t tmp_29926 = private_mem_29868[i_29924];\n                \n                ((__local int64_t *) local_mem_29853)[sharedIdx_29925] = tmp_29926;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_29927 = 0; i_29927 < chunk_sizze_29794; i_29927++) {\n                int64_t flat_idx_29928 = thd_offset_29870 + i_29927 * segscan_tblock_sizze_28703;\n                int64_t slice_29929 = mz2080U_21995;\n                int64_t gtid_28707 = flat_idx_29928;\n                int64_t remnant_29930 = flat_idx_29928 - gtid_28707;\n                \n                if (sl", "t64(flat_idx_29928, mz2080U_21995)) {\n                    int64_t tmp_29931 = ((__local int64_t *) local_mem_29853)[flat_idx_29928 - block_offset_29864];\n                    \n                    ((__global int64_t *) mem_29683)[gtid_28707] = tmp_29931;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28703\n    #undef chunk_sizze_29794\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegscan_28724_dim1, 1, 1)\nvoid human_genericf64zisegscan_28724(__global int *global_failure, int64_t nz2081U_21996, int64_t num_tblocks_28721, int64_t num_virt_blocks_29972, int64_t num_virt_threads_29973, __global unsigned char *A_mem_29680, __global unsigned char *mem_29684, __global unsigned char *mem_29687, __global unsigned char *mem_29689, __global unsigned char *status_flags_mem_29974, __global unsigned char *aggregates_mem_29976, __global unsigned char *incprefixes_mem_29978, __global unsigned char *aggregates_mem_29980, __global unsigned char *incprefixes_mem_29982, __global unsigned char *global_dynid_mem_29984)\n{\n    #define segscan_tblock_sizze_28719 (human_genericf64zisegscan_28724zisegscan_tblock_sizze_28719)\n    #define chunk_sizze_29971 (human_genericf64zisegscan_28724zichunk_sizze_29971)\n    \n    volatile __local unsigned char *local_mem_29996_backing_0 = &shared_mem[0];\n    const int64_t local_mem_29996_backing_0_offset = 0 + (smax64(smax64((int64_t) 320, sdiv_up64(segscan_tblock_sizze_28719, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_28719), smax64(chunk_sizze_29971 * segscan_tblock_sizze_28719, chunk_sizze_29971 * segscan_tblock_sizze_28719 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 320, sdiv_up64(segscan_tblock_sizze_28719, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_28719), smax64(chunk_sizze_29971 * segscan_tblock_sizze_28719, chunk_sizze_29971 * segscan_tblock_sizze_28719 * (int64_t) 8)), (int64_t) 8), (in", "t64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29987;\n    int32_t tblock_sizze_29990;\n    int32_t wave_sizze_29989;\n    int32_t block_id_29988;\n    int32_t global_tid_29986;\n    int64_t phys_tid_28724;\n    int32_t chunk_sizze_32b_29991;\n    int64_t byte_offsets_29992;\n    int64_t byte_offsets_29993;\n    int64_t warp_byte_offset_29994;\n    int64_t warp_byte_offset_29995;\n    __local unsigned char *local_mem_29996;\n    int64_t trans_arr_len_29997;\n    int64_t phys_block_id_30006;\n    int64_t virtloop_bound_30007;\n    \n    local_tid_29987 = get_local_id(0);\n    tblock_sizze_29990 = get_local_size(0);\n    wave_sizze_29989 = LOCKSTEP_WIDTH;\n    block_id_29988 = get_tblock_id(0);\n    global_tid_29986 = block_id_29988 * tblock_sizze_29990 + local_tid_29987;\n    phys_tid_28724 = sext_i32_i64(global_tid_29986);\n    chunk_sizze_32b_29991 = sext_i64_i32(chunk_sizze_29971);\n    byte_offsets_29992 = segscan_tblock_sizze_28719;\n    byte_offsets_29993 = sdiv_up64(byte_offsets_29992, (int64_t) 8) * (int64_t) 8 + segscan_tblock_sizze_28719 * (int64_t) 8;\n    warp_byte_offset_29994 = (int64_t) 64;\n    warp_byte_offset_29995 = sdiv_up64(warp_byte_offset_29994, (int64_t) 8) * (int64_t) 8 + (int64_t) 256;\n    // Allocate reusable shared memory\n    { }\n    local_mem_29996 = (__local unsigned char *) local_mem_29996_backing_0;\n    trans_arr_len_29997 = chunk_sizze_29971 * segscan_tblock_sizze_28719;\n    phys_block_id_30006 = get_tblock_id(0);\n    virtloop_bound_30007 = sdiv_up64(num_virt_blocks_29972 - phys_block_id_30006, num_tblocks_28721);\n    for (int64_t virtloop_i_30008 = 0; virtloop_i_30008 < virtloop_bound_30007; virtloop_i_30008++) {\n        int64_t dynamic_id_30009;\n        int64_t block_offset_30010;\n        int64_t sgm_idx_30011;\n        int32_t boundary_30012;\n        int32_t segsizze_compact_30013;\n        bool private_mem_30014[chunk_sizze_29971];\n        double private_mem_30016[chunk_sizze_29971];\n        int64_t thd_offset_30018",
                                    ";\n        bool acc_30045;\n        double acc_30046;\n        bool prefix_30060;\n        double prefix_30061;\n        bool block_new_sgm_30062;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_29987 == 0) {\n                dynamic_id_30009 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_29984)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_29996)[(int64_t) 0] = dynamic_id_30009;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30009 == num_virt_blocks_29972 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_29984)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30009 = ((__local int32_t *) local_mem_29996)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30010 = dynamic_id_30009 * chunk_sizze_29971 * segscan_tblock_sizze_28719;\n        sgm_idx_30011 = smod64(block_offset_30010, nz2081U_21996);\n        boundary_30012 = sext_i64_i32(smin64(chunk_sizze_29971 * segscan_tblock_sizze_28719, nz2081U_21996 - sgm_idx_30011));\n        segsizze_compact_30013 = sext_i64_i32(smin64(chunk_sizze_29971 * segscan_tblock_sizze_28719, nz2081U_21996));\n        thd_offset_30018 = block_offset_30010 + sext_i32_i64(local_tid_29987);\n        // Load and map\n        {\n            for (int64_t i_30019 = 0; i_30019 < chunk_sizze_29971; i_30019++) {\n                int64_t virt_tid_30020 = thd_offset_30018 + i_30019 * segscan_tblock_sizze_28719;\n                int64_t slice_30021 = nz2081U_21996;\n                int64_t gtid_28723 = virt_tid_30020;\n                int64_t remnant_30022 = virt_tid_30020 - gtid_28723;\n                \n                if (slt64(virt_tid_30020, nz20", "81U_21996)) {\n                    bool x_26937 = ((__global bool *) mem_29684)[gtid_28723];\n                    double x_26938 = ((__global double *) A_mem_29680)[gtid_28723];\n                    \n                    private_mem_30014[i_30019] = x_26937;\n                    private_mem_30016[i_30019] = x_26938;\n                } else {\n                    private_mem_30014[i_30019] = 0;\n                    private_mem_30016[i_30019] = 0.0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30023 = 0; i_30023 < chunk_sizze_29971; i_30023++) {\n                int64_t sharedIdx_30024 = sext_i32_i64(local_tid_29987) + i_30023 * segscan_tblock_sizze_28719;\n                bool tmp_30025 = private_mem_30014[i_30023];\n                \n                ((__local bool *) local_mem_29996)[sharedIdx_30024] = tmp_30025;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30026 = 0; i_30026 < chunk_sizze_29971; i_30026++) {\n                int64_t sharedIdx_30027 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30026;\n                bool tmp_30028 = ((__local bool *) local_mem_29996)[sharedIdx_30027];\n                \n                private_mem_30014[i_30026] = tmp_30028;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30029 = 0; i_30029 < chunk_sizze_29971; i_30029++) {\n                int64_t sharedIdx_30030 = sext_i32_i64(local_tid_29987) + i_30029 * segscan_tblock_sizze_28719;\n                double tmp_30031 = private_mem_30016[i_30029];\n                \n                ((__local double *) local_mem_29996)[sharedIdx_30030] = tmp_30031;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30032 = 0; i_30032 < chunk_sizze_29971; i_30032++) {\n                int64_t sharedIdx_30033 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30032;\n                double tmp_30034 =", " ((__local double *) local_mem_29996)[sharedIdx_30033];\n                \n                private_mem_30016[i_30032] = tmp_30034;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30035 = 0; i_30035 < chunk_sizze_29971 - (int64_t) 1; i_30035++) {\n                bool eta_p_26930;\n                bool eta_p_26932;\n                \n                eta_p_26930 = private_mem_30014[i_30035];\n                eta_p_26932 = private_mem_30014[i_30035 + (int64_t) 1];\n                \n                double eta_p_26931;\n                double eta_p_26933;\n                \n                eta_p_26931 = private_mem_30016[i_30035];\n                eta_p_26933 = private_mem_30016[i_30035 + (int64_t) 1];\n                \n                bool tmp_26934 = eta_p_26930 || eta_p_26932;\n                double tmp_26935;\n                \n                if (eta_p_26932) {\n                    tmp_26935 = eta_p_26933;\n                } else {\n                    double defunc_0_op_res_26936 = eta_p_26931 + eta_p_26933;\n                    \n                    tmp_26935 = defunc_0_op_res_26936;\n                }\n                private_mem_30014[i_30035 + (int64_t) 1] = tmp_26934;\n                private_mem_30016[i_30035 + (int64_t) 1] = tmp_26935;\n            }\n        }\n        // Publish results in shared memory\n        {\n            bool tmp_30036 = private_mem_30014[chunk_sizze_29971 - (int64_t) 1];\n            \n            ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = tmp_30036;\n            \n            double tmp_30037 = private_mem_30016[chunk_sizze_29971 - (int64_t) 1];\n            \n            ((__local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + sext_i32_i64(local_tid_29987)] = tmp_30037;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            bool eta_p_30038;\n            double eta_p_30039;\n    ",
                                    "        bool eta_p_30040;\n            double eta_p_30041;\n            bool eta_p_30047;\n            double eta_p_30048;\n            bool eta_p_30049;\n            double eta_p_30050;\n            bool ltid_in_bounds_30054 = slt64(sext_i32_i64(local_tid_29987), num_virt_threads_29973);\n            int32_t skip_threads_30055;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30054) {\n                    eta_p_30040 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)];\n                    eta_p_30041 = ((volatile __local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + sext_i32_i64(local_tid_29987)];\n                    if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                        eta_p_30038 = eta_p_30040;\n                        eta_p_30039 = eta_p_30041;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30055 = 1;\n                while (slt32(skip_threads_30055, 32)) {\n                    bool thread_active_30056 = sle32(skip_threads_30055, local_tid_29987 - squot32(local_tid_29987, 32) * 32) && ltid_in_bounds_30054;\n                    \n                    if (thread_active_30056) {\n                        // read operands\n                        {\n                            eta_p_30038 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30055)];\n                            eta_p_30039 = ((volatile __local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30055))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30056) {\n                            bool tmp_30042 = eta_p_30038 || eta_p_30040;\n          ", "                  double tmp_30043;\n                            \n                            if (eta_p_30040) {\n                                tmp_30043 = eta_p_30041;\n                            } else {\n                                double defunc_0_op_res_30044 = eta_p_30039 + eta_p_30041;\n                                \n                                tmp_30043 = defunc_0_op_res_30044;\n                            }\n                            eta_p_30038 = tmp_30042;\n                            eta_p_30039 = tmp_30043;\n                        }\n                    }\n                    if (sle32(wave_sizze_29989, skip_threads_30055)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30056) {\n                        // write result\n                        {\n                            ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30038;\n                            eta_p_30040 = eta_p_30038;\n                            ((volatile __local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + sext_i32_i64(local_tid_29987)] = eta_p_30039;\n                            eta_p_30041 = eta_p_30039;\n                        }\n                    }\n                    if (sle32(wave_sizze_29989, skip_threads_30055)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30055 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 31 && ltid_in_bounds_30054) {\n                    ((volatile __local bool *) local_mem_29996)[sext_i32_i64(squot32(local_tid_29987, 32))] = eta_p_30038;\n                    ((volatile __local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + sext_i32_i64(squot32(local_tid", "_29987, 32))] = eta_p_30039;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30057;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_29987, 32) == 0 && ltid_in_bounds_30054) {\n                        eta_p_30049 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)];\n                        eta_p_30050 = ((volatile __local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + sext_i32_i64(local_tid_29987)];\n                        if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                            eta_p_30047 = eta_p_30049;\n                            eta_p_30048 = eta_p_30050;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30057 = 1;\n                    while (slt32(skip_threads_30057, 32)) {\n                        bool thread_active_30058 = sle32(skip_threads_30057, local_tid_29987 - squot32(local_tid_29987, 32) * 32) && (squot32(local_tid_29987, 32) == 0 && ltid_in_bounds_30054);\n                        \n                        if (thread_active_30058) {\n                            // read operands\n                            {\n                                eta_p_30047 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30057)];\n                                eta_p_30048 = ((volatile __local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30057))];\n                            }\n                        }\n                        // perform operation\n                        {\n                   ",
                                    "         if (thread_active_30058) {\n                                bool tmp_30051 = eta_p_30047 || eta_p_30049;\n                                double tmp_30052;\n                                \n                                if (eta_p_30049) {\n                                    tmp_30052 = eta_p_30050;\n                                } else {\n                                    double defunc_0_op_res_30053 = eta_p_30048 + eta_p_30050;\n                                    \n                                    tmp_30052 = defunc_0_op_res_30053;\n                                }\n                                eta_p_30047 = tmp_30051;\n                                eta_p_30048 = tmp_30052;\n                            }\n                        }\n                        if (sle32(wave_sizze_29989, skip_threads_30057)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30058) {\n                            // write result\n                            {\n                                ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30047;\n                                eta_p_30049 = eta_p_30047;\n                                ((volatile __local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + sext_i32_i64(local_tid_29987)] = eta_p_30048;\n                                eta_p_30050 = eta_p_30048;\n                            }\n                        }\n                        if (sle32(wave_sizze_29989, skip_threads_30057)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30057 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30059 = squot32(local_tid_29987, 32) == 0 || !ltid_in_bounds_30054;\n            \n            // carry-in for every block except the first\n            {\n", "                // read operands\n                {\n                    if (!no_carry_in_30059) {\n                        eta_p_30040 = eta_p_30038;\n                        eta_p_30041 = eta_p_30039;\n                        eta_p_30038 = ((__local bool *) local_mem_29996)[sext_i32_i64(squot32(local_tid_29987, 32)) - (int64_t) 1];\n                        eta_p_30039 = ((__local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + (sext_i32_i64(squot32(local_tid_29987, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30059) {\n                        bool tmp_30042 = eta_p_30038 || eta_p_30040;\n                        double tmp_30043;\n                        \n                        if (eta_p_30040) {\n                            tmp_30043 = eta_p_30041;\n                        } else {\n                            double defunc_0_op_res_30044 = eta_p_30039 + eta_p_30041;\n                            \n                            tmp_30043 = defunc_0_op_res_30044;\n                        }\n                        eta_p_30038 = tmp_30042;\n                        eta_p_30039 = tmp_30043;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30059) {\n                        ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30038;\n                        ((__local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + sext_i32_i64(local_tid_29987)] = eta_p_30039;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_29987, 32) == 0 && ltid_in_bounds_30054) {\n                    ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30040;\n                    ((__local double *)", " local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + sext_i32_i64(local_tid_29987)] = eta_p_30041;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_29987 == 0) {\n                acc_30045 = ((__local bool *) local_mem_29996)[segscan_tblock_sizze_28719 - (int64_t) 1];\n                acc_30046 = ((__local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + (segscan_tblock_sizze_28719 - (int64_t) 1)];\n            } else {\n                acc_30045 = ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - (int64_t) 1];\n                acc_30046 = ((__local double *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 8) + (sext_i32_i64(local_tid_29987) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30060 = 0;\n        prefix_30061 = 0.0;\n        block_new_sgm_30062 = sgm_idx_30011 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30062 && local_tid_29987 == 0) {\n                ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009] = acc_30045;\n                ((volatile __global double *) incprefixes_mem_29982)[dynamic_id_30009] = acc_30046;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 2;\n                acc_30045 = 0;\n                acc_30046 = 0.0;\n            }\n            if (!block_new_sgm_30062 && slt32(local_tid_29987, wave_sizze_29989)) {\n                if (local_tid_29987 == 0) {\n                    ((volatile __global bool *) aggregates_mem_29976)[dynamic_id_30009] = acc_30045;\n                    ((volatile __global double *) aggregates_mem_29980)[dynamic_id_30009] = acc_30046;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 1;\n                   ",
                                    " \n                    int8_t tmp_30063 = ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_29996)[(int64_t) 0] = tmp_30063;\n                }\n                mem_fence_local();\n                \n                int8_t status_30064 = ((__local int8_t *) local_mem_29996)[(int64_t) 0];\n                \n                if (status_30064 == (int8_t) 2) {\n                    if (local_tid_29987 == 0) {\n                        prefix_30060 = ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009 - (int64_t) 1];\n                        prefix_30061 = ((volatile __global double *) incprefixes_mem_29982)[dynamic_id_30009 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30065 = sext_i64_i32(dynamic_id_30009 - sext_i32_i64(wave_sizze_29989));\n                    \n                    while (slt32(wave_sizze_29989 * -1, readOffset_30065)) {\n                        int32_t read_i_30066 = readOffset_30065 + local_tid_29987;\n                        bool aggr_30067 = 0;\n                        double aggr_30068 = 0.0;\n                        int8_t flag_30069 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30066)) {\n                            flag_30069 = ((volatile __global int8_t *) status_flags_mem_29974)[sext_i32_i64(read_i_30066)];\n                            if (flag_30069 == (int8_t) 2) {\n                                aggr_30067 = ((volatile __global bool *) incprefixes_mem_29978)[sext_i32_i64(read_i_30066)];\n                                aggr_30068 = ((volatile __global double *) incprefixes_mem_29982)[sext_i32_i64(read_i_30066)];\n                            } else if (flag_30069 == (int8_t) 1) {\n                                aggr_30067 = ((volatile __global bool *) aggregates_mem_29976)[sext_i32_i64(read_i_30066)];\n                                aggr_3006", "8 = ((volatile __global double *) aggregates_mem_29980)[sext_i32_i64(read_i_30066)];\n                            }\n                        }\n                        ((__local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)] = aggr_30067;\n                        ((__local double *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 8) + sext_i32_i64(local_tid_29987)] = aggr_30068;\n                        ((__local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = flag_30069;\n                        flag_30069 = ((__local int8_t *) local_mem_29996)[sext_i32_i64(wave_sizze_29989) - (int64_t) 1];\n                        if (slt8(flag_30069, (int8_t) 2)) {\n                            int8_t flg_x_30077;\n                            int8_t flg_y_30078;\n                            bool eta_p_30070;\n                            double eta_p_30071;\n                            bool eta_p_30072;\n                            double eta_p_30073;\n                            int32_t skip_threads_30079;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30078 = ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)];\n                                eta_p_30072 = ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)];\n                                eta_p_30073 = ((volatile __local double *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 8) + sext_i32_i64(local_tid_29987)];\n                                if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                                    eta_p_30070 = eta_p_30072;\n                                    eta_p_30071 = eta_p_30073;\n                                    flg_x_30077 = flg_y_30078;\n                                }\n                            }\n                            // in-block scan (hopefully no", " barriers needed)\n                            {\n                                skip_threads_30079 = 1;\n                                while (slt32(skip_threads_30079, 32)) {\n                                    if (sle32(skip_threads_30079, local_tid_29987 - squot32(local_tid_29987, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30077 = ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30079)];\n                                            eta_p_30070 = ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30079))];\n                                            eta_p_30071 = ((volatile __local double *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 8) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30079))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30078 == (int8_t) 2 || flg_y_30078 == (int8_t) 0) {\n                                                flg_x_30077 = flg_y_30078;\n                                                eta_p_30070 = eta_p_30072;\n                                                eta_p_30071 = eta_p_30073;\n                                            } else {\n                                                bool tmp_30074 = eta_p_30070 || eta_p_30072;\n                                                double tmp_30075;\n                                                \n                                                if (eta_p_30072) {\n                                                    tmp_30075 = eta_p_30073;\n                                                } else {\n                                                    double defunc_0_op_res_30076 = eta_p",
                                    "_30071 + eta_p_30073;\n                                                    \n                                                    tmp_30075 = defunc_0_op_res_30076;\n                                                }\n                                                eta_p_30070 = tmp_30074;\n                                                eta_p_30071 = tmp_30075;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = flg_x_30077;\n                                            flg_y_30078 = flg_x_30077;\n                                            ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)] = eta_p_30070;\n                                            eta_p_30072 = eta_p_30070;\n                                            ((volatile __local double *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 8) + sext_i32_i64(local_tid_29987)] = eta_p_30071;\n                                            eta_p_30073 = eta_p_30071;\n                                        }\n                                    }\n                                    skip_threads_30079 *= 2;\n                                }\n                            }\n                        }\n                        flag_30069 = ((__local int8_t *) local_mem_29996)[sext_i32_i64(wave_sizze_29989) - (int64_t) 1];\n                        aggr_30067 = ((__local bool *) local_mem_29996)[(int64_t) 32 + (sext_i32_i64(wave_sizze_29989) - (int64_t) 1)];\n                        aggr_30068 = ((__local double *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 8) + (sext_i32_i64(wave_sizze_29989) - (int64_t) 1)];\n                        if (flag_30069 == (int8_t) 2) {\n                            readOffset_30065 = wave_sizze_299", "89 * -1;\n                        } else if (flag_30069 == (int8_t) 1) {\n                            readOffset_30065 -= wave_sizze_29989;\n                        }\n                        if (slt8((int8_t) 0, flag_30069)) {\n                            bool eta_p_30080 = aggr_30067;\n                            double eta_p_30081 = aggr_30068;\n                            bool eta_p_30082 = prefix_30060;\n                            double eta_p_30083 = prefix_30061;\n                            bool tmp_30084 = eta_p_30080 || eta_p_30082;\n                            double tmp_30085;\n                            \n                            if (eta_p_30082) {\n                                tmp_30085 = eta_p_30083;\n                            } else {\n                                double defunc_0_op_res_30086 = eta_p_30081 + eta_p_30083;\n                                \n                                tmp_30085 = defunc_0_op_res_30086;\n                            }\n                            prefix_30060 = tmp_30084;\n                            prefix_30061 = tmp_30085;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_29987 == 0) {\n                    if (boundary_30012 == sext_i64_i32(segscan_tblock_sizze_28719 * chunk_sizze_29971)) {\n                        bool eta_p_30087 = prefix_30060;\n                        double eta_p_30088 = prefix_30061;\n                        bool eta_p_30089 = acc_30045;\n                        double eta_p_30090 = acc_30046;\n                        bool tmp_30091 = eta_p_30087 || eta_p_30089;\n                        double tmp_30092;\n                        \n                        if (eta_p_30089) {\n                            tmp_30092 = eta_p_30090;\n                        } else {\n                            double defunc_0_op_res_30093 = eta_p_30088 + eta_p_30090;\n                            \n                            tmp_30092 = defunc_0_o", "p_res_30093;\n                        }\n                        ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009] = tmp_30091;\n                        ((volatile __global double *) incprefixes_mem_29982)[dynamic_id_30009] = tmp_30092;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 2;\n                    }\n                    ((__local bool *) local_mem_29996)[(int64_t) 32] = prefix_30060;\n                    ((__local double *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 8)] = prefix_30061;\n                    acc_30045 = 0;\n                    acc_30046 = 0.0;\n                }\n            }\n            if (!(dynamic_id_30009 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30060 = ((__local bool *) local_mem_29996)[(int64_t) 32];\n                prefix_30061 = ((__local double *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 8)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            bool eta_p_30094;\n            bool eta_p_30096;\n            bool eta_p_30101 = prefix_30060;\n            bool eta_p_30103 = acc_30045;\n            double eta_p_30095;\n            double eta_p_30097;\n            double eta_p_30102 = prefix_30061;\n            double eta_p_30104 = acc_30046;\n            \n            if (slt32(local_tid_29987 * chunk_sizze_32b_29991, boundary_30012) && !block_new_sgm_30062) {\n                bool tmp_30105 = eta_p_30101 || eta_p_30103;\n                double tmp_30106;\n                \n                if (eta_p_30103) {\n                    tmp_30106 = eta_p_30104;\n                } else {\n                    double defunc_0_op_res_30107 = eta_p_30102 + eta_p_30104;\n                    \n                    tmp_30106 = defunc_0_op_res_30107;\n                }\n                eta_p_30094 = tmp_30105;\n      ",
                                    "          eta_p_30095 = tmp_30106;\n            } else {\n                eta_p_30094 = acc_30045;\n                eta_p_30095 = acc_30046;\n            }\n            \n            int32_t stopping_point_30108 = segsizze_compact_30013 - srem32(local_tid_29987 * chunk_sizze_32b_29991 - 1 + segsizze_compact_30013 - boundary_30012, segsizze_compact_30013);\n            \n            for (int64_t i_30109 = 0; i_30109 < chunk_sizze_29971; i_30109++) {\n                if (slt32(sext_i64_i32(i_30109), stopping_point_30108 - 1)) {\n                    eta_p_30096 = private_mem_30014[i_30109];\n                    eta_p_30097 = private_mem_30016[i_30109];\n                    \n                    bool tmp_30098 = eta_p_30094 || eta_p_30096;\n                    double tmp_30099;\n                    \n                    if (eta_p_30096) {\n                        tmp_30099 = eta_p_30097;\n                    } else {\n                        double defunc_0_op_res_30100 = eta_p_30095 + eta_p_30097;\n                        \n                        tmp_30099 = defunc_0_op_res_30100;\n                    }\n                    private_mem_30014[i_30109] = tmp_30098;\n                    private_mem_30016[i_30109] = tmp_30099;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30110 = 0; i_30110 < chunk_sizze_29971; i_30110++) {\n                int64_t sharedIdx_30111 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30110;\n                bool tmp_30112 = private_mem_30014[i_30110];\n                \n                ((__local bool *) local_mem_29996)[sharedIdx_30111] = tmp_30112;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30113 = 0; i_30113 < chunk_sizze_29971; i_30113++) {\n                int64_t flat_idx_30114 = thd_offset_30018 + i_30113 * segscan_tblock_sizze_28719;\n                int64_t slice_30115 = nz2081U_21996;\n                in", "t64_t gtid_28723 = flat_idx_30114;\n                int64_t remnant_30116 = flat_idx_30114 - gtid_28723;\n                \n                if (slt64(flat_idx_30114, nz2081U_21996)) {\n                    bool tmp_30117 = ((__local bool *) local_mem_29996)[flat_idx_30114 - block_offset_30010];\n                    \n                    ((__global bool *) mem_29687)[gtid_28723] = tmp_30117;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30118 = 0; i_30118 < chunk_sizze_29971; i_30118++) {\n                int64_t sharedIdx_30119 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30118;\n                double tmp_30120 = private_mem_30016[i_30118];\n                \n                ((__local double *) local_mem_29996)[sharedIdx_30119] = tmp_30120;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30121 = 0; i_30121 < chunk_sizze_29971; i_30121++) {\n                int64_t flat_idx_30122 = thd_offset_30018 + i_30121 * segscan_tblock_sizze_28719;\n                int64_t slice_30123 = nz2081U_21996;\n                int64_t gtid_28723 = flat_idx_30122;\n                int64_t remnant_30124 = flat_idx_30122 - gtid_28723;\n                \n                if (slt64(flat_idx_30122, nz2081U_21996)) {\n                    double tmp_30125 = ((__local double *) local_mem_29996)[flat_idx_30122 - block_offset_30010];\n                    \n                    ((__global double *) mem_29689)[gtid_28723] = tmp_30125;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28719\n    #undef chunk_sizze_29971\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegscan_28732_dim1, 1, 1)\nvoid human_genericf64zisegscan_28732(__global int *global_failure, int64_t mz2080U_21995, int64_t num_tblocks_28729, int64_t num_virt_blocks_30132, int64_t num_virt_threads_30133, __global unsigned char *shp_mem_29678, __global unsigned char *", "mem_29692, __global unsigned char *status_flags_mem_30134, __global unsigned char *aggregates_mem_30136, __global unsigned char *incprefixes_mem_30138, __global unsigned char *global_dynid_mem_30140)\n{\n    #define segscan_tblock_sizze_28727 (human_genericf64zisegscan_28732zisegscan_tblock_sizze_28727)\n    #define chunk_sizze_30131 (human_genericf64zisegscan_28732zichunk_sizze_30131)\n    \n    volatile __local unsigned char *local_mem_30150_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30150_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28727), chunk_sizze_30131 * segscan_tblock_sizze_28727 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28727), chunk_sizze_30131 * segscan_tblock_sizze_28727 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30143;\n    int32_t tblock_sizze_30146;\n    int32_t wave_sizze_30145;\n    int32_t block_id_30144;\n    int32_t global_tid_30142;\n    int64_t phys_tid_28732;\n    int32_t chunk_sizze_32b_30147;\n    int64_t byte_offsets_30148;\n    int64_t warp_byte_offset_30149;\n    __local unsigned char *local_mem_30150;\n    int64_t trans_arr_len_30151;\n    int64_t phys_block_id_30157;\n    int64_t virtloop_bound_30158;\n    \n    local_tid_30143 = get_local_id(0);\n    tblock_sizze_30146 = get_local_size(0);\n    wave_sizze_30145 = LOCKSTEP_WIDTH;\n    block_id_30144 = get_tblock_id(0);\n    global_tid_30142 = block_id_30144 * tblock_sizze_30146 + local_tid_30143;\n    phys_tid_28732 = sext_i32_i64(global_tid_30142);\n    chunk_sizze_32b_30147 = sext_i64_i32(chunk_sizze_30131);\n    byte_offsets_30148 = segscan_tblock_sizze_28727 * (int64_t) 4;\n    warp_byte_offset_30149 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30150 = (__local unsigned char *) local_mem_30150_backing_0;\n    trans_arr_len_30151 = chunk_sizze_30131 * segscan_tblock_sizze_28727",
                                    ";\n    phys_block_id_30157 = get_tblock_id(0);\n    virtloop_bound_30158 = sdiv_up64(num_virt_blocks_30132 - phys_block_id_30157, num_tblocks_28729);\n    for (int64_t virtloop_i_30159 = 0; virtloop_i_30159 < virtloop_bound_30158; virtloop_i_30159++) {\n        int64_t dynamic_id_30160;\n        int64_t block_offset_30161;\n        int64_t sgm_idx_30162;\n        int32_t boundary_30163;\n        int32_t segsizze_compact_30164;\n        int32_t private_mem_30165[chunk_sizze_30131];\n        int64_t thd_offset_30167;\n        int32_t acc_30183;\n        int32_t prefix_30193;\n        bool block_new_sgm_30194;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30143 == 0) {\n                dynamic_id_30160 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30140)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30150)[(int64_t) 0] = dynamic_id_30160;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30160 == num_virt_blocks_30132 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30140)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30160 = ((__local int32_t *) local_mem_30150)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30161 = dynamic_id_30160 * chunk_sizze_30131 * segscan_tblock_sizze_28727;\n        sgm_idx_30162 = smod64(block_offset_30161, mz2080U_21995);\n        boundary_30163 = sext_i64_i32(smin64(chunk_sizze_30131 * segscan_tblock_sizze_28727, mz2080U_21995 - sgm_idx_30162));\n        segsizze_compact_30164 = sext_i64_i32(smin64(chunk_sizze_30131 * segscan_tblock_sizze_28727, mz2080U_21995));\n        thd_offset_30167 = block_offset_30161 + sext_i32_i64(local_ti", "d_30143);\n        // Load and map\n        {\n            for (int64_t i_30168 = 0; i_30168 < chunk_sizze_30131; i_30168++) {\n                int64_t virt_tid_30169 = thd_offset_30167 + i_30168 * segscan_tblock_sizze_28727;\n                int64_t slice_30170 = mz2080U_21995;\n                int64_t gtid_28731 = virt_tid_30169;\n                int64_t remnant_30171 = virt_tid_30169 - gtid_28731;\n                \n                if (slt64(virt_tid_30169, mz2080U_21995)) {\n                    int32_t x_27663 = ((__global int32_t *) shp_mem_29678)[gtid_28731];\n                    \n                    private_mem_30165[i_30168] = x_27663;\n                } else {\n                    private_mem_30165[i_30168] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30172 = 0; i_30172 < chunk_sizze_30131; i_30172++) {\n                int64_t sharedIdx_30173 = sext_i32_i64(local_tid_30143) + i_30172 * segscan_tblock_sizze_28727;\n                int32_t tmp_30174 = private_mem_30165[i_30172];\n                \n                ((__local int32_t *) local_mem_30150)[sharedIdx_30173] = tmp_30174;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30175 = 0; i_30175 < chunk_sizze_30131; i_30175++) {\n                int64_t sharedIdx_30176 = sext_i32_i64(local_tid_30143) * chunk_sizze_30131 + i_30175;\n                int32_t tmp_30177 = ((__local int32_t *) local_mem_30150)[sharedIdx_30176];\n                \n                private_mem_30165[i_30175] = tmp_30177;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30178 = 0; i_30178 < chunk_sizze_30131 - (int64_t) 1; i_30178++) {\n                int32_t eta_p_27660;\n                int32_t eta_p_27661;\n                \n                eta_p_27660 = private_mem_30165[i_30178];\n                eta_p_27661 = private_mem_30165[i_30", "178 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_27662 = add32(eta_p_27660, eta_p_27661);\n                \n                private_mem_30165[i_30178 + (int64_t) 1] = defunc_0_op_res_27662;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_30179 = private_mem_30165[chunk_sizze_30131 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = tmp_30179;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_30180;\n            int32_t eta_p_30181;\n            int32_t eta_p_30184;\n            int32_t eta_p_30185;\n            bool ltid_in_bounds_30187 = slt64(sext_i32_i64(local_tid_30143), num_virt_threads_30133);\n            int32_t skip_threads_30188;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30187) {\n                    eta_p_30181 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                    if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                        eta_p_30180 = eta_p_30181;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30188 = 1;\n                while (slt32(skip_threads_30188, 32)) {\n                    bool thread_active_30189 = sle32(skip_threads_30188, local_tid_30143 - squot32(local_tid_30143, 32) * 32) && ltid_in_bounds_30187;\n                    \n                    if (thread_active_30189) {\n                        // read operands\n                        {\n                            eta_p_30180 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30188)];\n                        }\n                    }\n                    // perform operation\n                 ",
                                    "   {\n                        if (thread_active_30189) {\n                            int32_t defunc_0_op_res_30182 = add32(eta_p_30180, eta_p_30181);\n                            \n                            eta_p_30180 = defunc_0_op_res_30182;\n                        }\n                    }\n                    if (sle32(wave_sizze_30145, skip_threads_30188)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30189) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30180;\n                            eta_p_30181 = eta_p_30180;\n                        }\n                    }\n                    if (sle32(wave_sizze_30145, skip_threads_30188)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30188 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 31 && ltid_in_bounds_30187) {\n                    ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(squot32(local_tid_30143, 32))] = eta_p_30180;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30190;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187) {\n                        eta_p_30185 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                        if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                            eta_p_30184", " = eta_p_30185;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30190 = 1;\n                    while (slt32(skip_threads_30190, 32)) {\n                        bool thread_active_30191 = sle32(skip_threads_30190, local_tid_30143 - squot32(local_tid_30143, 32) * 32) && (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187);\n                        \n                        if (thread_active_30191) {\n                            // read operands\n                            {\n                                eta_p_30184 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30190)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30191) {\n                                int32_t defunc_0_op_res_30186 = add32(eta_p_30184, eta_p_30185);\n                                \n                                eta_p_30184 = defunc_0_op_res_30186;\n                            }\n                        }\n                        if (sle32(wave_sizze_30145, skip_threads_30190)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30191) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30184;\n                                eta_p_30185 = eta_p_30184;\n                            }\n                        }\n                        if (sle32(wave_sizze_30145, skip_threads_30190)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30190 *= 2;\n                    }\n                }\n            }\n    ", "        barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30192 = squot32(local_tid_30143, 32) == 0 || !ltid_in_bounds_30187;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30192) {\n                        eta_p_30181 = eta_p_30180;\n                        eta_p_30180 = ((__local int32_t *) local_mem_30150)[sext_i32_i64(squot32(local_tid_30143, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30192) {\n                        int32_t defunc_0_op_res_30182 = add32(eta_p_30180, eta_p_30181);\n                        \n                        eta_p_30180 = defunc_0_op_res_30182;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30192) {\n                        ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30180;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187) {\n                    ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30181;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30143 == 0) {\n                acc_30183 = ((__local int32_t *) local_mem_30150)[segscan_tblock_sizze_28727 - (int64_t) 1];\n            } else {\n                acc_30183 = ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30193 = 0;\n        block_new_sgm_30194 = sgm_idx_30162 == (int64_t) 0;\n        // Perform l",
                                    "ookback\n        {\n            if (block_new_sgm_30194 && local_tid_30143 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160] = acc_30183;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 2;\n                acc_30183 = 0;\n            }\n            if (!block_new_sgm_30194 && slt32(local_tid_30143, wave_sizze_30145)) {\n                if (local_tid_30143 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_30136)[dynamic_id_30160] = acc_30183;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 1;\n                    \n                    int8_t tmp_30195 = ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30150)[(int64_t) 0] = tmp_30195;\n                }\n                mem_fence_local();\n                \n                int8_t status_30196 = ((__local int8_t *) local_mem_30150)[(int64_t) 0];\n                \n                if (status_30196 == (int8_t) 2) {\n                    if (local_tid_30143 == 0) {\n                        prefix_30193 = ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30197 = sext_i64_i32(dynamic_id_30160 - sext_i32_i64(wave_sizze_30145));\n                    \n                    while (slt32(wave_sizze_30145 * -1, readOffset_30197)) {\n                        int32_t read_i_30198 = readOffset_30197 + local_tid_30143;\n                        int32_t aggr_30199 = 0;\n                        int8_t flag_30200 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30198)) {\n                            flag_30200 = ((volatile __global int8_t *) sta", "tus_flags_mem_30134)[sext_i32_i64(read_i_30198)];\n                            if (flag_30200 == (int8_t) 2) {\n                                aggr_30199 = ((volatile __global int32_t *) incprefixes_mem_30138)[sext_i32_i64(read_i_30198)];\n                            } else if (flag_30200 == (int8_t) 1) {\n                                aggr_30199 = ((volatile __global int32_t *) aggregates_mem_30136)[sext_i32_i64(read_i_30198)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_30150)[(int64_t) 8 + sext_i32_i64(local_tid_30143)] = aggr_30199;\n                        ((__local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = flag_30200;\n                        flag_30200 = ((__local int8_t *) local_mem_30150)[sext_i32_i64(wave_sizze_30145) - (int64_t) 1];\n                        if (slt8(flag_30200, (int8_t) 2)) {\n                            int8_t flg_x_30204;\n                            int8_t flg_y_30205;\n                            int32_t eta_p_30201;\n                            int32_t eta_p_30202;\n                            int32_t skip_threads_30206;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30205 = ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                                eta_p_30202 = ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8 + sext_i32_i64(local_tid_30143)];\n                                if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                                    eta_p_30201 = eta_p_30202;\n                                    flg_x_30204 = flg_y_30205;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30206 = 1;\n                      ", "          while (slt32(skip_threads_30206, 32)) {\n                                    if (sle32(skip_threads_30206, local_tid_30143 - squot32(local_tid_30143, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30204 = ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30206)];\n                                            eta_p_30201 = ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8 + (sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30206))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30205 == (int8_t) 2 || flg_y_30205 == (int8_t) 0) {\n                                                flg_x_30204 = flg_y_30205;\n                                                eta_p_30201 = eta_p_30202;\n                                            } else {\n                                                int32_t defunc_0_op_res_30203 = add32(eta_p_30201, eta_p_30202);\n                                                \n                                                eta_p_30201 = defunc_0_op_res_30203;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = flg_x_30204;\n                                            flg_y_30205 = flg_x_30204;\n                                            ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8 + sext_i32_i64(local_tid_30143)] = eta_p_30201;\n                                            eta_p_30202 = eta_p_30201;\n                                        }\n            ",
                                    "                        }\n                                    skip_threads_30206 *= 2;\n                                }\n                            }\n                        }\n                        flag_30200 = ((__local int8_t *) local_mem_30150)[sext_i32_i64(wave_sizze_30145) - (int64_t) 1];\n                        aggr_30199 = ((__local int32_t *) local_mem_30150)[(int64_t) 8 + (sext_i32_i64(wave_sizze_30145) - (int64_t) 1)];\n                        if (flag_30200 == (int8_t) 2) {\n                            readOffset_30197 = wave_sizze_30145 * -1;\n                        } else if (flag_30200 == (int8_t) 1) {\n                            readOffset_30197 -= wave_sizze_30145;\n                        }\n                        if (slt8((int8_t) 0, flag_30200)) {\n                            int32_t eta_p_30207 = aggr_30199;\n                            int32_t eta_p_30208 = prefix_30193;\n                            int32_t defunc_0_op_res_30209 = add32(eta_p_30207, eta_p_30208);\n                            \n                            prefix_30193 = defunc_0_op_res_30209;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30143 == 0) {\n                    if (boundary_30163 == sext_i64_i32(segscan_tblock_sizze_28727 * chunk_sizze_30131)) {\n                        int32_t eta_p_30210 = prefix_30193;\n                        int32_t eta_p_30211 = acc_30183;\n                        int32_t defunc_0_op_res_30212 = add32(eta_p_30210, eta_p_30211);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160] = defunc_0_op_res_30212;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_30150)[(int64_t) 8] = prefix_30193;\n                    acc_30183 = 0;\n", "                }\n            }\n            if (!(dynamic_id_30160 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30193 = ((__local int32_t *) local_mem_30150)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_30213;\n            int32_t eta_p_30214;\n            int32_t eta_p_30216 = prefix_30193;\n            int32_t eta_p_30217 = acc_30183;\n            \n            if (slt32(local_tid_30143 * chunk_sizze_32b_30147, boundary_30163) && !block_new_sgm_30194) {\n                int32_t defunc_0_op_res_30218 = add32(eta_p_30216, eta_p_30217);\n                \n                eta_p_30213 = defunc_0_op_res_30218;\n            } else {\n                eta_p_30213 = acc_30183;\n            }\n            \n            int32_t stopping_point_30219 = segsizze_compact_30164 - srem32(local_tid_30143 * chunk_sizze_32b_30147 - 1 + segsizze_compact_30164 - boundary_30163, segsizze_compact_30164);\n            \n            for (int64_t i_30220 = 0; i_30220 < chunk_sizze_30131; i_30220++) {\n                if (slt32(sext_i64_i32(i_30220), stopping_point_30219 - 1)) {\n                    eta_p_30214 = private_mem_30165[i_30220];\n                    \n                    int32_t defunc_0_op_res_30215 = add32(eta_p_30213, eta_p_30214);\n                    \n                    private_mem_30165[i_30220] = defunc_0_op_res_30215;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30221 = 0; i_30221 < chunk_sizze_30131; i_30221++) {\n                int64_t sharedIdx_30222 = sext_i32_i64(local_tid_30143) * chunk_sizze_30131 + i_30221;\n                int32_t tmp_30223 = private_mem_30165[i_30221];\n                \n                ((__local int32_t *) local_mem_30150)[sharedIdx_30222] = tmp_30223;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE)", ";\n            for (int64_t i_30224 = 0; i_30224 < chunk_sizze_30131; i_30224++) {\n                int64_t flat_idx_30225 = thd_offset_30167 + i_30224 * segscan_tblock_sizze_28727;\n                int64_t slice_30226 = mz2080U_21995;\n                int64_t gtid_28731 = flat_idx_30225;\n                int64_t remnant_30227 = flat_idx_30225 - gtid_28731;\n                \n                if (slt64(flat_idx_30225, mz2080U_21995)) {\n                    int32_t tmp_30228 = ((__local int32_t *) local_mem_30150)[flat_idx_30225 - block_offset_30161];\n                    \n                    ((__global int32_t *) mem_29692)[gtid_28731] = tmp_30228;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28727\n    #undef chunk_sizze_30131\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegscan_28885_dim1, 1, 1)\nvoid human_genericf64zisegscan_28885(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_21995, int64_t nz2081U_21996, int64_t num_tblocks_28882, int64_t num_virt_blocks_30441, int64_t num_virt_threads_30442, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *mem_29709, __global unsigned char *mem_29712, __global unsigned char *mem_29714, __global unsigned char *status_flags_mem_30443, __global unsigned char *aggregates_mem_30445, __global unsigned char *incprefixes_mem_30447, __global unsigned char *global_dynid_mem_30449)\n{\n    #define segscan_tblock_sizze_28880 (human_genericf64zisegscan_28885zisegscan_tblock_sizze_28880)\n    #define chunk_sizze_30440 (human_genericf64zisegscan_28885zichunk_sizze_30440)\n    \n    volatile __local unsigned char *local_mem_30459_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30459_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28880), chunk_sizze_30440 * segscan",
                                    "_tblock_sizze_28880 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28880), chunk_sizze_30440 * segscan_tblock_sizze_28880 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30452;\n    int32_t tblock_sizze_30455;\n    int32_t wave_sizze_30454;\n    int32_t block_id_30453;\n    int32_t global_tid_30451;\n    int64_t phys_tid_28885;\n    int32_t chunk_sizze_32b_30456;\n    int64_t byte_offsets_30457;\n    int64_t warp_byte_offset_30458;\n    __local unsigned char *local_mem_30459;\n    int64_t trans_arr_len_30460;\n    int64_t phys_block_id_30466;\n    int64_t virtloop_bound_30467;\n    \n    local_tid_30452 = get_local_id(0);\n    tblock_sizze_30455 = get_local_size(0);\n    wave_sizze_30454 = LOCKSTEP_WIDTH;\n    block_id_30453 = get_tblock_id(0);\n    global_tid_30451 = block_id_30453 * tblock_sizze_30455 + local_tid_30452;\n    phys_tid_28885 = sext_i32_i64(global_tid_30451);\n    chunk_sizze_32b_30456 = sext_i64_i32(chunk_sizze_30440);\n    byte_offsets_30457 = segscan_tblock_sizze_28880 * (int64_t) 8;\n    warp_byte_offset_30458 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30459 = (__local unsigned char *) local_mem_30459_backing_0;\n    trans_arr_len_30460 = chunk_sizze_30440 * segscan_tblock_sizze_28880;\n    phys_block_id_30466 = get_tblock_id(0);\n    virtloop_bound_30467 = sdiv_up64(num_virt_blocks_30441 - phys_block_id_30466, num_tblocks_28882);\n    for (int64_t virtloop_i_30468 = 0; virtloop_i_30468 < virtloop_bound_30467; virtloop_i_30468++) {\n        int64_t dynamic_id_30469;\n        int64_t block_offset_30470;\n        int64_t sgm_idx_30471;\n        int32_t boundary_30472;\n        int32_t segsizze_compact_30473;\n        int64_t private_", "mem_30474[chunk_sizze_30440];\n        int64_t thd_offset_30476;\n        int64_t acc_30492;\n        int64_t prefix_30502;\n        bool block_new_sgm_30503;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30452 == 0) {\n                dynamic_id_30469 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30449)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30459)[(int64_t) 0] = dynamic_id_30469;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30469 == num_virt_blocks_30441 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30449)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30469 = ((__local int32_t *) local_mem_30459)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30470 = dynamic_id_30469 * chunk_sizze_30440 * segscan_tblock_sizze_28880;\n        sgm_idx_30471 = smod64(block_offset_30470, nz2081U_21996);\n        boundary_30472 = sext_i64_i32(smin64(chunk_sizze_30440 * segscan_tblock_sizze_28880, nz2081U_21996 - sgm_idx_30471));\n        segsizze_compact_30473 = sext_i64_i32(smin64(chunk_sizze_30440 * segscan_tblock_sizze_28880, nz2081U_21996));\n        thd_offset_30476 = block_offset_30470 + sext_i32_i64(local_tid_30452);\n        // Load and map\n        {\n            for (int64_t i_30477 = 0; i_30477 < chunk_sizze_30440; i_30477++) {\n                int64_t virt_tid_30478 = thd_offset_30476 + i_30477 * segscan_tblock_sizze_28880;\n                int64_t slice_30479 = nz2081U_21996;\n                int64_t gtid_28884 = virt_tid_30478;\n                int64_t remnant_30480 = virt_tid_30478 - gtid_28884;\n                \n                if (slt64(virt_ti", "d_30478, nz2081U_21996)) {\n                    int32_t eta_p_27407 = ((__global int32_t *) II1_mem_29679)[gtid_28884];\n                    int64_t ii_27408 = sext_i32_i64(eta_p_27407);\n                    bool x_27409 = sle64((int64_t) 0, ii_27408);\n                    bool y_27410 = slt64(ii_27408, mz2080U_21995);\n                    bool bounds_check_27411 = x_27409 && y_27410;\n                    bool index_certs_27412;\n                    \n                    if (!bounds_check_27411) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 15) == -1) {\n                                global_failure_args[0] = (int64_t) ii_27408;\n                                global_failure_args[1] = (int64_t) mz2080U_21995;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int32_t zeze_lhs_27413 = ((__global int32_t *) mem_29709)[ii_27408];\n                    bool cond_27414 = zeze_lhs_27413 == -1;\n                    bool defunc_0_p_res_27415;\n                    \n                    if (cond_27414) {\n                        defunc_0_p_res_27415 = 0;\n                    } else {\n                        double eta_p_27406 = ((__global double *) A_mem_29680)[gtid_28884];\n                        bool cond_27416 = zeze_lhs_27413 == 0;\n                        bool defunc_0_p_res_f_res_27417;\n                        \n                        if (cond_27416) {\n                            double lt_arg1_28159 = ((__global double *) mem_29695)[ii_27408];\n                            bool defunc_0_lt_res_28160 = eta_p_27406 < lt_arg1_28159;\n                            \n                            defunc_0_p_res_f_res_27417 = defunc_0_lt_res_28160;\n                        } else {\n                            bool cond_27420 = zeze_lhs_27413 == 1;\n     ",
                                    "                       bool defunc_0_p_res_f_res_f_res_27421;\n                            \n                            if (cond_27420) {\n                                defunc_0_p_res_f_res_f_res_27421 = 0;\n                            } else {\n                                double lt_arg1_27422 = ((__global double *) mem_29695)[ii_27408];\n                                bool defunc_0_lt_res_27423 = eta_p_27406 < lt_arg1_27422;\n                                bool cond_27424 = !defunc_0_lt_res_27423;\n                                bool defunc_0_eq_res_27425 = eta_p_27406 == lt_arg1_27422;\n                                bool defunc_0_p_res_f_res_f_res_f_res_t_res_27426 = !defunc_0_eq_res_27425;\n                                bool x_27427 = cond_27424 && defunc_0_p_res_f_res_f_res_f_res_t_res_27426;\n                                \n                                defunc_0_p_res_f_res_f_res_27421 = x_27427;\n                            }\n                            defunc_0_p_res_f_res_27417 = defunc_0_p_res_f_res_f_res_27421;\n                        }\n                        defunc_0_p_res_27415 = defunc_0_p_res_f_res_27417;\n                    }\n                    \n                    int64_t defunc_0_f_res_27428 = btoi_bool_i64(defunc_0_p_res_27415);\n                    \n                    ((__global int64_t *) mem_29714)[gtid_28884] = defunc_0_f_res_27428;\n                    private_mem_30474[i_30477] = defunc_0_f_res_27428;\n                } else {\n                    private_mem_30474[i_30477] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30481 = 0; i_30481 < chunk_sizze_30440; i_30481++) {\n                int64_t sharedIdx_30482 = sext_i32_i64(local_tid_30452) + i_30481 * segscan_tblock_sizze_28880;\n                int64_t tmp_30483 ", "= private_mem_30474[i_30481];\n                \n                ((__local int64_t *) local_mem_30459)[sharedIdx_30482] = tmp_30483;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30484 = 0; i_30484 < chunk_sizze_30440; i_30484++) {\n                int64_t sharedIdx_30485 = sext_i32_i64(local_tid_30452) * chunk_sizze_30440 + i_30484;\n                int64_t tmp_30486 = ((__local int64_t *) local_mem_30459)[sharedIdx_30485];\n                \n                private_mem_30474[i_30484] = tmp_30486;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30487 = 0; i_30487 < chunk_sizze_30440 - (int64_t) 1; i_30487++) {\n                int64_t eta_p_27075;\n                int64_t eta_p_27076;\n                \n                eta_p_27075 = private_mem_30474[i_30487];\n                eta_p_27076 = private_mem_30474[i_30487 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27077 = add64(eta_p_27075, eta_p_27076);\n                \n                private_mem_30474[i_30487 + (int64_t) 1] = defunc_0_op_res_27077;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_30488 = private_mem_30474[chunk_sizze_30440 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = tmp_30488;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_30489;\n            int64_t eta_p_30490;\n            int64_t eta_p_30493;\n            int64_t eta_p_30494;\n            bool ltid_in_bounds_30496 = slt64(sext_i32_i64(local_tid_30452), num_virt_threads_30442);\n            int32_t skip_threads_30497;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30496) {\n                    eta_p_30490 = ((volatile __local int64_t *) local_mem_30459)[sext_i32", "_i64(local_tid_30452)];\n                    if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 0) {\n                        eta_p_30489 = eta_p_30490;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30497 = 1;\n                while (slt32(skip_threads_30497, 32)) {\n                    bool thread_active_30498 = sle32(skip_threads_30497, local_tid_30452 - squot32(local_tid_30452, 32) * 32) && ltid_in_bounds_30496;\n                    \n                    if (thread_active_30498) {\n                        // read operands\n                        {\n                            eta_p_30489 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30497)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30498) {\n                            int64_t defunc_0_op_res_30491 = add64(eta_p_30489, eta_p_30490);\n                            \n                            eta_p_30489 = defunc_0_op_res_30491;\n                        }\n                    }\n                    if (sle32(wave_sizze_30454, skip_threads_30497)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30498) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30489;\n                            eta_p_30490 = eta_p_30489;\n                        }\n                    }\n                    if (sle32(wave_sizze_30454, skip_threads_30497)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30497 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread",
                                    " of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 31 && ltid_in_bounds_30496) {\n                    ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(squot32(local_tid_30452, 32))] = eta_p_30489;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30499;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496) {\n                        eta_p_30494 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)];\n                        if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 0) {\n                            eta_p_30493 = eta_p_30494;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30499 = 1;\n                    while (slt32(skip_threads_30499, 32)) {\n                        bool thread_active_30500 = sle32(skip_threads_30499, local_tid_30452 - squot32(local_tid_30452, 32) * 32) && (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496);\n                        \n                        if (thread_active_30500) {\n                            // read operands\n                            {\n                                eta_p_30493 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30499)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30500) {\n                                int64_t defunc_0_op_res_30495 = add64(eta_p_30493, eta_p_30494);\n               ", "                 \n                                eta_p_30493 = defunc_0_op_res_30495;\n                            }\n                        }\n                        if (sle32(wave_sizze_30454, skip_threads_30499)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30500) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30493;\n                                eta_p_30494 = eta_p_30493;\n                            }\n                        }\n                        if (sle32(wave_sizze_30454, skip_threads_30499)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30499 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30501 = squot32(local_tid_30452, 32) == 0 || !ltid_in_bounds_30496;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30501) {\n                        eta_p_30490 = eta_p_30489;\n                        eta_p_30489 = ((__local int64_t *) local_mem_30459)[sext_i32_i64(squot32(local_tid_30452, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30501) {\n                        int64_t defunc_0_op_res_30491 = add64(eta_p_30489, eta_p_30490);\n                        \n                        eta_p_30489 = defunc_0_op_res_30491;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30501) {\n                        ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] =", " eta_p_30489;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496) {\n                    ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30490;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30452 == 0) {\n                acc_30492 = ((__local int64_t *) local_mem_30459)[segscan_tblock_sizze_28880 - (int64_t) 1];\n            } else {\n                acc_30492 = ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30502 = (int64_t) 0;\n        block_new_sgm_30503 = sgm_idx_30471 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30503 && local_tid_30452 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469] = acc_30492;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 2;\n                acc_30492 = (int64_t) 0;\n            }\n            if (!block_new_sgm_30503 && slt32(local_tid_30452, wave_sizze_30454)) {\n                if (local_tid_30452 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_30445)[dynamic_id_30469] = acc_30492;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 1;\n                    \n                    int8_t tmp_30504 = ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30459)[(int64_t) 0] = tmp_30504;\n                }\n                mem_fence_",
                                    "local();\n                \n                int8_t status_30505 = ((__local int8_t *) local_mem_30459)[(int64_t) 0];\n                \n                if (status_30505 == (int8_t) 2) {\n                    if (local_tid_30452 == 0) {\n                        prefix_30502 = ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30506 = sext_i64_i32(dynamic_id_30469 - sext_i32_i64(wave_sizze_30454));\n                    \n                    while (slt32(wave_sizze_30454 * -1, readOffset_30506)) {\n                        int32_t read_i_30507 = readOffset_30506 + local_tid_30452;\n                        int64_t aggr_30508 = (int64_t) 0;\n                        int8_t flag_30509 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30507)) {\n                            flag_30509 = ((volatile __global int8_t *) status_flags_mem_30443)[sext_i32_i64(read_i_30507)];\n                            if (flag_30509 == (int8_t) 2) {\n                                aggr_30508 = ((volatile __global int64_t *) incprefixes_mem_30447)[sext_i32_i64(read_i_30507)];\n                            } else if (flag_30509 == (int8_t) 1) {\n                                aggr_30508 = ((volatile __global int64_t *) aggregates_mem_30445)[sext_i32_i64(read_i_30507)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)] = aggr_30508;\n                        ((__local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = flag_30509;\n                        flag_30509 = ((__local int8_t *) local_mem_30459)[sext_i32_i64(wave_sizze_30454) - (int64_t) 1];\n                        if (slt8(flag_30509, (int8_t) 2)) {\n                            int8_t flg_x_30513;\n                            int8_t flg_y_30514;\n                            int64_t eta_p_305", "10;\n                            int64_t eta_p_30511;\n                            int32_t skip_threads_30515;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30514 = ((volatile __local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)];\n                                eta_p_30511 = ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)];\n                                if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 0) {\n                                    eta_p_30510 = eta_p_30511;\n                                    flg_x_30513 = flg_y_30514;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30515 = 1;\n                                while (slt32(skip_threads_30515, 32)) {\n                                    if (sle32(skip_threads_30515, local_tid_30452 - squot32(local_tid_30452, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30513 = ((volatile __local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30515)];\n                                            eta_p_30510 = ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + (sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30515))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30514 == (int8_t) 2 || flg_y_30514 == (int8_t) 0) {\n                                                flg_x_30513 = flg_y_30514;\n                                                eta_p_30510 = eta_p_30511;\n      ", "                                      } else {\n                                                int64_t defunc_0_op_res_30512 = add64(eta_p_30510, eta_p_30511);\n                                                \n                                                eta_p_30510 = defunc_0_op_res_30512;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = flg_x_30513;\n                                            flg_y_30514 = flg_x_30513;\n                                            ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)] = eta_p_30510;\n                                            eta_p_30511 = eta_p_30510;\n                                        }\n                                    }\n                                    skip_threads_30515 *= 2;\n                                }\n                            }\n                        }\n                        flag_30509 = ((__local int8_t *) local_mem_30459)[sext_i32_i64(wave_sizze_30454) - (int64_t) 1];\n                        aggr_30508 = ((__local int64_t *) local_mem_30459)[(int64_t) 4 + (sext_i32_i64(wave_sizze_30454) - (int64_t) 1)];\n                        if (flag_30509 == (int8_t) 2) {\n                            readOffset_30506 = wave_sizze_30454 * -1;\n                        } else if (flag_30509 == (int8_t) 1) {\n                            readOffset_30506 -= wave_sizze_30454;\n                        }\n                        if (slt8((int8_t) 0, flag_30509)) {\n                            int64_t eta_p_30516 = aggr_30508;\n                            int64_t eta_p_30517 = prefix_30502;\n                            int64_t defunc_0_op_res_30518 = add64(eta_p_30516, eta_p_30517);\n                            \n            ",
                                    "                prefix_30502 = defunc_0_op_res_30518;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30452 == 0) {\n                    if (boundary_30472 == sext_i64_i32(segscan_tblock_sizze_28880 * chunk_sizze_30440)) {\n                        int64_t eta_p_30519 = prefix_30502;\n                        int64_t eta_p_30520 = acc_30492;\n                        int64_t defunc_0_op_res_30521 = add64(eta_p_30519, eta_p_30520);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469] = defunc_0_op_res_30521;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_30459)[(int64_t) 4] = prefix_30502;\n                    acc_30492 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_30469 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30502 = ((__local int64_t *) local_mem_30459)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_30522;\n            int64_t eta_p_30523;\n            int64_t eta_p_30525 = prefix_30502;\n            int64_t eta_p_30526 = acc_30492;\n            \n            if (slt32(local_tid_30452 * chunk_sizze_32b_30456, boundary_30472) && !block_new_sgm_30503) {\n                int64_t defunc_0_op_res_30527 = add64(eta_p_30525, eta_p_30526);\n                \n                eta_p_30522 = defunc_0_op_res_30527;\n            } else {\n                eta_p_30522 = acc_30492;\n            }\n            \n            int32_t stopping_point_30528 = segsizze_compact_30473 - srem32(local_tid_30452 * chunk_sizze_32b_30456 - 1 + segsizze_compact_30473 - boundary_30472, segsizze_compact_30473", ");\n            \n            for (int64_t i_30529 = 0; i_30529 < chunk_sizze_30440; i_30529++) {\n                if (slt32(sext_i64_i32(i_30529), stopping_point_30528 - 1)) {\n                    eta_p_30523 = private_mem_30474[i_30529];\n                    \n                    int64_t defunc_0_op_res_30524 = add64(eta_p_30522, eta_p_30523);\n                    \n                    private_mem_30474[i_30529] = defunc_0_op_res_30524;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30530 = 0; i_30530 < chunk_sizze_30440; i_30530++) {\n                int64_t sharedIdx_30531 = sext_i32_i64(local_tid_30452) * chunk_sizze_30440 + i_30530;\n                int64_t tmp_30532 = private_mem_30474[i_30530];\n                \n                ((__local int64_t *) local_mem_30459)[sharedIdx_30531] = tmp_30532;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30533 = 0; i_30533 < chunk_sizze_30440; i_30533++) {\n                int64_t flat_idx_30534 = thd_offset_30476 + i_30533 * segscan_tblock_sizze_28880;\n                int64_t slice_30535 = nz2081U_21996;\n                int64_t gtid_28884 = flat_idx_30534;\n                int64_t remnant_30536 = flat_idx_30534 - gtid_28884;\n                \n                if (slt64(flat_idx_30534, nz2081U_21996)) {\n                    int64_t tmp_30537 = ((__local int64_t *) local_mem_30459)[flat_idx_30534 - block_offset_30470];\n                    \n                    ((__global int64_t *) mem_29712)[gtid_28884] = tmp_30537;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28880\n    #undef chunk_sizze_30440\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegscan_28901_dim1, 1, 1)\nvoid human_genericf64zisegscan_28901(__global int *global_failure, int64_t mz2080U_21995, int64_t num_tblocks_28898, int64_t num", "_virt_blocks_30570, int64_t num_virt_threads_30571, __global unsigned char *mem_param_29725, __global unsigned char *mem_29737, __global unsigned char *status_flags_mem_30572, __global unsigned char *aggregates_mem_30574, __global unsigned char *incprefixes_mem_30576, __global unsigned char *global_dynid_mem_30578)\n{\n    #define segscan_tblock_sizze_28896 (human_genericf64zisegscan_28901zisegscan_tblock_sizze_28896)\n    #define chunk_sizze_30569 (human_genericf64zisegscan_28901zichunk_sizze_30569)\n    \n    volatile __local unsigned char *local_mem_30588_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30588_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28896), chunk_sizze_30569 * segscan_tblock_sizze_28896 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28896), chunk_sizze_30569 * segscan_tblock_sizze_28896 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30581;\n    int32_t tblock_sizze_30584;\n    int32_t wave_sizze_30583;\n    int32_t block_id_30582;\n    int32_t global_tid_30580;\n    int64_t phys_tid_28901;\n    int32_t chunk_sizze_32b_30585;\n    int64_t byte_offsets_30586;\n    int64_t warp_byte_offset_30587;\n    __local unsigned char *local_mem_30588;\n    int64_t trans_arr_len_30589;\n    int64_t phys_block_id_30595;\n    int64_t virtloop_bound_30596;\n    \n    local_tid_30581 = get_local_id(0);\n    tblock_sizze_30584 = get_local_size(0);\n    wave_sizze_30583 = LOCKSTEP_WIDTH;\n    block_id_30582 = get_tblock_id(0);\n    global_tid_30580 = block_id_30582 * tblock_sizze_30584 + local_tid_30581;\n    phys_tid_28901 = sext_i32_i64(global_tid_30580);\n    chunk_sizze_32b_30585 = sext_i64_i32(chunk_sizze_30569);\n    byte_offsets_30586 = segscan_tblock_sizze_28896 * (int64_t) 4;\n    warp_byte_offset_30587 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30588 = (__local",
                                    " unsigned char *) local_mem_30588_backing_0;\n    trans_arr_len_30589 = chunk_sizze_30569 * segscan_tblock_sizze_28896;\n    phys_block_id_30595 = get_tblock_id(0);\n    virtloop_bound_30596 = sdiv_up64(num_virt_blocks_30570 - phys_block_id_30595, num_tblocks_28898);\n    for (int64_t virtloop_i_30597 = 0; virtloop_i_30597 < virtloop_bound_30596; virtloop_i_30597++) {\n        int64_t dynamic_id_30598;\n        int64_t block_offset_30599;\n        int64_t sgm_idx_30600;\n        int32_t boundary_30601;\n        int32_t segsizze_compact_30602;\n        int32_t private_mem_30603[chunk_sizze_30569];\n        int64_t thd_offset_30605;\n        int32_t acc_30621;\n        int32_t prefix_30631;\n        bool block_new_sgm_30632;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30581 == 0) {\n                dynamic_id_30598 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30578)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30588)[(int64_t) 0] = dynamic_id_30598;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30598 == num_virt_blocks_30570 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30578)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30598 = ((__local int32_t *) local_mem_30588)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30599 = dynamic_id_30598 * chunk_sizze_30569 * segscan_tblock_sizze_28896;\n        sgm_idx_30600 = smod64(block_offset_30599, mz2080U_21995);\n        boundary_30601 = sext_i64_i32(smin64(chunk_sizze_30569 * segscan_tblock_sizze_28896, mz2080U_21995 - sgm_idx_30600));\n        segsizze_compact_30602 = sext_i64_i32(smin64(chunk_sizze_30569", " * segscan_tblock_sizze_28896, mz2080U_21995));\n        thd_offset_30605 = block_offset_30599 + sext_i32_i64(local_tid_30581);\n        // Load and map\n        {\n            for (int64_t i_30606 = 0; i_30606 < chunk_sizze_30569; i_30606++) {\n                int64_t virt_tid_30607 = thd_offset_30605 + i_30606 * segscan_tblock_sizze_28896;\n                int64_t slice_30608 = mz2080U_21995;\n                int64_t gtid_28900 = virt_tid_30607;\n                int64_t remnant_30609 = virt_tid_30607 - gtid_28900;\n                \n                if (slt64(virt_tid_30607, mz2080U_21995)) {\n                    int32_t x_27136 = ((__global int32_t *) mem_param_29725)[gtid_28900];\n                    \n                    private_mem_30603[i_30606] = x_27136;\n                } else {\n                    private_mem_30603[i_30606] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30610 = 0; i_30610 < chunk_sizze_30569; i_30610++) {\n                int64_t sharedIdx_30611 = sext_i32_i64(local_tid_30581) + i_30610 * segscan_tblock_sizze_28896;\n                int32_t tmp_30612 = private_mem_30603[i_30610];\n                \n                ((__local int32_t *) local_mem_30588)[sharedIdx_30611] = tmp_30612;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30613 = 0; i_30613 < chunk_sizze_30569; i_30613++) {\n                int64_t sharedIdx_30614 = sext_i32_i64(local_tid_30581) * chunk_sizze_30569 + i_30613;\n                int32_t tmp_30615 = ((__local int32_t *) local_mem_30588)[sharedIdx_30614];\n                \n                private_mem_30603[i_30613] = tmp_30615;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30616 = 0; i_30616 < chunk_sizze_30569 - (int64_t) 1; i_30616++) {\n                int32_t eta_p_27133;\n                int32_t eta_p_27134;\n        ", "        \n                eta_p_27133 = private_mem_30603[i_30616];\n                eta_p_27134 = private_mem_30603[i_30616 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_27135 = add32(eta_p_27133, eta_p_27134);\n                \n                private_mem_30603[i_30616 + (int64_t) 1] = defunc_0_op_res_27135;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_30617 = private_mem_30603[chunk_sizze_30569 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = tmp_30617;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_30618;\n            int32_t eta_p_30619;\n            int32_t eta_p_30622;\n            int32_t eta_p_30623;\n            bool ltid_in_bounds_30625 = slt64(sext_i32_i64(local_tid_30581), num_virt_threads_30571);\n            int32_t skip_threads_30626;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30625) {\n                    eta_p_30619 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)];\n                    if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                        eta_p_30618 = eta_p_30619;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30626 = 1;\n                while (slt32(skip_threads_30626, 32)) {\n                    bool thread_active_30627 = sle32(skip_threads_30626, local_tid_30581 - squot32(local_tid_30581, 32) * 32) && ltid_in_bounds_30625;\n                    \n                    if (thread_active_30627) {\n                        // read operands\n                        {\n                            eta_p_30618 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_thre",
                                    "ads_30626)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30627) {\n                            int32_t defunc_0_op_res_30620 = add32(eta_p_30618, eta_p_30619);\n                            \n                            eta_p_30618 = defunc_0_op_res_30620;\n                        }\n                    }\n                    if (sle32(wave_sizze_30583, skip_threads_30626)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30627) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30618;\n                            eta_p_30619 = eta_p_30618;\n                        }\n                    }\n                    if (sle32(wave_sizze_30583, skip_threads_30626)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30626 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 31 && ltid_in_bounds_30625) {\n                    ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(squot32(local_tid_30581, 32))] = eta_p_30618;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30628;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30581, 32) == 0 && ltid_in_bounds_30625) {\n                        eta_p_30623 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)];\n          ", "              if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                            eta_p_30622 = eta_p_30623;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30628 = 1;\n                    while (slt32(skip_threads_30628, 32)) {\n                        bool thread_active_30629 = sle32(skip_threads_30628, local_tid_30581 - squot32(local_tid_30581, 32) * 32) && (squot32(local_tid_30581, 32) == 0 && ltid_in_bounds_30625);\n                        \n                        if (thread_active_30629) {\n                            // read operands\n                            {\n                                eta_p_30622 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30628)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30629) {\n                                int32_t defunc_0_op_res_30624 = add32(eta_p_30622, eta_p_30623);\n                                \n                                eta_p_30622 = defunc_0_op_res_30624;\n                            }\n                        }\n                        if (sle32(wave_sizze_30583, skip_threads_30628)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30629) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30622;\n                                eta_p_30623 = eta_p_30622;\n                            }\n                        }\n                        if (sle32(wave_sizze_30583, skip_threads_30628)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n              ", "          }\n                        skip_threads_30628 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30630 = squot32(local_tid_30581, 32) == 0 || !ltid_in_bounds_30625;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30630) {\n                        eta_p_30619 = eta_p_30618;\n                        eta_p_30618 = ((__local int32_t *) local_mem_30588)[sext_i32_i64(squot32(local_tid_30581, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30630) {\n                        int32_t defunc_0_op_res_30620 = add32(eta_p_30618, eta_p_30619);\n                        \n                        eta_p_30618 = defunc_0_op_res_30620;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30630) {\n                        ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30618;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30581, 32) == 0 && ltid_in_bounds_30625) {\n                    ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30619;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30581 == 0) {\n                acc_30621 = ((__local int32_t *) local_mem_30588)[segscan_tblock_sizze_28896 - (int64_t) 1];\n            } else {\n                acc_30621 = ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE",
                                    ");\n        }\n        prefix_30631 = 0;\n        block_new_sgm_30632 = sgm_idx_30600 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30632 && local_tid_30581 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598] = acc_30621;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 2;\n                acc_30621 = 0;\n            }\n            if (!block_new_sgm_30632 && slt32(local_tid_30581, wave_sizze_30583)) {\n                if (local_tid_30581 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_30574)[dynamic_id_30598] = acc_30621;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 1;\n                    \n                    int8_t tmp_30633 = ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30588)[(int64_t) 0] = tmp_30633;\n                }\n                mem_fence_local();\n                \n                int8_t status_30634 = ((__local int8_t *) local_mem_30588)[(int64_t) 0];\n                \n                if (status_30634 == (int8_t) 2) {\n                    if (local_tid_30581 == 0) {\n                        prefix_30631 = ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30635 = sext_i64_i32(dynamic_id_30598 - sext_i32_i64(wave_sizze_30583));\n                    \n                    while (slt32(wave_sizze_30583 * -1, readOffset_30635)) {\n                        int32_t read_i_30636 = readOffset_30635 + local_tid_30581;\n                        int32_t aggr_30637 = 0;\n                        int8_t flag_30638 = (int8_t) 0;\n                        \n         ", "               if (sle32(0, read_i_30636)) {\n                            flag_30638 = ((volatile __global int8_t *) status_flags_mem_30572)[sext_i32_i64(read_i_30636)];\n                            if (flag_30638 == (int8_t) 2) {\n                                aggr_30637 = ((volatile __global int32_t *) incprefixes_mem_30576)[sext_i32_i64(read_i_30636)];\n                            } else if (flag_30638 == (int8_t) 1) {\n                                aggr_30637 = ((volatile __global int32_t *) aggregates_mem_30574)[sext_i32_i64(read_i_30636)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)] = aggr_30637;\n                        ((__local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = flag_30638;\n                        flag_30638 = ((__local int8_t *) local_mem_30588)[sext_i32_i64(wave_sizze_30583) - (int64_t) 1];\n                        if (slt8(flag_30638, (int8_t) 2)) {\n                            int8_t flg_x_30642;\n                            int8_t flg_y_30643;\n                            int32_t eta_p_30639;\n                            int32_t eta_p_30640;\n                            int32_t skip_threads_30644;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30643 = ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)];\n                                eta_p_30640 = ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)];\n                                if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                                    eta_p_30639 = eta_p_30640;\n                                    flg_x_30642 = flg_y_30643;\n                                }\n                            }\n                            // in-block scan (hopefully no barrie", "rs needed)\n                            {\n                                skip_threads_30644 = 1;\n                                while (slt32(skip_threads_30644, 32)) {\n                                    if (sle32(skip_threads_30644, local_tid_30581 - squot32(local_tid_30581, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30642 = ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30644)];\n                                            eta_p_30639 = ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + (sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30644))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30643 == (int8_t) 2 || flg_y_30643 == (int8_t) 0) {\n                                                flg_x_30642 = flg_y_30643;\n                                                eta_p_30639 = eta_p_30640;\n                                            } else {\n                                                int32_t defunc_0_op_res_30641 = add32(eta_p_30639, eta_p_30640);\n                                                \n                                                eta_p_30639 = defunc_0_op_res_30641;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = flg_x_30642;\n                                            flg_y_30643 = flg_x_30642;\n                                            ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)] = eta_p_30639;\n      ",
                                    "                                      eta_p_30640 = eta_p_30639;\n                                        }\n                                    }\n                                    skip_threads_30644 *= 2;\n                                }\n                            }\n                        }\n                        flag_30638 = ((__local int8_t *) local_mem_30588)[sext_i32_i64(wave_sizze_30583) - (int64_t) 1];\n                        aggr_30637 = ((__local int32_t *) local_mem_30588)[(int64_t) 8 + (sext_i32_i64(wave_sizze_30583) - (int64_t) 1)];\n                        if (flag_30638 == (int8_t) 2) {\n                            readOffset_30635 = wave_sizze_30583 * -1;\n                        } else if (flag_30638 == (int8_t) 1) {\n                            readOffset_30635 -= wave_sizze_30583;\n                        }\n                        if (slt8((int8_t) 0, flag_30638)) {\n                            int32_t eta_p_30645 = aggr_30637;\n                            int32_t eta_p_30646 = prefix_30631;\n                            int32_t defunc_0_op_res_30647 = add32(eta_p_30645, eta_p_30646);\n                            \n                            prefix_30631 = defunc_0_op_res_30647;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30581 == 0) {\n                    if (boundary_30601 == sext_i64_i32(segscan_tblock_sizze_28896 * chunk_sizze_30569)) {\n                        int32_t eta_p_30648 = prefix_30631;\n                        int32_t eta_p_30649 = acc_30621;\n                        int32_t defunc_0_op_res_30650 = add32(eta_p_30648, eta_p_30649);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598] = defunc_0_op_res_30650;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 2;\n                    }\n   ", "                 ((__local int32_t *) local_mem_30588)[(int64_t) 8] = prefix_30631;\n                    acc_30621 = 0;\n                }\n            }\n            if (!(dynamic_id_30598 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30631 = ((__local int32_t *) local_mem_30588)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_30651;\n            int32_t eta_p_30652;\n            int32_t eta_p_30654 = prefix_30631;\n            int32_t eta_p_30655 = acc_30621;\n            \n            if (slt32(local_tid_30581 * chunk_sizze_32b_30585, boundary_30601) && !block_new_sgm_30632) {\n                int32_t defunc_0_op_res_30656 = add32(eta_p_30654, eta_p_30655);\n                \n                eta_p_30651 = defunc_0_op_res_30656;\n            } else {\n                eta_p_30651 = acc_30621;\n            }\n            \n            int32_t stopping_point_30657 = segsizze_compact_30602 - srem32(local_tid_30581 * chunk_sizze_32b_30585 - 1 + segsizze_compact_30602 - boundary_30601, segsizze_compact_30602);\n            \n            for (int64_t i_30658 = 0; i_30658 < chunk_sizze_30569; i_30658++) {\n                if (slt32(sext_i64_i32(i_30658), stopping_point_30657 - 1)) {\n                    eta_p_30652 = private_mem_30603[i_30658];\n                    \n                    int32_t defunc_0_op_res_30653 = add32(eta_p_30651, eta_p_30652);\n                    \n                    private_mem_30603[i_30658] = defunc_0_op_res_30653;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30659 = 0; i_30659 < chunk_sizze_30569; i_30659++) {\n                int64_t sharedIdx_30660 = sext_i32_i64(local_tid_30581) * chunk_sizze_30569 + i_30659;\n                int32_t tmp_30661 = private_mem_30603[i_30659];\n                \n                ((_", "_local int32_t *) local_mem_30588)[sharedIdx_30660] = tmp_30661;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30662 = 0; i_30662 < chunk_sizze_30569; i_30662++) {\n                int64_t flat_idx_30663 = thd_offset_30605 + i_30662 * segscan_tblock_sizze_28896;\n                int64_t slice_30664 = mz2080U_21995;\n                int64_t gtid_28900 = flat_idx_30663;\n                int64_t remnant_30665 = flat_idx_30663 - gtid_28900;\n                \n                if (slt64(flat_idx_30663, mz2080U_21995)) {\n                    int32_t tmp_30666 = ((__local int32_t *) local_mem_30588)[flat_idx_30663 - block_offset_30599];\n                    \n                    ((__global int32_t *) mem_29737)[gtid_28900] = tmp_30666;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_28896\n    #undef chunk_sizze_30569\n}\nFUTHARK_KERNEL_SIZED(human_genericf64zisegscan_29178_dim1, 1, 1)\nvoid human_genericf64zisegscan_29178(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_21995, int64_t loop_dz2081Uz2088Uz2087U_27125, int64_t num_tblocks_29175, int64_t num_virt_blocks_30879, int64_t num_virt_threads_30880, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *mem_29754, __global unsigned char *mem_29757, __global unsigned char *mem_29759, __global unsigned char *status_flags_mem_30881, __global unsigned char *aggregates_mem_30883, __global unsigned char *incprefixes_mem_30885, __global unsigned char *global_dynid_mem_30887)\n{\n    #define segscan_tblock_sizze_29173 (human_genericf64zisegscan_29178zisegscan_tblock_sizze_29173)\n    #define chunk_sizze_30878 (human_genericf64zisegscan_29178zichunk_sizze_30878)\n    \n    volatile __local unsigned char *local_mem_30897_backing_0 = &shared_mem[0];\n    const int64",
                                    "_t local_mem_30897_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29173), chunk_sizze_30878 * segscan_tblock_sizze_29173 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29173), chunk_sizze_30878 * segscan_tblock_sizze_29173 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30890;\n    int32_t tblock_sizze_30893;\n    int32_t wave_sizze_30892;\n    int32_t block_id_30891;\n    int32_t global_tid_30889;\n    int64_t phys_tid_29178;\n    int32_t chunk_sizze_32b_30894;\n    int64_t byte_offsets_30895;\n    int64_t warp_byte_offset_30896;\n    __local unsigned char *local_mem_30897;\n    int64_t trans_arr_len_30898;\n    int64_t phys_block_id_30904;\n    int64_t virtloop_bound_30905;\n    \n    local_tid_30890 = get_local_id(0);\n    tblock_sizze_30893 = get_local_size(0);\n    wave_sizze_30892 = LOCKSTEP_WIDTH;\n    block_id_30891 = get_tblock_id(0);\n    global_tid_30889 = block_id_30891 * tblock_sizze_30893 + local_tid_30890;\n    phys_tid_29178 = sext_i32_i64(global_tid_30889);\n    chunk_sizze_32b_30894 = sext_i64_i32(chunk_sizze_30878);\n    byte_offsets_30895 = segscan_tblock_sizze_29173 * (int64_t) 8;\n    warp_byte_offset_30896 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30897 = (__local unsigned char *) local_mem_30897_backing_0;\n    trans_arr_len_30898 = chunk_sizze_30878 * segscan_tblock_sizze_29173;\n    phys_block_id_30904 = get_tblock_id(0);\n    virtloop_bound_30905 = sdiv_up64(num_virt_blocks_30879 - phys_block_id_30904, num_tblocks_29175);\n    for (int64_t virtloop_i_30906 = 0; virtloop_i_30906 < virtloop_bound_30905; virtloop_i_30906++) {\n        int64_t dynamic_id_30907;\n        int64_t block", "_offset_30908;\n        int64_t sgm_idx_30909;\n        int32_t boundary_30910;\n        int32_t segsizze_compact_30911;\n        int64_t private_mem_30912[chunk_sizze_30878];\n        int64_t thd_offset_30914;\n        int64_t acc_30930;\n        int64_t prefix_30940;\n        bool block_new_sgm_30941;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30890 == 0) {\n                dynamic_id_30907 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30887)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30897)[(int64_t) 0] = dynamic_id_30907;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30907 == num_virt_blocks_30879 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30887)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30907 = ((__local int32_t *) local_mem_30897)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30908 = dynamic_id_30907 * chunk_sizze_30878 * segscan_tblock_sizze_29173;\n        sgm_idx_30909 = smod64(block_offset_30908, loop_dz2081Uz2088Uz2087U_27125);\n        boundary_30910 = sext_i64_i32(smin64(chunk_sizze_30878 * segscan_tblock_sizze_29173, loop_dz2081Uz2088Uz2087U_27125 - sgm_idx_30909));\n        segsizze_compact_30911 = sext_i64_i32(smin64(chunk_sizze_30878 * segscan_tblock_sizze_29173, loop_dz2081Uz2088Uz2087U_27125));\n        thd_offset_30914 = block_offset_30908 + sext_i32_i64(local_tid_30890);\n        // Load and map\n        {\n            for (int64_t i_30915 = 0; i_30915 < chunk_sizze_30878; i_30915++) {\n                int64_t virt_tid_30916 = thd_offset_30914 + i_30915 * segscan_tblock_sizze_29173;\n                int64_t slice_30", "917 = loop_dz2081Uz2088Uz2087U_27125;\n                int64_t gtid_29177 = virt_tid_30916;\n                int64_t remnant_30918 = virt_tid_30916 - gtid_29177;\n                \n                if (slt64(virt_tid_30916, loop_dz2081Uz2088Uz2087U_27125)) {\n                    int32_t eta_p_27750 = ((__global int32_t *) mem_param_29728)[gtid_29177];\n                    int64_t ii_27751 = sext_i32_i64(eta_p_27750);\n                    bool x_27752 = sle64((int64_t) 0, ii_27751);\n                    bool y_27753 = slt64(ii_27751, mz2080U_21995);\n                    bool bounds_check_27754 = x_27752 && y_27753;\n                    bool index_certs_27755;\n                    \n                    if (!bounds_check_27754) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 23) == -1) {\n                                global_failure_args[0] = (int64_t) ii_27751;\n                                global_failure_args[1] = (int64_t) mz2080U_21995;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int32_t zeze_lhs_27756 = ((__global int32_t *) mem_29754)[ii_27751];\n                    bool cond_27757 = zeze_lhs_27756 == -1;\n                    bool defunc_0_p_res_27758;\n                    \n                    if (cond_27757) {\n                        defunc_0_p_res_27758 = 0;\n                    } else {\n                        double eta_p_27749 = ((__global double *) mem_param_29731)[gtid_29177];\n                        bool cond_27759 = zeze_lhs_27756 == 0;\n                        bool defunc_0_p_res_f_res_27760;\n                        \n                        if (cond_27759) {\n                            double lt_arg1_28187 = ((__global double *) mem_29740)[ii_27751];\n                            bool defunc_0_lt_res_28188 = eta_p_2774",
                                    "9 < lt_arg1_28187;\n                            \n                            defunc_0_p_res_f_res_27760 = defunc_0_lt_res_28188;\n                        } else {\n                            bool cond_27763 = zeze_lhs_27756 == 1;\n                            bool defunc_0_p_res_f_res_f_res_27764;\n                            \n                            if (cond_27763) {\n                                defunc_0_p_res_f_res_f_res_27764 = 0;\n                            } else {\n                                double lt_arg1_27765 = ((__global double *) mem_29740)[ii_27751];\n                                bool defunc_0_lt_res_27766 = eta_p_27749 < lt_arg1_27765;\n                                bool cond_27767 = !defunc_0_lt_res_27766;\n                                bool defunc_0_eq_res_27768 = eta_p_27749 == lt_arg1_27765;\n                                bool defunc_0_p_res_f_res_f_res_f_res_t_res_27769 = !defunc_0_eq_res_27768;\n                                bool x_27770 = cond_27767 && defunc_0_p_res_f_res_f_res_f_res_t_res_27769;\n                                \n                                defunc_0_p_res_f_res_f_res_27764 = x_27770;\n                            }\n                            defunc_0_p_res_f_res_27760 = defunc_0_p_res_f_res_f_res_27764;\n                        }\n                        defunc_0_p_res_27758 = defunc_0_p_res_f_res_27760;\n                    }\n                    \n                    int64_t defunc_0_f_res_27771 = btoi_bool_i64(defunc_0_p_res_27758);\n                    \n                    ((__global int64_t *) mem_29759)[gtid_29177] = defunc_0_f_res_27771;\n                    private_mem_30912[i_30915] = defunc_0_f_res_27771;\n                } else {\n                    private_mem_30912[i_30915] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n   ", "     {\n            for (int64_t i_30919 = 0; i_30919 < chunk_sizze_30878; i_30919++) {\n                int64_t sharedIdx_30920 = sext_i32_i64(local_tid_30890) + i_30919 * segscan_tblock_sizze_29173;\n                int64_t tmp_30921 = private_mem_30912[i_30919];\n                \n                ((__local int64_t *) local_mem_30897)[sharedIdx_30920] = tmp_30921;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30922 = 0; i_30922 < chunk_sizze_30878; i_30922++) {\n                int64_t sharedIdx_30923 = sext_i32_i64(local_tid_30890) * chunk_sizze_30878 + i_30922;\n                int64_t tmp_30924 = ((__local int64_t *) local_mem_30897)[sharedIdx_30923];\n                \n                private_mem_30912[i_30922] = tmp_30924;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30925 = 0; i_30925 < chunk_sizze_30878 - (int64_t) 1; i_30925++) {\n                int64_t eta_p_27331;\n                int64_t eta_p_27332;\n                \n                eta_p_27331 = private_mem_30912[i_30925];\n                eta_p_27332 = private_mem_30912[i_30925 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27333 = add64(eta_p_27331, eta_p_27332);\n                \n                private_mem_30912[i_30925 + (int64_t) 1] = defunc_0_op_res_27333;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_30926 = private_mem_30912[chunk_sizze_30878 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = tmp_30926;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_30927;\n            int64_t eta_p_30928;\n            int64_t eta_p_30931;\n            int64_t eta_p_30932;\n            bool ltid_in_bounds_30934 = slt64(sext_i32_i64(local_tid_30890), num_virt_threads_30880);\n           ", " int32_t skip_threads_30935;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30934) {\n                    eta_p_30928 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)];\n                    if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                        eta_p_30927 = eta_p_30928;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30935 = 1;\n                while (slt32(skip_threads_30935, 32)) {\n                    bool thread_active_30936 = sle32(skip_threads_30935, local_tid_30890 - squot32(local_tid_30890, 32) * 32) && ltid_in_bounds_30934;\n                    \n                    if (thread_active_30936) {\n                        // read operands\n                        {\n                            eta_p_30927 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30935)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30936) {\n                            int64_t defunc_0_op_res_30929 = add64(eta_p_30927, eta_p_30928);\n                            \n                            eta_p_30927 = defunc_0_op_res_30929;\n                        }\n                    }\n                    if (sle32(wave_sizze_30892, skip_threads_30935)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30936) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30927;\n                            eta_p_30928 = eta_p_30927;\n                        }\n                    }\n                    if (sle32(wave_sizze_30892, skip_thread",
                                    "s_30935)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30935 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 31 && ltid_in_bounds_30934) {\n                    ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(squot32(local_tid_30890, 32))] = eta_p_30927;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30937;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934) {\n                        eta_p_30932 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)];\n                        if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                            eta_p_30931 = eta_p_30932;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30937 = 1;\n                    while (slt32(skip_threads_30937, 32)) {\n                        bool thread_active_30938 = sle32(skip_threads_30937, local_tid_30890 - squot32(local_tid_30890, 32) * 32) && (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934);\n                        \n                        if (thread_active_30938) {\n                            // read operands\n                            {\n                                eta_p_30931 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30937)];\n                            }\n                        }\n     ", "                   // perform operation\n                        {\n                            if (thread_active_30938) {\n                                int64_t defunc_0_op_res_30933 = add64(eta_p_30931, eta_p_30932);\n                                \n                                eta_p_30931 = defunc_0_op_res_30933;\n                            }\n                        }\n                        if (sle32(wave_sizze_30892, skip_threads_30937)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30938) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30931;\n                                eta_p_30932 = eta_p_30931;\n                            }\n                        }\n                        if (sle32(wave_sizze_30892, skip_threads_30937)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30937 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30939 = squot32(local_tid_30890, 32) == 0 || !ltid_in_bounds_30934;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30939) {\n                        eta_p_30928 = eta_p_30927;\n                        eta_p_30927 = ((__local int64_t *) local_mem_30897)[sext_i32_i64(squot32(local_tid_30890, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30939) {\n                        int64_t defunc_0_op_res_30929 = add64(eta_p_30927, eta_p_30928);\n                        \n                        eta_p_30927 = defunc_0_op_res_30929;\n   ", "                 }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30939) {\n                        ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30927;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934) {\n                    ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30928;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30890 == 0) {\n                acc_30930 = ((__local int64_t *) local_mem_30897)[segscan_tblock_sizze_29173 - (int64_t) 1];\n            } else {\n                acc_30930 = ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30940 = (int64_t) 0;\n        block_new_sgm_30941 = sgm_idx_30909 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30941 && local_tid_30890 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_30907] = acc_30930;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 2;\n                acc_30930 = (int64_t) 0;\n            }\n            if (!block_new_sgm_30941 && slt32(local_tid_30890, wave_sizze_30892)) {\n                if (local_tid_30890 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_30883)[dynamic_id_30907] = acc_30930;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 1;\n                    \n                    int8_t tmp_30942 = ((volatile ",
                                    "__global int8_t *) status_flags_mem_30881)[dynamic_id_30907 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30897)[(int64_t) 0] = tmp_30942;\n                }\n                mem_fence_local();\n                \n                int8_t status_30943 = ((__local int8_t *) local_mem_30897)[(int64_t) 0];\n                \n                if (status_30943 == (int8_t) 2) {\n                    if (local_tid_30890 == 0) {\n                        prefix_30940 = ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_30907 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30944 = sext_i64_i32(dynamic_id_30907 - sext_i32_i64(wave_sizze_30892));\n                    \n                    while (slt32(wave_sizze_30892 * -1, readOffset_30944)) {\n                        int32_t read_i_30945 = readOffset_30944 + local_tid_30890;\n                        int64_t aggr_30946 = (int64_t) 0;\n                        int8_t flag_30947 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30945)) {\n                            flag_30947 = ((volatile __global int8_t *) status_flags_mem_30881)[sext_i32_i64(read_i_30945)];\n                            if (flag_30947 == (int8_t) 2) {\n                                aggr_30946 = ((volatile __global int64_t *) incprefixes_mem_30885)[sext_i32_i64(read_i_30945)];\n                            } else if (flag_30947 == (int8_t) 1) {\n                                aggr_30946 = ((volatile __global int64_t *) aggregates_mem_30883)[sext_i32_i64(read_i_30945)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)] = aggr_30946;\n                        ((__local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = flag_30947;\n                        flag_30947 = ((__local int8_t *) local_mem_30897)[sext_i32_i64(wa", "ve_sizze_30892) - (int64_t) 1];\n                        if (slt8(flag_30947, (int8_t) 2)) {\n                            int8_t flg_x_30951;\n                            int8_t flg_y_30952;\n                            int64_t eta_p_30948;\n                            int64_t eta_p_30949;\n                            int32_t skip_threads_30953;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30952 = ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)];\n                                eta_p_30949 = ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)];\n                                if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                                    eta_p_30948 = eta_p_30949;\n                                    flg_x_30951 = flg_y_30952;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30953 = 1;\n                                while (slt32(skip_threads_30953, 32)) {\n                                    if (sle32(skip_threads_30953, local_tid_30890 - squot32(local_tid_30890, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30951 = ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30953)];\n                                            eta_p_30948 = ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + (sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30953))];\n                                        }\n                                        // perform operation\n                                        {\n                             ", "               if (flg_y_30952 == (int8_t) 2 || flg_y_30952 == (int8_t) 0) {\n                                                flg_x_30951 = flg_y_30952;\n                                                eta_p_30948 = eta_p_30949;\n                                            } else {\n                                                int64_t defunc_0_op_res_30950 = add64(eta_p_30948, eta_p_30949);\n                                                \n                                                eta_p_30948 = defunc_0_op_res_30950;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = flg_x_30951;\n                                            flg_y_30952 = flg_x_30951;\n                                            ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)] = eta_p_30948;\n                                            eta_p_30949 = eta_p_30948;\n                                        }\n                                    }\n                                    skip_threads_30953 *= 2;\n                                }\n                            }\n                        }\n                        flag_30947 = ((__local int8_t *) local_mem_30897)[sext_i32_i64(wave_sizze_30892) - (int64_t) 1];\n                        aggr_30946 = ((__local int64_t *) local_mem_30897)[(int64_t) 4 + (sext_i32_i64(wave_sizze_30892) - (int64_t) 1)];\n                        if (flag_30947 == (int8_t) 2) {\n                            readOffset_30944 = wave_sizze_30892 * -1;\n                        } else if (flag_30947 == (int8_t) 1) {\n                            readOffset_30944 -= wave_sizze_30892;\n                        }\n                        if (slt8((int8_t) 0, flag_30947)) {\n                           ",
                                    " int64_t eta_p_30954 = aggr_30946;\n                            int64_t eta_p_30955 = prefix_30940;\n                            int64_t defunc_0_op_res_30956 = add64(eta_p_30954, eta_p_30955);\n                            \n                            prefix_30940 = defunc_0_op_res_30956;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30890 == 0) {\n                    if (boundary_30910 == sext_i64_i32(segscan_tblock_sizze_29173 * chunk_sizze_30878)) {\n                        int64_t eta_p_30957 = prefix_30940;\n                        int64_t eta_p_30958 = acc_30930;\n                        int64_t defunc_0_op_res_30959 = add64(eta_p_30957, eta_p_30958);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_30907] = defunc_0_op_res_30959;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_30897)[(int64_t) 4] = prefix_30940;\n                    acc_30930 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_30907 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30940 = ((__local int64_t *) local_mem_30897)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_30960;\n            int64_t eta_p_30961;\n            int64_t eta_p_30963 = prefix_30940;\n            int64_t eta_p_30964 = acc_30930;\n            \n            if (slt32(local_tid_30890 * chunk_sizze_32b_30894, boundary_30910) && !block_new_sgm_30941) {\n                int64_t defunc_0_op_res_30965 = add64(eta_p_30963, eta_p_30964);\n                \n                eta_p_30960 = defunc_0_op_res_30965;\n            } else {\n                eta", "_p_30960 = acc_30930;\n            }\n            \n            int32_t stopping_point_30966 = segsizze_compact_30911 - srem32(local_tid_30890 * chunk_sizze_32b_30894 - 1 + segsizze_compact_30911 - boundary_30910, segsizze_compact_30911);\n            \n            for (int64_t i_30967 = 0; i_30967 < chunk_sizze_30878; i_30967++) {\n                if (slt32(sext_i64_i32(i_30967), stopping_point_30966 - 1)) {\n                    eta_p_30961 = private_mem_30912[i_30967];\n                    \n                    int64_t defunc_0_op_res_30962 = add64(eta_p_30960, eta_p_30961);\n                    \n                    private_mem_30912[i_30967] = defunc_0_op_res_30962;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30968 = 0; i_30968 < chunk_sizze_30878; i_30968++) {\n                int64_t sharedIdx_30969 = sext_i32_i64(local_tid_30890) * chunk_sizze_30878 + i_30968;\n                int64_t tmp_30970 = private_mem_30912[i_30968];\n                \n                ((__local int64_t *) local_mem_30897)[sharedIdx_30969] = tmp_30970;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30971 = 0; i_30971 < chunk_sizze_30878; i_30971++) {\n                int64_t flat_idx_30972 = thd_offset_30914 + i_30971 * segscan_tblock_sizze_29173;\n                int64_t slice_30973 = loop_dz2081Uz2088Uz2087U_27125;\n                int64_t gtid_29177 = flat_idx_30972;\n                int64_t remnant_30974 = flat_idx_30972 - gtid_29177;\n                \n                if (slt64(flat_idx_30972, loop_dz2081Uz2088Uz2087U_27125)) {\n                    int64_t tmp_30975 = ((__local int64_t *) local_mem_30897)[flat_idx_30972 - block_offset_30908];\n                    \n                    ((__global int64_t *) mem_29757)[gtid_29177] = tmp_30975;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    ret", "urn;\n    #undef segscan_tblock_sizze_29173\n    #undef chunk_sizze_30878\n}\nFUTHARK_KERNEL_SIZED(human_generici32ziseghist_global_29274_dim1, 1, 1)\nvoid human_generici32ziseghist_global_29274(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_25210, int64_t nz2081U_25211, int64_t num_tblocks_29269, int64_t num_subhistos_30239, int32_t chk_i_30320, int64_t hist_H_chk_30321, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242)\n{\n    #define seghist_tblock_sizze_29267 (human_generici32ziseghist_global_29274ziseghist_tblock_sizze_29267)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30323;\n    int32_t tblock_sizze_30326;\n    int32_t wave_sizze_30325;\n    int32_t block_id_30324;\n    int32_t global_tid_30322;\n    int64_t phys_tid_29274;\n    int32_t subhisto_ind_30327;\n    int64_t num_chunks_30328;\n    \n    local_tid_30323 = get_local_id(0);\n    tblock_sizze_30326 = get_local_size(0);\n    wave_sizze_30325 = LOCKSTEP_WIDTH;\n    block_id_30324 = get_tblock_id(0);\n    global_tid_30322 = block_id_30324 * tblock_sizze_30326 + local_tid_30323;\n    phys_tid_29274 = sext_i32_i64(global_tid_30322);\n    subhisto_ind_30327 = squot32(global_tid_30322, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_29267 * num_tblocks_29269), sext_i64_i32(num_subhistos_30239)));\n    num_chunks_30328 = sdiv_up64(nz2081U_25211, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_29267 * num_tblocks_29269)));\n    for (int64_t chunk_i_30329 = 0; chunk_i_30329 < num_chunks_30328; chunk_i_30329++) {\n        int64_t i_30330 = chunk_i_30329 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_29267 * num_tblocks_29269)) + sext_i32_i64(global_tid_30322);\n        \n        if (slt64(i_30330, nz2081U_25211)) {\n            int64_t slice_30331;\n            int64_t gt",
                                    "id_29273;\n            int64_t remnant_30332;\n            \n            slice_30331 = nz2081U_25211;\n            gtid_29273 = i_30330;\n            remnant_30332 = i_30330 - gtid_29273;\n            if (slt64(i_30330, nz2081U_25211)) {\n                int32_t eta_p_29282;\n                int64_t ii_29283;\n                bool x_29284;\n                bool y_29285;\n                bool bounds_check_29286;\n                bool index_certs_29287;\n                int32_t eta_p_29281;\n                int32_t eq_arg1_29288;\n                bool defunc_0_eq_res_29289;\n                bool defunc_0_lt_res_29290;\n                int32_t bool_res_29291;\n                int32_t bool_res_29292;\n                \n                eta_p_29282 = ((__global int32_t *) II1_mem_29679)[gtid_29273];\n                ii_29283 = sext_i32_i64(eta_p_29282);\n                x_29284 = sle64((int64_t) 0, ii_29283);\n                y_29285 = slt64(ii_29283, mz2080U_25210);\n                bounds_check_29286 = x_29284 && y_29285;\n                if (!bounds_check_29286) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 26) == -1) {\n                            global_failure_args[0] = (int64_t) ii_29283;\n                            global_failure_args[1] = (int64_t) mz2080U_25210;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                eta_p_29281 = ((__global int32_t *) A_mem_29680)[gtid_29273];\n                eq_arg1_29288 = ((__global int32_t *) mem_29695)[ii_29283];\n                defunc_0_eq_res_29289 = eta_p_29281 == eq_arg1_29288;\n                defunc_0_lt_res_29290 = slt32(eta_p_29281, eq_arg1_29288);\n                bool_res_29291 = btoi_bool_i32(defunc_0_lt_res_29290);\n                bool_res_29292 = btoi_bool_i32(defunc_0_eq_res_29289);\n                // save map-out results\n                { }\n                // perform atomic updates\n                ", "{\n                    if (sle64(sext_i32_i64(chk_i_30320) * hist_H_chk_30321, ii_29283) && (slt64(ii_29283, sext_i32_i64(chk_i_30320) * hist_H_chk_30321 + hist_H_chk_30321) && (sle64((int64_t) 0, ii_29283) && slt64(ii_29283, mz2080U_25210)))) {\n                        int32_t eta_p_29275;\n                        int32_t eta_p_29276;\n                        int32_t eta_p_29277;\n                        int32_t eta_p_29278;\n                        \n                        eta_p_29277 = bool_res_29291;\n                        eta_p_29278 = bool_res_29292;\n                        \n                        int32_t old_30333;\n                        \n                        old_30333 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30240)[sext_i32_i64(subhisto_ind_30327) * mz2080U_25210 + ii_29283], (int) eta_p_29277);\n                        \n                        int32_t old_30334;\n                        \n                        old_30334 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30242)[sext_i32_i64(subhisto_ind_30327) * mz2080U_25210 + ii_29283], (int) eta_p_29278);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_29267\n}\nFUTHARK_KERNEL_SIZED(human_generici32ziseghist_global_29565_dim1, 1, 1)\nvoid human_generici32ziseghist_global_29565(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_25210, int64_t loop_dz2081Uz2088Uz2087U_27125, int64_t num_tblocks_29560, int64_t num_subhistos_30677, int32_t chk_i_30758, int64_t hist_H_chk_30759, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define seghist_tblock_sizze_29558 (human_generici32ziseghist_global_29565ziseghis", "t_tblock_sizze_29558)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30761;\n    int32_t tblock_sizze_30764;\n    int32_t wave_sizze_30763;\n    int32_t block_id_30762;\n    int32_t global_tid_30760;\n    int64_t phys_tid_29565;\n    int32_t subhisto_ind_30765;\n    int64_t num_chunks_30766;\n    \n    local_tid_30761 = get_local_id(0);\n    tblock_sizze_30764 = get_local_size(0);\n    wave_sizze_30763 = LOCKSTEP_WIDTH;\n    block_id_30762 = get_tblock_id(0);\n    global_tid_30760 = block_id_30762 * tblock_sizze_30764 + local_tid_30761;\n    phys_tid_29565 = sext_i32_i64(global_tid_30760);\n    subhisto_ind_30765 = squot32(global_tid_30760, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_29558 * num_tblocks_29560), sext_i64_i32(num_subhistos_30677)));\n    num_chunks_30766 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_29558 * num_tblocks_29560)));\n    for (int64_t chunk_i_30767 = 0; chunk_i_30767 < num_chunks_30766; chunk_i_30767++) {\n        int64_t i_30768 = chunk_i_30767 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_29558 * num_tblocks_29560)) + sext_i32_i64(global_tid_30760);\n        \n        if (slt64(i_30768, loop_dz2081Uz2088Uz2087U_27125)) {\n            int64_t slice_30769;\n            int64_t gtid_29564;\n            int64_t remnant_30770;\n            \n            slice_30769 = loop_dz2081Uz2088Uz2087U_27125;\n            gtid_29564 = i_30768;\n            remnant_30770 = i_30768 - gtid_29564;\n            if (slt64(i_30768, loop_dz2081Uz2088Uz2087U_27125)) {\n                int32_t eta_p_29573;\n                int64_t ii_29574;\n                bool x_29575;\n                bool y_29576;\n                bool bounds_check_29577;\n                bool index_certs_29578;\n                int32_t eta_p_29572;\n                int32_t eq_arg1_29579;\n                bool defunc_0_eq_res_29580;\n                bool defunc_0_lt_res_29581;\n                int32_t bool_res_29582;\n                int32_t bool_res_29583;\n ",
                                    "               \n                eta_p_29573 = ((__global int32_t *) mem_param_29728)[gtid_29564];\n                ii_29574 = sext_i32_i64(eta_p_29573);\n                x_29575 = sle64((int64_t) 0, ii_29574);\n                y_29576 = slt64(ii_29574, mz2080U_25210);\n                bounds_check_29577 = x_29575 && y_29576;\n                if (!bounds_check_29577) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 34) == -1) {\n                            global_failure_args[0] = (int64_t) ii_29574;\n                            global_failure_args[1] = (int64_t) mz2080U_25210;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                eta_p_29572 = ((__global int32_t *) mem_param_29731)[gtid_29564];\n                eq_arg1_29579 = ((__global int32_t *) mem_29740)[ii_29574];\n                defunc_0_eq_res_29580 = eta_p_29572 == eq_arg1_29579;\n                defunc_0_lt_res_29581 = slt32(eta_p_29572, eq_arg1_29579);\n                bool_res_29582 = btoi_bool_i32(defunc_0_lt_res_29581);\n                bool_res_29583 = btoi_bool_i32(defunc_0_eq_res_29580);\n                // save map-out results\n                { }\n                // perform atomic updates\n                {\n                    if (sle64(sext_i32_i64(chk_i_30758) * hist_H_chk_30759, ii_29574) && (slt64(ii_29574, sext_i32_i64(chk_i_30758) * hist_H_chk_30759 + hist_H_chk_30759) && (sle64((int64_t) 0, ii_29574) && slt64(ii_29574, mz2080U_25210)))) {\n                        int32_t eta_p_29566;\n                        int32_t eta_p_29567;\n                        int32_t eta_p_29568;\n                        int32_t eta_p_29569;\n                        \n                        eta_p_29568 = bool_res_29582;\n                        eta_p_29569 = bool_res_29583;\n                        \n                        int32_t old_30771;\n                        \n                        old_3077", "1 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30678)[sext_i32_i64(subhisto_ind_30765) * mz2080U_25210 + ii_29574], (int) eta_p_29568);\n                        \n                        int32_t old_30772;\n                        \n                        old_30772 = atomic_add_i32_global(&((volatile __global int *) defunc_0_map_res_subhistos_mem_30680)[sext_i32_i64(subhisto_ind_30765) * mz2080U_25210 + ii_29574], (int) eta_p_29569);\n                    }\n                }\n            }\n        }\n    }\n    \n  error_0:\n    return;\n    #undef seghist_tblock_sizze_29558\n}\nFUTHARK_KERNEL_SIZED(human_generici32ziseghist_local_29274_dim1, 1, 1)\nvoid human_generici32ziseghist_local_29274(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_25210, int64_t nz2081U_25211, int64_t num_subhistos_30239, int64_t num_tblocks_30252, int32_t hist_M_30258, int32_t chk_i_30262, int64_t num_segments_30263, int64_t hist_H_chk_30264, int64_t histo_sizze_30265, int32_t init_per_thread_30266, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242)\n{\n    #define max_tblock_sizze_30251 (human_generici32ziseghist_local_29274zimax_tblock_sizze_30251)\n    \n    volatile __local unsigned char *subhistogram_local_mem_30282_backing_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_30282_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_30280_backing_0 = &shared_mem[subhistogram_local_mem_30282_backing_1_offset];\n    const int64_t subhistogram_local_mem_30280_backing_0_offset = subhistogram_local_mem_30282_backing_1_offset + ((int64_t) ", "4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30268;\n    int32_t tblock_sizze_30271;\n    int32_t wave_sizze_30270;\n    int32_t block_id_30269;\n    int32_t global_tid_30267;\n    int64_t phys_tid_29274;\n    int32_t phys_tblock_id_30272;\n    int32_t iterations_30273;\n    \n    local_tid_30268 = get_local_id(0);\n    tblock_sizze_30271 = get_local_size(0);\n    wave_sizze_30270 = LOCKSTEP_WIDTH;\n    block_id_30269 = get_tblock_id(0);\n    global_tid_30267 = block_id_30269 * tblock_sizze_30271 + local_tid_30268;\n    phys_tid_29274 = sext_i32_i64(global_tid_30267);\n    phys_tblock_id_30272 = get_tblock_id(0);\n    iterations_30273 = sdiv_up32(sext_i64_i32(num_tblocks_30252 * num_segments_30263) - phys_tblock_id_30272, sext_i64_i32(num_tblocks_30252));\n    for (int32_t i_30274 = 0; i_30274 < iterations_30273; i_30274++) {\n        int32_t virt_tblock_id_30275;\n        int32_t flat_segment_id_30276;\n        int32_t gid_in_segment_30277;\n        int32_t pgtid_in_segment_30278;\n        int32_t threads_per_segment_30279;\n        __local unsigned char *subhistogram_local_mem_30280;\n        __local unsigned char *subhistogram_local_mem_30282;\n        int32_t thread_local_subhisto_i_30284;\n        int64_t num_chunks_30297;\n        \n        virt_tblock_id_30275 = phys_tblock_id_30272 + i_30274 * sext_i64_i32(num_tblocks_30252);\n        flat_segment_id_30276 = squot32(virt_tblock_id_30275, sext_i64_i32(num_tblocks_30252));\n        gid_in_segment_30277 = srem32(virt_tblock_id_30275, sext_i64_i32(num_tblocks_30252));\n        pgtid_in_segment_30278 = gid_in_segment_30277 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n        th",
                                    "reads_per_segment_30279 = sext_i64_i32(num_tblocks_30252 * max_tblock_sizze_30251);\n        subhistogram_local_mem_30280 = (__local unsigned char *) subhistogram_local_mem_30280_backing_0;\n        subhistogram_local_mem_30282 = (__local unsigned char *) subhistogram_local_mem_30282_backing_1;\n        thread_local_subhisto_i_30284 = srem32(local_tid_30268, hist_M_30258);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_30285 = 0; local_i_30285 < init_per_thread_30266; local_i_30285++) {\n                int32_t j_30286 = local_i_30285 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n                int32_t j_offset_30287 = hist_M_30258 * sext_i64_i32(histo_sizze_30265) * gid_in_segment_30277 + j_30286;\n                int32_t local_subhisto_i_30288 = squot32(j_30286, sext_i64_i32(histo_sizze_30265));\n                int32_t global_subhisto_i_30289 = squot32(j_offset_30287, sext_i64_i32(histo_sizze_30265));\n                \n                if (slt32(j_30286, hist_M_30258 * sext_i64_i32(histo_sizze_30265))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30289 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30239)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264) && slt64(sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264, mz2080U_25210)))) {\n                            int32_t tmp_30290 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(local_subhisto_i_30288) * hist_H_chk_30264 + ", "sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265)))] = tmp_30290;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(local_subhisto_i_30288) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30286, sext_i64_i32(histo_sizze_30265)))] = 0;\n                        }\n                    }\n                }\n            }\n            for (int32_t local_i_30291 = 0; local_i_30291 < init_per_thread_30266; local_i_30291++) {\n                int32_t j_30292 = local_i_30291 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n                int32_t j_offset_30293 = hist_M_30258 * sext_i64_i32(histo_sizze_30265) * gid_in_segment_30277 + j_30292;\n                int32_t local_subhisto_i_30294 = squot32(j_30292, sext_i64_i32(histo_sizze_30265));\n                int32_t global_subhisto_i_30295 = squot32(j_offset_30293, sext_i64_i32(histo_sizze_30265));\n                \n                if (slt32(j_30292, hist_M_30258 * sext_i64_i32(histo_sizze_30265))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30295 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30239)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264) && slt64(sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264, mz2080U_25210)))) {\n                            int32_t tmp_30296 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265))) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(local_subhisto_i_30294) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30292, sext_i64", "_i32(histo_sizze_30265)))] = tmp_30296;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(local_subhisto_i_30294) * hist_H_chk_30264 + sext_i32_i64(srem32(j_30292, sext_i64_i32(histo_sizze_30265)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_30297 = sdiv_up64(nz2081U_25211, sext_i32_i64(threads_per_segment_30279));\n        for (int64_t chunk_i_30298 = 0; chunk_i_30298 < num_chunks_30297; chunk_i_30298++) {\n            int64_t i_30299 = chunk_i_30298 * sext_i32_i64(threads_per_segment_30279) + sext_i32_i64(pgtid_in_segment_30278);\n            \n            if (slt64(i_30299, nz2081U_25211)) {\n                int64_t gtid_29273;\n                int32_t eta_p_29282;\n                int64_t ii_29283;\n                bool x_29284;\n                bool y_29285;\n                bool bounds_check_29286;\n                bool index_certs_29287;\n                int32_t eta_p_29281;\n                int32_t eq_arg1_29288;\n                bool defunc_0_eq_res_29289;\n                bool defunc_0_lt_res_29290;\n                int32_t bool_res_29291;\n                int32_t bool_res_29292;\n                \n                gtid_29273 = i_30299;\n                eta_p_29282 = ((__global int32_t *) II1_mem_29679)[gtid_29273];\n                ii_29283 = sext_i32_i64(eta_p_29282);\n                x_29284 = sle64((int64_t) 0, ii_29283);\n                y_29285 = slt64(ii_29283, mz2080U_25210);\n                bounds_check_29286 = x_29284 && y_29285;\n                if (!bounds_check_29286) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 25) == -1) {\n                            global_failure_args[0] = (int64_t) ii_29283;\n                            global_failure_args[1] = (int64_t) mz2080U_25210;\n                            ;\n                        }\n       ",
                                    "                 local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                eta_p_29281 = ((__global int32_t *) A_mem_29680)[gtid_29273];\n                eq_arg1_29288 = ((__global int32_t *) mem_29695)[ii_29283];\n                defunc_0_eq_res_29289 = eta_p_29281 == eq_arg1_29288;\n                defunc_0_lt_res_29290 = slt32(eta_p_29281, eq_arg1_29288);\n                bool_res_29291 = btoi_bool_i32(defunc_0_lt_res_29290);\n                bool_res_29292 = btoi_bool_i32(defunc_0_eq_res_29289);\n                if (chk_i_30262 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, ii_29283) && slt64(ii_29283, mz2080U_25210)) && (sle64(sext_i32_i64(chk_i_30262) * hist_H_chk_30264, ii_29283) && slt64(ii_29283, sext_i32_i64(chk_i_30262) * hist_H_chk_30264 + hist_H_chk_30264))) {\n                        int32_t eta_p_29275;\n                        int32_t eta_p_29276;\n                        int32_t eta_p_29277;\n                        int32_t eta_p_29278;\n                        \n                        eta_p_29277 = bool_res_29291;\n                        eta_p_29278 = bool_res_29292;\n                        \n                        int32_t old_30300;\n                        \n                        old_30300 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30280)[sext_i32_i64(thread_local_subhisto_i_30284) * hist_H_chk_30264 + (ii_29283 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264)], (int) eta_p_29277);\n                        \n                        int32_t old_30301;\n                        \n                        old_30301 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30282)[sext_i32_i64(thread_local_subhisto_i_30284) * hist_H_chk_30264 + (ii_29283 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264)], (int) eta_p_29278", ");\n                    }\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_30302 = smin64(hist_H_chk_30264, mz2080U_25210 - sext_i32_i64(chk_i_30262) * hist_H_chk_30264);\n            int32_t histo_sizze_30303 = sext_i64_i32(trunc_H_30302);\n            \n            for (int32_t local_i_30304 = 0; local_i_30304 < init_per_thread_30266; local_i_30304++) {\n                int32_t j_30305 = local_i_30304 * sext_i64_i32(max_tblock_sizze_30251) + local_tid_30268;\n                \n                if (slt32(j_30305, histo_sizze_30303)) {\n                    int32_t eta_p_29275;\n                    int32_t eta_p_29276;\n                    int32_t eta_p_29277;\n                    int32_t eta_p_29278;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_29275 = ((__local int32_t *) subhistogram_local_mem_30280)[sext_i32_i64(j_30305)];\n                        eta_p_29276 = ((__local int32_t *) subhistogram_local_mem_30282)[sext_i32_i64(j_30305)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                    {\n                        for (int32_t subhisto_id_30306 = 0; subhisto_id_30306 < hist_M_30258 - 1; subhisto_id_30306++) {\n                            eta_p_29277 = ((__local int32_t *) subhistogram_local_mem_30280)[(sext_i32_i64(subhisto_id_30306) + (int64_t) 1) * hist_H_chk_30264 + sext_i32_i64(j_30305)];\n                            eta_p_29278 = ((__local int32_t *) subhistogram_local_mem_30282)[(sext_i32_i64(subhisto_id_30306) + (int64_t) 1) * hist_H_chk_30264 + sext_i32_i64(j_30305)];\n                            \n                          ", "  int32_t tmp_29279 = add32(eta_p_29275, eta_p_29277);\n                            int32_t tmp_29280 = add32(eta_p_29276, eta_p_29278);\n                            \n                            eta_p_29275 = tmp_29279;\n                            eta_p_29276 = tmp_29280;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[srem64(sext_i32_i64(virt_tblock_id_30275), num_tblocks_30252) * mz2080U_25210 + (sext_i32_i64(j_30305) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264)] = eta_p_29275;\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[srem64(sext_i32_i64(virt_tblock_id_30275), num_tblocks_30252) * mz2080U_25210 + (sext_i32_i64(j_30305) + sext_i32_i64(chk_i_30262) * hist_H_chk_30264)] = eta_p_29276;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_30251\n}\nFUTHARK_KERNEL_SIZED(human_generici32ziseghist_local_29565_dim1, 1, 1)\nvoid human_generici32ziseghist_local_29565(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_25210, int64_t loop_dz2081Uz2088Uz2087U_27125, int64_t num_subhistos_30677, int64_t num_tblocks_30690, int32_t hist_M_30696, int32_t chk_i_30700, int64_t num_segments_30701, int64_t hist_H_chk_30702, int64_t histo_sizze_30703, int32_t init_per_thread_30704, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define max_tblock_sizze_30689 (human_generici32ziseghist_local_29565zimax_tblock_sizze_30689)\n    \n    volatile __local unsigned char *subhistogram_local_mem_30720_bac",
                                    "king_1 = &shared_mem[0];\n    const int64_t subhistogram_local_mem_30720_backing_1_offset = 0 + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *subhistogram_local_mem_30718_backing_0 = &shared_mem[subhistogram_local_mem_30720_backing_1_offset];\n    const int64_t subhistogram_local_mem_30718_backing_0_offset = subhistogram_local_mem_30720_backing_1_offset + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30706;\n    int32_t tblock_sizze_30709;\n    int32_t wave_sizze_30708;\n    int32_t block_id_30707;\n    int32_t global_tid_30705;\n    int64_t phys_tid_29565;\n    int32_t phys_tblock_id_30710;\n    int32_t iterations_30711;\n    \n    local_tid_30706 = get_local_id(0);\n    tblock_sizze_30709 = get_local_size(0);\n    wave_sizze_30708 = LOCKSTEP_WIDTH;\n    block_id_30707 = get_tblock_id(0);\n    global_tid_30705 = block_id_30707 * tblock_sizze_30709 + local_tid_30706;\n    phys_tid_29565 = sext_i32_i64(global_tid_30705);\n    phys_tblock_id_30710 = get_tblock_id(0);\n    iterations_30711 = sdiv_up32(sext_i64_i32(num_tblocks_30690 * num_segments_30701) - phys_tblock_id_30710, sext_i64_i32(num_tblocks_30690));\n    for (int32_t i_30712 = 0; i_30712 < iterations_30711; i_30712++) {\n        int32_t virt_tblock_id_30713;\n        int32_t flat_segment_id_30714;\n        int32_t gid_in_segment_30715;\n        int32_t pgtid_in_segment_30716;\n        int32_t threads_per_segment_30717;\n        __local unsigned char *subhistogram_local_mem_30718;\n        __local unsigned char *subhistogram_lo", "cal_mem_30720;\n        int32_t thread_local_subhisto_i_30722;\n        int64_t num_chunks_30735;\n        \n        virt_tblock_id_30713 = phys_tblock_id_30710 + i_30712 * sext_i64_i32(num_tblocks_30690);\n        flat_segment_id_30714 = squot32(virt_tblock_id_30713, sext_i64_i32(num_tblocks_30690));\n        gid_in_segment_30715 = srem32(virt_tblock_id_30713, sext_i64_i32(num_tblocks_30690));\n        pgtid_in_segment_30716 = gid_in_segment_30715 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n        threads_per_segment_30717 = sext_i64_i32(num_tblocks_30690 * max_tblock_sizze_30689);\n        subhistogram_local_mem_30718 = (__local unsigned char *) subhistogram_local_mem_30718_backing_0;\n        subhistogram_local_mem_30720 = (__local unsigned char *) subhistogram_local_mem_30720_backing_1;\n        thread_local_subhisto_i_30722 = srem32(local_tid_30706, hist_M_30696);\n        // initialize histograms in shared memory\n        {\n            for (int32_t local_i_30723 = 0; local_i_30723 < init_per_thread_30704; local_i_30723++) {\n                int32_t j_30724 = local_i_30723 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                int32_t j_offset_30725 = hist_M_30696 * sext_i64_i32(histo_sizze_30703) * gid_in_segment_30715 + j_30724;\n                int32_t local_subhisto_i_30726 = squot32(j_30724, sext_i64_i32(histo_sizze_30703));\n                int32_t global_subhisto_i_30727 = squot32(j_offset_30725, sext_i64_i32(histo_sizze_30703));\n                \n                if (slt32(j_30724, hist_M_30696 * sext_i64_i32(histo_sizze_30703))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30727 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30677)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702) && slt64(sex", "t_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702, mz2080U_25210)))) {\n                            int32_t tmp_30728 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(local_subhisto_i_30726) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703)))] = tmp_30728;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(local_subhisto_i_30726) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30724, sext_i64_i32(histo_sizze_30703)))] = 0;\n                        }\n                    }\n                }\n            }\n            for (int32_t local_i_30729 = 0; local_i_30729 < init_per_thread_30704; local_i_30729++) {\n                int32_t j_30730 = local_i_30729 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                int32_t j_offset_30731 = hist_M_30696 * sext_i64_i32(histo_sizze_30703) * gid_in_segment_30715 + j_30730;\n                int32_t local_subhisto_i_30732 = squot32(j_30730, sext_i64_i32(histo_sizze_30703));\n                int32_t global_subhisto_i_30733 = squot32(j_offset_30731, sext_i64_i32(histo_sizze_30703));\n                \n                if (slt32(j_30730, hist_M_30696 * sext_i64_i32(histo_sizze_30703))) {\n                    // First subhistogram is initialised from global memory; others with neutral element.\n                    {\n                        if (global_subhisto_i_30733 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_30677)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702) && slt64(sext_i32_i64(srem32(j_30730, sext_i64_i3",
                                    "2(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702, mz2080U_25210)))) {\n                            int32_t tmp_30734 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703))) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702];\n                            \n                            ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(local_subhisto_i_30732) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703)))] = tmp_30734;\n                        } else {\n                            ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(local_subhisto_i_30732) * hist_H_chk_30702 + sext_i32_i64(srem32(j_30730, sext_i64_i32(histo_sizze_30703)))] = 0;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        num_chunks_30735 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, sext_i32_i64(threads_per_segment_30717));\n        for (int64_t chunk_i_30736 = 0; chunk_i_30736 < num_chunks_30735; chunk_i_30736++) {\n            int64_t i_30737 = chunk_i_30736 * sext_i32_i64(threads_per_segment_30717) + sext_i32_i64(pgtid_in_segment_30716);\n            \n            if (slt64(i_30737, loop_dz2081Uz2088Uz2087U_27125)) {\n                int64_t gtid_29564;\n                int32_t eta_p_29573;\n                int64_t ii_29574;\n                bool x_29575;\n                bool y_29576;\n                bool bounds_check_29577;\n                bool index_certs_29578;\n                int32_t eta_p_29572;\n                int32_t eq_arg1_29579;\n                bool defunc_0_eq_res_29580;\n                bool defunc_0_lt_res_29581;\n                int32_t bool_res_29582;\n                int32_t bool_res_29583;\n                \n                gtid_29564 = i_30737;\n                eta_p_29573 = ((__global int32_t *) mem_param_29728)[gtid_29564];\n                ii_29574 = sext_i32_i64(e", "ta_p_29573);\n                x_29575 = sle64((int64_t) 0, ii_29574);\n                y_29576 = slt64(ii_29574, mz2080U_25210);\n                bounds_check_29577 = x_29575 && y_29576;\n                if (!bounds_check_29577) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 33) == -1) {\n                            global_failure_args[0] = (int64_t) ii_29574;\n                            global_failure_args[1] = (int64_t) mz2080U_25210;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                eta_p_29572 = ((__global int32_t *) mem_param_29731)[gtid_29564];\n                eq_arg1_29579 = ((__global int32_t *) mem_29740)[ii_29574];\n                defunc_0_eq_res_29580 = eta_p_29572 == eq_arg1_29579;\n                defunc_0_lt_res_29581 = slt32(eta_p_29572, eq_arg1_29579);\n                bool_res_29582 = btoi_bool_i32(defunc_0_lt_res_29581);\n                bool_res_29583 = btoi_bool_i32(defunc_0_eq_res_29580);\n                if (chk_i_30700 == 0) {\n                    // save map-out results\n                    { }\n                }\n                // perform atomic updates\n                {\n                    if ((sle64((int64_t) 0, ii_29574) && slt64(ii_29574, mz2080U_25210)) && (sle64(sext_i32_i64(chk_i_30700) * hist_H_chk_30702, ii_29574) && slt64(ii_29574, sext_i32_i64(chk_i_30700) * hist_H_chk_30702 + hist_H_chk_30702))) {\n                        int32_t eta_p_29566;\n                        int32_t eta_p_29567;\n                        int32_t eta_p_29568;\n                        int32_t eta_p_29569;\n                        \n                        eta_p_29568 = bool_res_29582;\n                        eta_p_29569 = bool_res_29583;\n                        \n                        int32_t old_30738;\n                        \n                        old_30738 = atomic_add_i32_share", "d(&((volatile __local int *) subhistogram_local_mem_30718)[sext_i32_i64(thread_local_subhisto_i_30722) * hist_H_chk_30702 + (ii_29574 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702)], (int) eta_p_29568);\n                        \n                        int32_t old_30739;\n                        \n                        old_30739 = atomic_add_i32_shared(&((volatile __local int *) subhistogram_local_mem_30720)[sext_i32_i64(thread_local_subhisto_i_30722) * hist_H_chk_30702 + (ii_29574 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702)], (int) eta_p_29569);\n                    }\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n        // Compact the multiple shared memory subhistograms to result in global memory\n        {\n            int64_t trunc_H_30740 = smin64(hist_H_chk_30702, mz2080U_25210 - sext_i32_i64(chk_i_30700) * hist_H_chk_30702);\n            int32_t histo_sizze_30741 = sext_i64_i32(trunc_H_30740);\n            \n            for (int32_t local_i_30742 = 0; local_i_30742 < init_per_thread_30704; local_i_30742++) {\n                int32_t j_30743 = local_i_30742 * sext_i64_i32(max_tblock_sizze_30689) + local_tid_30706;\n                \n                if (slt32(j_30743, histo_sizze_30741)) {\n                    int32_t eta_p_29566;\n                    int32_t eta_p_29567;\n                    int32_t eta_p_29568;\n                    int32_t eta_p_29569;\n                    \n                    // Read values from subhistogram 0.\n                    {\n                        eta_p_29566 = ((__local int32_t *) subhistogram_local_mem_30718)[sext_i32_i64(j_30743)];\n                        eta_p_29567 = ((__local int32_t *) subhistogram_local_mem_30720)[sext_i32_i64(j_30743)];\n                    }\n                    // Accumulate based on values in other subhistograms.\n                ",
                                    "    {\n                        for (int32_t subhisto_id_30744 = 0; subhisto_id_30744 < hist_M_30696 - 1; subhisto_id_30744++) {\n                            eta_p_29568 = ((__local int32_t *) subhistogram_local_mem_30718)[(sext_i32_i64(subhisto_id_30744) + (int64_t) 1) * hist_H_chk_30702 + sext_i32_i64(j_30743)];\n                            eta_p_29569 = ((__local int32_t *) subhistogram_local_mem_30720)[(sext_i32_i64(subhisto_id_30744) + (int64_t) 1) * hist_H_chk_30702 + sext_i32_i64(j_30743)];\n                            \n                            int32_t tmp_29570 = add32(eta_p_29566, eta_p_29568);\n                            int32_t tmp_29571 = add32(eta_p_29567, eta_p_29569);\n                            \n                            eta_p_29566 = tmp_29570;\n                            eta_p_29567 = tmp_29571;\n                        }\n                    }\n                    // Put final bucket value in global memory.\n                    {\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[srem64(sext_i32_i64(virt_tblock_id_30713), num_tblocks_30690) * mz2080U_25210 + (sext_i32_i64(j_30743) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702)] = eta_p_29566;\n                        ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[srem64(sext_i32_i64(virt_tblock_id_30713), num_tblocks_30690) * mz2080U_25210 + (sext_i32_i64(j_30743) + sext_i32_i64(chk_i_30700) * hist_H_chk_30702)] = eta_p_29567;\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_2:\n    return;\n    #undef max_tblock_sizze_30689\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegmap_29196_dim1, 1, 1)\nvoid human_generici32zisegmap_29196(__global int *global_failure, int64_t mz2080U_25210, int64_t nz2081U_25211, int64_t num_tblocks_29201, int32_t virt_num_tblocks_29953, __global unsigned char *mem_29683, __global unsigned char *mem_29684)\n{\n    #define segmap_tblock_sizze_29199", " (human_generici32zisegmap_29196zisegmap_tblock_sizze_29199)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29955;\n    int32_t tblock_sizze_29958;\n    int32_t wave_sizze_29957;\n    int32_t block_id_29956;\n    int32_t global_tid_29954;\n    int64_t phys_tid_29196;\n    int32_t phys_tblock_id_29959;\n    int32_t iterations_29960;\n    \n    local_tid_29955 = get_local_id(0);\n    tblock_sizze_29958 = get_local_size(0);\n    wave_sizze_29957 = LOCKSTEP_WIDTH;\n    block_id_29956 = get_tblock_id(0);\n    global_tid_29954 = block_id_29956 * tblock_sizze_29958 + local_tid_29955;\n    phys_tid_29196 = sext_i32_i64(global_tid_29954);\n    phys_tblock_id_29959 = get_tblock_id(0);\n    iterations_29960 = sdiv_up32(virt_num_tblocks_29953 - phys_tblock_id_29959, sext_i64_i32(num_tblocks_29201));\n    for (int32_t i_29961 = 0; i_29961 < iterations_29960; i_29961++) {\n        int32_t virt_tblock_id_29962;\n        int64_t global_tid_29963;\n        int64_t slice_29964;\n        int64_t write_i_29195;\n        int64_t remnant_29965;\n        \n        virt_tblock_id_29962 = phys_tblock_id_29959 + i_29961 * sext_i64_i32(num_tblocks_29201);\n        global_tid_29963 = sext_i32_i64(virt_tblock_id_29962) * segmap_tblock_sizze_29199 + sext_i32_i64(local_tid_29955);\n        slice_29964 = mz2080U_25210;\n        write_i_29195 = global_tid_29963;\n        remnant_29965 = global_tid_29963 - write_i_29195;\n        if (slt64(write_i_29195, mz2080U_25210)) {\n            int64_t zv_lhs_27704;\n            int64_t tmp_27705;\n            bool cond_27708;\n            int64_t lifted_lambda_res_27709;\n            \n            zv_lhs_27704 = add64((int64_t) -1, write_i_29195);\n            tmp_27705 = smod64(zv_lhs_27704, mz2080U_25210);\n            cond_27708 = write_i_29195 == (int64_t) 0;\n            if (cond_27708) {\n                lifted_lambda_res_27709 = (int64_t) 0;\n            } else {\n                int64_t lifted_lambda_res_27706 = ((__global int64_t *) mem_29683)[tmp_27705];\n        ", "        \n                lifted_lambda_res_27709 = lifted_lambda_res_27706;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27709) && slt64(lifted_lambda_res_27709, nz2081U_25211)) {\n                ((__global bool *) mem_29684)[lifted_lambda_res_27709] = 1;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_29199\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegmap_29248_dim1, 1, 1)\nvoid human_generici32zisegmap_29248(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_25210, int64_t nz2081U_25211, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29689, __global unsigned char *mem_29692, __global unsigned char *mem_29695)\n{\n    #define segmap_tblock_sizze_29244 (human_generici32zisegmap_29248zisegmap_tblock_sizze_29244)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30231;\n    int32_t tblock_sizze_30234;\n    int32_t wave_sizze_30233;\n    int32_t block_id_30232;\n    int32_t global_tid_30230;\n    int64_t phys_tid_29248;\n    int64_t global_tid_30235;\n    int64_t slice_30236;\n    int64_t gtid_29247;\n    int64_t remnant_30237;\n    \n    local_tid_30231 = get_local_id(0);\n    tblock_sizze_30234 = get_local_size(0);\n    wave_sizze_30233 = LOCKSTEP_WIDTH;\n    block_id_30232 = get_tblock_id(0);\n    global_tid_30230 = block_id_30232 * tblock_sizze_30234 + local_tid_30231;\n    phys_tid_29248 = sext_i32_i64(global_tid_30230);\n    global_tid_30235 = sext_i32_i64(block_id_30232) * segmap_tblock_sizze_29244 + sext_i32_i64(local_tid_30231);\n    slice_30236 = mz2080U_25210;\n    gtid_29247 = global_tid_30235;\n    remnant_30237 = global_tid_30235 - gtid_29247;\n    if (slt64(gtid_29247, mz2080U_25210)) {\n        int32_t eta_p_29250;\n        bool cond_29252;\n        int32_t lifted_lambda_res_29253;\n        float i32_res_29261;\n        float i32_res_29262;\n        float f32_a",
                                    "rg0_29263;\n        int32_t f32_res_29264;\n        \n        eta_p_29250 = ((__global int32_t *) shp_mem_29678)[gtid_29247];\n        cond_29252 = eta_p_29250 == 0;\n        if (cond_29252) {\n            lifted_lambda_res_29253 = 0;\n        } else {\n            int32_t eta_p_29249;\n            int32_t tmp_29254;\n            int64_t tmp_29255;\n            bool x_29256;\n            bool y_29257;\n            bool bounds_check_29258;\n            bool index_certs_29259;\n            int32_t lifted_lambda_res_f_res_29260;\n            \n            eta_p_29249 = ((__global int32_t *) mem_29692)[gtid_29247];\n            tmp_29254 = sub32(eta_p_29249, 1);\n            tmp_29255 = sext_i32_i64(tmp_29254);\n            x_29256 = sle64((int64_t) 0, tmp_29255);\n            y_29257 = slt64(tmp_29255, nz2081U_25211);\n            bounds_check_29258 = x_29256 && y_29257;\n            if (!bounds_check_29258) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 24) == -1) {\n                        global_failure_args[0] = (int64_t) tmp_29255;\n                        global_failure_args[1] = (int64_t) nz2081U_25211;\n                        ;\n                    }\n                    return;\n                }\n            }\n            lifted_lambda_res_f_res_29260 = ((__global int32_t *) mem_29689)[tmp_29255];\n            lifted_lambda_res_29253 = lifted_lambda_res_f_res_29260;\n        }\n        i32_res_29261 = sitofp_i32_f32(eta_p_29250);\n        i32_res_29262 = sitofp_i32_f32(lifted_lambda_res_29253);\n        f32_arg0_29263 = i32_res_29262 / i32_res_29261;\n        f32_res_29264 = fptosi_f32_i32(f32_arg0_29263);\n        ((__global int32_t *) mem_29695)[gtid_29247] = f32_res_29264;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_29244\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegmap_29336_dim1, 1, 1)\nvoid human_generici32zisegmap_29336(__global int *global_failure, int64_t mz2080U_25210, __global unsigned char *ks_mem_29677, __global unsigned", " char *shp_mem_29678, __global unsigned char *mem_29695, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *mem_29703, __global unsigned char *mem_29705, __global unsigned char *mem_29707, __global unsigned char *mem_29709)\n{\n    #define segmap_tblock_sizze_29329 (human_generici32zisegmap_29336zisegmap_tblock_sizze_29329)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30428;\n    int32_t tblock_sizze_30431;\n    int32_t wave_sizze_30430;\n    int32_t block_id_30429;\n    int32_t global_tid_30427;\n    int64_t phys_tid_29336;\n    int64_t global_tid_30432;\n    int64_t slice_30433;\n    int64_t gtid_29335;\n    int64_t remnant_30434;\n    \n    local_tid_30428 = get_local_id(0);\n    tblock_sizze_30431 = get_local_size(0);\n    wave_sizze_30430 = LOCKSTEP_WIDTH;\n    block_id_30429 = get_tblock_id(0);\n    global_tid_30427 = block_id_30429 * tblock_sizze_30431 + local_tid_30428;\n    phys_tid_29336 = sext_i32_i64(global_tid_30427);\n    global_tid_30432 = sext_i32_i64(block_id_30429) * segmap_tblock_sizze_29329 + sext_i32_i64(local_tid_30428);\n    slice_30433 = mz2080U_25210;\n    gtid_29335 = global_tid_30432;\n    remnant_30434 = global_tid_30432 - gtid_29335;\n    if (slt64(gtid_29335, mz2080U_25210)) {\n        int32_t eta_p_29337;\n        int32_t eta_p_29338;\n        int32_t eta_p_29339;\n        int32_t eta_p_29340;\n        bool cond_29342;\n        int32_t lifted_lambda_res_29343;\n        bool cond_29349;\n        int32_t lifted_lambda_res_29350;\n        bool cond_29351;\n        int32_t lifted_lambda_res_29352;\n        int32_t lifted_lambda_res_29358;\n        \n        eta_p_29337 = ((__global int32_t *) mem_29699)[gtid_29335];\n        eta_p_29338 = ((__global int32_t *) mem_29697)[gtid_29335];\n        eta_p_29339 = ((__global int32_t *) shp_mem_29678)[gtid_29335];\n        eta_p_29340 = ((__global int32_t *) ks_mem_29677)[gtid_29335];\n        cond_29342 = eta_p_29339 == 0;\n        if (cond_29342) {\n            lifted", "_lambda_res_29343 = -1;\n        } else {\n            bool cond_29344;\n            int32_t lifted_lambda_res_f_res_29345;\n            \n            cond_29344 = sle32(eta_p_29340, eta_p_29337);\n            if (cond_29344) {\n                lifted_lambda_res_f_res_29345 = 0;\n            } else {\n                int32_t zlze_rhs_29346;\n                bool cond_29347;\n                int32_t lifted_lambda_res_f_res_f_res_29348;\n                \n                zlze_rhs_29346 = add32(eta_p_29337, eta_p_29338);\n                cond_29347 = sle32(eta_p_29340, zlze_rhs_29346);\n                if (cond_29347) {\n                    lifted_lambda_res_f_res_f_res_29348 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_29348 = 2;\n                }\n                lifted_lambda_res_f_res_29345 = lifted_lambda_res_f_res_f_res_29348;\n            }\n            lifted_lambda_res_29343 = lifted_lambda_res_f_res_29345;\n        }\n        cond_29349 = lifted_lambda_res_29343 == 1;\n        if (cond_29349) {\n            int32_t eta_p_29341 = ((__global int32_t *) mem_29695)[gtid_29335];\n            \n            lifted_lambda_res_29350 = eta_p_29341;\n        } else {\n            lifted_lambda_res_29350 = 0;\n        }\n        cond_29351 = lifted_lambda_res_29343 == -1;\n        if (cond_29351) {\n            lifted_lambda_res_29352 = -1;\n        } else {\n            bool cond_29353;\n            int32_t lifted_lambda_res_f_res_29354;\n            \n            cond_29353 = lifted_lambda_res_29343 == 0;\n            if (cond_29353) {\n                lifted_lambda_res_f_res_29354 = eta_p_29340;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_29355;\n                \n                if (cond_29349) {\n                    lifted_lambda_res_f_res_f_res_29355 = -1;\n                } else {\n                    int32_t zm_lhs_29356;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_29357;\n                    \n                    zm_lhs_2",
                                    "9356 = sub32(eta_p_29340, eta_p_29337);\n                    lifted_lambda_res_f_res_f_res_f_res_29357 = sub32(zm_lhs_29356, eta_p_29338);\n                    lifted_lambda_res_f_res_f_res_29355 = lifted_lambda_res_f_res_f_res_f_res_29357;\n                }\n                lifted_lambda_res_f_res_29354 = lifted_lambda_res_f_res_f_res_29355;\n            }\n            lifted_lambda_res_29352 = lifted_lambda_res_f_res_29354;\n        }\n        if (cond_29351) {\n            lifted_lambda_res_29358 = 0;\n        } else {\n            bool cond_29359;\n            int32_t lifted_lambda_res_f_res_29360;\n            \n            cond_29359 = lifted_lambda_res_29343 == 0;\n            if (cond_29359) {\n                lifted_lambda_res_f_res_29360 = eta_p_29337;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_29361;\n                \n                if (cond_29349) {\n                    lifted_lambda_res_f_res_f_res_29361 = 0;\n                } else {\n                    int32_t zm_lhs_29362;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_29363;\n                    \n                    zm_lhs_29362 = sub32(eta_p_29339, eta_p_29337);\n                    lifted_lambda_res_f_res_f_res_f_res_29363 = sub32(zm_lhs_29362, eta_p_29338);\n                    lifted_lambda_res_f_res_f_res_29361 = lifted_lambda_res_f_res_f_res_f_res_29363;\n                }\n                lifted_lambda_res_f_res_29360 = lifted_lambda_res_f_res_f_res_29361;\n            }\n            lifted_lambda_res_29358 = lifted_lambda_res_f_res_29360;\n        }\n        ((__global int32_t *) mem_29703)[gtid_29335] = lifted_lambda_res_29358;\n        ((__global int32_t *) mem_29705)[gtid_29335] = lifted_lambda_res_29352;\n        ((__global int32_t *) mem_29707)[gtid_29335] = lifted_lambda_res_29350;\n        ((__global int32_t *) mem_29709)[gtid_29335] = lifted_lambda_res_29343;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_29329\n}\nFUTHARK_KERNEL_SIZED(human_generi", "ci32zisegmap_29373_dim1, 1, 1)\nvoid human_generici32zisegmap_29373(__global int *global_failure, int64_t nz2081U_25211, int64_t m_27089, int64_t num_tblocks_29378, int32_t virt_num_tblocks_30539, __global unsigned char *II1_mem_29679, __global unsigned char *A_mem_29680, __global unsigned char *mem_29712, __global unsigned char *mem_29714, __global unsigned char *mem_29716, __global unsigned char *mem_29718)\n{\n    #define segmap_tblock_sizze_29376 (human_generici32zisegmap_29373zisegmap_tblock_sizze_29376)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30541;\n    int32_t tblock_sizze_30544;\n    int32_t wave_sizze_30543;\n    int32_t block_id_30542;\n    int32_t global_tid_30540;\n    int64_t phys_tid_29373;\n    int32_t phys_tblock_id_30545;\n    int32_t iterations_30546;\n    \n    local_tid_30541 = get_local_id(0);\n    tblock_sizze_30544 = get_local_size(0);\n    wave_sizze_30543 = LOCKSTEP_WIDTH;\n    block_id_30542 = get_tblock_id(0);\n    global_tid_30540 = block_id_30542 * tblock_sizze_30544 + local_tid_30541;\n    phys_tid_29373 = sext_i32_i64(global_tid_30540);\n    phys_tblock_id_30545 = get_tblock_id(0);\n    iterations_30546 = sdiv_up32(virt_num_tblocks_30539 - phys_tblock_id_30545, sext_i64_i32(num_tblocks_29378));\n    for (int32_t i_30547 = 0; i_30547 < iterations_30546; i_30547++) {\n        int32_t virt_tblock_id_30548;\n        int64_t global_tid_30549;\n        int64_t slice_30550;\n        int64_t write_i_29372;\n        int64_t remnant_30551;\n        \n        virt_tblock_id_30548 = phys_tblock_id_30545 + i_30547 * sext_i64_i32(num_tblocks_29378);\n        global_tid_30549 = sext_i32_i64(virt_tblock_id_30548) * segmap_tblock_sizze_29376 + sext_i32_i64(local_tid_30541);\n        slice_30550 = nz2081U_25211;\n        write_i_29372 = global_tid_30549;\n        remnant_30551 = global_tid_30549 - write_i_29372;\n        if (slt64(write_i_29372, nz2081U_25211)) {\n            int64_t eta_p_27397;\n            int32_t write_value_27399;\n            int32", "_t write_value_27400;\n            bool cond_27401;\n            int64_t lifted_lambda_res_27402;\n            \n            eta_p_27397 = ((__global int64_t *) mem_29714)[write_i_29372];\n            write_value_27399 = ((__global int32_t *) A_mem_29680)[write_i_29372];\n            write_value_27400 = ((__global int32_t *) II1_mem_29679)[write_i_29372];\n            cond_27401 = eta_p_27397 == (int64_t) 1;\n            if (cond_27401) {\n                int64_t eta_p_27398;\n                int64_t lifted_lambda_res_t_res_28162;\n                \n                eta_p_27398 = ((__global int64_t *) mem_29712)[write_i_29372];\n                lifted_lambda_res_t_res_28162 = sub64(eta_p_27398, (int64_t) 1);\n                lifted_lambda_res_27402 = lifted_lambda_res_t_res_28162;\n            } else {\n                lifted_lambda_res_27402 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27402) && slt64(lifted_lambda_res_27402, m_27089)) {\n                ((__global int32_t *) mem_29718)[lifted_lambda_res_27402] = write_value_27399;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27402) && slt64(lifted_lambda_res_27402, m_27089)) {\n                ((__global int32_t *) mem_29716)[lifted_lambda_res_27402] = write_value_27400;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_29376\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegmap_29478_dim1, 1, 1)\nvoid human_generici32zisegmap_29478(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_25210, int64_t loop_dz2081Uz2088Uz2087U_27125, __global unsigned char *mem_param_29725, __global unsigned char *mem_param_29731, __global unsigned char *mem_29737, __global unsigned char *mem_29740)\n{\n    #define segmap_tblock_sizze_29474 (human_generici32zisegmap_29478zisegmap_tblock_sizze_29474)\n    if (*global_failure >= 0)\n        return;\n  ",
                                    "  \n    int32_t local_tid_30669;\n    int32_t tblock_sizze_30672;\n    int32_t wave_sizze_30671;\n    int32_t block_id_30670;\n    int32_t global_tid_30668;\n    int64_t phys_tid_29478;\n    int64_t global_tid_30673;\n    int64_t slice_30674;\n    int64_t gtid_29477;\n    int64_t remnant_30675;\n    \n    local_tid_30669 = get_local_id(0);\n    tblock_sizze_30672 = get_local_size(0);\n    wave_sizze_30671 = LOCKSTEP_WIDTH;\n    block_id_30670 = get_tblock_id(0);\n    global_tid_30668 = block_id_30670 * tblock_sizze_30672 + local_tid_30669;\n    phys_tid_29478 = sext_i32_i64(global_tid_30668);\n    global_tid_30673 = sext_i32_i64(block_id_30670) * segmap_tblock_sizze_29474 + sext_i32_i64(local_tid_30669);\n    slice_30674 = mz2080U_25210;\n    gtid_29477 = global_tid_30673;\n    remnant_30675 = global_tid_30673 - gtid_29477;\n    if (slt64(gtid_29477, mz2080U_25210)) {\n        int32_t eta_p_29480;\n        int64_t zv_lhs_29481;\n        int64_t tmp_29482;\n        bool cond_29484;\n        int32_t lifted_lambda_res_29485;\n        bool cond_29486;\n        int32_t defunc_0_f_res_29487;\n        \n        eta_p_29480 = ((__global int32_t *) mem_param_29725)[gtid_29477];\n        zv_lhs_29481 = add64((int64_t) -1, gtid_29477);\n        tmp_29482 = smod64(zv_lhs_29481, mz2080U_25210);\n        cond_29484 = gtid_29477 == (int64_t) 0;\n        if (cond_29484) {\n            lifted_lambda_res_29485 = 0;\n        } else {\n            int32_t lifted_lambda_res_29483 = ((__global int32_t *) mem_29737)[tmp_29482];\n            \n            lifted_lambda_res_29485 = lifted_lambda_res_29483;\n        }\n        cond_29486 = eta_p_29480 == 0;\n        if (cond_29486) {\n            defunc_0_f_res_29487 = 0;\n        } else {\n            bool cond_29488;\n            int32_t defunc_0_f_res_f_res_29489;\n            \n            cond_29488 = eta_p_29480 == 1;\n            if (cond_29488) {\n                int64_t off_29490;\n                bool x_29491;\n                bool y_29492;\n                bool bounds_check_29493;\n  ", "              bool index_certs_29494;\n                int32_t defunc_0_f_res_f_res_t_res_29495;\n                \n                off_29490 = sext_i32_i64(lifted_lambda_res_29485);\n                x_29491 = sle64((int64_t) 0, off_29490);\n                y_29492 = slt64(off_29490, loop_dz2081Uz2088Uz2087U_27125);\n                bounds_check_29493 = x_29491 && y_29492;\n                if (!bounds_check_29493) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 28) == -1) {\n                            global_failure_args[0] = (int64_t) off_29490;\n                            global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                            ;\n                        }\n                        return;\n                    }\n                }\n                defunc_0_f_res_f_res_t_res_29495 = ((__global int32_t *) mem_param_29731)[off_29490];\n                defunc_0_f_res_f_res_29489 = defunc_0_f_res_f_res_t_res_29495;\n            } else {\n                bool cond_29496;\n                int32_t defunc_0_f_res_f_res_f_res_29497;\n                \n                cond_29496 = eta_p_29480 == 2;\n                if (cond_29496) {\n                    int64_t off_29498;\n                    bool x_29499;\n                    bool y_29500;\n                    bool bounds_check_29501;\n                    bool index_certs_29502;\n                    int32_t defunc_0_f_res_f_res_f_res_t_res_29503;\n                    \n                    off_29498 = sext_i32_i64(lifted_lambda_res_29485);\n                    x_29499 = sle64((int64_t) 0, off_29498);\n                    y_29500 = slt64(off_29498, loop_dz2081Uz2088Uz2087U_27125);\n                    bounds_check_29501 = x_29499 && y_29500;\n                    if (!bounds_check_29501) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 29) == -1) {\n                                global_failure_args[0] = (int64_t) o", "ff_29498;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    defunc_0_f_res_f_res_f_res_t_res_29503 = ((__global int32_t *) mem_param_29731)[off_29498];\n                    defunc_0_f_res_f_res_f_res_29497 = defunc_0_f_res_f_res_f_res_t_res_29503;\n                } else {\n                    int64_t off_29504;\n                    bool x_29505;\n                    bool y_29506;\n                    bool bounds_check_29507;\n                    bool index_certs_29508;\n                    int32_t zp_rhs_29510;\n                    int32_t mid_29511;\n                    int64_t mid_29512;\n                    bool x_29513;\n                    bool y_29514;\n                    bool bounds_check_29515;\n                    bool index_certs_29516;\n                    int32_t zm_lhs_29518;\n                    int32_t last_29519;\n                    int64_t last_29520;\n                    bool x_29521;\n                    bool y_29522;\n                    bool bounds_check_29523;\n                    bool index_certs_29524;\n                    int32_t first_29509;\n                    int32_t mid_29517;\n                    int32_t last_29525;\n                    bool defunc_0_lt_res_29526;\n                    bool defunc_0_eq_res_29527;\n                    bool x_29528;\n                    bool y_29529;\n                    bool cond_29530;\n                    int32_t defunc_0_median3_res_29531;\n                    \n                    off_29504 = sext_i32_i64(lifted_lambda_res_29485);\n                    x_29505 = sle64((int64_t) 0, off_29504);\n                    y_29506 = slt64(off_29504, loop_dz2081Uz2088Uz2087U_27125);\n                    bounds_check_29507 = x_29505 && y_29506;\n                    if (!bounds_check_29507) {\n                        {\n               ",
                                    "             if (atomic_cmpxchg_i32_global(global_failure, -1, 30) == -1) {\n                                global_failure_args[0] = (int64_t) off_29504;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    zp_rhs_29510 = sdiv32(eta_p_29480, 2);\n                    mid_29511 = add32(lifted_lambda_res_29485, zp_rhs_29510);\n                    mid_29512 = sext_i32_i64(mid_29511);\n                    x_29513 = sle64((int64_t) 0, mid_29512);\n                    y_29514 = slt64(mid_29512, loop_dz2081Uz2088Uz2087U_27125);\n                    bounds_check_29515 = x_29513 && y_29514;\n                    if (!bounds_check_29515) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 31) == -1) {\n                                global_failure_args[0] = (int64_t) mid_29512;\n                                global_failure_args[1] = (int64_t) loop_dz2081Uz2088Uz2087U_27125;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    zm_lhs_29518 = add32(eta_p_29480, lifted_lambda_res_29485);\n                    last_29519 = sub32(zm_lhs_29518, 1);\n                    last_29520 = sext_i32_i64(last_29519);\n                    x_29521 = sle64((int64_t) 0, last_29520);\n                    y_29522 = slt64(last_29520, loop_dz2081Uz2088Uz2087U_27125);\n                    bounds_check_29523 = x_29521 && y_29522;\n                    if (!bounds_check_29523) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 32) == -1) {\n                                global_failure_args[0] = (int64_t) last_29520;\n                                global_failure_args[1] = (int64_t) loop", "_dz2081Uz2088Uz2087U_27125;\n                                ;\n                            }\n                            return;\n                        }\n                    }\n                    first_29509 = ((__global int32_t *) mem_param_29731)[off_29504];\n                    mid_29517 = ((__global int32_t *) mem_param_29731)[mid_29512];\n                    last_29525 = ((__global int32_t *) mem_param_29731)[last_29520];\n                    defunc_0_lt_res_29526 = slt32(first_29509, mid_29517);\n                    defunc_0_eq_res_29527 = first_29509 == mid_29517;\n                    x_29528 = !defunc_0_lt_res_29526;\n                    y_29529 = defunc_0_eq_res_29527 && x_29528;\n                    cond_29530 = defunc_0_lt_res_29526 || y_29529;\n                    if (cond_29530) {\n                        bool defunc_0_lt_res_29532;\n                        bool defunc_0_eq_res_29533;\n                        bool x_29534;\n                        bool y_29535;\n                        bool cond_29536;\n                        int32_t defunc_0_median3_res_t_res_29537;\n                        \n                        defunc_0_lt_res_29532 = slt32(mid_29517, last_29525);\n                        defunc_0_eq_res_29533 = mid_29517 == last_29525;\n                        x_29534 = !defunc_0_lt_res_29532;\n                        y_29535 = defunc_0_eq_res_29533 && x_29534;\n                        cond_29536 = defunc_0_lt_res_29532 || y_29535;\n                        if (cond_29536) {\n                            defunc_0_median3_res_t_res_29537 = mid_29517;\n                        } else {\n                            bool defunc_0_lt_res_29538;\n                            bool defunc_0_eq_res_29539;\n                            bool x_29540;\n                            bool y_29541;\n                            bool cond_29542;\n                            int32_t defunc_0_median3_res_t_res_f_res_29543;\n                            \n                            defunc_0_lt_res_2953", "8 = slt32(first_29509, last_29525);\n                            defunc_0_eq_res_29539 = first_29509 == last_29525;\n                            x_29540 = !defunc_0_lt_res_29538;\n                            y_29541 = defunc_0_eq_res_29539 && x_29540;\n                            cond_29542 = defunc_0_lt_res_29538 || y_29541;\n                            if (cond_29542) {\n                                defunc_0_median3_res_t_res_f_res_29543 = last_29525;\n                            } else {\n                                defunc_0_median3_res_t_res_f_res_29543 = first_29509;\n                            }\n                            defunc_0_median3_res_t_res_29537 = defunc_0_median3_res_t_res_f_res_29543;\n                        }\n                        defunc_0_median3_res_29531 = defunc_0_median3_res_t_res_29537;\n                    } else {\n                        bool defunc_0_lt_res_29544;\n                        bool defunc_0_eq_res_29545;\n                        bool x_29546;\n                        bool y_29547;\n                        bool cond_29548;\n                        int32_t defunc_0_median3_res_f_res_29549;\n                        \n                        defunc_0_lt_res_29544 = slt32(first_29509, last_29525);\n                        defunc_0_eq_res_29545 = first_29509 == last_29525;\n                        x_29546 = !defunc_0_lt_res_29544;\n                        y_29547 = defunc_0_eq_res_29545 && x_29546;\n                        cond_29548 = defunc_0_lt_res_29544 || y_29547;\n                        if (cond_29548) {\n                            defunc_0_median3_res_f_res_29549 = first_29509;\n                        } else {\n                            bool defunc_0_lt_res_29550;\n                            bool defunc_0_eq_res_29551;\n                            bool x_29552;\n                            bool y_29553;\n                            bool cond_29554;\n                            int32_t defunc_0_median3_res_f_res_f_res_29555;\n               ",
                                    "             \n                            defunc_0_lt_res_29550 = slt32(mid_29517, last_29525);\n                            defunc_0_eq_res_29551 = mid_29517 == last_29525;\n                            x_29552 = !defunc_0_lt_res_29550;\n                            y_29553 = defunc_0_eq_res_29551 && x_29552;\n                            cond_29554 = defunc_0_lt_res_29550 || y_29553;\n                            if (cond_29554) {\n                                defunc_0_median3_res_f_res_f_res_29555 = last_29525;\n                            } else {\n                                defunc_0_median3_res_f_res_f_res_29555 = mid_29517;\n                            }\n                            defunc_0_median3_res_f_res_29549 = defunc_0_median3_res_f_res_f_res_29555;\n                        }\n                        defunc_0_median3_res_29531 = defunc_0_median3_res_f_res_29549;\n                    }\n                    defunc_0_f_res_f_res_f_res_29497 = defunc_0_median3_res_29531;\n                }\n                defunc_0_f_res_f_res_29489 = defunc_0_f_res_f_res_f_res_29497;\n            }\n            defunc_0_f_res_29487 = defunc_0_f_res_f_res_29489;\n        }\n        ((__global int32_t *) mem_29740)[gtid_29477] = defunc_0_f_res_29487;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_29474\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegmap_29628_dim1, 1, 1)\nvoid human_generici32zisegmap_29628(__global int *global_failure, int64_t mz2080U_25210, __global unsigned char *mem_param_29722, __global unsigned char *mem_param_29725, __global unsigned char *mem_param_29734, __global unsigned char *mem_29740, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *mem_29748, __global unsigned char *mem_29750, __global unsigned char *mem_29752, __global unsigned char *mem_29754)\n{\n    #define segmap_tblock_sizze_29621 (human_generici32zisegmap_29628zisegmap_tblock_sizze_29621)\n    if (*global_failure >= 0)\n        return;\n    \n    int32", "_t local_tid_30866;\n    int32_t tblock_sizze_30869;\n    int32_t wave_sizze_30868;\n    int32_t block_id_30867;\n    int32_t global_tid_30865;\n    int64_t phys_tid_29628;\n    int64_t global_tid_30870;\n    int64_t slice_30871;\n    int64_t gtid_29627;\n    int64_t remnant_30872;\n    \n    local_tid_30866 = get_local_id(0);\n    tblock_sizze_30869 = get_local_size(0);\n    wave_sizze_30868 = LOCKSTEP_WIDTH;\n    block_id_30867 = get_tblock_id(0);\n    global_tid_30865 = block_id_30867 * tblock_sizze_30869 + local_tid_30866;\n    phys_tid_29628 = sext_i32_i64(global_tid_30865);\n    global_tid_30870 = sext_i32_i64(block_id_30867) * segmap_tblock_sizze_29621 + sext_i32_i64(local_tid_30866);\n    slice_30871 = mz2080U_25210;\n    gtid_29627 = global_tid_30870;\n    remnant_30872 = global_tid_30870 - gtid_29627;\n    if (slt64(gtid_29627, mz2080U_25210)) {\n        int32_t eta_p_29629;\n        int32_t eta_p_29630;\n        int32_t eta_p_29631;\n        int32_t eta_p_29632;\n        bool cond_29635;\n        int32_t lifted_lambda_res_29636;\n        bool cond_29642;\n        int32_t lifted_lambda_res_29643;\n        bool cond_29644;\n        int32_t lifted_lambda_res_29645;\n        int32_t lifted_lambda_res_29651;\n        \n        eta_p_29629 = ((__global int32_t *) mem_29744)[gtid_29627];\n        eta_p_29630 = ((__global int32_t *) mem_29742)[gtid_29627];\n        eta_p_29631 = ((__global int32_t *) mem_param_29725)[gtid_29627];\n        eta_p_29632 = ((__global int32_t *) mem_param_29722)[gtid_29627];\n        cond_29635 = eta_p_29631 == 0;\n        if (cond_29635) {\n            lifted_lambda_res_29636 = -1;\n        } else {\n            bool cond_29637;\n            int32_t lifted_lambda_res_f_res_29638;\n            \n            cond_29637 = sle32(eta_p_29632, eta_p_29629);\n            if (cond_29637) {\n                lifted_lambda_res_f_res_29638 = 0;\n            } else {\n                int32_t zlze_rhs_29639;\n                bool cond_29640;\n                int32_t lifted_lambda_res_f_res_f_res_2", "9641;\n                \n                zlze_rhs_29639 = add32(eta_p_29629, eta_p_29630);\n                cond_29640 = sle32(eta_p_29632, zlze_rhs_29639);\n                if (cond_29640) {\n                    lifted_lambda_res_f_res_f_res_29641 = 1;\n                } else {\n                    lifted_lambda_res_f_res_f_res_29641 = 2;\n                }\n                lifted_lambda_res_f_res_29638 = lifted_lambda_res_f_res_f_res_29641;\n            }\n            lifted_lambda_res_29636 = lifted_lambda_res_f_res_29638;\n        }\n        cond_29642 = lifted_lambda_res_29636 == 1;\n        if (cond_29642) {\n            int32_t eta_p_29634 = ((__global int32_t *) mem_29740)[gtid_29627];\n            \n            lifted_lambda_res_29643 = eta_p_29634;\n        } else {\n            int32_t eta_p_29633 = ((__global int32_t *) mem_param_29734)[gtid_29627];\n            \n            lifted_lambda_res_29643 = eta_p_29633;\n        }\n        cond_29644 = lifted_lambda_res_29636 == -1;\n        if (cond_29644) {\n            lifted_lambda_res_29645 = -1;\n        } else {\n            bool cond_29646;\n            int32_t lifted_lambda_res_f_res_29647;\n            \n            cond_29646 = lifted_lambda_res_29636 == 0;\n            if (cond_29646) {\n                lifted_lambda_res_f_res_29647 = eta_p_29632;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_29648;\n                \n                if (cond_29642) {\n                    lifted_lambda_res_f_res_f_res_29648 = -1;\n                } else {\n                    int32_t zm_lhs_29649;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_29650;\n                    \n                    zm_lhs_29649 = sub32(eta_p_29632, eta_p_29629);\n                    lifted_lambda_res_f_res_f_res_f_res_29650 = sub32(zm_lhs_29649, eta_p_29630);\n                    lifted_lambda_res_f_res_f_res_29648 = lifted_lambda_res_f_res_f_res_f_res_29650;\n                }\n                lifted_lambda_res_f_res_29647 = lifted_l",
                                    "ambda_res_f_res_f_res_29648;\n            }\n            lifted_lambda_res_29645 = lifted_lambda_res_f_res_29647;\n        }\n        if (cond_29644) {\n            lifted_lambda_res_29651 = 0;\n        } else {\n            bool cond_29652;\n            int32_t lifted_lambda_res_f_res_29653;\n            \n            cond_29652 = lifted_lambda_res_29636 == 0;\n            if (cond_29652) {\n                lifted_lambda_res_f_res_29653 = eta_p_29629;\n            } else {\n                int32_t lifted_lambda_res_f_res_f_res_29654;\n                \n                if (cond_29642) {\n                    lifted_lambda_res_f_res_f_res_29654 = 0;\n                } else {\n                    int32_t zm_lhs_29655;\n                    int32_t lifted_lambda_res_f_res_f_res_f_res_29656;\n                    \n                    zm_lhs_29655 = sub32(eta_p_29631, eta_p_29629);\n                    lifted_lambda_res_f_res_f_res_f_res_29656 = sub32(zm_lhs_29655, eta_p_29630);\n                    lifted_lambda_res_f_res_f_res_29654 = lifted_lambda_res_f_res_f_res_f_res_29656;\n                }\n                lifted_lambda_res_f_res_29653 = lifted_lambda_res_f_res_f_res_29654;\n            }\n            lifted_lambda_res_29651 = lifted_lambda_res_f_res_29653;\n        }\n        ((__global int32_t *) mem_29748)[gtid_29627] = lifted_lambda_res_29651;\n        ((__global int32_t *) mem_29750)[gtid_29627] = lifted_lambda_res_29645;\n        ((__global int32_t *) mem_29752)[gtid_29627] = lifted_lambda_res_29643;\n        ((__global int32_t *) mem_29754)[gtid_29627] = lifted_lambda_res_29636;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_tblock_sizze_29621\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegmap_29666_dim1, 1, 1)\nvoid human_generici32zisegmap_29666(__global int *global_failure, int64_t loop_dz2081Uz2088Uz2087U_27125, int64_t m_27345, int64_t num_tblocks_29671, int32_t virt_num_tblocks_30977, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned ", "char *mem_29757, __global unsigned char *mem_29759, __global unsigned char *mem_29761, __global unsigned char *mem_29763)\n{\n    #define segmap_tblock_sizze_29669 (human_generici32zisegmap_29666zisegmap_tblock_sizze_29669)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30979;\n    int32_t tblock_sizze_30982;\n    int32_t wave_sizze_30981;\n    int32_t block_id_30980;\n    int32_t global_tid_30978;\n    int64_t phys_tid_29666;\n    int32_t phys_tblock_id_30983;\n    int32_t iterations_30984;\n    \n    local_tid_30979 = get_local_id(0);\n    tblock_sizze_30982 = get_local_size(0);\n    wave_sizze_30981 = LOCKSTEP_WIDTH;\n    block_id_30980 = get_tblock_id(0);\n    global_tid_30978 = block_id_30980 * tblock_sizze_30982 + local_tid_30979;\n    phys_tid_29666 = sext_i32_i64(global_tid_30978);\n    phys_tblock_id_30983 = get_tblock_id(0);\n    iterations_30984 = sdiv_up32(virt_num_tblocks_30977 - phys_tblock_id_30983, sext_i64_i32(num_tblocks_29671));\n    for (int32_t i_30985 = 0; i_30985 < iterations_30984; i_30985++) {\n        int32_t virt_tblock_id_30986;\n        int64_t global_tid_30987;\n        int64_t slice_30988;\n        int64_t write_i_29665;\n        int64_t remnant_30989;\n        \n        virt_tblock_id_30986 = phys_tblock_id_30983 + i_30985 * sext_i64_i32(num_tblocks_29671);\n        global_tid_30987 = sext_i32_i64(virt_tblock_id_30986) * segmap_tblock_sizze_29669 + sext_i32_i64(local_tid_30979);\n        slice_30988 = loop_dz2081Uz2088Uz2087U_27125;\n        write_i_29665 = global_tid_30987;\n        remnant_30989 = global_tid_30987 - write_i_29665;\n        if (slt64(write_i_29665, loop_dz2081Uz2088Uz2087U_27125)) {\n            int64_t eta_p_27740;\n            int32_t write_value_27742;\n            int32_t write_value_27743;\n            bool cond_27744;\n            int64_t lifted_lambda_res_27745;\n            \n            eta_p_27740 = ((__global int64_t *) mem_29759)[write_i_29665];\n            write_value_27742 = ((__global int32_t *) mem_param_29731)[w", "rite_i_29665];\n            write_value_27743 = ((__global int32_t *) mem_param_29728)[write_i_29665];\n            cond_27744 = eta_p_27740 == (int64_t) 1;\n            if (cond_27744) {\n                int64_t eta_p_27741;\n                int64_t lifted_lambda_res_t_res_28190;\n                \n                eta_p_27741 = ((__global int64_t *) mem_29757)[write_i_29665];\n                lifted_lambda_res_t_res_28190 = sub64(eta_p_27741, (int64_t) 1);\n                lifted_lambda_res_27745 = lifted_lambda_res_t_res_28190;\n            } else {\n                lifted_lambda_res_27745 = (int64_t) -1;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27745) && slt64(lifted_lambda_res_27745, m_27345)) {\n                ((__global int32_t *) mem_29763)[lifted_lambda_res_27745] = write_value_27742;\n            }\n            if (sle64((int64_t) 0, lifted_lambda_res_27745) && slt64(lifted_lambda_res_27745, m_27345)) {\n                ((__global int32_t *) mem_29761)[lifted_lambda_res_27745] = write_value_27743;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segmap_tblock_sizze_29669\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegred_large_30337_dim1, 1, 1)\nvoid human_generici32zisegred_large_30337(__global int *global_failure, int64_t mz2080U_25210, int64_t num_tblocks_29269, int64_t num_subhistos_30239, int64_t blocks_per_segment_30375, int64_t q_30376, int64_t num_virtblocks_30377, int64_t threads_per_segment_30378, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242, __global unsigned char *segred_tmp_mem_30379, __global unsigned char *segred_tmp_mem_30381, __global unsigned char *counters_mem_30383)\n{\n    #define seghist_tblock_sizze_29267 (human_generici32zisegred_large_30337ziseghist_tblock_sizze_29267)\n    #define chunk_sizze_30338 (hu",
                                    "man_generici32zisegred_large_30337zichunk_sizze_30338)\n    \n    volatile __local unsigned char *sync_arr_mem_30394_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_30394_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_30392_backing_1 = &shared_mem[sync_arr_mem_30394_backing_2_offset];\n    const int64_t red_arr_i32_mem_30392_backing_1_offset = sync_arr_mem_30394_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_29267 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29267, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30390_backing_0 = &shared_mem[red_arr_i32_mem_30392_backing_1_offset];\n    const int64_t red_arr_i32_mem_30390_backing_0_offset = red_arr_i32_mem_30392_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_29267 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29267, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30386;\n    int32_t tblock_sizze_30389;\n    int32_t wave_sizze_30388;\n    int32_t block_id_30387;\n    int32_t global_tid_30385;\n    int64_t flat_gtid_30337;\n    __local unsigned char *red_arr_i32_mem_30390;\n    __local unsigned char *red_arr_i32_mem_30392;\n    __local unsigned char *sync_arr_mem_30394;\n    int32_t phys_tblock_id_30396;\n    int32_t iterations_30397;\n    \n    local_tid_30386 = get_local_id(0);\n    tblock_sizze_30389 = get_local_size(0);\n    wave_sizze_30388 = LOCKSTEP_WIDTH;\n    block_id_30387 = get_tblock_id(0);\n    global_tid_30385 = block_id_30387 * tblock_sizze_30389 + local_tid_30386;\n    flat_gtid_30337 = sext_i32_i64(global_tid_30385);\n    red_arr_i32_mem_30390 = (__local unsigned char *) red_arr_i32_mem_30390_backing_0;\n    red_arr_i32_mem_30392 = (__local unsigned char *) red_arr_i32_mem_30392_backing_1;\n    sync_arr_mem_30394 = (__local unsigned char *) sync_arr_mem_30394_backing_2;\n    phys_tblock_id_30396 = get_tblock_id(0);\n    iterations_30397 = sd", "iv_up32(sext_i64_i32(num_virtblocks_30377) - phys_tblock_id_30396, sext_i64_i32(num_tblocks_29269));\n    for (int32_t i_30398 = 0; i_30398 < iterations_30397; i_30398++) {\n        int32_t virt_tblock_id_30399;\n        int64_t flat_segment_id_30400;\n        int64_t global_tid_30401;\n        int64_t slice_30402;\n        int64_t bucket_id_30335;\n        int64_t remnant_30403;\n        int64_t subhistogram_id_30336;\n        int32_t eta_p_block_res_acc_30404;\n        int32_t eta_p_block_res_acc_30405;\n        int32_t eta_p_29275;\n        int32_t eta_p_29276;\n        int32_t eta_p_29277;\n        int32_t eta_p_29278;\n        int64_t tblock_id_in_segment_30412;\n        int64_t block_base_offset_30413;\n        int32_t offset_30416;\n        int32_t skip_waves_30417;\n        int32_t eta_p_30406;\n        int32_t eta_p_30407;\n        int32_t eta_p_30408;\n        int32_t eta_p_30409;\n        \n        virt_tblock_id_30399 = phys_tblock_id_30396 + i_30398 * sext_i64_i32(num_tblocks_29269);\n        flat_segment_id_30400 = squot64(sext_i32_i64(virt_tblock_id_30399), blocks_per_segment_30375);\n        global_tid_30401 = srem64(sext_i32_i64(virt_tblock_id_30399) * seghist_tblock_sizze_29267 + sext_i32_i64(local_tid_30386), threads_per_segment_30378);\n        slice_30402 = mz2080U_25210;\n        bucket_id_30335 = flat_segment_id_30400;\n        remnant_30403 = flat_segment_id_30400 - bucket_id_30335;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_30404 = 0;\n            eta_p_block_res_acc_30405 = 0;\n        }\n        tblock_id_in_segment_30412 = squot64(global_tid_30401, seghist_tblock_sizze_29267);\n        block_base_offset_30413 = tblock_id_in_segment_30412 * q_30376 * seghist_tblock_sizze_29267;\n        for (int64_t i_30414 = 0; i_30414 < q_30376; i_30414++) {\n            int64_t block_offset_30415 = block_base_offset_30413 + i_30414 * seghist_tblock_sizze_29267;\n            \n            subhistogram_id_30336 = global_tid_30401 +", " threads_per_segment_30378 * i_30414;\n            if (slt64(subhistogram_id_30336, num_subhistos_30239)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_29275 = eta_p_block_res_acc_30404;\n                        eta_p_29276 = eta_p_block_res_acc_30405;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_29277 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[subhistogram_id_30336 * mz2080U_25210 + bucket_id_30335];\n                        eta_p_29278 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[subhistogram_id_30336 * mz2080U_25210 + bucket_id_30335];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_29279 = add32(eta_p_29275, eta_p_29277);\n                        int32_t tmp_29280 = add32(eta_p_29276, eta_p_29278);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_30404 = tmp_29279;\n                            eta_p_block_res_acc_30405 = tmp_29280;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_block_res_acc_30404;\n            ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_block_res_acc_30405;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_30417 = 1;\n        offset_30416 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_30386, sext_i64_i32(seghist_tblock_sizze_29267))) {\n                eta_p_30406 = ((__local int32_t *) re",
                                    "d_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                eta_p_30407 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n            }\n        }\n        offset_30416 = 1;\n        while (slt32(offset_30416, wave_sizze_30388)) {\n            if (slt32(local_tid_30386 + offset_30416, sext_i64_i32(seghist_tblock_sizze_29267)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) & (2 * offset_30416 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_30408 = ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                    eta_p_30409 = ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                    int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                    \n                    eta_p_30406 = tmp_30410;\n                    eta_p_30407 = tmp_30411;\n                }\n                // write result of operation\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                    ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                }\n            }\n            offset_30416 *= 2;\n        }\n        while (slt32(skip_waves_30417, squot32(sext_i64_i32(seghist_tblock_sizze_29267) + wave_sizze_30388 - 1, wave_sizze_30388))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_30416 = skip_waves_30417 * wave_sizze_30388;\n            if (slt32(local_tid_30386 + offset_30416, sext_i64_i32(seghist_tblock_sizze_29267)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) == 0 && (squo", "t32(local_tid_30386, wave_sizze_30388) & (2 * skip_waves_30417 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_30408 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                    eta_p_30409 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30416)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                    int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                    \n                    eta_p_30406 = tmp_30410;\n                    eta_p_30407 = tmp_30411;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                    ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                }\n            }\n            skip_waves_30417 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest reset to ne\n        {\n            if (sext_i32_i64(local_tid_30386) == (int64_t) 0) {\n                eta_p_block_res_acc_30404 = eta_p_30406;\n                eta_p_block_res_acc_30405 = eta_p_30407;\n            } else {\n                eta_p_block_res_acc_30404 = 0;\n                eta_p_block_res_acc_30405 = 0;\n            }\n        }\n        if (blocks_per_segment_30375 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_30386 == 0) {\n                    ((__global int32_t *) mem_29699)[bucket_id_30335] = eta_p_block_res_acc_30404;\n                    ((__global int32_t *) mem_29697)[bucket_id_30335] = eta_p_block_res_acc_30405;\n                }\n            }\n        } else {\n        ", "    int32_t old_counter_30418;\n            bool is_last_block_30419;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_30386 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_30379)[sext_i32_i64(virt_tblock_id_30399)] = eta_p_block_res_acc_30404;\n                    mem_fence_global();\n                    ((__global int32_t *) segred_tmp_mem_30381)[sext_i32_i64(virt_tblock_id_30399)] = eta_p_block_res_acc_30405;\n                    mem_fence_global();\n                    old_counter_30418 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30383)[srem64(flat_segment_id_30400, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_30394)[(int64_t) 0] = old_counter_30418 == sext_i64_i32(blocks_per_segment_30375 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_30419 = ((__local bool *) sync_arr_mem_30394)[(int64_t) 0];\n            if (is_last_block_30419) {\n                if (local_tid_30386 == 0) {\n                    old_counter_30418 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30383)[srem64(flat_segment_id_30400, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_30375));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_30420 = sdiv_up64(blocks_per_segment_30375, seghist_tblock_sizze_29267);\n                    \n                    eta_p_29275 = 0;\n                    eta_p_29276 = 0;\n                    for (int64_t i_30421 = 0; i_30421 < read_per_thread_30420; i_30421++) {\n                        int64_t block_res_id_30422 = sext_i32_i64(local_tid_30386) * read_per_thread_30420 + i_30421;\n                        int64_t index_of_block_res_30423 = flat_segment_id_30400 * blocks_per_segment_30375 + block_res_id_30422;\n         ",
                                    "               \n                        if (slt64(block_res_id_30422, blocks_per_segment_30375)) {\n                            eta_p_29277 = ((__global int32_t *) segred_tmp_mem_30379)[index_of_block_res_30423];\n                            eta_p_29278 = ((__global int32_t *) segred_tmp_mem_30381)[index_of_block_res_30423];\n                            \n                            int32_t tmp_29279 = add32(eta_p_29275, eta_p_29277);\n                            int32_t tmp_29280 = add32(eta_p_29276, eta_p_29278);\n                            \n                            eta_p_29275 = tmp_29279;\n                            eta_p_29276 = tmp_29280;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_29275;\n                ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_29276;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_30424;\n                    int32_t skip_waves_30425 = 1;\n                    int32_t eta_p_30406;\n                    int32_t eta_p_30407;\n                    int32_t eta_p_30408;\n                    int32_t eta_p_30409;\n                    \n                    offset_30424 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_30386, sext_i64_i32(seghist_tblock_sizze_29267))) {\n                            eta_p_30406 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            eta_p_30407 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                        }\n                    }\n                    offset_30424 = 1;\n                    while (slt32(offset_30424, wave_sizze_30388)) {\n                        if (slt32(lo", "cal_tid_30386 + offset_30424, sext_i64_i32(seghist_tblock_sizze_29267)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) & (2 * offset_30424 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_30408 = ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                                eta_p_30409 = ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                                int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                                \n                                eta_p_30406 = tmp_30410;\n                                eta_p_30407 = tmp_30411;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                            }\n                        }\n                        offset_30424 *= 2;\n                    }\n                    while (slt32(skip_waves_30425, squot32(sext_i64_i32(seghist_tblock_sizze_29267) + wave_sizze_30388 - 1, wave_sizze_30388))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_30424 = skip_waves_30425 * wave_sizze_30388;\n                        if (slt32(local_tid_30386 + offset_30424, sext_i64_i32(seghist_tblock_sizze_29267)) && ((local_tid_30386 - squot32(local_tid_30386, wave_sizze_30388) * wave_sizze_30388) == 0 && (squot32(local_tid_30386", ", wave_sizze_30388) & (2 * skip_waves_30425 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_30408 = ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                                eta_p_30409 = ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386 + offset_30424)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30410 = add32(eta_p_30406, eta_p_30408);\n                                int32_t tmp_30411 = add32(eta_p_30407, eta_p_30409);\n                                \n                                eta_p_30406 = tmp_30410;\n                                eta_p_30407 = tmp_30411;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_30390)[sext_i32_i64(local_tid_30386)] = eta_p_30406;\n                                ((__local int32_t *) red_arr_i32_mem_30392)[sext_i32_i64(local_tid_30386)] = eta_p_30407;\n                            }\n                        }\n                        skip_waves_30425 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_30386 == 0) {\n                            ((__global int32_t *) mem_29699)[bucket_id_30335] = eta_p_30406;\n                            ((__global int32_t *) mem_29697)[bucket_id_30335] = eta_p_30407;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_29267\n    #undef chunk_sizze_30338\n}\nFUTHARK_KERNEL_SIZED(human_generici32zi",
                                    "segred_large_30775_dim1, 1, 1)\nvoid human_generici32zisegred_large_30775(__global int *global_failure, int64_t mz2080U_25210, int64_t num_tblocks_29560, int64_t num_subhistos_30677, int64_t blocks_per_segment_30813, int64_t q_30814, int64_t num_virtblocks_30815, int64_t threads_per_segment_30816, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680, __global unsigned char *segred_tmp_mem_30817, __global unsigned char *segred_tmp_mem_30819, __global unsigned char *counters_mem_30821)\n{\n    #define seghist_tblock_sizze_29558 (human_generici32zisegred_large_30775ziseghist_tblock_sizze_29558)\n    #define chunk_sizze_30776 (human_generici32zisegred_large_30775zichunk_sizze_30776)\n    \n    volatile __local unsigned char *sync_arr_mem_30832_backing_2 = &shared_mem[0];\n    const int64_t sync_arr_mem_30832_backing_2_offset = 0 + 8;\n    volatile __local unsigned char *red_arr_i32_mem_30830_backing_1 = &shared_mem[sync_arr_mem_30832_backing_2_offset];\n    const int64_t red_arr_i32_mem_30830_backing_1_offset = sync_arr_mem_30832_backing_2_offset + ((int64_t) 4 * seghist_tblock_sizze_29558 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29558, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30828_backing_0 = &shared_mem[red_arr_i32_mem_30830_backing_1_offset];\n    const int64_t red_arr_i32_mem_30828_backing_0_offset = red_arr_i32_mem_30830_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_29558 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29558, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30824;\n    int32_t tblock_sizze_30827;\n    int32_t wave_sizze_30826;\n    int32_t block_id_30825;\n    int32_t global_tid_30823;\n    int64_t flat_gtid_30775;\n    __local unsigned char *red_arr_i32_mem_30828;\n    __local uns", "igned char *red_arr_i32_mem_30830;\n    __local unsigned char *sync_arr_mem_30832;\n    int32_t phys_tblock_id_30834;\n    int32_t iterations_30835;\n    \n    local_tid_30824 = get_local_id(0);\n    tblock_sizze_30827 = get_local_size(0);\n    wave_sizze_30826 = LOCKSTEP_WIDTH;\n    block_id_30825 = get_tblock_id(0);\n    global_tid_30823 = block_id_30825 * tblock_sizze_30827 + local_tid_30824;\n    flat_gtid_30775 = sext_i32_i64(global_tid_30823);\n    red_arr_i32_mem_30828 = (__local unsigned char *) red_arr_i32_mem_30828_backing_0;\n    red_arr_i32_mem_30830 = (__local unsigned char *) red_arr_i32_mem_30830_backing_1;\n    sync_arr_mem_30832 = (__local unsigned char *) sync_arr_mem_30832_backing_2;\n    phys_tblock_id_30834 = get_tblock_id(0);\n    iterations_30835 = sdiv_up32(sext_i64_i32(num_virtblocks_30815) - phys_tblock_id_30834, sext_i64_i32(num_tblocks_29560));\n    for (int32_t i_30836 = 0; i_30836 < iterations_30835; i_30836++) {\n        int32_t virt_tblock_id_30837;\n        int64_t flat_segment_id_30838;\n        int64_t global_tid_30839;\n        int64_t slice_30840;\n        int64_t bucket_id_30773;\n        int64_t remnant_30841;\n        int64_t subhistogram_id_30774;\n        int32_t eta_p_block_res_acc_30842;\n        int32_t eta_p_block_res_acc_30843;\n        int32_t eta_p_29566;\n        int32_t eta_p_29567;\n        int32_t eta_p_29568;\n        int32_t eta_p_29569;\n        int64_t tblock_id_in_segment_30850;\n        int64_t block_base_offset_30851;\n        int32_t offset_30854;\n        int32_t skip_waves_30855;\n        int32_t eta_p_30844;\n        int32_t eta_p_30845;\n        int32_t eta_p_30846;\n        int32_t eta_p_30847;\n        \n        virt_tblock_id_30837 = phys_tblock_id_30834 + i_30836 * sext_i64_i32(num_tblocks_29560);\n        flat_segment_id_30838 = squot64(sext_i32_i64(virt_tblock_id_30837), blocks_per_segment_30813);\n        global_tid_30839 = srem64(sext_i32_i64(virt_tblock_id_30837) * seghist_tblock_sizze_29558 + sext_i32_i64(local_tid_30824), threads_p", "er_segment_30816);\n        slice_30840 = mz2080U_25210;\n        bucket_id_30773 = flat_segment_id_30838;\n        remnant_30841 = flat_segment_id_30838 - bucket_id_30773;\n        // ne-initialise the outer (per-block) accumulator(s)\n        {\n            eta_p_block_res_acc_30842 = 0;\n            eta_p_block_res_acc_30843 = 0;\n        }\n        tblock_id_in_segment_30850 = squot64(global_tid_30839, seghist_tblock_sizze_29558);\n        block_base_offset_30851 = tblock_id_in_segment_30850 * q_30814 * seghist_tblock_sizze_29558;\n        for (int64_t i_30852 = 0; i_30852 < q_30814; i_30852++) {\n            int64_t block_offset_30853 = block_base_offset_30851 + i_30852 * seghist_tblock_sizze_29558;\n            \n            subhistogram_id_30774 = global_tid_30839 + threads_per_segment_30816 * i_30852;\n            if (slt64(subhistogram_id_30774, num_subhistos_30677)) {\n                // apply map function(s)\n                {\n                    // load accumulator(s)\n                    {\n                        eta_p_29566 = eta_p_block_res_acc_30842;\n                        eta_p_29567 = eta_p_block_res_acc_30843;\n                    }\n                    // load next value(s)\n                    {\n                        eta_p_29568 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[subhistogram_id_30774 * mz2080U_25210 + bucket_id_30773];\n                        eta_p_29569 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[subhistogram_id_30774 * mz2080U_25210 + bucket_id_30773];\n                    }\n                    // apply reduction operator(s)\n                    {\n                        int32_t tmp_29570 = add32(eta_p_29566, eta_p_29568);\n                        int32_t tmp_29571 = add32(eta_p_29567, eta_p_29569);\n                        \n                        // store in accumulator(s)\n                        {\n                            eta_p_block_res_acc_30842 = tmp_29570;\n                            eta_p_block_res_acc_30843 ",
                                    "= tmp_29571;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // store accs. prims go in lmem; non-prims in params (in global mem)\n        {\n            ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_block_res_acc_30842;\n            ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_block_res_acc_30843;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        skip_waves_30855 = 1;\n        offset_30854 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_30824, sext_i64_i32(seghist_tblock_sizze_29558))) {\n                eta_p_30844 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                eta_p_30845 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n            }\n        }\n        offset_30854 = 1;\n        while (slt32(offset_30854, wave_sizze_30826)) {\n            if (slt32(local_tid_30824 + offset_30854, sext_i64_i32(seghist_tblock_sizze_29558)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) & (2 * offset_30854 - 1)) == 0) {\n                // read array element\n                {\n                    eta_p_30846 = ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                    eta_p_30847 = ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                    int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                    \n                    eta_p_30844 = tmp_30848;\n                    eta_p_30845 = tmp_30849;\n                }\n                // write result of opera", "tion\n                {\n                    ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                    ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                }\n            }\n            offset_30854 *= 2;\n        }\n        while (slt32(skip_waves_30855, squot32(sext_i64_i32(seghist_tblock_sizze_29558) + wave_sizze_30826 - 1, wave_sizze_30826))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_30854 = skip_waves_30855 * wave_sizze_30826;\n            if (slt32(local_tid_30824 + offset_30854, sext_i64_i32(seghist_tblock_sizze_29558)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) == 0 && (squot32(local_tid_30824, wave_sizze_30826) & (2 * skip_waves_30855 - 1)) == 0)) {\n                // read array element\n                {\n                    eta_p_30846 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                    eta_p_30847 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30854)];\n                }\n                // apply reduction operation\n                {\n                    int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                    int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                    \n                    eta_p_30844 = tmp_30848;\n                    eta_p_30845 = tmp_30849;\n                }\n                // write result of operation\n                {\n                    ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                    ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                }\n            }\n            skip_waves_30855 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // thread 0 updates per-block acc(s); rest rese", "t to ne\n        {\n            if (sext_i32_i64(local_tid_30824) == (int64_t) 0) {\n                eta_p_block_res_acc_30842 = eta_p_30844;\n                eta_p_block_res_acc_30843 = eta_p_30845;\n            } else {\n                eta_p_block_res_acc_30842 = 0;\n                eta_p_block_res_acc_30843 = 0;\n            }\n        }\n        if (blocks_per_segment_30813 == (int64_t) 1) {\n            // first thread in block saves final result to memory\n            {\n                if (local_tid_30824 == 0) {\n                    ((__global int32_t *) mem_29744)[bucket_id_30773] = eta_p_block_res_acc_30842;\n                    ((__global int32_t *) mem_29742)[bucket_id_30773] = eta_p_block_res_acc_30843;\n                }\n            }\n        } else {\n            int32_t old_counter_30856;\n            bool is_last_block_30857;\n            \n            // first thread in block saves block result to global memory\n            {\n                if (local_tid_30824 == 0) {\n                    ((__global int32_t *) segred_tmp_mem_30817)[sext_i32_i64(virt_tblock_id_30837)] = eta_p_block_res_acc_30842;\n                    mem_fence_global();\n                    ((__global int32_t *) segred_tmp_mem_30819)[sext_i32_i64(virt_tblock_id_30837)] = eta_p_block_res_acc_30843;\n                    mem_fence_global();\n                    old_counter_30856 = atomic_add_i32_global(&((volatile __global int *) counters_mem_30821)[srem64(flat_segment_id_30838, (int64_t) 20480)], (int) 1);\n                    ((__local bool *) sync_arr_mem_30832)[(int64_t) 0] = old_counter_30856 == sext_i64_i32(blocks_per_segment_30813 - (int64_t) 1);\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            is_last_block_30857 = ((__local bool *) sync_arr_mem_30832)[(int64_t) 0];\n            if (is_last_block_30857) {\n                if (local_tid_30824 == 0) {\n                    old_counter_30856 = atomic_add_i32_global(&((volatile __global int *) counter",
                                    "s_mem_30821)[srem64(flat_segment_id_30838, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_30813));\n                }\n                // read in the per-block-results\n                {\n                    int64_t read_per_thread_30858 = sdiv_up64(blocks_per_segment_30813, seghist_tblock_sizze_29558);\n                    \n                    eta_p_29566 = 0;\n                    eta_p_29567 = 0;\n                    for (int64_t i_30859 = 0; i_30859 < read_per_thread_30858; i_30859++) {\n                        int64_t block_res_id_30860 = sext_i32_i64(local_tid_30824) * read_per_thread_30858 + i_30859;\n                        int64_t index_of_block_res_30861 = flat_segment_id_30838 * blocks_per_segment_30813 + block_res_id_30860;\n                        \n                        if (slt64(block_res_id_30860, blocks_per_segment_30813)) {\n                            eta_p_29568 = ((__global int32_t *) segred_tmp_mem_30817)[index_of_block_res_30861];\n                            eta_p_29569 = ((__global int32_t *) segred_tmp_mem_30819)[index_of_block_res_30861];\n                            \n                            int32_t tmp_29570 = add32(eta_p_29566, eta_p_29568);\n                            int32_t tmp_29571 = add32(eta_p_29567, eta_p_29569);\n                            \n                            eta_p_29566 = tmp_29570;\n                            eta_p_29567 = tmp_29571;\n                        }\n                    }\n                }\n                ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_29566;\n                ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_29567;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-block results\n                {\n                    int32_t offset_30862;\n                    int32_t skip_waves_30863 = 1;\n                    int32_t eta_p_30844;\n                    int32_t eta_p_30845;\n                ", "    int32_t eta_p_30846;\n                    int32_t eta_p_30847;\n                    \n                    offset_30862 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_30824, sext_i64_i32(seghist_tblock_sizze_29558))) {\n                            eta_p_30844 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                            eta_p_30845 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                        }\n                    }\n                    offset_30862 = 1;\n                    while (slt32(offset_30862, wave_sizze_30826)) {\n                        if (slt32(local_tid_30824 + offset_30862, sext_i64_i32(seghist_tblock_sizze_29558)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) & (2 * offset_30862 - 1)) == 0) {\n                            // read array element\n                            {\n                                eta_p_30846 = ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                                eta_p_30847 = ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                                int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                                \n                                eta_p_30844 = tmp_30848;\n                                eta_p_30845 = tmp_30849;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] ", "= eta_p_30844;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                            }\n                        }\n                        offset_30862 *= 2;\n                    }\n                    while (slt32(skip_waves_30863, squot32(sext_i64_i32(seghist_tblock_sizze_29558) + wave_sizze_30826 - 1, wave_sizze_30826))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_30862 = skip_waves_30863 * wave_sizze_30826;\n                        if (slt32(local_tid_30824 + offset_30862, sext_i64_i32(seghist_tblock_sizze_29558)) && ((local_tid_30824 - squot32(local_tid_30824, wave_sizze_30826) * wave_sizze_30826) == 0 && (squot32(local_tid_30824, wave_sizze_30826) & (2 * skip_waves_30863 - 1)) == 0)) {\n                            // read array element\n                            {\n                                eta_p_30846 = ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                                eta_p_30847 = ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824 + offset_30862)];\n                            }\n                            // apply reduction operation\n                            {\n                                int32_t tmp_30848 = add32(eta_p_30844, eta_p_30846);\n                                int32_t tmp_30849 = add32(eta_p_30845, eta_p_30847);\n                                \n                                eta_p_30844 = tmp_30848;\n                                eta_p_30845 = tmp_30849;\n                            }\n                            // write result of operation\n                            {\n                                ((__local int32_t *) red_arr_i32_mem_30828)[sext_i32_i64(local_tid_30824)] = eta_p_30844;\n                                ((__local int32_t *) red_arr_i32_mem_30830)[sext_i32_i64(local_tid_30824)] = eta_p_30845;\n                       ",
                                    "     }\n                        }\n                        skip_waves_30863 *= 2;\n                    }\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_30824 == 0) {\n                            ((__global int32_t *) mem_29744)[bucket_id_30773] = eta_p_30844;\n                            ((__global int32_t *) mem_29742)[bucket_id_30773] = eta_p_30845;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_6:\n    return;\n    #undef seghist_tblock_sizze_29558\n    #undef chunk_sizze_30776\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegred_small_30337_dim1, 1, 1)\nvoid human_generici32zisegred_small_30337(__global int *global_failure, int64_t mz2080U_25210, int64_t num_tblocks_29269, int64_t num_subhistos_30239, int64_t segment_sizze_nonzzero_30339, __global unsigned char *mem_29697, __global unsigned char *mem_29699, __global unsigned char *defunc_0_map_res_subhistos_mem_30240, __global unsigned char *defunc_0_map_res_subhistos_mem_30242)\n{\n    #define seghist_tblock_sizze_29267 (human_generici32zisegred_small_30337ziseghist_tblock_sizze_29267)\n    \n    volatile __local unsigned char *red_arr_i32_mem_30348_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_30348_backing_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_29267 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29267, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30346_backing_0 = &shared_mem[red_arr_i32_mem_30348_backing_1_offset];\n    const int64_t red_arr_i32_mem_30346_backing_0_offset = red_arr_i32_mem_30348_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_29267 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29267, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        ret", "urn;\n    \n    int32_t local_tid_30342;\n    int32_t tblock_sizze_30345;\n    int32_t wave_sizze_30344;\n    int32_t block_id_30343;\n    int32_t global_tid_30341;\n    int64_t flat_gtid_30337;\n    __local unsigned char *red_arr_i32_mem_30346;\n    __local unsigned char *red_arr_i32_mem_30348;\n    int32_t phys_tblock_id_30350;\n    int32_t iterations_30351;\n    \n    local_tid_30342 = get_local_id(0);\n    tblock_sizze_30345 = get_local_size(0);\n    wave_sizze_30344 = LOCKSTEP_WIDTH;\n    block_id_30343 = get_tblock_id(0);\n    global_tid_30341 = block_id_30343 * tblock_sizze_30345 + local_tid_30342;\n    flat_gtid_30337 = sext_i32_i64(global_tid_30341);\n    red_arr_i32_mem_30346 = (__local unsigned char *) red_arr_i32_mem_30346_backing_0;\n    red_arr_i32_mem_30348 = (__local unsigned char *) red_arr_i32_mem_30348_backing_1;\n    phys_tblock_id_30350 = get_tblock_id(0);\n    iterations_30351 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_25210, squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339))) - phys_tblock_id_30350, sext_i64_i32(num_tblocks_29269));\n    for (int32_t i_30352 = 0; i_30352 < iterations_30351; i_30352++) {\n        int32_t virt_tblock_id_30353;\n        int64_t slice_30354;\n        int64_t bucket_id_30335;\n        int64_t remnant_30355;\n        int64_t subhistogram_id_30336;\n        \n        virt_tblock_id_30353 = phys_tblock_id_30350 + i_30352 * sext_i64_i32(num_tblocks_29269);\n        slice_30354 = mz2080U_25210;\n        bucket_id_30335 = squot64(sext_i32_i64(local_tid_30342), segment_sizze_nonzzero_30339) + sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339);\n        remnant_30355 = squot64(sext_i32_i64(local_tid_30342), segment_sizze_nonzzero_30339) + sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339) - bucket_id_30335;\n        subhistogram_id_30336 = srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239);\n        // apply map function if in boun", "ds\n        {\n            if (slt64((int64_t) 0, num_subhistos_30239) && (slt64(bucket_id_30335, mz2080U_25210) && slt64(sext_i32_i64(local_tid_30342), num_subhistos_30239 * squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_30356 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30240)[subhistogram_id_30336 * mz2080U_25210 + bucket_id_30335];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = tmp_30356;\n                    \n                    int32_t tmp_30357 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30242)[subhistogram_id_30336 * mz2080U_25210 + bucket_id_30335];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = tmp_30357;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_30239)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_29275;\n                int32_t eta_p_29276;\n                int32_t eta_p_29277;\n                int32_t eta_p_29278;\n                int32_t eta_p_30358;\n                int32_t eta_p_30359;\n                int32_t eta_p_30360;\n                int32_t eta_p_30361;\n                bool ltid_in_bounds_30364 = slt64(sext_i32_i64(local_tid_30342), num_subhistos_30239 * squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339));\n                int32_t skip_threads_30365;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_30364) {\n                        eta_p_2927",
                                    "7 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)];\n                        eta_p_29278 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)];\n                        if ((local_tid_30342 - squot32(local_tid_30342, 32) * 32) == 0) {\n                            eta_p_29275 = eta_p_29277;\n                            eta_p_29276 = eta_p_29278;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30365 = 1;\n                    while (slt32(skip_threads_30365, 32)) {\n                        bool thread_active_30366 = sle32(skip_threads_30365, local_tid_30342 - squot32(local_tid_30342, 32) * 32) && ltid_in_bounds_30364;\n                        \n                        if (thread_active_30366) {\n                            // read operands\n                            {\n                                eta_p_29275 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30365)];\n                                eta_p_29276 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30365)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_30367 = slt64(srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239), sext_i32_i64(local_tid_30342) - sext_i32_i64(local_tid_30342 - skip_threads_30365));\n                            \n                            if (thread_active_30366 && inactive_30367) {\n                                eta_p_29275 = eta_p_29277;\n                                eta_p_29276 = eta_p_29278;\n                            }\n                            if (thread_active_30366) {\n                                if (!inactive_30367) {\n          ", "                          int32_t tmp_29279 = add32(eta_p_29275, eta_p_29277);\n                                    int32_t tmp_29280 = add32(eta_p_29276, eta_p_29278);\n                                    \n                                    eta_p_29275 = tmp_29279;\n                                    eta_p_29276 = tmp_29280;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_30344, skip_threads_30365)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30366) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_29275;\n                                eta_p_29277 = eta_p_29275;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_29276;\n                                eta_p_29278 = eta_p_29276;\n                            }\n                        }\n                        if (sle32(wave_sizze_30344, skip_threads_30365)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30365 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_30342 - squot32(local_tid_30342, 32) * 32) == 31 && ltid_in_bounds_30364) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(squot32(local_tid_30342, 32))] = eta_p_29275;\n                        ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(squot32(local_tid_30342, 32))] = eta_p_29276;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n      ", "          // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_30368;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364) {\n                            eta_p_30360 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)];\n                            eta_p_30361 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)];\n                            if ((local_tid_30342 - squot32(local_tid_30342, 32) * 32) == 0) {\n                                eta_p_30358 = eta_p_30360;\n                                eta_p_30359 = eta_p_30361;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_30368 = 1;\n                        while (slt32(skip_threads_30368, 32)) {\n                            bool thread_active_30369 = sle32(skip_threads_30368, local_tid_30342 - squot32(local_tid_30342, 32) * 32) && (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364);\n                            \n                            if (thread_active_30369) {\n                                // read operands\n                                {\n                                    eta_p_30358 = ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30368)];\n                                    eta_p_30359 = ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342) - sext_i32_i64(skip_threads_30368)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_30370 = slt64(srem",
                                    "64(sext_i32_i64(local_tid_30342 * 32 + 32 - 1), num_subhistos_30239), sext_i32_i64(local_tid_30342 * 32 + 32 - 1) - sext_i32_i64((local_tid_30342 - skip_threads_30368) * 32 + 32 - 1));\n                                \n                                if (thread_active_30369 && inactive_30370) {\n                                    eta_p_30358 = eta_p_30360;\n                                    eta_p_30359 = eta_p_30361;\n                                }\n                                if (thread_active_30369) {\n                                    if (!inactive_30370) {\n                                        int32_t tmp_30362 = add32(eta_p_30358, eta_p_30360);\n                                        int32_t tmp_30363 = add32(eta_p_30359, eta_p_30361);\n                                        \n                                        eta_p_30358 = tmp_30362;\n                                        eta_p_30359 = tmp_30363;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_30344, skip_threads_30368)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_30369) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_30358;\n                                    eta_p_30360 = eta_p_30358;\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_30359;\n                                    eta_p_30361 = eta_p_30359;\n                                }\n                            }\n                            if (sle32(wave_sizze_30344, skip_threads_30368)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            s", "kip_threads_30368 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_30371 = squot32(local_tid_30342, 32) == 0 || !ltid_in_bounds_30364;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_30371) {\n                            eta_p_29277 = eta_p_29275;\n                            eta_p_29278 = eta_p_29276;\n                            eta_p_29275 = ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(squot32(local_tid_30342, 32)) - (int64_t) 1];\n                            eta_p_29276 = ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(squot32(local_tid_30342, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_30372 = slt64(srem64(sext_i32_i64(local_tid_30342), num_subhistos_30239), sext_i32_i64(local_tid_30342) - sext_i32_i64(squot32(local_tid_30342, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_30371) {\n                            if (inactive_30372) {\n                                eta_p_29275 = eta_p_29277;\n                                eta_p_29276 = eta_p_29278;\n                            }\n                        }\n                        if (!no_carry_in_30371) {\n                            if (!inactive_30372) {\n                                int32_t tmp_29279 = add32(eta_p_29275, eta_p_29277);\n                                int32_t tmp_29280 = add32(eta_p_29276, eta_p_29278);\n                                \n                                eta_p_29275 = tmp_29279;\n                                eta_p_29276 = tmp_29280;\n                            }\n                        }\n                    }\n                    // write final re", "sult\n                    {\n                        if (!no_carry_in_30371) {\n                            ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_29275;\n                            ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_29276;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_30342, 32) == 0 && ltid_in_bounds_30364) {\n                        ((__local int32_t *) red_arr_i32_mem_30346)[sext_i32_i64(local_tid_30342)] = eta_p_29277;\n                        ((__local int32_t *) red_arr_i32_mem_30348)[sext_i32_i64(local_tid_30342)] = eta_p_29278;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid_30342), mz2080U_25210) && slt64(sext_i32_i64(local_tid_30342), squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339))) {\n                int32_t tmp_30373 = ((__local int32_t *) red_arr_i32_mem_30346)[(sext_i32_i64(local_tid_30342) + (int64_t) 1) * segment_sizze_nonzzero_30339 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29699)[sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid_30342)] = tmp_30373;\n                \n                int32_t tmp_30374 = ((__local int32_t *) red_arr_i32_mem_30348)[(sext_i32_i64(local_tid_30342) + (int64_t) 1) * segment_sizze_nonzzero_30339 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29697)[sext_i32_i64(virt_tblock_id_30353) * squot64(seghist_tblock_",
                                    "sizze_29267, segment_sizze_nonzzero_30339) + sext_i32_i64(local_tid_30342)] = tmp_30374;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_29267\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegred_small_30775_dim1, 1, 1)\nvoid human_generici32zisegred_small_30775(__global int *global_failure, int64_t mz2080U_25210, int64_t num_tblocks_29560, int64_t num_subhistos_30677, int64_t segment_sizze_nonzzero_30777, __global unsigned char *mem_29742, __global unsigned char *mem_29744, __global unsigned char *defunc_0_map_res_subhistos_mem_30678, __global unsigned char *defunc_0_map_res_subhistos_mem_30680)\n{\n    #define seghist_tblock_sizze_29558 (human_generici32zisegred_small_30775ziseghist_tblock_sizze_29558)\n    \n    volatile __local unsigned char *red_arr_i32_mem_30786_backing_1 = &shared_mem[0];\n    const int64_t red_arr_i32_mem_30786_backing_1_offset = 0 + ((int64_t) 4 * seghist_tblock_sizze_29558 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29558, (int64_t) 8), (int64_t) 8));\n    volatile __local unsigned char *red_arr_i32_mem_30784_backing_0 = &shared_mem[red_arr_i32_mem_30786_backing_1_offset];\n    const int64_t red_arr_i32_mem_30784_backing_0_offset = red_arr_i32_mem_30786_backing_1_offset + ((int64_t) 4 * seghist_tblock_sizze_29558 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29558, (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30780;\n    int32_t tblock_sizze_30783;\n    int32_t wave_sizze_30782;\n    int32_t block_id_30781;\n    int32_t global_tid_30779;\n    int64_t flat_gtid_30775;\n    __local unsigned char *red_arr_i32_mem_30784;\n    __local unsigned char *red_arr_i32_mem_30786;\n    int32_t phys_tblock_id_30788;\n    int32_t iterations_30789;\n    \n    local_tid_30780 = get_local_id(0);\n    tblock_sizze_30783 = get_local_size(0);\n    ", "wave_sizze_30782 = LOCKSTEP_WIDTH;\n    block_id_30781 = get_tblock_id(0);\n    global_tid_30779 = block_id_30781 * tblock_sizze_30783 + local_tid_30780;\n    flat_gtid_30775 = sext_i32_i64(global_tid_30779);\n    red_arr_i32_mem_30784 = (__local unsigned char *) red_arr_i32_mem_30784_backing_0;\n    red_arr_i32_mem_30786 = (__local unsigned char *) red_arr_i32_mem_30786_backing_1;\n    phys_tblock_id_30788 = get_tblock_id(0);\n    iterations_30789 = sdiv_up32(sext_i64_i32(sdiv_up64(mz2080U_25210, squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777))) - phys_tblock_id_30788, sext_i64_i32(num_tblocks_29560));\n    for (int32_t i_30790 = 0; i_30790 < iterations_30789; i_30790++) {\n        int32_t virt_tblock_id_30791;\n        int64_t slice_30792;\n        int64_t bucket_id_30773;\n        int64_t remnant_30793;\n        int64_t subhistogram_id_30774;\n        \n        virt_tblock_id_30791 = phys_tblock_id_30788 + i_30790 * sext_i64_i32(num_tblocks_29560);\n        slice_30792 = mz2080U_25210;\n        bucket_id_30773 = squot64(sext_i32_i64(local_tid_30780), segment_sizze_nonzzero_30777) + sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777);\n        remnant_30793 = squot64(sext_i32_i64(local_tid_30780), segment_sizze_nonzzero_30777) + sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777) - bucket_id_30773;\n        subhistogram_id_30774 = srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677);\n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, num_subhistos_30677) && (slt64(bucket_id_30773, mz2080U_25210) && slt64(sext_i32_i64(local_tid_30780), num_subhistos_30677 * squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777)))) {\n                // save results to be reduced\n                {\n                    int32_t tmp_30794 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30678)[subhistogram_id_30774 * mz2080U_2521", "0 + bucket_id_30773];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = tmp_30794;\n                    \n                    int32_t tmp_30795 = ((__global int32_t *) defunc_0_map_res_subhistos_mem_30680)[subhistogram_id_30774 * mz2080U_25210 + bucket_id_30773];\n                    \n                    ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = tmp_30795;\n                }\n            } else {\n                ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = 0;\n                ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = 0;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, num_subhistos_30677)) {\n            // perform segmented scan to imitate reduction\n            {\n                int32_t eta_p_29566;\n                int32_t eta_p_29567;\n                int32_t eta_p_29568;\n                int32_t eta_p_29569;\n                int32_t eta_p_30796;\n                int32_t eta_p_30797;\n                int32_t eta_p_30798;\n                int32_t eta_p_30799;\n                bool ltid_in_bounds_30802 = slt64(sext_i32_i64(local_tid_30780), num_subhistos_30677 * squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777));\n                int32_t skip_threads_30803;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_30802) {\n                        eta_p_29568 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)];\n                        eta_p_29569 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)];\n                        if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == 0) {\n                            eta_p_29566 = eta_p_29568;\n                            eta_p_29567 = eta_p_29569;\n                        }\n      ",
                                    "              }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30803 = 1;\n                    while (slt32(skip_threads_30803, 32)) {\n                        bool thread_active_30804 = sle32(skip_threads_30803, local_tid_30780 - squot32(local_tid_30780, 32) * 32) && ltid_in_bounds_30802;\n                        \n                        if (thread_active_30804) {\n                            // read operands\n                            {\n                                eta_p_29566 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30803)];\n                                eta_p_29567 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30803)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_30805 = slt64(srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677), sext_i32_i64(local_tid_30780) - sext_i32_i64(local_tid_30780 - skip_threads_30803));\n                            \n                            if (thread_active_30804 && inactive_30805) {\n                                eta_p_29566 = eta_p_29568;\n                                eta_p_29567 = eta_p_29569;\n                            }\n                            if (thread_active_30804) {\n                                if (!inactive_30805) {\n                                    int32_t tmp_29570 = add32(eta_p_29566, eta_p_29568);\n                                    int32_t tmp_29571 = add32(eta_p_29567, eta_p_29569);\n                                    \n                                    eta_p_29566 = tmp_29570;\n                                    eta_p_29567 = tmp_29571;\n                                }\n                            }\n                        }\n                        if ", "(sle32(wave_sizze_30782, skip_threads_30803)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30804) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_29566;\n                                eta_p_29568 = eta_p_29566;\n                                ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_29567;\n                                eta_p_29569 = eta_p_29567;\n                            }\n                        }\n                        if (sle32(wave_sizze_30782, skip_threads_30803)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30803 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == 31 && ltid_in_bounds_30802) {\n                        ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(squot32(local_tid_30780, 32))] = eta_p_29566;\n                        ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(squot32(local_tid_30780, 32))] = eta_p_29567;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_30806;\n                    \n                    // read input for in-block scan\n                    {\n                        if (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802) {\n                            eta_p_30798 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i3", "2_i64(local_tid_30780)];\n                            eta_p_30799 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)];\n                            if ((local_tid_30780 - squot32(local_tid_30780, 32) * 32) == 0) {\n                                eta_p_30796 = eta_p_30798;\n                                eta_p_30797 = eta_p_30799;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_30806 = 1;\n                        while (slt32(skip_threads_30806, 32)) {\n                            bool thread_active_30807 = sle32(skip_threads_30806, local_tid_30780 - squot32(local_tid_30780, 32) * 32) && (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802);\n                            \n                            if (thread_active_30807) {\n                                // read operands\n                                {\n                                    eta_p_30796 = ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30806)];\n                                    eta_p_30797 = ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780) - sext_i32_i64(skip_threads_30806)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_30808 = slt64(srem64(sext_i32_i64(local_tid_30780 * 32 + 32 - 1), num_subhistos_30677), sext_i32_i64(local_tid_30780 * 32 + 32 - 1) - sext_i32_i64((local_tid_30780 - skip_threads_30806) * 32 + 32 - 1));\n                                \n                                if (thread_active_30807 && inactive_30808) {\n                                    eta_p_30796 = eta_p_30798;\n                                    eta_p_30797 = eta_p_30799;\n                       ",
                                    "         }\n                                if (thread_active_30807) {\n                                    if (!inactive_30808) {\n                                        int32_t tmp_30800 = add32(eta_p_30796, eta_p_30798);\n                                        int32_t tmp_30801 = add32(eta_p_30797, eta_p_30799);\n                                        \n                                        eta_p_30796 = tmp_30800;\n                                        eta_p_30797 = tmp_30801;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_30782, skip_threads_30806)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_30807) {\n                                // write result\n                                {\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_30796;\n                                    eta_p_30798 = eta_p_30796;\n                                    ((volatile __local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_30797;\n                                    eta_p_30799 = eta_p_30797;\n                                }\n                            }\n                            if (sle32(wave_sizze_30782, skip_threads_30806)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_30806 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_30809 = squot32(local_tid_30780, 32) == 0 || !ltid_in_bounds_30802;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_car", "ry_in_30809) {\n                            eta_p_29568 = eta_p_29566;\n                            eta_p_29569 = eta_p_29567;\n                            eta_p_29566 = ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(squot32(local_tid_30780, 32)) - (int64_t) 1];\n                            eta_p_29567 = ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(squot32(local_tid_30780, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_30810 = slt64(srem64(sext_i32_i64(local_tid_30780), num_subhistos_30677), sext_i32_i64(local_tid_30780) - sext_i32_i64(squot32(local_tid_30780, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_30809) {\n                            if (inactive_30810) {\n                                eta_p_29566 = eta_p_29568;\n                                eta_p_29567 = eta_p_29569;\n                            }\n                        }\n                        if (!no_carry_in_30809) {\n                            if (!inactive_30810) {\n                                int32_t tmp_29570 = add32(eta_p_29566, eta_p_29568);\n                                int32_t tmp_29571 = add32(eta_p_29567, eta_p_29569);\n                                \n                                eta_p_29566 = tmp_29570;\n                                eta_p_29567 = tmp_29571;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_30809) {\n                            ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_29566;\n                            ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_29567;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // ", "restore correct values for first block\n                {\n                    if (squot32(local_tid_30780, 32) == 0 && ltid_in_bounds_30802) {\n                        ((__local int32_t *) red_arr_i32_mem_30784)[sext_i32_i64(local_tid_30780)] = eta_p_29568;\n                        ((__local int32_t *) red_arr_i32_mem_30786)[sext_i32_i64(local_tid_30780)] = eta_p_29569;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777) + sext_i32_i64(local_tid_30780), mz2080U_25210) && slt64(sext_i32_i64(local_tid_30780), squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777))) {\n                int32_t tmp_30811 = ((__local int32_t *) red_arr_i32_mem_30784)[(sext_i32_i64(local_tid_30780) + (int64_t) 1) * segment_sizze_nonzzero_30777 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29744)[sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777) + sext_i32_i64(local_tid_30780)] = tmp_30811;\n                \n                int32_t tmp_30812 = ((__local int32_t *) red_arr_i32_mem_30786)[(sext_i32_i64(local_tid_30780) + (int64_t) 1) * segment_sizze_nonzzero_30777 - (int64_t) 1];\n                \n                ((__global int32_t *) mem_29742)[sext_i32_i64(virt_tblock_id_30791) * squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777) + sext_i32_i64(local_tid_30780)] = tmp_30812;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_3:\n    return;\n    #undef seghist_tblock_sizze_29558\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegscan_29194_dim1, 1, 1)\nvoid human_generici32zisegscan_29194(__global int *global_failure, int64_t mz2080U_25210, int",
                                    "64_t num_tblocks_29191, int64_t num_virt_blocks_29795, int64_t num_virt_threads_29796, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29683, __global unsigned char *status_flags_mem_29797, __global unsigned char *aggregates_mem_29819, __global unsigned char *incprefixes_mem_29821, __global unsigned char *global_dynid_mem_29823)\n{\n    #define segscan_tblock_sizze_29189 (human_generici32zisegscan_29194zisegscan_tblock_sizze_29189)\n    #define chunk_sizze_29794 (human_generici32zisegscan_29194zichunk_sizze_29794)\n    \n    volatile __local unsigned char *local_mem_29853_backing_0 = &shared_mem[0];\n    const int64_t local_mem_29853_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29189), chunk_sizze_29794 * segscan_tblock_sizze_29189 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29189), chunk_sizze_29794 * segscan_tblock_sizze_29189 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29846;\n    int32_t tblock_sizze_29849;\n    int32_t wave_sizze_29848;\n    int32_t block_id_29847;\n    int32_t global_tid_29845;\n    int64_t phys_tid_29194;\n    int32_t chunk_sizze_32b_29850;\n    int64_t byte_offsets_29851;\n    int64_t warp_byte_offset_29852;\n    __local unsigned char *local_mem_29853;\n    int64_t trans_arr_len_29854;\n    int64_t phys_block_id_29860;\n    int64_t virtloop_bound_29861;\n    \n    local_tid_29846 = get_local_id(0);\n    tblock_sizze_29849 = get_local_size(0);\n    wave_sizze_29848 = LOCKSTEP_WIDTH;\n    block_id_29847 = get_tblock_id(0);\n    global_tid_29845 = block_id_29847 * tblock_sizze_29849 + local_tid_29846;\n    phys_tid_29194 = sext_i32_i64(global_tid_29845);\n    chunk_sizze_32b_29850 = sext_i64_i32(chunk_sizze_29794);\n    byte_offsets_29851 = segscan_tblock_sizze_29189 * (int64_t) 8;\n    warp_byte_offset_29852 = (int64_t) 288;\n    // Allocate reusable shared memory\n    {", " }\n    local_mem_29853 = (__local unsigned char *) local_mem_29853_backing_0;\n    trans_arr_len_29854 = chunk_sizze_29794 * segscan_tblock_sizze_29189;\n    phys_block_id_29860 = get_tblock_id(0);\n    virtloop_bound_29861 = sdiv_up64(num_virt_blocks_29795 - phys_block_id_29860, num_tblocks_29191);\n    for (int64_t virtloop_i_29862 = 0; virtloop_i_29862 < virtloop_bound_29861; virtloop_i_29862++) {\n        int64_t dynamic_id_29863;\n        int64_t block_offset_29864;\n        int64_t sgm_idx_29865;\n        int32_t boundary_29866;\n        int32_t segsizze_compact_29867;\n        int64_t private_mem_29868[chunk_sizze_29794];\n        int64_t thd_offset_29870;\n        int64_t acc_29886;\n        int64_t prefix_29896;\n        bool block_new_sgm_29897;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_29846 == 0) {\n                dynamic_id_29863 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_29823)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_29853)[(int64_t) 0] = dynamic_id_29863;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_29863 == num_virt_blocks_29795 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_29823)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_29863 = ((__local int32_t *) local_mem_29853)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_29864 = dynamic_id_29863 * chunk_sizze_29794 * segscan_tblock_sizze_29189;\n        sgm_idx_29865 = smod64(block_offset_29864, mz2080U_25210);\n        boundary_29866 = sext_i64_i32(smin64(chunk_sizze_29794 * segscan_tblock_sizze_29189, mz2080U_25210 - sgm_idx_29865));\n        segsizze_compact_29867 = sext", "_i64_i32(smin64(chunk_sizze_29794 * segscan_tblock_sizze_29189, mz2080U_25210));\n        thd_offset_29870 = block_offset_29864 + sext_i32_i64(local_tid_29846);\n        // Load and map\n        {\n            for (int64_t i_29871 = 0; i_29871 < chunk_sizze_29794; i_29871++) {\n                int64_t virt_tid_29872 = thd_offset_29870 + i_29871 * segscan_tblock_sizze_29189;\n                int64_t slice_29873 = mz2080U_25210;\n                int64_t gtid_29193 = virt_tid_29872;\n                int64_t remnant_29874 = virt_tid_29872 - gtid_29193;\n                \n                if (slt64(virt_tid_29872, mz2080U_25210)) {\n                    int32_t eta_p_27712 = ((__global int32_t *) shp_mem_29678)[gtid_29193];\n                    int64_t i32_res_27713 = sext_i32_i64(eta_p_27712);\n                    \n                    private_mem_29868[i_29871] = i32_res_27713;\n                } else {\n                    private_mem_29868[i_29871] = (int64_t) 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_29875 = 0; i_29875 < chunk_sizze_29794; i_29875++) {\n                int64_t sharedIdx_29876 = sext_i32_i64(local_tid_29846) + i_29875 * segscan_tblock_sizze_29189;\n                int64_t tmp_29877 = private_mem_29868[i_29875];\n                \n                ((__local int64_t *) local_mem_29853)[sharedIdx_29876] = tmp_29877;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_29878 = 0; i_29878 < chunk_sizze_29794; i_29878++) {\n                int64_t sharedIdx_29879 = sext_i32_i64(local_tid_29846) * chunk_sizze_29794 + i_29878;\n                int64_t tmp_29880 = ((__local int64_t *) local_mem_29853)[sharedIdx_29879];\n                \n                private_mem_29868[i_29878] = tmp_29880;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_29881 = 0; i_29881 < chunk_",
                                    "sizze_29794 - (int64_t) 1; i_29881++) {\n                int64_t eta_p_27379;\n                int64_t eta_p_27380;\n                \n                eta_p_27379 = private_mem_29868[i_29881];\n                eta_p_27380 = private_mem_29868[i_29881 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27381 = add64(eta_p_27379, eta_p_27380);\n                \n                private_mem_29868[i_29881 + (int64_t) 1] = defunc_0_op_res_27381;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_29882 = private_mem_29868[chunk_sizze_29794 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = tmp_29882;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_29883;\n            int64_t eta_p_29884;\n            int64_t eta_p_29887;\n            int64_t eta_p_29888;\n            bool ltid_in_bounds_29890 = slt64(sext_i32_i64(local_tid_29846), num_virt_threads_29796);\n            int32_t skip_threads_29891;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_29890) {\n                    eta_p_29884 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                    if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                        eta_p_29883 = eta_p_29884;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_29891 = 1;\n                while (slt32(skip_threads_29891, 32)) {\n                    bool thread_active_29892 = sle32(skip_threads_29891, local_tid_29846 - squot32(local_tid_29846, 32) * 32) && ltid_in_bounds_29890;\n                    \n                    if (thread_active_29892) {\n                        // read operands\n                        {\n                     ", "       eta_p_29883 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29891)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_29892) {\n                            int64_t defunc_0_op_res_29885 = add64(eta_p_29883, eta_p_29884);\n                            \n                            eta_p_29883 = defunc_0_op_res_29885;\n                        }\n                    }\n                    if (sle32(wave_sizze_29848, skip_threads_29891)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_29892) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29883;\n                            eta_p_29884 = eta_p_29883;\n                        }\n                    }\n                    if (sle32(wave_sizze_29848, skip_threads_29891)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_29891 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 31 && ltid_in_bounds_29890) {\n                    ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(squot32(local_tid_29846, 32))] = eta_p_29883;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_29893;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_29846, 32) == 0 && ltid_in_bounds_29890) {\n     ", "                   eta_p_29888 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                        if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                            eta_p_29887 = eta_p_29888;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_29893 = 1;\n                    while (slt32(skip_threads_29893, 32)) {\n                        bool thread_active_29894 = sle32(skip_threads_29893, local_tid_29846 - squot32(local_tid_29846, 32) * 32) && (squot32(local_tid_29846, 32) == 0 && ltid_in_bounds_29890);\n                        \n                        if (thread_active_29894) {\n                            // read operands\n                            {\n                                eta_p_29887 = ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29893)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_29894) {\n                                int64_t defunc_0_op_res_29889 = add64(eta_p_29887, eta_p_29888);\n                                \n                                eta_p_29887 = defunc_0_op_res_29889;\n                            }\n                        }\n                        if (sle32(wave_sizze_29848, skip_threads_29893)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_29894) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29887;\n                                eta_p_29888 = eta_p_29887;\n                            }\n                        }\n                        i",
                                    "f (sle32(wave_sizze_29848, skip_threads_29893)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_29893 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_29895 = squot32(local_tid_29846, 32) == 0 || !ltid_in_bounds_29890;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_29895) {\n                        eta_p_29884 = eta_p_29883;\n                        eta_p_29883 = ((__local int64_t *) local_mem_29853)[sext_i32_i64(squot32(local_tid_29846, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_29895) {\n                        int64_t defunc_0_op_res_29885 = add64(eta_p_29883, eta_p_29884);\n                        \n                        eta_p_29883 = defunc_0_op_res_29885;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_29895) {\n                        ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29883;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_29846, 32) == 0 && ltid_in_bounds_29890) {\n                    ((__local int64_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = eta_p_29884;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_29846 == 0) {\n                acc_29886 = ((__local int64_t *) local_mem_29853)[segscan_tblock_sizze_29189 - (int64_t) 1];\n            } else {\n                acc_29886 = ((__local int64", "_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_29896 = (int64_t) 0;\n        block_new_sgm_29897 = sgm_idx_29865 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_29897 && local_tid_29846 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863] = acc_29886;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 2;\n                acc_29886 = (int64_t) 0;\n            }\n            if (!block_new_sgm_29897 && slt32(local_tid_29846, wave_sizze_29848)) {\n                if (local_tid_29846 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_29819)[dynamic_id_29863] = acc_29886;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 1;\n                    \n                    int8_t tmp_29898 = ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_29853)[(int64_t) 0] = tmp_29898;\n                }\n                mem_fence_local();\n                \n                int8_t status_29899 = ((__local int8_t *) local_mem_29853)[(int64_t) 0];\n                \n                if (status_29899 == (int8_t) 2) {\n                    if (local_tid_29846 == 0) {\n                        prefix_29896 = ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_29900 = sext_i64_i32(dynamic_id_29863 - sext_i32_i64(wave_sizze_29848));\n                    \n                    while (slt32(wave_sizze_29848 * -1, readOffset_29900)) {\n                        int32_t read_i_29901 = readOffset_29900 + local_tid_298", "46;\n                        int64_t aggr_29902 = (int64_t) 0;\n                        int8_t flag_29903 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_29901)) {\n                            flag_29903 = ((volatile __global int8_t *) status_flags_mem_29797)[sext_i32_i64(read_i_29901)];\n                            if (flag_29903 == (int8_t) 2) {\n                                aggr_29902 = ((volatile __global int64_t *) incprefixes_mem_29821)[sext_i32_i64(read_i_29901)];\n                            } else if (flag_29903 == (int8_t) 1) {\n                                aggr_29902 = ((volatile __global int64_t *) aggregates_mem_29819)[sext_i32_i64(read_i_29901)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)] = aggr_29902;\n                        ((__local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = flag_29903;\n                        flag_29903 = ((__local int8_t *) local_mem_29853)[sext_i32_i64(wave_sizze_29848) - (int64_t) 1];\n                        if (slt8(flag_29903, (int8_t) 2)) {\n                            int8_t flg_x_29907;\n                            int8_t flg_y_29908;\n                            int64_t eta_p_29904;\n                            int64_t eta_p_29905;\n                            int32_t skip_threads_29909;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_29908 = ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)];\n                                eta_p_29905 = ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)];\n                                if ((local_tid_29846 - squot32(local_tid_29846, 32) * 32) == 0) {\n                                    eta_p_29904 = eta_p_29905;\n                                    flg_",
                                    "x_29907 = flg_y_29908;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_29909 = 1;\n                                while (slt32(skip_threads_29909, 32)) {\n                                    if (sle32(skip_threads_29909, local_tid_29846 - squot32(local_tid_29846, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_29907 = ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29909)];\n                                            eta_p_29904 = ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + (sext_i32_i64(local_tid_29846) - sext_i32_i64(skip_threads_29909))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_29908 == (int8_t) 2 || flg_y_29908 == (int8_t) 0) {\n                                                flg_x_29907 = flg_y_29908;\n                                                eta_p_29904 = eta_p_29905;\n                                            } else {\n                                                int64_t defunc_0_op_res_29906 = add64(eta_p_29904, eta_p_29905);\n                                                \n                                                eta_p_29904 = defunc_0_op_res_29906;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_29853)[sext_i32_i64(local_tid_29846)] = flg_x_29907;\n                                            flg_y_29908 = flg_x_29907;\n     ", "                                       ((volatile __local int64_t *) local_mem_29853)[(int64_t) 4 + sext_i32_i64(local_tid_29846)] = eta_p_29904;\n                                            eta_p_29905 = eta_p_29904;\n                                        }\n                                    }\n                                    skip_threads_29909 *= 2;\n                                }\n                            }\n                        }\n                        flag_29903 = ((__local int8_t *) local_mem_29853)[sext_i32_i64(wave_sizze_29848) - (int64_t) 1];\n                        aggr_29902 = ((__local int64_t *) local_mem_29853)[(int64_t) 4 + (sext_i32_i64(wave_sizze_29848) - (int64_t) 1)];\n                        if (flag_29903 == (int8_t) 2) {\n                            readOffset_29900 = wave_sizze_29848 * -1;\n                        } else if (flag_29903 == (int8_t) 1) {\n                            readOffset_29900 -= wave_sizze_29848;\n                        }\n                        if (slt8((int8_t) 0, flag_29903)) {\n                            int64_t eta_p_29910 = aggr_29902;\n                            int64_t eta_p_29911 = prefix_29896;\n                            int64_t defunc_0_op_res_29912 = add64(eta_p_29910, eta_p_29911);\n                            \n                            prefix_29896 = defunc_0_op_res_29912;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_29846 == 0) {\n                    if (boundary_29866 == sext_i64_i32(segscan_tblock_sizze_29189 * chunk_sizze_29794)) {\n                        int64_t eta_p_29913 = prefix_29896;\n                        int64_t eta_p_29914 = acc_29886;\n                        int64_t defunc_0_op_res_29915 = add64(eta_p_29913, eta_p_29914);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_29821)[dynamic_id_29863] = defunc_0_op_res_29915;\n                        mem", "_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_29797)[dynamic_id_29863] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_29853)[(int64_t) 4] = prefix_29896;\n                    acc_29886 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_29863 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_29896 = ((__local int64_t *) local_mem_29853)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_29916;\n            int64_t eta_p_29917;\n            int64_t eta_p_29919 = prefix_29896;\n            int64_t eta_p_29920 = acc_29886;\n            \n            if (slt32(local_tid_29846 * chunk_sizze_32b_29850, boundary_29866) && !block_new_sgm_29897) {\n                int64_t defunc_0_op_res_29921 = add64(eta_p_29919, eta_p_29920);\n                \n                eta_p_29916 = defunc_0_op_res_29921;\n            } else {\n                eta_p_29916 = acc_29886;\n            }\n            \n            int32_t stopping_point_29922 = segsizze_compact_29867 - srem32(local_tid_29846 * chunk_sizze_32b_29850 - 1 + segsizze_compact_29867 - boundary_29866, segsizze_compact_29867);\n            \n            for (int64_t i_29923 = 0; i_29923 < chunk_sizze_29794; i_29923++) {\n                if (slt32(sext_i64_i32(i_29923), stopping_point_29922 - 1)) {\n                    eta_p_29917 = private_mem_29868[i_29923];\n                    \n                    int64_t defunc_0_op_res_29918 = add64(eta_p_29916, eta_p_29917);\n                    \n                    private_mem_29868[i_29923] = defunc_0_op_res_29918;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_29924 = 0; i_29924 < chunk_sizze_29794; i_29924++) {\n                int64_t sharedIdx_29925 =",
                                    " sext_i32_i64(local_tid_29846) * chunk_sizze_29794 + i_29924;\n                int64_t tmp_29926 = private_mem_29868[i_29924];\n                \n                ((__local int64_t *) local_mem_29853)[sharedIdx_29925] = tmp_29926;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_29927 = 0; i_29927 < chunk_sizze_29794; i_29927++) {\n                int64_t flat_idx_29928 = thd_offset_29870 + i_29927 * segscan_tblock_sizze_29189;\n                int64_t slice_29929 = mz2080U_25210;\n                int64_t gtid_29193 = flat_idx_29928;\n                int64_t remnant_29930 = flat_idx_29928 - gtid_29193;\n                \n                if (slt64(flat_idx_29928, mz2080U_25210)) {\n                    int64_t tmp_29931 = ((__local int64_t *) local_mem_29853)[flat_idx_29928 - block_offset_29864];\n                    \n                    ((__global int64_t *) mem_29683)[gtid_29193] = tmp_29931;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_29189\n    #undef chunk_sizze_29794\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegscan_29210_dim1, 1, 1)\nvoid human_generici32zisegscan_29210(__global int *global_failure, int64_t nz2081U_25211, int64_t num_tblocks_29207, int64_t num_virt_blocks_29972, int64_t num_virt_threads_29973, __global unsigned char *A_mem_29680, __global unsigned char *mem_29684, __global unsigned char *mem_29687, __global unsigned char *mem_29689, __global unsigned char *status_flags_mem_29974, __global unsigned char *aggregates_mem_29976, __global unsigned char *incprefixes_mem_29978, __global unsigned char *aggregates_mem_29980, __global unsigned char *incprefixes_mem_29982, __global unsigned char *global_dynid_mem_29984)\n{\n    #define segscan_tblock_sizze_29205 (human_generici32zisegscan_29210zisegscan_tblock_sizze_29205)\n    #define chunk_sizze_29971 (human_generici32zisegscan_29210zichunk_sizze_29971)\n    \n    volatile __local unsi", "gned char *local_mem_29996_backing_0 = &shared_mem[0];\n    const int64_t local_mem_29996_backing_0_offset = 0 + (smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_29205, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_29205), smax64(chunk_sizze_29971 * segscan_tblock_sizze_29205, chunk_sizze_29971 * segscan_tblock_sizze_29205 * (int64_t) 4)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_29205, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_29205), smax64(chunk_sizze_29971 * segscan_tblock_sizze_29205, chunk_sizze_29971 * segscan_tblock_sizze_29205 * (int64_t) 4)), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_29987;\n    int32_t tblock_sizze_29990;\n    int32_t wave_sizze_29989;\n    int32_t block_id_29988;\n    int32_t global_tid_29986;\n    int64_t phys_tid_29210;\n    int32_t chunk_sizze_32b_29991;\n    int64_t byte_offsets_29992;\n    int64_t byte_offsets_29993;\n    int64_t warp_byte_offset_29994;\n    int64_t warp_byte_offset_29995;\n    __local unsigned char *local_mem_29996;\n    int64_t trans_arr_len_29997;\n    int64_t phys_block_id_30006;\n    int64_t virtloop_bound_30007;\n    \n    local_tid_29987 = get_local_id(0);\n    tblock_sizze_29990 = get_local_size(0);\n    wave_sizze_29989 = LOCKSTEP_WIDTH;\n    block_id_29988 = get_tblock_id(0);\n    global_tid_29986 = block_id_29988 * tblock_sizze_29990 + local_tid_29987;\n    phys_tid_29210 = sext_i32_i64(global_tid_29986);\n    chunk_sizze_32b_29991 = sext_i64_i32(chunk_sizze_29971);\n    byte_offsets_29992 = segscan_tblock_sizze_29205;\n    byte_offsets_29993 = sdiv_up64(byte_offsets_29992, (int64_t) 4) * (int64_t) 4 + segscan_tblock_sizze_29205 * (int64_t) 4;\n    warp_byte_offset_29994 = (int64_t) 64;\n    warp_byte_offset_29995 = sdiv_up64(warp_byte_offset_29994, (int64_t) 4) * (int64_t) 4 + (int64_t) 128;\n    // Allocate reusable shared memory\n    { }\n    local_mem_29996 = (__local ", "unsigned char *) local_mem_29996_backing_0;\n    trans_arr_len_29997 = chunk_sizze_29971 * segscan_tblock_sizze_29205;\n    phys_block_id_30006 = get_tblock_id(0);\n    virtloop_bound_30007 = sdiv_up64(num_virt_blocks_29972 - phys_block_id_30006, num_tblocks_29207);\n    for (int64_t virtloop_i_30008 = 0; virtloop_i_30008 < virtloop_bound_30007; virtloop_i_30008++) {\n        int64_t dynamic_id_30009;\n        int64_t block_offset_30010;\n        int64_t sgm_idx_30011;\n        int32_t boundary_30012;\n        int32_t segsizze_compact_30013;\n        bool private_mem_30014[chunk_sizze_29971];\n        int32_t private_mem_30016[chunk_sizze_29971];\n        int64_t thd_offset_30018;\n        bool acc_30045;\n        int32_t acc_30046;\n        bool prefix_30060;\n        int32_t prefix_30061;\n        bool block_new_sgm_30062;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_29987 == 0) {\n                dynamic_id_30009 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_29984)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_29996)[(int64_t) 0] = dynamic_id_30009;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30009 == num_virt_blocks_29972 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_29984)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30009 = ((__local int32_t *) local_mem_29996)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30010 = dynamic_id_30009 * chunk_sizze_29971 * segscan_tblock_sizze_29205;\n        sgm_idx_30011 = smod64(block_offset_30010, nz2081U_25211);\n        boundary_30012 = sext_i64_i32(smin64(chunk_sizze_29971 * segscan_tblock_sizze_29205, nz",
                                    "2081U_25211 - sgm_idx_30011));\n        segsizze_compact_30013 = sext_i64_i32(smin64(chunk_sizze_29971 * segscan_tblock_sizze_29205, nz2081U_25211));\n        thd_offset_30018 = block_offset_30010 + sext_i32_i64(local_tid_29987);\n        // Load and map\n        {\n            for (int64_t i_30019 = 0; i_30019 < chunk_sizze_29971; i_30019++) {\n                int64_t virt_tid_30020 = thd_offset_30018 + i_30019 * segscan_tblock_sizze_29205;\n                int64_t slice_30021 = nz2081U_25211;\n                int64_t gtid_29209 = virt_tid_30020;\n                int64_t remnant_30022 = virt_tid_30020 - gtid_29209;\n                \n                if (slt64(virt_tid_30020, nz2081U_25211)) {\n                    bool x_26937 = ((__global bool *) mem_29684)[gtid_29209];\n                    int32_t x_26938 = ((__global int32_t *) A_mem_29680)[gtid_29209];\n                    \n                    private_mem_30014[i_30019] = x_26937;\n                    private_mem_30016[i_30019] = x_26938;\n                } else {\n                    private_mem_30014[i_30019] = 0;\n                    private_mem_30016[i_30019] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30023 = 0; i_30023 < chunk_sizze_29971; i_30023++) {\n                int64_t sharedIdx_30024 = sext_i32_i64(local_tid_29987) + i_30023 * segscan_tblock_sizze_29205;\n                bool tmp_30025 = private_mem_30014[i_30023];\n                \n                ((__local bool *) local_mem_29996)[sharedIdx_30024] = tmp_30025;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30026 = 0; i_30026 < chunk_sizze_29971; i_30026++) {\n                int64_t sharedIdx_30027 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30026;\n                bool tmp_30028 = ((__local bool *) local_mem_29996)[sharedIdx_30027];\n                \n                private_mem_30014[i_30026] = tmp_30028;\n      ", "      }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30029 = 0; i_30029 < chunk_sizze_29971; i_30029++) {\n                int64_t sharedIdx_30030 = sext_i32_i64(local_tid_29987) + i_30029 * segscan_tblock_sizze_29205;\n                int32_t tmp_30031 = private_mem_30016[i_30029];\n                \n                ((__local int32_t *) local_mem_29996)[sharedIdx_30030] = tmp_30031;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30032 = 0; i_30032 < chunk_sizze_29971; i_30032++) {\n                int64_t sharedIdx_30033 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30032;\n                int32_t tmp_30034 = ((__local int32_t *) local_mem_29996)[sharedIdx_30033];\n                \n                private_mem_30016[i_30032] = tmp_30034;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30035 = 0; i_30035 < chunk_sizze_29971 - (int64_t) 1; i_30035++) {\n                bool eta_p_26930;\n                bool eta_p_26932;\n                \n                eta_p_26930 = private_mem_30014[i_30035];\n                eta_p_26932 = private_mem_30014[i_30035 + (int64_t) 1];\n                \n                int32_t eta_p_26931;\n                int32_t eta_p_26933;\n                \n                eta_p_26931 = private_mem_30016[i_30035];\n                eta_p_26933 = private_mem_30016[i_30035 + (int64_t) 1];\n                \n                bool tmp_26934 = eta_p_26930 || eta_p_26932;\n                int32_t tmp_26935;\n                \n                if (eta_p_26932) {\n                    tmp_26935 = eta_p_26933;\n                } else {\n                    int32_t defunc_0_op_res_26936 = add32(eta_p_26931, eta_p_26933);\n                    \n                    tmp_26935 = defunc_0_op_res_26936;\n                }\n                private_mem_30014[i_30035 + (int64_t) 1] = tmp_26934;\n                private_mem_30016[i_30035 + (int64_t) 1", "] = tmp_26935;\n            }\n        }\n        // Publish results in shared memory\n        {\n            bool tmp_30036 = private_mem_30014[chunk_sizze_29971 - (int64_t) 1];\n            \n            ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = tmp_30036;\n            \n            int32_t tmp_30037 = private_mem_30016[chunk_sizze_29971 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = tmp_30037;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            bool eta_p_30038;\n            int32_t eta_p_30039;\n            bool eta_p_30040;\n            int32_t eta_p_30041;\n            bool eta_p_30047;\n            int32_t eta_p_30048;\n            bool eta_p_30049;\n            int32_t eta_p_30050;\n            bool ltid_in_bounds_30054 = slt64(sext_i32_i64(local_tid_29987), num_virt_threads_29973);\n            int32_t skip_threads_30055;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30054) {\n                    eta_p_30040 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)];\n                    eta_p_30041 = ((volatile __local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)];\n                    if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                        eta_p_30038 = eta_p_30040;\n                        eta_p_30039 = eta_p_30041;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30055 = 1;\n                while (slt32(skip_threads_30055, 32)) {\n                    bool thread_active_30056 = sle32(skip_threads_30055, local_tid_29987 - squot32(local_tid_29987, 32) * 32) && ltid_in_bounds_30054;\n                    \n             ",
                                    "       if (thread_active_30056) {\n                        // read operands\n                        {\n                            eta_p_30038 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30055)];\n                            eta_p_30039 = ((volatile __local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30055))];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30056) {\n                            bool tmp_30042 = eta_p_30038 || eta_p_30040;\n                            int32_t tmp_30043;\n                            \n                            if (eta_p_30040) {\n                                tmp_30043 = eta_p_30041;\n                            } else {\n                                int32_t defunc_0_op_res_30044 = add32(eta_p_30039, eta_p_30041);\n                                \n                                tmp_30043 = defunc_0_op_res_30044;\n                            }\n                            eta_p_30038 = tmp_30042;\n                            eta_p_30039 = tmp_30043;\n                        }\n                    }\n                    if (sle32(wave_sizze_29989, skip_threads_30055)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30056) {\n                        // write result\n                        {\n                            ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30038;\n                            eta_p_30040 = eta_p_30038;\n                            ((volatile __local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30039;\n                            eta_p_30041 = eta_p_30039;\n                        }\n                    }\n            ", "        if (sle32(wave_sizze_29989, skip_threads_30055)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30055 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 31 && ltid_in_bounds_30054) {\n                    ((volatile __local bool *) local_mem_29996)[sext_i32_i64(squot32(local_tid_29987, 32))] = eta_p_30038;\n                    ((volatile __local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(squot32(local_tid_29987, 32))] = eta_p_30039;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30057;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_29987, 32) == 0 && ltid_in_bounds_30054) {\n                        eta_p_30049 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)];\n                        eta_p_30050 = ((volatile __local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)];\n                        if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                            eta_p_30047 = eta_p_30049;\n                            eta_p_30048 = eta_p_30050;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30057 = 1;\n                    while (slt32(skip_threads_30057, 32)) {\n                        bool thread_active_30058 = sle32(skip_threads_30057, local_tid_29987 - squot32(local_tid_29987, 32) * 32) && (squot32", "(local_tid_29987, 32) == 0 && ltid_in_bounds_30054);\n                        \n                        if (thread_active_30058) {\n                            // read operands\n                            {\n                                eta_p_30047 = ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30057)];\n                                eta_p_30048 = ((volatile __local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30057))];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30058) {\n                                bool tmp_30051 = eta_p_30047 || eta_p_30049;\n                                int32_t tmp_30052;\n                                \n                                if (eta_p_30049) {\n                                    tmp_30052 = eta_p_30050;\n                                } else {\n                                    int32_t defunc_0_op_res_30053 = add32(eta_p_30048, eta_p_30050);\n                                    \n                                    tmp_30052 = defunc_0_op_res_30053;\n                                }\n                                eta_p_30047 = tmp_30051;\n                                eta_p_30048 = tmp_30052;\n                            }\n                        }\n                        if (sle32(wave_sizze_29989, skip_threads_30057)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30058) {\n                            // write result\n                            {\n                                ((volatile __local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30047;\n                                eta_p_30049 = eta_p_30047;\n                                ((volatile __local int32_t *",
                                    ") local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30048;\n                                eta_p_30050 = eta_p_30048;\n                            }\n                        }\n                        if (sle32(wave_sizze_29989, skip_threads_30057)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30057 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30059 = squot32(local_tid_29987, 32) == 0 || !ltid_in_bounds_30054;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30059) {\n                        eta_p_30040 = eta_p_30038;\n                        eta_p_30041 = eta_p_30039;\n                        eta_p_30038 = ((__local bool *) local_mem_29996)[sext_i32_i64(squot32(local_tid_29987, 32)) - (int64_t) 1];\n                        eta_p_30039 = ((__local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (sext_i32_i64(squot32(local_tid_29987, 32)) - (int64_t) 1)];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30059) {\n                        bool tmp_30042 = eta_p_30038 || eta_p_30040;\n                        int32_t tmp_30043;\n                        \n                        if (eta_p_30040) {\n                            tmp_30043 = eta_p_30041;\n                        } else {\n                            int32_t defunc_0_op_res_30044 = add32(eta_p_30039, eta_p_30041);\n                            \n                            tmp_30043 = defunc_0_op_res_30044;\n                        }\n                        eta_p_30038 = tmp_30042;\n                        eta_p_30039 = tmp_30043;\n                    }\n                }\n            ", "    // write final result\n                {\n                    if (!no_carry_in_30059) {\n                        ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30038;\n                        ((__local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30039;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_29987, 32) == 0 && ltid_in_bounds_30054) {\n                    ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = eta_p_30040;\n                    ((__local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30041;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_29987 == 0) {\n                acc_30045 = ((__local bool *) local_mem_29996)[segscan_tblock_sizze_29205 - (int64_t) 1];\n                acc_30046 = ((__local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (segscan_tblock_sizze_29205 - (int64_t) 1)];\n            } else {\n                acc_30045 = ((__local bool *) local_mem_29996)[sext_i32_i64(local_tid_29987) - (int64_t) 1];\n                acc_30046 = ((__local int32_t *) local_mem_29996)[squot64(byte_offsets_29992, (int64_t) 4) + (sext_i32_i64(local_tid_29987) - (int64_t) 1)];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30060 = 0;\n        prefix_30061 = 0;\n        block_new_sgm_30062 = sgm_idx_30011 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30062 && local_tid_29987 == 0) {\n                ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009] = acc_30045;\n                ((volatile __global int32_t *) incprefixes_mem_29982)[dynamic_id_", "30009] = acc_30046;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 2;\n                acc_30045 = 0;\n                acc_30046 = 0;\n            }\n            if (!block_new_sgm_30062 && slt32(local_tid_29987, wave_sizze_29989)) {\n                if (local_tid_29987 == 0) {\n                    ((volatile __global bool *) aggregates_mem_29976)[dynamic_id_30009] = acc_30045;\n                    ((volatile __global int32_t *) aggregates_mem_29980)[dynamic_id_30009] = acc_30046;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 1;\n                    \n                    int8_t tmp_30063 = ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_29996)[(int64_t) 0] = tmp_30063;\n                }\n                mem_fence_local();\n                \n                int8_t status_30064 = ((__local int8_t *) local_mem_29996)[(int64_t) 0];\n                \n                if (status_30064 == (int8_t) 2) {\n                    if (local_tid_29987 == 0) {\n                        prefix_30060 = ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009 - (int64_t) 1];\n                        prefix_30061 = ((volatile __global int32_t *) incprefixes_mem_29982)[dynamic_id_30009 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30065 = sext_i64_i32(dynamic_id_30009 - sext_i32_i64(wave_sizze_29989));\n                    \n                    while (slt32(wave_sizze_29989 * -1, readOffset_30065)) {\n                        int32_t read_i_30066 = readOffset_30065 + local_tid_29987;\n                        bool aggr_30067 = 0;\n                        int32_t aggr_30068 = 0;\n                        int8_t flag_30069 = (int8_t) 0;\n               ",
                                    "         \n                        if (sle32(0, read_i_30066)) {\n                            flag_30069 = ((volatile __global int8_t *) status_flags_mem_29974)[sext_i32_i64(read_i_30066)];\n                            if (flag_30069 == (int8_t) 2) {\n                                aggr_30067 = ((volatile __global bool *) incprefixes_mem_29978)[sext_i32_i64(read_i_30066)];\n                                aggr_30068 = ((volatile __global int32_t *) incprefixes_mem_29982)[sext_i32_i64(read_i_30066)];\n                            } else if (flag_30069 == (int8_t) 1) {\n                                aggr_30067 = ((volatile __global bool *) aggregates_mem_29976)[sext_i32_i64(read_i_30066)];\n                                aggr_30068 = ((volatile __global int32_t *) aggregates_mem_29980)[sext_i32_i64(read_i_30066)];\n                            }\n                        }\n                        ((__local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)] = aggr_30067;\n                        ((__local int32_t *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = aggr_30068;\n                        ((__local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = flag_30069;\n                        flag_30069 = ((__local int8_t *) local_mem_29996)[sext_i32_i64(wave_sizze_29989) - (int64_t) 1];\n                        if (slt8(flag_30069, (int8_t) 2)) {\n                            int8_t flg_x_30077;\n                            int8_t flg_y_30078;\n                            bool eta_p_30070;\n                            int32_t eta_p_30071;\n                            bool eta_p_30072;\n                            int32_t eta_p_30073;\n                            int32_t skip_threads_30079;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30078 = ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64", "(local_tid_29987)];\n                                eta_p_30072 = ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)];\n                                eta_p_30073 = ((volatile __local int32_t *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + sext_i32_i64(local_tid_29987)];\n                                if ((local_tid_29987 - squot32(local_tid_29987, 32) * 32) == 0) {\n                                    eta_p_30070 = eta_p_30072;\n                                    eta_p_30071 = eta_p_30073;\n                                    flg_x_30077 = flg_y_30078;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30079 = 1;\n                                while (slt32(skip_threads_30079, 32)) {\n                                    if (sle32(skip_threads_30079, local_tid_29987 - squot32(local_tid_29987, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30077 = ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30079)];\n                                            eta_p_30070 = ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30079))];\n                                            eta_p_30071 = ((volatile __local int32_t *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + (sext_i32_i64(local_tid_29987) - sext_i32_i64(skip_threads_30079))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30078 == (int8_t) 2 || flg_y_30078 == (int8_t) 0) {\n                                    ", "            flg_x_30077 = flg_y_30078;\n                                                eta_p_30070 = eta_p_30072;\n                                                eta_p_30071 = eta_p_30073;\n                                            } else {\n                                                bool tmp_30074 = eta_p_30070 || eta_p_30072;\n                                                int32_t tmp_30075;\n                                                \n                                                if (eta_p_30072) {\n                                                    tmp_30075 = eta_p_30073;\n                                                } else {\n                                                    int32_t defunc_0_op_res_30076 = add32(eta_p_30071, eta_p_30073);\n                                                    \n                                                    tmp_30075 = defunc_0_op_res_30076;\n                                                }\n                                                eta_p_30070 = tmp_30074;\n                                                eta_p_30071 = tmp_30075;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_29996)[sext_i32_i64(local_tid_29987)] = flg_x_30077;\n                                            flg_y_30078 = flg_x_30077;\n                                            ((volatile __local bool *) local_mem_29996)[(int64_t) 32 + sext_i32_i64(local_tid_29987)] = eta_p_30070;\n                                            eta_p_30072 = eta_p_30070;\n                                            ((volatile __local int32_t *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + sext_i32_i64(local_tid_29987)] = eta_p_30071;\n                                            eta_p_30073 = eta_p_30071;\n                           ",
                                    "             }\n                                    }\n                                    skip_threads_30079 *= 2;\n                                }\n                            }\n                        }\n                        flag_30069 = ((__local int8_t *) local_mem_29996)[sext_i32_i64(wave_sizze_29989) - (int64_t) 1];\n                        aggr_30067 = ((__local bool *) local_mem_29996)[(int64_t) 32 + (sext_i32_i64(wave_sizze_29989) - (int64_t) 1)];\n                        aggr_30068 = ((__local int32_t *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4) + (sext_i32_i64(wave_sizze_29989) - (int64_t) 1)];\n                        if (flag_30069 == (int8_t) 2) {\n                            readOffset_30065 = wave_sizze_29989 * -1;\n                        } else if (flag_30069 == (int8_t) 1) {\n                            readOffset_30065 -= wave_sizze_29989;\n                        }\n                        if (slt8((int8_t) 0, flag_30069)) {\n                            bool eta_p_30080 = aggr_30067;\n                            int32_t eta_p_30081 = aggr_30068;\n                            bool eta_p_30082 = prefix_30060;\n                            int32_t eta_p_30083 = prefix_30061;\n                            bool tmp_30084 = eta_p_30080 || eta_p_30082;\n                            int32_t tmp_30085;\n                            \n                            if (eta_p_30082) {\n                                tmp_30085 = eta_p_30083;\n                            } else {\n                                int32_t defunc_0_op_res_30086 = add32(eta_p_30081, eta_p_30083);\n                                \n                                tmp_30085 = defunc_0_op_res_30086;\n                            }\n                            prefix_30060 = tmp_30084;\n                            prefix_30061 = tmp_30085;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_29987 == 0) {\n   ", "                 if (boundary_30012 == sext_i64_i32(segscan_tblock_sizze_29205 * chunk_sizze_29971)) {\n                        bool eta_p_30087 = prefix_30060;\n                        int32_t eta_p_30088 = prefix_30061;\n                        bool eta_p_30089 = acc_30045;\n                        int32_t eta_p_30090 = acc_30046;\n                        bool tmp_30091 = eta_p_30087 || eta_p_30089;\n                        int32_t tmp_30092;\n                        \n                        if (eta_p_30089) {\n                            tmp_30092 = eta_p_30090;\n                        } else {\n                            int32_t defunc_0_op_res_30093 = add32(eta_p_30088, eta_p_30090);\n                            \n                            tmp_30092 = defunc_0_op_res_30093;\n                        }\n                        ((volatile __global bool *) incprefixes_mem_29978)[dynamic_id_30009] = tmp_30091;\n                        ((volatile __global int32_t *) incprefixes_mem_29982)[dynamic_id_30009] = tmp_30092;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_29974)[dynamic_id_30009] = (int8_t) 2;\n                    }\n                    ((__local bool *) local_mem_29996)[(int64_t) 32] = prefix_30060;\n                    ((__local int32_t *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4)] = prefix_30061;\n                    acc_30045 = 0;\n                    acc_30046 = 0;\n                }\n            }\n            if (!(dynamic_id_30009 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30060 = ((__local bool *) local_mem_29996)[(int64_t) 32];\n                prefix_30061 = ((__local int32_t *) local_mem_29996)[squot64(warp_byte_offset_29994, (int64_t) 4)];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            bool eta_p_30094;\n            bool eta_p_30096;\n            bool eta_p_3010", "1 = prefix_30060;\n            bool eta_p_30103 = acc_30045;\n            int32_t eta_p_30095;\n            int32_t eta_p_30097;\n            int32_t eta_p_30102 = prefix_30061;\n            int32_t eta_p_30104 = acc_30046;\n            \n            if (slt32(local_tid_29987 * chunk_sizze_32b_29991, boundary_30012) && !block_new_sgm_30062) {\n                bool tmp_30105 = eta_p_30101 || eta_p_30103;\n                int32_t tmp_30106;\n                \n                if (eta_p_30103) {\n                    tmp_30106 = eta_p_30104;\n                } else {\n                    int32_t defunc_0_op_res_30107 = add32(eta_p_30102, eta_p_30104);\n                    \n                    tmp_30106 = defunc_0_op_res_30107;\n                }\n                eta_p_30094 = tmp_30105;\n                eta_p_30095 = tmp_30106;\n            } else {\n                eta_p_30094 = acc_30045;\n                eta_p_30095 = acc_30046;\n            }\n            \n            int32_t stopping_point_30108 = segsizze_compact_30013 - srem32(local_tid_29987 * chunk_sizze_32b_29991 - 1 + segsizze_compact_30013 - boundary_30012, segsizze_compact_30013);\n            \n            for (int64_t i_30109 = 0; i_30109 < chunk_sizze_29971; i_30109++) {\n                if (slt32(sext_i64_i32(i_30109), stopping_point_30108 - 1)) {\n                    eta_p_30096 = private_mem_30014[i_30109];\n                    eta_p_30097 = private_mem_30016[i_30109];\n                    \n                    bool tmp_30098 = eta_p_30094 || eta_p_30096;\n                    int32_t tmp_30099;\n                    \n                    if (eta_p_30096) {\n                        tmp_30099 = eta_p_30097;\n                    } else {\n                        int32_t defunc_0_op_res_30100 = add32(eta_p_30095, eta_p_30097);\n                        \n                        tmp_30099 = defunc_0_op_res_30100;\n                    }\n                    private_mem_30014[i_30109] = tmp_30098;\n                    private_mem_30016[i_30109] = tmp_",
                                    "30099;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30110 = 0; i_30110 < chunk_sizze_29971; i_30110++) {\n                int64_t sharedIdx_30111 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30110;\n                bool tmp_30112 = private_mem_30014[i_30110];\n                \n                ((__local bool *) local_mem_29996)[sharedIdx_30111] = tmp_30112;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30113 = 0; i_30113 < chunk_sizze_29971; i_30113++) {\n                int64_t flat_idx_30114 = thd_offset_30018 + i_30113 * segscan_tblock_sizze_29205;\n                int64_t slice_30115 = nz2081U_25211;\n                int64_t gtid_29209 = flat_idx_30114;\n                int64_t remnant_30116 = flat_idx_30114 - gtid_29209;\n                \n                if (slt64(flat_idx_30114, nz2081U_25211)) {\n                    bool tmp_30117 = ((__local bool *) local_mem_29996)[flat_idx_30114 - block_offset_30010];\n                    \n                    ((__global bool *) mem_29687)[gtid_29209] = tmp_30117;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30118 = 0; i_30118 < chunk_sizze_29971; i_30118++) {\n                int64_t sharedIdx_30119 = sext_i32_i64(local_tid_29987) * chunk_sizze_29971 + i_30118;\n                int32_t tmp_30120 = private_mem_30016[i_30118];\n                \n                ((__local int32_t *) local_mem_29996)[sharedIdx_30119] = tmp_30120;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30121 = 0; i_30121 < chunk_sizze_29971; i_30121++) {\n                int64_t flat_idx_30122 = thd_offset_30018 + i_30121 * segscan_tblock_sizze_29205;\n                int64_t slice_30123 = nz2081U_25211;\n                int64_t gtid_29209 = flat_idx_30122;\n                int64_t remnant_30124 = flat_idx_30122 - gtid", "_29209;\n                \n                if (slt64(flat_idx_30122, nz2081U_25211)) {\n                    int32_t tmp_30125 = ((__local int32_t *) local_mem_29996)[flat_idx_30122 - block_offset_30010];\n                    \n                    ((__global int32_t *) mem_29689)[gtid_29209] = tmp_30125;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_29205\n    #undef chunk_sizze_29971\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegscan_29218_dim1, 1, 1)\nvoid human_generici32zisegscan_29218(__global int *global_failure, int64_t mz2080U_25210, int64_t num_tblocks_29215, int64_t num_virt_blocks_30132, int64_t num_virt_threads_30133, __global unsigned char *shp_mem_29678, __global unsigned char *mem_29692, __global unsigned char *status_flags_mem_30134, __global unsigned char *aggregates_mem_30136, __global unsigned char *incprefixes_mem_30138, __global unsigned char *global_dynid_mem_30140)\n{\n    #define segscan_tblock_sizze_29213 (human_generici32zisegscan_29218zisegscan_tblock_sizze_29213)\n    #define chunk_sizze_30131 (human_generici32zisegscan_29218zichunk_sizze_30131)\n    \n    volatile __local unsigned char *local_mem_30150_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30150_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_29213), chunk_sizze_30131 * segscan_tblock_sizze_29213 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_29213), chunk_sizze_30131 * segscan_tblock_sizze_29213 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30143;\n    int32_t tblock_sizze_30146;\n    int32_t wave_sizze_30145;\n    int32_t block_id_30144;\n    int32_t global_tid_30142;\n    int64_t phys_tid_29218;\n    int32_t chunk_sizze_32b_30147;\n    int64_t byte_offsets_30148;\n    int64_t warp_byte_offset_30149;\n    __local ", "unsigned char *local_mem_30150;\n    int64_t trans_arr_len_30151;\n    int64_t phys_block_id_30157;\n    int64_t virtloop_bound_30158;\n    \n    local_tid_30143 = get_local_id(0);\n    tblock_sizze_30146 = get_local_size(0);\n    wave_sizze_30145 = LOCKSTEP_WIDTH;\n    block_id_30144 = get_tblock_id(0);\n    global_tid_30142 = block_id_30144 * tblock_sizze_30146 + local_tid_30143;\n    phys_tid_29218 = sext_i32_i64(global_tid_30142);\n    chunk_sizze_32b_30147 = sext_i64_i32(chunk_sizze_30131);\n    byte_offsets_30148 = segscan_tblock_sizze_29213 * (int64_t) 4;\n    warp_byte_offset_30149 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30150 = (__local unsigned char *) local_mem_30150_backing_0;\n    trans_arr_len_30151 = chunk_sizze_30131 * segscan_tblock_sizze_29213;\n    phys_block_id_30157 = get_tblock_id(0);\n    virtloop_bound_30158 = sdiv_up64(num_virt_blocks_30132 - phys_block_id_30157, num_tblocks_29215);\n    for (int64_t virtloop_i_30159 = 0; virtloop_i_30159 < virtloop_bound_30158; virtloop_i_30159++) {\n        int64_t dynamic_id_30160;\n        int64_t block_offset_30161;\n        int64_t sgm_idx_30162;\n        int32_t boundary_30163;\n        int32_t segsizze_compact_30164;\n        int32_t private_mem_30165[chunk_sizze_30131];\n        int64_t thd_offset_30167;\n        int32_t acc_30183;\n        int32_t prefix_30193;\n        bool block_new_sgm_30194;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30143 == 0) {\n                dynamic_id_30160 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30140)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30150)[(int64_t) 0] = dynamic_id_30160;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30160 == num_virt_blocks_30132 - (in",
                                    "t64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30140)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30160 = ((__local int32_t *) local_mem_30150)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30161 = dynamic_id_30160 * chunk_sizze_30131 * segscan_tblock_sizze_29213;\n        sgm_idx_30162 = smod64(block_offset_30161, mz2080U_25210);\n        boundary_30163 = sext_i64_i32(smin64(chunk_sizze_30131 * segscan_tblock_sizze_29213, mz2080U_25210 - sgm_idx_30162));\n        segsizze_compact_30164 = sext_i64_i32(smin64(chunk_sizze_30131 * segscan_tblock_sizze_29213, mz2080U_25210));\n        thd_offset_30167 = block_offset_30161 + sext_i32_i64(local_tid_30143);\n        // Load and map\n        {\n            for (int64_t i_30168 = 0; i_30168 < chunk_sizze_30131; i_30168++) {\n                int64_t virt_tid_30169 = thd_offset_30167 + i_30168 * segscan_tblock_sizze_29213;\n                int64_t slice_30170 = mz2080U_25210;\n                int64_t gtid_29217 = virt_tid_30169;\n                int64_t remnant_30171 = virt_tid_30169 - gtid_29217;\n                \n                if (slt64(virt_tid_30169, mz2080U_25210)) {\n                    int32_t x_27663 = ((__global int32_t *) shp_mem_29678)[gtid_29217];\n                    \n                    private_mem_30165[i_30168] = x_27663;\n                } else {\n                    private_mem_30165[i_30168] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30172 = 0; i_30172 < chunk_sizze_30131; i_30172++) {\n                int64_t sharedIdx_30173 = sext_i32_i64(local_tid_30143) + i_30172 * segscan_tblock_sizze_29213;\n                int32_t tmp_30174 = private_mem_30165[i_30172];\n                \n                ((__local int32_t *) local_mem_30150)[sharedIdx_30173] = tmp_30174;\n       ", "     }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30175 = 0; i_30175 < chunk_sizze_30131; i_30175++) {\n                int64_t sharedIdx_30176 = sext_i32_i64(local_tid_30143) * chunk_sizze_30131 + i_30175;\n                int32_t tmp_30177 = ((__local int32_t *) local_mem_30150)[sharedIdx_30176];\n                \n                private_mem_30165[i_30175] = tmp_30177;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30178 = 0; i_30178 < chunk_sizze_30131 - (int64_t) 1; i_30178++) {\n                int32_t eta_p_27660;\n                int32_t eta_p_27661;\n                \n                eta_p_27660 = private_mem_30165[i_30178];\n                eta_p_27661 = private_mem_30165[i_30178 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_27662 = add32(eta_p_27660, eta_p_27661);\n                \n                private_mem_30165[i_30178 + (int64_t) 1] = defunc_0_op_res_27662;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_30179 = private_mem_30165[chunk_sizze_30131 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = tmp_30179;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_30180;\n            int32_t eta_p_30181;\n            int32_t eta_p_30184;\n            int32_t eta_p_30185;\n            bool ltid_in_bounds_30187 = slt64(sext_i32_i64(local_tid_30143), num_virt_threads_30133);\n            int32_t skip_threads_30188;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30187) {\n                    eta_p_30181 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                    if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                        eta_", "p_30180 = eta_p_30181;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30188 = 1;\n                while (slt32(skip_threads_30188, 32)) {\n                    bool thread_active_30189 = sle32(skip_threads_30188, local_tid_30143 - squot32(local_tid_30143, 32) * 32) && ltid_in_bounds_30187;\n                    \n                    if (thread_active_30189) {\n                        // read operands\n                        {\n                            eta_p_30180 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30188)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30189) {\n                            int32_t defunc_0_op_res_30182 = add32(eta_p_30180, eta_p_30181);\n                            \n                            eta_p_30180 = defunc_0_op_res_30182;\n                        }\n                    }\n                    if (sle32(wave_sizze_30145, skip_threads_30188)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30189) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30180;\n                            eta_p_30181 = eta_p_30180;\n                        }\n                    }\n                    if (sle32(wave_sizze_30145, skip_threads_30188)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30188 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 3",
                                    "1 && ltid_in_bounds_30187) {\n                    ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(squot32(local_tid_30143, 32))] = eta_p_30180;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30190;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187) {\n                        eta_p_30185 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                        if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                            eta_p_30184 = eta_p_30185;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30190 = 1;\n                    while (slt32(skip_threads_30190, 32)) {\n                        bool thread_active_30191 = sle32(skip_threads_30190, local_tid_30143 - squot32(local_tid_30143, 32) * 32) && (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187);\n                        \n                        if (thread_active_30191) {\n                            // read operands\n                            {\n                                eta_p_30184 = ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30190)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30191) {\n                                int32_t defunc_0_op_res_30186 = add32(eta_p_30184, eta_p_30185);\n                                \n                                eta_p_30184 = defunc_0_op_res_30186;\n                            }\n                     ", "   }\n                        if (sle32(wave_sizze_30145, skip_threads_30190)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30191) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30184;\n                                eta_p_30185 = eta_p_30184;\n                            }\n                        }\n                        if (sle32(wave_sizze_30145, skip_threads_30190)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30190 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30192 = squot32(local_tid_30143, 32) == 0 || !ltid_in_bounds_30187;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30192) {\n                        eta_p_30181 = eta_p_30180;\n                        eta_p_30180 = ((__local int32_t *) local_mem_30150)[sext_i32_i64(squot32(local_tid_30143, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30192) {\n                        int32_t defunc_0_op_res_30182 = add32(eta_p_30180, eta_p_30181);\n                        \n                        eta_p_30180 = defunc_0_op_res_30182;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30192) {\n                        ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30180;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore corre", "ct values for first block\n            {\n                if (squot32(local_tid_30143, 32) == 0 && ltid_in_bounds_30187) {\n                    ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = eta_p_30181;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30143 == 0) {\n                acc_30183 = ((__local int32_t *) local_mem_30150)[segscan_tblock_sizze_29213 - (int64_t) 1];\n            } else {\n                acc_30183 = ((__local int32_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30193 = 0;\n        block_new_sgm_30194 = sgm_idx_30162 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30194 && local_tid_30143 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160] = acc_30183;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 2;\n                acc_30183 = 0;\n            }\n            if (!block_new_sgm_30194 && slt32(local_tid_30143, wave_sizze_30145)) {\n                if (local_tid_30143 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_30136)[dynamic_id_30160] = acc_30183;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 1;\n                    \n                    int8_t tmp_30195 = ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30150)[(int64_t) 0] = tmp_30195;\n                }\n                mem_fence_local();\n                \n                int8_t status_30196 = ((__local int8_t *) local_mem_30150)[(int64_t) 0];\n                \n                if (status",
                                    "_30196 == (int8_t) 2) {\n                    if (local_tid_30143 == 0) {\n                        prefix_30193 = ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30197 = sext_i64_i32(dynamic_id_30160 - sext_i32_i64(wave_sizze_30145));\n                    \n                    while (slt32(wave_sizze_30145 * -1, readOffset_30197)) {\n                        int32_t read_i_30198 = readOffset_30197 + local_tid_30143;\n                        int32_t aggr_30199 = 0;\n                        int8_t flag_30200 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30198)) {\n                            flag_30200 = ((volatile __global int8_t *) status_flags_mem_30134)[sext_i32_i64(read_i_30198)];\n                            if (flag_30200 == (int8_t) 2) {\n                                aggr_30199 = ((volatile __global int32_t *) incprefixes_mem_30138)[sext_i32_i64(read_i_30198)];\n                            } else if (flag_30200 == (int8_t) 1) {\n                                aggr_30199 = ((volatile __global int32_t *) aggregates_mem_30136)[sext_i32_i64(read_i_30198)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_30150)[(int64_t) 8 + sext_i32_i64(local_tid_30143)] = aggr_30199;\n                        ((__local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = flag_30200;\n                        flag_30200 = ((__local int8_t *) local_mem_30150)[sext_i32_i64(wave_sizze_30145) - (int64_t) 1];\n                        if (slt8(flag_30200, (int8_t) 2)) {\n                            int8_t flg_x_30204;\n                            int8_t flg_y_30205;\n                            int32_t eta_p_30201;\n                            int32_t eta_p_30202;\n                            int32_t skip_threads_30206;\n                            \n                            //", " read input for in-block scan\n                            {\n                                flg_y_30205 = ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)];\n                                eta_p_30202 = ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8 + sext_i32_i64(local_tid_30143)];\n                                if ((local_tid_30143 - squot32(local_tid_30143, 32) * 32) == 0) {\n                                    eta_p_30201 = eta_p_30202;\n                                    flg_x_30204 = flg_y_30205;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30206 = 1;\n                                while (slt32(skip_threads_30206, 32)) {\n                                    if (sle32(skip_threads_30206, local_tid_30143 - squot32(local_tid_30143, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30204 = ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30206)];\n                                            eta_p_30201 = ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8 + (sext_i32_i64(local_tid_30143) - sext_i32_i64(skip_threads_30206))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30205 == (int8_t) 2 || flg_y_30205 == (int8_t) 0) {\n                                                flg_x_30204 = flg_y_30205;\n                                                eta_p_30201 = eta_p_30202;\n                                            } else {\n                                                int32_t defunc_0_op_res_30203 = add32(eta_p_30201, eta_p_30202);\n        ", "                                        \n                                                eta_p_30201 = defunc_0_op_res_30203;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30150)[sext_i32_i64(local_tid_30143)] = flg_x_30204;\n                                            flg_y_30205 = flg_x_30204;\n                                            ((volatile __local int32_t *) local_mem_30150)[(int64_t) 8 + sext_i32_i64(local_tid_30143)] = eta_p_30201;\n                                            eta_p_30202 = eta_p_30201;\n                                        }\n                                    }\n                                    skip_threads_30206 *= 2;\n                                }\n                            }\n                        }\n                        flag_30200 = ((__local int8_t *) local_mem_30150)[sext_i32_i64(wave_sizze_30145) - (int64_t) 1];\n                        aggr_30199 = ((__local int32_t *) local_mem_30150)[(int64_t) 8 + (sext_i32_i64(wave_sizze_30145) - (int64_t) 1)];\n                        if (flag_30200 == (int8_t) 2) {\n                            readOffset_30197 = wave_sizze_30145 * -1;\n                        } else if (flag_30200 == (int8_t) 1) {\n                            readOffset_30197 -= wave_sizze_30145;\n                        }\n                        if (slt8((int8_t) 0, flag_30200)) {\n                            int32_t eta_p_30207 = aggr_30199;\n                            int32_t eta_p_30208 = prefix_30193;\n                            int32_t defunc_0_op_res_30209 = add32(eta_p_30207, eta_p_30208);\n                            \n                            prefix_30193 = defunc_0_op_res_30209;\n                        }\n                        mem_fence_local();\n                    }\n                }\n     ",
                                    "           if (local_tid_30143 == 0) {\n                    if (boundary_30163 == sext_i64_i32(segscan_tblock_sizze_29213 * chunk_sizze_30131)) {\n                        int32_t eta_p_30210 = prefix_30193;\n                        int32_t eta_p_30211 = acc_30183;\n                        int32_t defunc_0_op_res_30212 = add32(eta_p_30210, eta_p_30211);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_30138)[dynamic_id_30160] = defunc_0_op_res_30212;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30134)[dynamic_id_30160] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_30150)[(int64_t) 8] = prefix_30193;\n                    acc_30183 = 0;\n                }\n            }\n            if (!(dynamic_id_30160 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30193 = ((__local int32_t *) local_mem_30150)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_30213;\n            int32_t eta_p_30214;\n            int32_t eta_p_30216 = prefix_30193;\n            int32_t eta_p_30217 = acc_30183;\n            \n            if (slt32(local_tid_30143 * chunk_sizze_32b_30147, boundary_30163) && !block_new_sgm_30194) {\n                int32_t defunc_0_op_res_30218 = add32(eta_p_30216, eta_p_30217);\n                \n                eta_p_30213 = defunc_0_op_res_30218;\n            } else {\n                eta_p_30213 = acc_30183;\n            }\n            \n            int32_t stopping_point_30219 = segsizze_compact_30164 - srem32(local_tid_30143 * chunk_sizze_32b_30147 - 1 + segsizze_compact_30164 - boundary_30163, segsizze_compact_30164);\n            \n            for (int64_t i_30220 = 0; i_30220 < chunk_sizze_30131; i_30220++) {\n                if (slt32(sext_i64_i32(i_30220), stopping_point_30219 - 1)) {\n    ", "                eta_p_30214 = private_mem_30165[i_30220];\n                    \n                    int32_t defunc_0_op_res_30215 = add32(eta_p_30213, eta_p_30214);\n                    \n                    private_mem_30165[i_30220] = defunc_0_op_res_30215;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30221 = 0; i_30221 < chunk_sizze_30131; i_30221++) {\n                int64_t sharedIdx_30222 = sext_i32_i64(local_tid_30143) * chunk_sizze_30131 + i_30221;\n                int32_t tmp_30223 = private_mem_30165[i_30221];\n                \n                ((__local int32_t *) local_mem_30150)[sharedIdx_30222] = tmp_30223;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30224 = 0; i_30224 < chunk_sizze_30131; i_30224++) {\n                int64_t flat_idx_30225 = thd_offset_30167 + i_30224 * segscan_tblock_sizze_29213;\n                int64_t slice_30226 = mz2080U_25210;\n                int64_t gtid_29217 = flat_idx_30225;\n                int64_t remnant_30227 = flat_idx_30225 - gtid_29217;\n                \n                if (slt64(flat_idx_30225, mz2080U_25210)) {\n                    int32_t tmp_30228 = ((__local int32_t *) local_mem_30150)[flat_idx_30225 - block_offset_30161];\n                    \n                    ((__global int32_t *) mem_29692)[gtid_29217] = tmp_30228;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_29213\n    #undef chunk_sizze_30131\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegscan_29371_dim1, 1, 1)\nvoid human_generici32zisegscan_29371(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_25210, int64_t nz2081U_25211, int64_t num_tblocks_29368, int64_t num_virt_blocks_30441, int64_t num_virt_threads_30442, __global unsigned char *II1_mem_29679,", " __global unsigned char *A_mem_29680, __global unsigned char *mem_29695, __global unsigned char *mem_29709, __global unsigned char *mem_29712, __global unsigned char *mem_29714, __global unsigned char *status_flags_mem_30443, __global unsigned char *aggregates_mem_30445, __global unsigned char *incprefixes_mem_30447, __global unsigned char *global_dynid_mem_30449)\n{\n    #define segscan_tblock_sizze_29366 (human_generici32zisegscan_29371zisegscan_tblock_sizze_29366)\n    #define chunk_sizze_30440 (human_generici32zisegscan_29371zichunk_sizze_30440)\n    \n    volatile __local unsigned char *local_mem_30459_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30459_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29366), chunk_sizze_30440 * segscan_tblock_sizze_29366 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29366), chunk_sizze_30440 * segscan_tblock_sizze_29366 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30452;\n    int32_t tblock_sizze_30455;\n    int32_t wave_sizze_30454;\n    int32_t block_id_30453;\n    int32_t global_tid_30451;\n    int64_t phys_tid_29371;\n    int32_t chunk_sizze_32b_30456;\n    int64_t byte_offsets_30457;\n    int64_t warp_byte_offset_30458;\n    __local unsigned char *local_mem_30459;\n    int64_t trans_arr_len_30460;\n    int64_t phys_block_id_30466;\n    int64_t virtloop_bound_30467;\n    \n    local_tid_30452 = get_local_id(0);\n    tblock_sizze_30455 = get_local_size(0);\n    wave_sizze_30454 = LOCKSTEP_WIDTH;\n    block_id_30453 = get_tblock_id(0);\n    global_tid_30451 = block_id_30453 * tblock_sizze_30455 + local_tid_30452;\n    phys_tid_29371 = sext_i32_i64(global_tid_30451);\n    chunk_sizze_32",
                                    "b_30456 = sext_i64_i32(chunk_sizze_30440);\n    byte_offsets_30457 = segscan_tblock_sizze_29366 * (int64_t) 8;\n    warp_byte_offset_30458 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30459 = (__local unsigned char *) local_mem_30459_backing_0;\n    trans_arr_len_30460 = chunk_sizze_30440 * segscan_tblock_sizze_29366;\n    phys_block_id_30466 = get_tblock_id(0);\n    virtloop_bound_30467 = sdiv_up64(num_virt_blocks_30441 - phys_block_id_30466, num_tblocks_29368);\n    for (int64_t virtloop_i_30468 = 0; virtloop_i_30468 < virtloop_bound_30467; virtloop_i_30468++) {\n        int64_t dynamic_id_30469;\n        int64_t block_offset_30470;\n        int64_t sgm_idx_30471;\n        int32_t boundary_30472;\n        int32_t segsizze_compact_30473;\n        int64_t private_mem_30474[chunk_sizze_30440];\n        int64_t thd_offset_30476;\n        int64_t acc_30492;\n        int64_t prefix_30502;\n        bool block_new_sgm_30503;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30452 == 0) {\n                dynamic_id_30469 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30449)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30459)[(int64_t) 0] = dynamic_id_30469;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30469 == num_virt_blocks_30441 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30449)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30469 = ((__local int32_t *) local_mem_30459)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30470 = dynamic_id_30469 * chunk_sizze_30440 * segscan_tblock_sizze_29366;\n        sgm_idx_30471 = smod64(b", "lock_offset_30470, nz2081U_25211);\n        boundary_30472 = sext_i64_i32(smin64(chunk_sizze_30440 * segscan_tblock_sizze_29366, nz2081U_25211 - sgm_idx_30471));\n        segsizze_compact_30473 = sext_i64_i32(smin64(chunk_sizze_30440 * segscan_tblock_sizze_29366, nz2081U_25211));\n        thd_offset_30476 = block_offset_30470 + sext_i32_i64(local_tid_30452);\n        // Load and map\n        {\n            for (int64_t i_30477 = 0; i_30477 < chunk_sizze_30440; i_30477++) {\n                int64_t virt_tid_30478 = thd_offset_30476 + i_30477 * segscan_tblock_sizze_29366;\n                int64_t slice_30479 = nz2081U_25211;\n                int64_t gtid_29370 = virt_tid_30478;\n                int64_t remnant_30480 = virt_tid_30478 - gtid_29370;\n                \n                if (slt64(virt_tid_30478, nz2081U_25211)) {\n                    int32_t eta_p_27407 = ((__global int32_t *) II1_mem_29679)[gtid_29370];\n                    int64_t ii_27408 = sext_i32_i64(eta_p_27407);\n                    bool x_27409 = sle64((int64_t) 0, ii_27408);\n                    bool y_27410 = slt64(ii_27408, mz2080U_25210);\n                    bool bounds_check_27411 = x_27409 && y_27410;\n                    bool index_certs_27412;\n                    \n                    if (!bounds_check_27411) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 27) == -1) {\n                                global_failure_args[0] = (int64_t) ii_27408;\n                                global_failure_args[1] = (int64_t) mz2080U_25210;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int32_t zeze_lhs_27413 = ((__global int32_t *) mem_29709)[ii_27408];\n                    bool cond_27414 = zeze_lhs_27413 == -1;\n                    bool defunc_0_p_res_27415;\n                ", "    \n                    if (cond_27414) {\n                        defunc_0_p_res_27415 = 0;\n                    } else {\n                        int32_t eta_p_27406 = ((__global int32_t *) A_mem_29680)[gtid_29370];\n                        bool cond_27416 = zeze_lhs_27413 == 0;\n                        bool defunc_0_p_res_f_res_27417;\n                        \n                        if (cond_27416) {\n                            int32_t lt_arg1_28159 = ((__global int32_t *) mem_29695)[ii_27408];\n                            bool defunc_0_lt_res_28160 = slt32(eta_p_27406, lt_arg1_28159);\n                            \n                            defunc_0_p_res_f_res_27417 = defunc_0_lt_res_28160;\n                        } else {\n                            bool cond_27420 = zeze_lhs_27413 == 1;\n                            bool defunc_0_p_res_f_res_f_res_27421;\n                            \n                            if (cond_27420) {\n                                defunc_0_p_res_f_res_f_res_27421 = 0;\n                            } else {\n                                int32_t lt_arg1_27422 = ((__global int32_t *) mem_29695)[ii_27408];\n                                bool defunc_0_lt_res_27423 = slt32(eta_p_27406, lt_arg1_27422);\n                                bool cond_27424 = !defunc_0_lt_res_27423;\n                                bool defunc_0_eq_res_27425 = eta_p_27406 == lt_arg1_27422;\n                                bool defunc_0_p_res_f_res_f_res_f_res_t_res_27426 = !defunc_0_eq_res_27425;\n                                bool x_27427 = cond_27424 && defunc_0_p_res_f_res_f_res_f_res_t_res_27426;\n                                \n                                defunc_0_p_res_f_res_f_res_27421 = x_27427;\n                            }\n                            defunc_0_p_res_f_res_27417 = defunc_0_p_res_f_res_f_res_27421;\n                        }\n                        defunc_0_p_res_27415 = defunc_0_p_res_f_res_27417;\n                    }\n                    \n ",
                                    "                   int64_t defunc_0_f_res_27428 = btoi_bool_i64(defunc_0_p_res_27415);\n                    \n                    ((__global int64_t *) mem_29714)[gtid_29370] = defunc_0_f_res_27428;\n                    private_mem_30474[i_30477] = defunc_0_f_res_27428;\n                } else {\n                    private_mem_30474[i_30477] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30481 = 0; i_30481 < chunk_sizze_30440; i_30481++) {\n                int64_t sharedIdx_30482 = sext_i32_i64(local_tid_30452) + i_30481 * segscan_tblock_sizze_29366;\n                int64_t tmp_30483 = private_mem_30474[i_30481];\n                \n                ((__local int64_t *) local_mem_30459)[sharedIdx_30482] = tmp_30483;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30484 = 0; i_30484 < chunk_sizze_30440; i_30484++) {\n                int64_t sharedIdx_30485 = sext_i32_i64(local_tid_30452) * chunk_sizze_30440 + i_30484;\n                int64_t tmp_30486 = ((__local int64_t *) local_mem_30459)[sharedIdx_30485];\n                \n                private_mem_30474[i_30484] = tmp_30486;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30487 = 0; i_30487 < chunk_sizze_30440 - (int64_t) 1; i_30487++) {\n                int64_t eta_p_27075;\n                int64_t eta_p_27076;\n                \n                eta_p_27075 = private_mem_30474[i_30487];\n                eta_p_27076 = private_mem_30474[i_30487 + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27077 = add64(eta_p_27075, eta_p_27076);\n                \n                private_mem_30474[i_30487 + (int64_t) 1] = defunc_0_op_res_27077;\n            }\n        }\n        // Pu", "blish results in shared memory\n        {\n            int64_t tmp_30488 = private_mem_30474[chunk_sizze_30440 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = tmp_30488;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_30489;\n            int64_t eta_p_30490;\n            int64_t eta_p_30493;\n            int64_t eta_p_30494;\n            bool ltid_in_bounds_30496 = slt64(sext_i32_i64(local_tid_30452), num_virt_threads_30442);\n            int32_t skip_threads_30497;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30496) {\n                    eta_p_30490 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)];\n                    if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 0) {\n                        eta_p_30489 = eta_p_30490;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30497 = 1;\n                while (slt32(skip_threads_30497, 32)) {\n                    bool thread_active_30498 = sle32(skip_threads_30497, local_tid_30452 - squot32(local_tid_30452, 32) * 32) && ltid_in_bounds_30496;\n                    \n                    if (thread_active_30498) {\n                        // read operands\n                        {\n                            eta_p_30489 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30497)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30498) {\n                            int64_t defunc_0_op_res_30491 = add64(eta_p_30489, eta_p_30490);\n                            \n                            eta_p_30489 = defunc_0_op_res_30491;\n           ", "             }\n                    }\n                    if (sle32(wave_sizze_30454, skip_threads_30497)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30498) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30489;\n                            eta_p_30490 = eta_p_30489;\n                        }\n                    }\n                    if (sle32(wave_sizze_30454, skip_threads_30497)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30497 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 31 && ltid_in_bounds_30496) {\n                    ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(squot32(local_tid_30452, 32))] = eta_p_30489;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30499;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496) {\n                        eta_p_30494 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)];\n                        if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 0) {\n                            eta_p_30493 = eta_p_30494;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30499 = 1;\n                    while (slt32(skip_threads_",
                                    "30499, 32)) {\n                        bool thread_active_30500 = sle32(skip_threads_30499, local_tid_30452 - squot32(local_tid_30452, 32) * 32) && (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496);\n                        \n                        if (thread_active_30500) {\n                            // read operands\n                            {\n                                eta_p_30493 = ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30499)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30500) {\n                                int64_t defunc_0_op_res_30495 = add64(eta_p_30493, eta_p_30494);\n                                \n                                eta_p_30493 = defunc_0_op_res_30495;\n                            }\n                        }\n                        if (sle32(wave_sizze_30454, skip_threads_30499)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30500) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30493;\n                                eta_p_30494 = eta_p_30493;\n                            }\n                        }\n                        if (sle32(wave_sizze_30454, skip_threads_30499)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30499 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30501 = squot32(local_tid_30452, 32) == 0 || !ltid_in_bounds_30496;\n            \n            // carry-in for every block except the first\n            {\n                // rea", "d operands\n                {\n                    if (!no_carry_in_30501) {\n                        eta_p_30490 = eta_p_30489;\n                        eta_p_30489 = ((__local int64_t *) local_mem_30459)[sext_i32_i64(squot32(local_tid_30452, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30501) {\n                        int64_t defunc_0_op_res_30491 = add64(eta_p_30489, eta_p_30490);\n                        \n                        eta_p_30489 = defunc_0_op_res_30491;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30501) {\n                        ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30489;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30452, 32) == 0 && ltid_in_bounds_30496) {\n                    ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = eta_p_30490;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30452 == 0) {\n                acc_30492 = ((__local int64_t *) local_mem_30459)[segscan_tblock_sizze_29366 - (int64_t) 1];\n            } else {\n                acc_30492 = ((__local int64_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30502 = (int64_t) 0;\n        block_new_sgm_30503 = sgm_idx_30471 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30503 && local_tid_30452 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469] = acc_30492;\n                mem_fence_global();\n                ((volatile", " __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 2;\n                acc_30492 = (int64_t) 0;\n            }\n            if (!block_new_sgm_30503 && slt32(local_tid_30452, wave_sizze_30454)) {\n                if (local_tid_30452 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_30445)[dynamic_id_30469] = acc_30492;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 1;\n                    \n                    int8_t tmp_30504 = ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30459)[(int64_t) 0] = tmp_30504;\n                }\n                mem_fence_local();\n                \n                int8_t status_30505 = ((__local int8_t *) local_mem_30459)[(int64_t) 0];\n                \n                if (status_30505 == (int8_t) 2) {\n                    if (local_tid_30452 == 0) {\n                        prefix_30502 = ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30506 = sext_i64_i32(dynamic_id_30469 - sext_i32_i64(wave_sizze_30454));\n                    \n                    while (slt32(wave_sizze_30454 * -1, readOffset_30506)) {\n                        int32_t read_i_30507 = readOffset_30506 + local_tid_30452;\n                        int64_t aggr_30508 = (int64_t) 0;\n                        int8_t flag_30509 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30507)) {\n                            flag_30509 = ((volatile __global int8_t *) status_flags_mem_30443)[sext_i32_i64(read_i_30507)];\n                            if (flag_30509 == (int8_t) 2) {\n                                aggr_30508 = ((volatile __global int64_t *) incprefixes_mem_30447)[sext_i32_i64(re",
                                    "ad_i_30507)];\n                            } else if (flag_30509 == (int8_t) 1) {\n                                aggr_30508 = ((volatile __global int64_t *) aggregates_mem_30445)[sext_i32_i64(read_i_30507)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)] = aggr_30508;\n                        ((__local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = flag_30509;\n                        flag_30509 = ((__local int8_t *) local_mem_30459)[sext_i32_i64(wave_sizze_30454) - (int64_t) 1];\n                        if (slt8(flag_30509, (int8_t) 2)) {\n                            int8_t flg_x_30513;\n                            int8_t flg_y_30514;\n                            int64_t eta_p_30510;\n                            int64_t eta_p_30511;\n                            int32_t skip_threads_30515;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30514 = ((volatile __local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)];\n                                eta_p_30511 = ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)];\n                                if ((local_tid_30452 - squot32(local_tid_30452, 32) * 32) == 0) {\n                                    eta_p_30510 = eta_p_30511;\n                                    flg_x_30513 = flg_y_30514;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30515 = 1;\n                                while (slt32(skip_threads_30515, 32)) {\n                                    if (sle32(skip_threads_30515, local_tid_30452 - squot32(local_tid_30452, 32) * 32)) {\n                                        // read oper", "ands\n                                        {\n                                            flg_x_30513 = ((volatile __local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30515)];\n                                            eta_p_30510 = ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + (sext_i32_i64(local_tid_30452) - sext_i32_i64(skip_threads_30515))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30514 == (int8_t) 2 || flg_y_30514 == (int8_t) 0) {\n                                                flg_x_30513 = flg_y_30514;\n                                                eta_p_30510 = eta_p_30511;\n                                            } else {\n                                                int64_t defunc_0_op_res_30512 = add64(eta_p_30510, eta_p_30511);\n                                                \n                                                eta_p_30510 = defunc_0_op_res_30512;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30459)[sext_i32_i64(local_tid_30452)] = flg_x_30513;\n                                            flg_y_30514 = flg_x_30513;\n                                            ((volatile __local int64_t *) local_mem_30459)[(int64_t) 4 + sext_i32_i64(local_tid_30452)] = eta_p_30510;\n                                            eta_p_30511 = eta_p_30510;\n                                        }\n                                    }\n                                    skip_threads_30515 *= 2;\n                                }\n                            }\n                        }\n                        flag_30509 = ((__local ", "int8_t *) local_mem_30459)[sext_i32_i64(wave_sizze_30454) - (int64_t) 1];\n                        aggr_30508 = ((__local int64_t *) local_mem_30459)[(int64_t) 4 + (sext_i32_i64(wave_sizze_30454) - (int64_t) 1)];\n                        if (flag_30509 == (int8_t) 2) {\n                            readOffset_30506 = wave_sizze_30454 * -1;\n                        } else if (flag_30509 == (int8_t) 1) {\n                            readOffset_30506 -= wave_sizze_30454;\n                        }\n                        if (slt8((int8_t) 0, flag_30509)) {\n                            int64_t eta_p_30516 = aggr_30508;\n                            int64_t eta_p_30517 = prefix_30502;\n                            int64_t defunc_0_op_res_30518 = add64(eta_p_30516, eta_p_30517);\n                            \n                            prefix_30502 = defunc_0_op_res_30518;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30452 == 0) {\n                    if (boundary_30472 == sext_i64_i32(segscan_tblock_sizze_29366 * chunk_sizze_30440)) {\n                        int64_t eta_p_30519 = prefix_30502;\n                        int64_t eta_p_30520 = acc_30492;\n                        int64_t defunc_0_op_res_30521 = add64(eta_p_30519, eta_p_30520);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_30447)[dynamic_id_30469] = defunc_0_op_res_30521;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30443)[dynamic_id_30469] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_30459)[(int64_t) 4] = prefix_30502;\n                    acc_30492 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_30469 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30502 = ((__local int64_t *) local_mem_30459)[(int64_t) 4];",
                                    "\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_30522;\n            int64_t eta_p_30523;\n            int64_t eta_p_30525 = prefix_30502;\n            int64_t eta_p_30526 = acc_30492;\n            \n            if (slt32(local_tid_30452 * chunk_sizze_32b_30456, boundary_30472) && !block_new_sgm_30503) {\n                int64_t defunc_0_op_res_30527 = add64(eta_p_30525, eta_p_30526);\n                \n                eta_p_30522 = defunc_0_op_res_30527;\n            } else {\n                eta_p_30522 = acc_30492;\n            }\n            \n            int32_t stopping_point_30528 = segsizze_compact_30473 - srem32(local_tid_30452 * chunk_sizze_32b_30456 - 1 + segsizze_compact_30473 - boundary_30472, segsizze_compact_30473);\n            \n            for (int64_t i_30529 = 0; i_30529 < chunk_sizze_30440; i_30529++) {\n                if (slt32(sext_i64_i32(i_30529), stopping_point_30528 - 1)) {\n                    eta_p_30523 = private_mem_30474[i_30529];\n                    \n                    int64_t defunc_0_op_res_30524 = add64(eta_p_30522, eta_p_30523);\n                    \n                    private_mem_30474[i_30529] = defunc_0_op_res_30524;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30530 = 0; i_30530 < chunk_sizze_30440; i_30530++) {\n                int64_t sharedIdx_30531 = sext_i32_i64(local_tid_30452) * chunk_sizze_30440 + i_30530;\n                int64_t tmp_30532 = private_mem_30474[i_30530];\n                \n                ((__local int64_t *) local_mem_30459)[sharedIdx_30531] = tmp_30532;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30533 = 0; i_30533 < chunk_sizze_30440; i_30533++) {\n                int64_t flat_idx_30534 = thd_offset_30476 + i_30533 * segscan_tblock_sizze_29366;\n                int64_t slice_3053", "5 = nz2081U_25211;\n                int64_t gtid_29370 = flat_idx_30534;\n                int64_t remnant_30536 = flat_idx_30534 - gtid_29370;\n                \n                if (slt64(flat_idx_30534, nz2081U_25211)) {\n                    int64_t tmp_30537 = ((__local int64_t *) local_mem_30459)[flat_idx_30534 - block_offset_30470];\n                    \n                    ((__global int64_t *) mem_29712)[gtid_29370] = tmp_30537;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_29366\n    #undef chunk_sizze_30440\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegscan_29387_dim1, 1, 1)\nvoid human_generici32zisegscan_29387(__global int *global_failure, int64_t mz2080U_25210, int64_t num_tblocks_29384, int64_t num_virt_blocks_30570, int64_t num_virt_threads_30571, __global unsigned char *mem_param_29725, __global unsigned char *mem_29737, __global unsigned char *status_flags_mem_30572, __global unsigned char *aggregates_mem_30574, __global unsigned char *incprefixes_mem_30576, __global unsigned char *global_dynid_mem_30578)\n{\n    #define segscan_tblock_sizze_29382 (human_generici32zisegscan_29387zisegscan_tblock_sizze_29382)\n    #define chunk_sizze_30569 (human_generici32zisegscan_29387zichunk_sizze_30569)\n    \n    volatile __local unsigned char *local_mem_30588_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30588_backing_0_offset = 0 + (smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_29382), chunk_sizze_30569 * segscan_tblock_sizze_29382 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_29382), chunk_sizze_30569 * segscan_tblock_sizze_29382 * (int64_t) 4), (int64_t) 8), (int64_t) 8));\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_30581;\n    int32_t tblock_sizze_30584;\n    int32_t wave_sizze_30583;\n    int32_t block_id_30582;\n    int32_t global_tid_30580;\n    int6", "4_t phys_tid_29387;\n    int32_t chunk_sizze_32b_30585;\n    int64_t byte_offsets_30586;\n    int64_t warp_byte_offset_30587;\n    __local unsigned char *local_mem_30588;\n    int64_t trans_arr_len_30589;\n    int64_t phys_block_id_30595;\n    int64_t virtloop_bound_30596;\n    \n    local_tid_30581 = get_local_id(0);\n    tblock_sizze_30584 = get_local_size(0);\n    wave_sizze_30583 = LOCKSTEP_WIDTH;\n    block_id_30582 = get_tblock_id(0);\n    global_tid_30580 = block_id_30582 * tblock_sizze_30584 + local_tid_30581;\n    phys_tid_29387 = sext_i32_i64(global_tid_30580);\n    chunk_sizze_32b_30585 = sext_i64_i32(chunk_sizze_30569);\n    byte_offsets_30586 = segscan_tblock_sizze_29382 * (int64_t) 4;\n    warp_byte_offset_30587 = (int64_t) 160;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30588 = (__local unsigned char *) local_mem_30588_backing_0;\n    trans_arr_len_30589 = chunk_sizze_30569 * segscan_tblock_sizze_29382;\n    phys_block_id_30595 = get_tblock_id(0);\n    virtloop_bound_30596 = sdiv_up64(num_virt_blocks_30570 - phys_block_id_30595, num_tblocks_29384);\n    for (int64_t virtloop_i_30597 = 0; virtloop_i_30597 < virtloop_bound_30596; virtloop_i_30597++) {\n        int64_t dynamic_id_30598;\n        int64_t block_offset_30599;\n        int64_t sgm_idx_30600;\n        int32_t boundary_30601;\n        int32_t segsizze_compact_30602;\n        int32_t private_mem_30603[chunk_sizze_30569];\n        int64_t thd_offset_30605;\n        int32_t acc_30621;\n        int32_t prefix_30631;\n        bool block_new_sgm_30632;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30581 == 0) {\n                dynamic_id_30598 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30578)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30588)[(int64_t) 0] = dynamic_id_30598;\n                }\n                // First thread in ",
                                    "last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30598 == num_virt_blocks_30570 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30578)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30598 = ((__local int32_t *) local_mem_30588)[(int64_t) 0];\n        barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30599 = dynamic_id_30598 * chunk_sizze_30569 * segscan_tblock_sizze_29382;\n        sgm_idx_30600 = smod64(block_offset_30599, mz2080U_25210);\n        boundary_30601 = sext_i64_i32(smin64(chunk_sizze_30569 * segscan_tblock_sizze_29382, mz2080U_25210 - sgm_idx_30600));\n        segsizze_compact_30602 = sext_i64_i32(smin64(chunk_sizze_30569 * segscan_tblock_sizze_29382, mz2080U_25210));\n        thd_offset_30605 = block_offset_30599 + sext_i32_i64(local_tid_30581);\n        // Load and map\n        {\n            for (int64_t i_30606 = 0; i_30606 < chunk_sizze_30569; i_30606++) {\n                int64_t virt_tid_30607 = thd_offset_30605 + i_30606 * segscan_tblock_sizze_29382;\n                int64_t slice_30608 = mz2080U_25210;\n                int64_t gtid_29386 = virt_tid_30607;\n                int64_t remnant_30609 = virt_tid_30607 - gtid_29386;\n                \n                if (slt64(virt_tid_30607, mz2080U_25210)) {\n                    int32_t x_27136 = ((__global int32_t *) mem_param_29725)[gtid_29386];\n                    \n                    private_mem_30603[i_30606] = x_27136;\n                } else {\n                    private_mem_30603[i_30606] = 0;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30610 = 0; i_30610 < chunk_sizze_30569; i_30610++) {\n                int64_t sharedIdx_30611 = sext_i32_i64(local_tid_30581) + i_30610 * segscan_tblock_sizze_29382;\n                int32_t tmp_30612 =", " private_mem_30603[i_30610];\n                \n                ((__local int32_t *) local_mem_30588)[sharedIdx_30611] = tmp_30612;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30613 = 0; i_30613 < chunk_sizze_30569; i_30613++) {\n                int64_t sharedIdx_30614 = sext_i32_i64(local_tid_30581) * chunk_sizze_30569 + i_30613;\n                int32_t tmp_30615 = ((__local int32_t *) local_mem_30588)[sharedIdx_30614];\n                \n                private_mem_30603[i_30613] = tmp_30615;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30616 = 0; i_30616 < chunk_sizze_30569 - (int64_t) 1; i_30616++) {\n                int32_t eta_p_27133;\n                int32_t eta_p_27134;\n                \n                eta_p_27133 = private_mem_30603[i_30616];\n                eta_p_27134 = private_mem_30603[i_30616 + (int64_t) 1];\n                \n                int32_t defunc_0_op_res_27135 = add32(eta_p_27133, eta_p_27134);\n                \n                private_mem_30603[i_30616 + (int64_t) 1] = defunc_0_op_res_27135;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int32_t tmp_30617 = private_mem_30603[chunk_sizze_30569 - (int64_t) 1];\n            \n            ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = tmp_30617;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int32_t eta_p_30618;\n            int32_t eta_p_30619;\n            int32_t eta_p_30622;\n            int32_t eta_p_30623;\n            bool ltid_in_bounds_30625 = slt64(sext_i32_i64(local_tid_30581), num_virt_threads_30571);\n            int32_t skip_threads_30626;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30625) {\n                    eta_p_30619 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_", "i64(local_tid_30581)];\n                    if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                        eta_p_30618 = eta_p_30619;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30626 = 1;\n                while (slt32(skip_threads_30626, 32)) {\n                    bool thread_active_30627 = sle32(skip_threads_30626, local_tid_30581 - squot32(local_tid_30581, 32) * 32) && ltid_in_bounds_30625;\n                    \n                    if (thread_active_30627) {\n                        // read operands\n                        {\n                            eta_p_30618 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30626)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_30627) {\n                            int32_t defunc_0_op_res_30620 = add32(eta_p_30618, eta_p_30619);\n                            \n                            eta_p_30618 = defunc_0_op_res_30620;\n                        }\n                    }\n                    if (sle32(wave_sizze_30583, skip_threads_30626)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30627) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30618;\n                            eta_p_30619 = eta_p_30618;\n                        }\n                    }\n                    if (sle32(wave_sizze_30583, skip_threads_30626)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30626 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread ",
                                    "of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 31 && ltid_in_bounds_30625) {\n                    ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(squot32(local_tid_30581, 32))] = eta_p_30618;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30628;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30581, 32) == 0 && ltid_in_bounds_30625) {\n                        eta_p_30623 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)];\n                        if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                            eta_p_30622 = eta_p_30623;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30628 = 1;\n                    while (slt32(skip_threads_30628, 32)) {\n                        bool thread_active_30629 = sle32(skip_threads_30628, local_tid_30581 - squot32(local_tid_30581, 32) * 32) && (squot32(local_tid_30581, 32) == 0 && ltid_in_bounds_30625);\n                        \n                        if (thread_active_30629) {\n                            // read operands\n                            {\n                                eta_p_30622 = ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30628)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30629) {\n                                int32_t defunc_0_op_res_30624 = add32(eta_p_30622, eta_p_30623);\n                ", "                \n                                eta_p_30622 = defunc_0_op_res_30624;\n                            }\n                        }\n                        if (sle32(wave_sizze_30583, skip_threads_30628)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30629) {\n                            // write result\n                            {\n                                ((volatile __local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30622;\n                                eta_p_30623 = eta_p_30622;\n                            }\n                        }\n                        if (sle32(wave_sizze_30583, skip_threads_30628)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30628 *= 2;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30630 = squot32(local_tid_30581, 32) == 0 || !ltid_in_bounds_30625;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30630) {\n                        eta_p_30619 = eta_p_30618;\n                        eta_p_30618 = ((__local int32_t *) local_mem_30588)[sext_i32_i64(squot32(local_tid_30581, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30630) {\n                        int32_t defunc_0_op_res_30620 = add32(eta_p_30618, eta_p_30619);\n                        \n                        eta_p_30618 = defunc_0_op_res_30620;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30630) {\n                        ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = ", "eta_p_30618;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30581, 32) == 0 && ltid_in_bounds_30625) {\n                    ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = eta_p_30619;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30581 == 0) {\n                acc_30621 = ((__local int32_t *) local_mem_30588)[segscan_tblock_sizze_29382 - (int64_t) 1];\n            } else {\n                acc_30621 = ((__local int32_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30631 = 0;\n        block_new_sgm_30632 = sgm_idx_30600 == (int64_t) 0;\n        // Perform lookback\n        {\n            if (block_new_sgm_30632 && local_tid_30581 == 0) {\n                ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598] = acc_30621;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 2;\n                acc_30621 = 0;\n            }\n            if (!block_new_sgm_30632 && slt32(local_tid_30581, wave_sizze_30583)) {\n                if (local_tid_30581 == 0) {\n                    ((volatile __global int32_t *) aggregates_mem_30574)[dynamic_id_30598] = acc_30621;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 1;\n                    \n                    int8_t tmp_30633 = ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30588)[(int64_t) 0] = tmp_30633;\n                }\n                mem_fence_local();\n            ",
                                    "    \n                int8_t status_30634 = ((__local int8_t *) local_mem_30588)[(int64_t) 0];\n                \n                if (status_30634 == (int8_t) 2) {\n                    if (local_tid_30581 == 0) {\n                        prefix_30631 = ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30635 = sext_i64_i32(dynamic_id_30598 - sext_i32_i64(wave_sizze_30583));\n                    \n                    while (slt32(wave_sizze_30583 * -1, readOffset_30635)) {\n                        int32_t read_i_30636 = readOffset_30635 + local_tid_30581;\n                        int32_t aggr_30637 = 0;\n                        int8_t flag_30638 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30636)) {\n                            flag_30638 = ((volatile __global int8_t *) status_flags_mem_30572)[sext_i32_i64(read_i_30636)];\n                            if (flag_30638 == (int8_t) 2) {\n                                aggr_30637 = ((volatile __global int32_t *) incprefixes_mem_30576)[sext_i32_i64(read_i_30636)];\n                            } else if (flag_30638 == (int8_t) 1) {\n                                aggr_30637 = ((volatile __global int32_t *) aggregates_mem_30574)[sext_i32_i64(read_i_30636)];\n                            }\n                        }\n                        ((__local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)] = aggr_30637;\n                        ((__local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = flag_30638;\n                        flag_30638 = ((__local int8_t *) local_mem_30588)[sext_i32_i64(wave_sizze_30583) - (int64_t) 1];\n                        if (slt8(flag_30638, (int8_t) 2)) {\n                            int8_t flg_x_30642;\n                            int8_t flg_y_30643;\n                            int32_t eta_p_30639;\n                           ", " int32_t eta_p_30640;\n                            int32_t skip_threads_30644;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30643 = ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)];\n                                eta_p_30640 = ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)];\n                                if ((local_tid_30581 - squot32(local_tid_30581, 32) * 32) == 0) {\n                                    eta_p_30639 = eta_p_30640;\n                                    flg_x_30642 = flg_y_30643;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30644 = 1;\n                                while (slt32(skip_threads_30644, 32)) {\n                                    if (sle32(skip_threads_30644, local_tid_30581 - squot32(local_tid_30581, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30642 = ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30644)];\n                                            eta_p_30639 = ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + (sext_i32_i64(local_tid_30581) - sext_i32_i64(skip_threads_30644))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30643 == (int8_t) 2 || flg_y_30643 == (int8_t) 0) {\n                                                flg_x_30642 = flg_y_30643;\n                                                eta_p_30639 = eta_p_30640;\n                                     ", "       } else {\n                                                int32_t defunc_0_op_res_30641 = add32(eta_p_30639, eta_p_30640);\n                                                \n                                                eta_p_30639 = defunc_0_op_res_30641;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30588)[sext_i32_i64(local_tid_30581)] = flg_x_30642;\n                                            flg_y_30643 = flg_x_30642;\n                                            ((volatile __local int32_t *) local_mem_30588)[(int64_t) 8 + sext_i32_i64(local_tid_30581)] = eta_p_30639;\n                                            eta_p_30640 = eta_p_30639;\n                                        }\n                                    }\n                                    skip_threads_30644 *= 2;\n                                }\n                            }\n                        }\n                        flag_30638 = ((__local int8_t *) local_mem_30588)[sext_i32_i64(wave_sizze_30583) - (int64_t) 1];\n                        aggr_30637 = ((__local int32_t *) local_mem_30588)[(int64_t) 8 + (sext_i32_i64(wave_sizze_30583) - (int64_t) 1)];\n                        if (flag_30638 == (int8_t) 2) {\n                            readOffset_30635 = wave_sizze_30583 * -1;\n                        } else if (flag_30638 == (int8_t) 1) {\n                            readOffset_30635 -= wave_sizze_30583;\n                        }\n                        if (slt8((int8_t) 0, flag_30638)) {\n                            int32_t eta_p_30645 = aggr_30637;\n                            int32_t eta_p_30646 = prefix_30631;\n                            int32_t defunc_0_op_res_30647 = add32(eta_p_30645, eta_p_30646);\n                            \n                            prefix_30631 = ",
                                    "defunc_0_op_res_30647;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30581 == 0) {\n                    if (boundary_30601 == sext_i64_i32(segscan_tblock_sizze_29382 * chunk_sizze_30569)) {\n                        int32_t eta_p_30648 = prefix_30631;\n                        int32_t eta_p_30649 = acc_30621;\n                        int32_t defunc_0_op_res_30650 = add32(eta_p_30648, eta_p_30649);\n                        \n                        ((volatile __global int32_t *) incprefixes_mem_30576)[dynamic_id_30598] = defunc_0_op_res_30650;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30572)[dynamic_id_30598] = (int8_t) 2;\n                    }\n                    ((__local int32_t *) local_mem_30588)[(int64_t) 8] = prefix_30631;\n                    acc_30621 = 0;\n                }\n            }\n            if (!(dynamic_id_30598 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30631 = ((__local int32_t *) local_mem_30588)[(int64_t) 8];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int32_t eta_p_30651;\n            int32_t eta_p_30652;\n            int32_t eta_p_30654 = prefix_30631;\n            int32_t eta_p_30655 = acc_30621;\n            \n            if (slt32(local_tid_30581 * chunk_sizze_32b_30585, boundary_30601) && !block_new_sgm_30632) {\n                int32_t defunc_0_op_res_30656 = add32(eta_p_30654, eta_p_30655);\n                \n                eta_p_30651 = defunc_0_op_res_30656;\n            } else {\n                eta_p_30651 = acc_30621;\n            }\n            \n            int32_t stopping_point_30657 = segsizze_compact_30602 - srem32(local_tid_30581 * chunk_sizze_32b_30585 - 1 + segsizze_compact_30602 - boundary_30601, segsizze_compact_30602);\n            \n            for (int64_t ", "i_30658 = 0; i_30658 < chunk_sizze_30569; i_30658++) {\n                if (slt32(sext_i64_i32(i_30658), stopping_point_30657 - 1)) {\n                    eta_p_30652 = private_mem_30603[i_30658];\n                    \n                    int32_t defunc_0_op_res_30653 = add32(eta_p_30651, eta_p_30652);\n                    \n                    private_mem_30603[i_30658] = defunc_0_op_res_30653;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30659 = 0; i_30659 < chunk_sizze_30569; i_30659++) {\n                int64_t sharedIdx_30660 = sext_i32_i64(local_tid_30581) * chunk_sizze_30569 + i_30659;\n                int32_t tmp_30661 = private_mem_30603[i_30659];\n                \n                ((__local int32_t *) local_mem_30588)[sharedIdx_30660] = tmp_30661;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30662 = 0; i_30662 < chunk_sizze_30569; i_30662++) {\n                int64_t flat_idx_30663 = thd_offset_30605 + i_30662 * segscan_tblock_sizze_29382;\n                int64_t slice_30664 = mz2080U_25210;\n                int64_t gtid_29386 = flat_idx_30663;\n                int64_t remnant_30665 = flat_idx_30663 - gtid_29386;\n                \n                if (slt64(flat_idx_30663, mz2080U_25210)) {\n                    int32_t tmp_30666 = ((__local int32_t *) local_mem_30588)[flat_idx_30663 - block_offset_30599];\n                    \n                    ((__global int32_t *) mem_29737)[gtid_29386] = tmp_30666;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_29382\n    #undef chunk_sizze_30569\n}\nFUTHARK_KERNEL_SIZED(human_generici32zisegscan_29664_dim1, 1, 1)\nvoid human_generici32zisegscan_29664(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t mz2080U_25210, int64_t loop_d", "z2081Uz2088Uz2087U_27125, int64_t num_tblocks_29661, int64_t num_virt_blocks_30879, int64_t num_virt_threads_30880, __global unsigned char *mem_param_29728, __global unsigned char *mem_param_29731, __global unsigned char *mem_29740, __global unsigned char *mem_29754, __global unsigned char *mem_29757, __global unsigned char *mem_29759, __global unsigned char *status_flags_mem_30881, __global unsigned char *aggregates_mem_30883, __global unsigned char *incprefixes_mem_30885, __global unsigned char *global_dynid_mem_30887)\n{\n    #define segscan_tblock_sizze_29659 (human_generici32zisegscan_29664zisegscan_tblock_sizze_29659)\n    #define chunk_sizze_30878 (human_generici32zisegscan_29664zichunk_sizze_30878)\n    \n    volatile __local unsigned char *local_mem_30897_backing_0 = &shared_mem[0];\n    const int64_t local_mem_30897_backing_0_offset = 0 + (smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29659), chunk_sizze_30878 * segscan_tblock_sizze_29659 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29659), chunk_sizze_30878 * segscan_tblock_sizze_29659 * (int64_t) 8), (int64_t) 8), (int64_t) 8));\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_30890;\n    int32_t tblock_sizze_30893;\n    int32_t wave_sizze_30892;\n    int32_t block_id_30891;\n    int32_t global_tid_30889;\n    int64_t phys_tid_29664;\n    int32_t chunk_sizze_32b_30894;\n    int64_t byte_offsets_30895;\n    int64_t warp_byte_offset_30896;\n    __local unsigned char *local_mem_30897;\n    int64_t trans_arr_len_30898;\n    int64_t phys_block_id_30904;\n    int64_t virtloop_bound_30905;\n    \n    local_tid_30890 = get_local_id(0);\n    tblock_sizze_30893 = get_local_size(0);\n    wave_sizze_30892 = LOCKSTEP_WIDTH;\n    block_id_30891 = get_tbl",
                                    "ock_id(0);\n    global_tid_30889 = block_id_30891 * tblock_sizze_30893 + local_tid_30890;\n    phys_tid_29664 = sext_i32_i64(global_tid_30889);\n    chunk_sizze_32b_30894 = sext_i64_i32(chunk_sizze_30878);\n    byte_offsets_30895 = segscan_tblock_sizze_29659 * (int64_t) 8;\n    warp_byte_offset_30896 = (int64_t) 288;\n    // Allocate reusable shared memory\n    { }\n    local_mem_30897 = (__local unsigned char *) local_mem_30897_backing_0;\n    trans_arr_len_30898 = chunk_sizze_30878 * segscan_tblock_sizze_29659;\n    phys_block_id_30904 = get_tblock_id(0);\n    virtloop_bound_30905 = sdiv_up64(num_virt_blocks_30879 - phys_block_id_30904, num_tblocks_29661);\n    for (int64_t virtloop_i_30906 = 0; virtloop_i_30906 < virtloop_bound_30905; virtloop_i_30906++) {\n        int64_t dynamic_id_30907;\n        int64_t block_offset_30908;\n        int64_t sgm_idx_30909;\n        int32_t boundary_30910;\n        int32_t segsizze_compact_30911;\n        int64_t private_mem_30912[chunk_sizze_30878];\n        int64_t thd_offset_30914;\n        int64_t acc_30930;\n        int64_t prefix_30940;\n        bool block_new_sgm_30941;\n        \n        // First thread in block fetches this block's dynamic_id\n        {\n            if (local_tid_30890 == 0) {\n                dynamic_id_30907 = atomic_add_i32_global(&((volatile __global int *) global_dynid_mem_30887)[(int64_t) 0], (int) 1);\n                // Set dynamic id for this block\n                {\n                    ((__local int64_t *) local_mem_30897)[(int64_t) 0] = dynamic_id_30907;\n                }\n                // First thread in last (virtual) block resets global dynamic_id\n                {\n                    if (dynamic_id_30907 == num_virt_blocks_30879 - (int64_t) 1) {\n                        ((__global int32_t *) global_dynid_mem_30887)[(int64_t) 0] = 0;\n                    }\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        dynamic_id_30907 = ((__local int32_t *) local_mem_30897)[(int64_t) 0];\n      ", "  barrier(CLK_LOCAL_MEM_FENCE);\n        block_offset_30908 = dynamic_id_30907 * chunk_sizze_30878 * segscan_tblock_sizze_29659;\n        sgm_idx_30909 = smod64(block_offset_30908, loop_dz2081Uz2088Uz2087U_27125);\n        boundary_30910 = sext_i64_i32(smin64(chunk_sizze_30878 * segscan_tblock_sizze_29659, loop_dz2081Uz2088Uz2087U_27125 - sgm_idx_30909));\n        segsizze_compact_30911 = sext_i64_i32(smin64(chunk_sizze_30878 * segscan_tblock_sizze_29659, loop_dz2081Uz2088Uz2087U_27125));\n        thd_offset_30914 = block_offset_30908 + sext_i32_i64(local_tid_30890);\n        // Load and map\n        {\n            for (int64_t i_30915 = 0; i_30915 < chunk_sizze_30878; i_30915++) {\n                int64_t virt_tid_30916 = thd_offset_30914 + i_30915 * segscan_tblock_sizze_29659;\n                int64_t slice_30917 = loop_dz2081Uz2088Uz2087U_27125;\n                int64_t gtid_29663 = virt_tid_30916;\n                int64_t remnant_30918 = virt_tid_30916 - gtid_29663;\n                \n                if (slt64(virt_tid_30916, loop_dz2081Uz2088Uz2087U_27125)) {\n                    int32_t eta_p_27750 = ((__global int32_t *) mem_param_29728)[gtid_29663];\n                    int64_t ii_27751 = sext_i32_i64(eta_p_27750);\n                    bool x_27752 = sle64((int64_t) 0, ii_27751);\n                    bool y_27753 = slt64(ii_27751, mz2080U_25210);\n                    bool bounds_check_27754 = x_27752 && y_27753;\n                    bool index_certs_27755;\n                    \n                    if (!bounds_check_27754) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 35) == -1) {\n                                global_failure_args[0] = (int64_t) ii_27751;\n                                global_failure_args[1] = (int64_t) mz2080U_25210;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n        ", "            }\n                    \n                    int32_t zeze_lhs_27756 = ((__global int32_t *) mem_29754)[ii_27751];\n                    bool cond_27757 = zeze_lhs_27756 == -1;\n                    bool defunc_0_p_res_27758;\n                    \n                    if (cond_27757) {\n                        defunc_0_p_res_27758 = 0;\n                    } else {\n                        int32_t eta_p_27749 = ((__global int32_t *) mem_param_29731)[gtid_29663];\n                        bool cond_27759 = zeze_lhs_27756 == 0;\n                        bool defunc_0_p_res_f_res_27760;\n                        \n                        if (cond_27759) {\n                            int32_t lt_arg1_28187 = ((__global int32_t *) mem_29740)[ii_27751];\n                            bool defunc_0_lt_res_28188 = slt32(eta_p_27749, lt_arg1_28187);\n                            \n                            defunc_0_p_res_f_res_27760 = defunc_0_lt_res_28188;\n                        } else {\n                            bool cond_27763 = zeze_lhs_27756 == 1;\n                            bool defunc_0_p_res_f_res_f_res_27764;\n                            \n                            if (cond_27763) {\n                                defunc_0_p_res_f_res_f_res_27764 = 0;\n                            } else {\n                                int32_t lt_arg1_27765 = ((__global int32_t *) mem_29740)[ii_27751];\n                                bool defunc_0_lt_res_27766 = slt32(eta_p_27749, lt_arg1_27765);\n                                bool cond_27767 = !defunc_0_lt_res_27766;\n                                bool defunc_0_eq_res_27768 = eta_p_27749 == lt_arg1_27765;\n                                bool defunc_0_p_res_f_res_f_res_f_res_t_res_27769 = !defunc_0_eq_res_27768;\n                                bool x_27770 = cond_27767 && defunc_0_p_res_f_res_f_res_f_res_t_res_27769;\n                                \n                                defunc_0_p_res_f_res_f_res_27764 = x_27770;\n               ",
                                    "             }\n                            defunc_0_p_res_f_res_27760 = defunc_0_p_res_f_res_f_res_27764;\n                        }\n                        defunc_0_p_res_27758 = defunc_0_p_res_f_res_27760;\n                    }\n                    \n                    int64_t defunc_0_f_res_27771 = btoi_bool_i64(defunc_0_p_res_27758);\n                    \n                    ((__global int64_t *) mem_29759)[gtid_29663] = defunc_0_f_res_27771;\n                    private_mem_30912[i_30915] = defunc_0_f_res_27771;\n                } else {\n                    private_mem_30912[i_30915] = (int64_t) 0;\n                }\n            }\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // Transpose scan inputs\n        {\n            for (int64_t i_30919 = 0; i_30919 < chunk_sizze_30878; i_30919++) {\n                int64_t sharedIdx_30920 = sext_i32_i64(local_tid_30890) + i_30919 * segscan_tblock_sizze_29659;\n                int64_t tmp_30921 = private_mem_30912[i_30919];\n                \n                ((__local int64_t *) local_mem_30897)[sharedIdx_30920] = tmp_30921;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30922 = 0; i_30922 < chunk_sizze_30878; i_30922++) {\n                int64_t sharedIdx_30923 = sext_i32_i64(local_tid_30890) * chunk_sizze_30878 + i_30922;\n                int64_t tmp_30924 = ((__local int64_t *) local_mem_30897)[sharedIdx_30923];\n                \n                private_mem_30912[i_30922] = tmp_30924;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Per thread scan\n        {\n            for (int64_t i_30925 = 0; i_30925 < chunk_sizze_30878 - (int64_t) 1; i_30925++) {\n                int64_t eta_p_27331;\n                int64_t eta_p_27332;\n                \n                eta_p_27331 = private_mem_30912[i_30925];\n                eta_p_27332 = private_mem_30912[i_30925", " + (int64_t) 1];\n                \n                int64_t defunc_0_op_res_27333 = add64(eta_p_27331, eta_p_27332);\n                \n                private_mem_30912[i_30925 + (int64_t) 1] = defunc_0_op_res_27333;\n            }\n        }\n        // Publish results in shared memory\n        {\n            int64_t tmp_30926 = private_mem_30912[chunk_sizze_30878 - (int64_t) 1];\n            \n            ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = tmp_30926;\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        // Scan results (with warp scan)\n        {\n            int64_t eta_p_30927;\n            int64_t eta_p_30928;\n            int64_t eta_p_30931;\n            int64_t eta_p_30932;\n            bool ltid_in_bounds_30934 = slt64(sext_i32_i64(local_tid_30890), num_virt_threads_30880);\n            int32_t skip_threads_30935;\n            \n            // read input for in-block scan\n            {\n                if (ltid_in_bounds_30934) {\n                    eta_p_30928 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)];\n                    if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                        eta_p_30927 = eta_p_30928;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_30935 = 1;\n                while (slt32(skip_threads_30935, 32)) {\n                    bool thread_active_30936 = sle32(skip_threads_30935, local_tid_30890 - squot32(local_tid_30890, 32) * 32) && ltid_in_bounds_30934;\n                    \n                    if (thread_active_30936) {\n                        // read operands\n                        {\n                            eta_p_30927 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30935)];\n                        }\n                    }\n                    // perform operation\n                    ", "{\n                        if (thread_active_30936) {\n                            int64_t defunc_0_op_res_30929 = add64(eta_p_30927, eta_p_30928);\n                            \n                            eta_p_30927 = defunc_0_op_res_30929;\n                        }\n                    }\n                    if (sle32(wave_sizze_30892, skip_threads_30935)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_30936) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30927;\n                            eta_p_30928 = eta_p_30927;\n                        }\n                    }\n                    if (sle32(wave_sizze_30892, skip_threads_30935)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_30935 *= 2;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // last thread of block 'i' writes its result to offset 'i'\n            {\n                if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 31 && ltid_in_bounds_30934) {\n                    ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(squot32(local_tid_30890, 32))] = eta_p_30927;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n            {\n                int32_t skip_threads_30937;\n                \n                // read input for in-block scan\n                {\n                    if (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934) {\n                        eta_p_30932 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)];\n                        if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                            eta_p_30931 = ",
                                    "eta_p_30932;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_30937 = 1;\n                    while (slt32(skip_threads_30937, 32)) {\n                        bool thread_active_30938 = sle32(skip_threads_30937, local_tid_30890 - squot32(local_tid_30890, 32) * 32) && (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934);\n                        \n                        if (thread_active_30938) {\n                            // read operands\n                            {\n                                eta_p_30931 = ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30937)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            if (thread_active_30938) {\n                                int64_t defunc_0_op_res_30933 = add64(eta_p_30931, eta_p_30932);\n                                \n                                eta_p_30931 = defunc_0_op_res_30933;\n                            }\n                        }\n                        if (sle32(wave_sizze_30892, skip_threads_30937)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_30938) {\n                            // write result\n                            {\n                                ((volatile __local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30931;\n                                eta_p_30932 = eta_p_30931;\n                            }\n                        }\n                        if (sle32(wave_sizze_30892, skip_threads_30937)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_30937 *= 2;\n                    }\n                }\n            }\n       ", "     barrier(CLK_LOCAL_MEM_FENCE);\n            \n            bool no_carry_in_30939 = squot32(local_tid_30890, 32) == 0 || !ltid_in_bounds_30934;\n            \n            // carry-in for every block except the first\n            {\n                // read operands\n                {\n                    if (!no_carry_in_30939) {\n                        eta_p_30928 = eta_p_30927;\n                        eta_p_30927 = ((__local int64_t *) local_mem_30897)[sext_i32_i64(squot32(local_tid_30890, 32)) - (int64_t) 1];\n                    }\n                }\n                // perform operation\n                {\n                    if (!no_carry_in_30939) {\n                        int64_t defunc_0_op_res_30929 = add64(eta_p_30927, eta_p_30928);\n                        \n                        eta_p_30927 = defunc_0_op_res_30929;\n                    }\n                }\n                // write final result\n                {\n                    if (!no_carry_in_30939) {\n                        ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30927;\n                    }\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // restore correct values for first block\n            {\n                if (squot32(local_tid_30890, 32) == 0 && ltid_in_bounds_30934) {\n                    ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = eta_p_30928;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if (local_tid_30890 == 0) {\n                acc_30930 = ((__local int64_t *) local_mem_30897)[segscan_tblock_sizze_29659 - (int64_t) 1];\n            } else {\n                acc_30930 = ((__local int64_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - (int64_t) 1];\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n        prefix_30940 = (int64_t) 0;\n        block_new_sgm_30941 = sgm_idx_30909 == (int64_t) 0;\n        // Pe", "rform lookback\n        {\n            if (block_new_sgm_30941 && local_tid_30890 == 0) {\n                ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_30907] = acc_30930;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 2;\n                acc_30930 = (int64_t) 0;\n            }\n            if (!block_new_sgm_30941 && slt32(local_tid_30890, wave_sizze_30892)) {\n                if (local_tid_30890 == 0) {\n                    ((volatile __global int64_t *) aggregates_mem_30883)[dynamic_id_30907] = acc_30930;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 1;\n                    \n                    int8_t tmp_30942 = ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907 - (int64_t) 1];\n                    \n                    ((volatile __local int8_t *) local_mem_30897)[(int64_t) 0] = tmp_30942;\n                }\n                mem_fence_local();\n                \n                int8_t status_30943 = ((__local int8_t *) local_mem_30897)[(int64_t) 0];\n                \n                if (status_30943 == (int8_t) 2) {\n                    if (local_tid_30890 == 0) {\n                        prefix_30940 = ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_30907 - (int64_t) 1];\n                    }\n                } else {\n                    int32_t readOffset_30944 = sext_i64_i32(dynamic_id_30907 - sext_i32_i64(wave_sizze_30892));\n                    \n                    while (slt32(wave_sizze_30892 * -1, readOffset_30944)) {\n                        int32_t read_i_30945 = readOffset_30944 + local_tid_30890;\n                        int64_t aggr_30946 = (int64_t) 0;\n                        int8_t flag_30947 = (int8_t) 0;\n                        \n                        if (sle32(0, read_i_30945)) {\n                            flag_30947 = ((vola",
                                    "tile __global int8_t *) status_flags_mem_30881)[sext_i32_i64(read_i_30945)];\n                            if (flag_30947 == (int8_t) 2) {\n                                aggr_30946 = ((volatile __global int64_t *) incprefixes_mem_30885)[sext_i32_i64(read_i_30945)];\n                            } else if (flag_30947 == (int8_t) 1) {\n                                aggr_30946 = ((volatile __global int64_t *) aggregates_mem_30883)[sext_i32_i64(read_i_30945)];\n                            }\n                        }\n                        ((__local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)] = aggr_30946;\n                        ((__local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = flag_30947;\n                        flag_30947 = ((__local int8_t *) local_mem_30897)[sext_i32_i64(wave_sizze_30892) - (int64_t) 1];\n                        if (slt8(flag_30947, (int8_t) 2)) {\n                            int8_t flg_x_30951;\n                            int8_t flg_y_30952;\n                            int64_t eta_p_30948;\n                            int64_t eta_p_30949;\n                            int32_t skip_threads_30953;\n                            \n                            // read input for in-block scan\n                            {\n                                flg_y_30952 = ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)];\n                                eta_p_30949 = ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)];\n                                if ((local_tid_30890 - squot32(local_tid_30890, 32) * 32) == 0) {\n                                    eta_p_30948 = eta_p_30949;\n                                    flg_x_30951 = flg_y_30952;\n                                }\n                            }\n                            // in-block scan (hopefully no barriers needed)\n                            {\n                                skip_threads_30953 ", "= 1;\n                                while (slt32(skip_threads_30953, 32)) {\n                                    if (sle32(skip_threads_30953, local_tid_30890 - squot32(local_tid_30890, 32) * 32)) {\n                                        // read operands\n                                        {\n                                            flg_x_30951 = ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30953)];\n                                            eta_p_30948 = ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + (sext_i32_i64(local_tid_30890) - sext_i32_i64(skip_threads_30953))];\n                                        }\n                                        // perform operation\n                                        {\n                                            if (flg_y_30952 == (int8_t) 2 || flg_y_30952 == (int8_t) 0) {\n                                                flg_x_30951 = flg_y_30952;\n                                                eta_p_30948 = eta_p_30949;\n                                            } else {\n                                                int64_t defunc_0_op_res_30950 = add64(eta_p_30948, eta_p_30949);\n                                                \n                                                eta_p_30948 = defunc_0_op_res_30950;\n                                            }\n                                        }\n                                        // write result\n                                        {\n                                            ((volatile __local int8_t *) local_mem_30897)[sext_i32_i64(local_tid_30890)] = flg_x_30951;\n                                            flg_y_30952 = flg_x_30951;\n                                            ((volatile __local int64_t *) local_mem_30897)[(int64_t) 4 + sext_i32_i64(local_tid_30890)] = eta_p_30948;\n                                            eta_p_30949 = eta_p_30948;\n                           ", "             }\n                                    }\n                                    skip_threads_30953 *= 2;\n                                }\n                            }\n                        }\n                        flag_30947 = ((__local int8_t *) local_mem_30897)[sext_i32_i64(wave_sizze_30892) - (int64_t) 1];\n                        aggr_30946 = ((__local int64_t *) local_mem_30897)[(int64_t) 4 + (sext_i32_i64(wave_sizze_30892) - (int64_t) 1)];\n                        if (flag_30947 == (int8_t) 2) {\n                            readOffset_30944 = wave_sizze_30892 * -1;\n                        } else if (flag_30947 == (int8_t) 1) {\n                            readOffset_30944 -= wave_sizze_30892;\n                        }\n                        if (slt8((int8_t) 0, flag_30947)) {\n                            int64_t eta_p_30954 = aggr_30946;\n                            int64_t eta_p_30955 = prefix_30940;\n                            int64_t defunc_0_op_res_30956 = add64(eta_p_30954, eta_p_30955);\n                            \n                            prefix_30940 = defunc_0_op_res_30956;\n                        }\n                        mem_fence_local();\n                    }\n                }\n                if (local_tid_30890 == 0) {\n                    if (boundary_30910 == sext_i64_i32(segscan_tblock_sizze_29659 * chunk_sizze_30878)) {\n                        int64_t eta_p_30957 = prefix_30940;\n                        int64_t eta_p_30958 = acc_30930;\n                        int64_t defunc_0_op_res_30959 = add64(eta_p_30957, eta_p_30958);\n                        \n                        ((volatile __global int64_t *) incprefixes_mem_30885)[dynamic_id_30907] = defunc_0_op_res_30959;\n                        mem_fence_global();\n                        ((volatile __global int8_t *) status_flags_mem_30881)[dynamic_id_30907] = (int8_t) 2;\n                    }\n                    ((__local int64_t *) local_mem_30897)[(int64_t) 4] = prefix_30940;\n        ",
                                    "            acc_30930 = (int64_t) 0;\n                }\n            }\n            if (!(dynamic_id_30907 == (int64_t) 0)) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                prefix_30940 = ((__local int64_t *) local_mem_30897)[(int64_t) 4];\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        // Distribute results\n        {\n            int64_t eta_p_30960;\n            int64_t eta_p_30961;\n            int64_t eta_p_30963 = prefix_30940;\n            int64_t eta_p_30964 = acc_30930;\n            \n            if (slt32(local_tid_30890 * chunk_sizze_32b_30894, boundary_30910) && !block_new_sgm_30941) {\n                int64_t defunc_0_op_res_30965 = add64(eta_p_30963, eta_p_30964);\n                \n                eta_p_30960 = defunc_0_op_res_30965;\n            } else {\n                eta_p_30960 = acc_30930;\n            }\n            \n            int32_t stopping_point_30966 = segsizze_compact_30911 - srem32(local_tid_30890 * chunk_sizze_32b_30894 - 1 + segsizze_compact_30911 - boundary_30910, segsizze_compact_30911);\n            \n            for (int64_t i_30967 = 0; i_30967 < chunk_sizze_30878; i_30967++) {\n                if (slt32(sext_i64_i32(i_30967), stopping_point_30966 - 1)) {\n                    eta_p_30961 = private_mem_30912[i_30967];\n                    \n                    int64_t defunc_0_op_res_30962 = add64(eta_p_30960, eta_p_30961);\n                    \n                    private_mem_30912[i_30967] = defunc_0_op_res_30962;\n                }\n            }\n        }\n        // Transpose scan output and Write it to global memory in coalesced fashion\n        {\n            for (int64_t i_30968 = 0; i_30968 < chunk_sizze_30878; i_30968++) {\n                int64_t sharedIdx_30969 = sext_i32_i64(local_tid_30890) * chunk_sizze_30878 + i_30968;\n                int64_t tmp_30970 = private_mem_30912[i_30968];\n                \n                ((__local int64_t *) local_mem_30897)[sharedIdx_30969] = tmp_30970;\n            }\n   ", "         barrier(CLK_LOCAL_MEM_FENCE);\n            for (int64_t i_30971 = 0; i_30971 < chunk_sizze_30878; i_30971++) {\n                int64_t flat_idx_30972 = thd_offset_30914 + i_30971 * segscan_tblock_sizze_29659;\n                int64_t slice_30973 = loop_dz2081Uz2088Uz2087U_27125;\n                int64_t gtid_29663 = flat_idx_30972;\n                int64_t remnant_30974 = flat_idx_30972 - gtid_29663;\n                \n                if (slt64(flat_idx_30972, loop_dz2081Uz2088Uz2087U_27125)) {\n                    int64_t tmp_30975 = ((__local int64_t *) local_mem_30897)[flat_idx_30972 - block_offset_30908];\n                    \n                    ((__global int64_t *) mem_29757)[gtid_29663] = tmp_30975;\n                }\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_tblock_sizze_29659\n    #undef chunk_sizze_30878\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

// Config stuff included in every GPU backend.
struct gpu_config {
  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_cache;
  size_t default_shared_memory;
  size_t default_registers;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

// The following are dummy sizes that mean the concrete defaults
// will be set during initialisation via hardware-inspection-based
// heuristics.
struct gpu_config gpu_config_initial = {
  0
};

// Must be defined by the user.
static int gpu_macros(struct futhark_context *ctx, char*** names, int64_t** values);

static void gpu_init_log(struct futhark_context *ctx);
struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
      } else {                                  \
        free(serror);                           \
      }                                         \
      return bad;                               \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  char* cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  char* *nvrtc_opts;

  char* preferred_device;
  int preferred_device_num;

  int unified_memory;

  char* dump_ptx_to;
  char* load_ptx_from;

  struct gpu_config gpu;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (char**) malloc(sizeof(char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = strdup("");

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->unified_memory = 2;

  cfg->gpu = gpu_config_initial;
  cfg->gpu.default_block_size = 256;
  cfg->gpu.default_tile_size = 32;
  cfg->gpu.default_reg_tile_size = 2;
  cfg->gpu.default_threshold = 32*1024;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  for (int i = 0; i < cfg->num_nvrtc_opts; i++) {
    free(cfg->nvrtc_opts[i]);
  }
  free(cfg->nvrtc_opts);
  free(cfg->dump_ptx_to);
  free(cfg->load_ptx_from);
  free(cfg->preferred_device);
  free(cfg->program);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = strdup(opt);
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  free(cfg->preferred_device);
  cfg->preferred_device = strdup(s);
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  free(cfg->program);
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  free(cfg->dump_ptx_to);
  cfg->dump_ptx_to = strdup(path);
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  free(cfg->load_ptx_from);
  cfg->load_ptx_from = strdup(path);
}

void futhark_context_config_set_unified_memory(struct futhark_context_config* cfg, int flag) {
  cfg->unified_memory = flag;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  struct event_list event_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  struct program* program;
  bool program_initialised;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_thread_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;
  size_t max_registers;
  size_t max_cache;

  size_t lockstep_width;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  char** macro_names;
  int64_t* macro_vals;
  int num_macros = gpu_macros(ctx, &macro_names, &macro_vals);

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_macros + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_thread_block_size",
                        (int)ctx->max_thread_block_size);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_shared_memory",
                        (int)ctx->max_shared_memory);
  opts[i++] = msgprintf("-D%s=%d",
                        "max_registers",
                        (int)ctx->max_registers);

  for (int j = 0; j < num_macros; j++) {
    opts[i++] = msgprintf("-D%s=%zu", macro_names[j], macro_vals[j]);
  }

  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_thread_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  free(macro_names);
  free(macro_vals);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->gpu.default_block_size > ctx->max_thread_block_size) {
    if (cfg->gpu.default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_thread_block_size, cfg->gpu.default_block_size);
    }
    cfg->gpu.default_block_size = ctx->max_thread_block_size;
  }
  if (cfg->gpu.default_grid_size > ctx->max_grid_size) {
    if (cfg->gpu.default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->gpu.default_grid_size);
    }
    cfg->gpu.default_grid_size = ctx->max_grid_size;
  }
  if (cfg->gpu.default_tile_size > ctx->max_tile_size) {
    if (cfg->gpu.default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->gpu.default_tile_size);
    }
    cfg->gpu.default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->gpu.default_grid_size_changed) {
    cfg->gpu.default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->gpu.default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "thread_block_size") == size_class) {
      max_value = ctx->max_thread_block_size;
      default_value = cfg->gpu.default_block_size;
    } else if (strstr(size_class, "grid_size") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->gpu.default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->gpu.default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->gpu.default_reg_tile_size;
    } else if (strstr(size_class, "shared_memory") == size_class) {
      max_value = ctx->max_shared_memory;
      default_value = ctx->max_shared_memory;
    } else if (strstr(size_class, "cache") == size_class) {
      max_value = ctx->max_cache;
      default_value = ctx->max_cache;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->gpu.default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

struct cuda_event {
  cudaEvent_t start;
  cudaEvent_t end;
};

static struct cuda_event* cuda_event_new(struct futhark_context* ctx) {
  if (ctx->profiling && !ctx->profiling_paused) {
    struct cuda_event* e = malloc(sizeof(struct cuda_event));
    cudaEventCreate(&e->start);
    cudaEventCreate(&e->end);
    return e;
  } else {
    return NULL;
  }
}

static int cuda_event_report(struct str_builder* sb, struct cuda_event* e) {
  float ms;
  CUresult err;
  if ((err = cuEventElapsedTime(&ms, e->start, e->end)) != CUDA_SUCCESS) {
    return err;
  }

  // CUDA provides milisecond resolution, but we want microseconds.
  str_builder(sb, ",\"duration\":%f", ms*1000);

  if ((err = cuEventDestroy(e->start)) != CUDA_SUCCESS) {
    return 1;
  }

  if ((err = cuEventDestroy(e->end)) != CUDA_SUCCESS) {
    return 1;
  }

  free(e);

  return 0;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;
  ctx->kernels = NULL;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  if (ctx->cfg->unified_memory == 2) {
    ctx->cfg->unified_memory = device_query(ctx->dev, MANAGED_MEMORY);
  }

  if (ctx->cfg->logging) {
    if (ctx->cfg->unified_memory) {
      fprintf(ctx->log, "Using managed memory\n");
    } else {
      fprintf(ctx->log, "Using unmanaged memory\n");
    }
  }

  ctx->max_thread_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_thread_block_size);
  ctx->max_threshold = 1U<<31; // No limit.
  ctx->max_bespoke = 1U<<31; // No limit.

  if (ctx->cfg->gpu.default_registers != 0) {
    ctx->max_registers = ctx->cfg->gpu.default_registers;
  } else {
    ctx->max_registers = device_query(ctx->dev, MAX_REGISTERS_PER_BLOCK);
  }

  if (ctx->cfg->gpu.default_shared_memory != 0) {
    ctx->max_shared_memory = ctx->cfg->gpu.default_shared_memory;
  } else {
    // MAX_SHARED_MEMORY_PER_BLOCK gives bogus numbers (48KiB); probably
    // for backwards compatibility.  Add _OPTIN and you seem to get the
    // right number.
    ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK_OPTIN);
#if CUDART_VERSION >= 12000
    ctx->max_shared_memory -= device_query(ctx->dev, RESERVED_SHARED_MEMORY_PER_BLOCK);
#endif
  }

  if (ctx->cfg->gpu.default_cache != 0) {
    ctx->max_cache = ctx->cfg->gpu.default_cache;
  } else {
    ctx->max_cache = device_query(ctx->dev, L2_CACHE_SIZE);
  }

  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);

  gpu_init_log(ctx);

  ctx->error = cuda_module_setup(ctx,
                                 ctx->cfg->program,
                                 (const char**)ctx->cfg->nvrtc_opts,
                                 ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  if (ctx->kernels != NULL) {
    free_builtin_kernels(ctx, ctx->kernels);
    cuMemFree(ctx->global_failure);
    cuMemFree(ctx->global_failure_args);
    CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
    CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
    CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
  }
  free_list_destroy(&ctx->gpu_free_list);
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
  // Unless the below is set, the kernel is limited to 48KiB of memory.
  CUDA_SUCCEED_FATAL(cuFuncSetAttribute(*kernel,
                                        cudaFuncAttributeMaxDynamicSharedMemorySize,
                                        ctx->max_shared_memory));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_scalar_from_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  struct cuda_event *event = cuda_event_new(ctx);
  if (event != NULL) {
    add_event(ctx,
              "copy_dev_to_dev",
              strdup(""),
              event,
              (event_report_fn)cuda_event_report);
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyAsync(dst+dst_offset, src+src_offset, nbytes, ctx->stream));
  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_host_to_dev",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    struct cuda_event *event = cuda_event_new(ctx);
    if (event != NULL) {
      add_event(ctx,
                "copy_dev_to_host",
                strdup(""),
                event,
                (event_report_fn)cuda_event_report);
      CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (event != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int shared_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;

  if (shared_mem_bytes > ctx->max_shared_memory) {
    set_error(ctx, msgprintf("Kernel %s with %d bytes of memory exceeds device limit of %d\n",
                             name, shared_mem_bytes, (int)ctx->max_shared_memory));
    return 1;
  }

  int64_t time_start = 0, time_end = 0;
  if (ctx->debugging) {
    time_start = get_wall_time();
  }

  struct cuda_event *event = cuda_event_new(ctx);

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->start, ctx->stream));
    add_event(ctx,
              name,
              msgprintf("Kernel %s with\n"
                        "  grid=(%d,%d,%d)\n"
                        "  block=(%d,%d,%d)\n"
                        "  shared memory=%d",
                        name,
                        grid[0], grid[1], grid[2],
                        block[0], block[1], block[2],
                        shared_mem_bytes),
              event,
              (event_report_fn)cuda_event_report);
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    shared_mem_bytes, ctx->stream,
                    args, NULL));

  if (event != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(event->end, ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n", time_diff);
  }
  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res;
  if (ctx->cfg->unified_memory) {
    res = cuMemAllocManaged(mem_out, size, CU_MEM_ATTACH_GLOBAL);
  } else {
    res = cuMemAlloc(mem_out, size);
  }

  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }

  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int shared_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

static void gpu_init_log(struct futhark_context *ctx) {
  if (ctx->cfg->logging) {
    fprintf(ctx->log, "Default block size: %ld\n", (long)ctx->cfg->gpu.default_block_size);
    fprintf(ctx->log, "Default grid size: %ld\n", (long)ctx->cfg->gpu.default_grid_size);
    fprintf(ctx->log, "Default tile size: %ld\n", (long)ctx->cfg->gpu.default_tile_size);
    fprintf(ctx->log, "Default register tile size: %ld\n", (long)ctx->cfg->gpu.default_reg_tile_size);
    fprintf(ctx->log, "Default cache: %ld\n", (long)ctx->cfg->gpu.default_cache);
    fprintf(ctx->log, "Default registers: %ld\n", (long)ctx->cfg->gpu.default_registers);
    fprintf(ctx->log, "Default threshold: %ld\n", (long)ctx->cfg->gpu.default_threshold);
    fprintf(ctx->log, "Max thread block size: %ld\n", (long)ctx->max_thread_block_size);
    fprintf(ctx->log, "Max grid size: %ld\n", (long)ctx->max_grid_size);
    fprintf(ctx->log, "Max tile size: %ld\n", (long)ctx->max_tile_size);
    fprintf(ctx->log, "Max threshold: %ld\n", (long)ctx->max_threshold);
    fprintf(ctx->log, "Max shared memory: %ld\n", (long)ctx->max_shared_memory);
    fprintf(ctx->log, "Max registers: %ld\n", (long)ctx->max_registers);
    fprintf(ctx->log, "Max cache: %ld\n", (long)ctx->max_cache);
    fprintf(ctx->log, "Lockstep width: %ld\n", (long)ctx->lockstep_width);
  }
}

// Generic GPU command line options.

void futhark_context_config_set_default_thread_block_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_block_size = size;
  cfg->gpu.default_block_size_changed = 1;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  futhark_context_config_set_default_thread_block_size(cfg, size);
}

void futhark_context_config_set_default_grid_size(struct futhark_context_config *cfg, int num) {
  cfg->gpu.default_grid_size = num;
  cfg->gpu.default_grid_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  futhark_context_config_set_default_grid_size(cfg, num);
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_tile_size = size;
  cfg->gpu.default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_reg_tile_size = size;
}

void futhark_context_config_set_default_cache(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_cache = size;
}

void futhark_context_config_set_default_registers(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_registers = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->gpu.default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_thread_block_size") == 0 ||
      strcmp(param_name, "default_group_size") == 0) {
    cfg->gpu.default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_grid_size") == 0 ||
      strcmp(param_name, "default_num_groups") == 0) {
    cfg->gpu.default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->gpu.default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->gpu.default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->gpu.default_reg_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_cache") == 0) {
    cfg->gpu.default_cache = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_shared_memory") == 0) {
    cfg->gpu.default_shared_memory = new_value;
    return 0;
  }

  return 1;
}

// End of GPU command line optiopns.

// Max number of thead blocks we allow along the second or third
// dimension for transpositions.
#define MAX_TR_THREAD_BLOCKS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of thead blocks we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_THREAD_BLOCKS;
  int32_t repeat_2 = grid[2] / MAX_TR_THREAD_BLOCKS;
  grid[1] = repeat_1 > 0 ? MAX_TR_THREAD_BLOCKS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_THREAD_BLOCKS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded thread block size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static int gpu_macros(struct futhark_context *ctx, char ***names_out, int64_t **values_out)
{
    int num_macros = 150;
    char **names = malloc(num_macros * sizeof(char *));
    int64_t *values = malloc(num_macros * sizeof(int64_t));
    
    {
        names[0] = "human_generici32zisegmap_29666_dim1";
        values[0] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29668;
    }
    {
        names[1] = "human_generici32zisegmap_29666zisegmap_tblock_sizze_29669";
        values[1] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29668;
    }
    {
        names[2] = "human_generici32zisegscan_29664_dim1";
        values[2] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29658;
    }
    {
        names[3] = "human_generici32zisegscan_29664zisegscan_tblock_sizze_29659";
        values[3] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29658;
    }
    {
        names[4] = "human_generici32zisegscan_29664zichunk_sizze_30878";
        values[4] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[5] = "human_generici32zisegmap_29628_dim1";
        values[5] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29587;
    }
    {
        names[6] = "human_generici32zisegmap_29628zisegmap_tblock_sizze_29621";
        values[6] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29587;
    }
    {
        names[7] = "human_generici32zisegred_large_30775_dim1";
        values[7] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557;
    }
    {
        names[8] = "human_generici32zisegred_large_30775ziseghist_tblock_sizze_29558";
        values[8] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557;
    }
    {
        names[9] = "human_generici32zisegred_large_30775zichunk_sizze_30776";
        values[9] = (int64_t) 1;
    }
    {
        names[10] = "human_generici32zisegred_small_30775_dim1";
        values[10] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557;
    }
    {
        names[11] = "human_generici32zisegred_small_30775ziseghist_tblock_sizze_29558";
        values[11] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557;
    }
    {
        names[12] = "human_generici32ziseghist_global_29565_dim1";
        values[12] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557;
    }
    {
        names[13] = "human_generici32ziseghist_global_29565ziseghist_tblock_sizze_29558";
        values[13] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557;
    }
    {
        names[14] = "human_generici32ziseghist_local_29565_dim1";
        values[14] = ctx->max_thread_block_size;
    }
    {
        names[15] = "human_generici32ziseghist_local_29565zimax_tblock_sizze_30689";
        values[15] = ctx->max_thread_block_size;
    }
    {
        names[16] = "human_generici32zisegmap_29478_dim1";
        values[16] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29391;
    }
    {
        names[17] = "human_generici32zisegmap_29478zisegmap_tblock_sizze_29474";
        values[17] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29391;
    }
    {
        names[18] = "human_generici32zisegscan_29387_dim1";
        values[18] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29381;
    }
    {
        names[19] = "human_generici32zisegscan_29387zisegscan_tblock_sizze_29382";
        values[19] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29381;
    }
    {
        names[20] = "human_generici32zisegscan_29387zichunk_sizze_30569";
        values[20] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[21] = "human_generici32zisegmap_29373_dim1";
        values[21] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29375;
    }
    {
        names[22] = "human_generici32zisegmap_29373zisegmap_tblock_sizze_29376";
        values[22] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29375;
    }
    {
        names[23] = "human_generici32zisegscan_29371_dim1";
        values[23] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29365;
    }
    {
        names[24] = "human_generici32zisegscan_29371zisegscan_tblock_sizze_29366";
        values[24] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29365;
    }
    {
        names[25] = "human_generici32zisegscan_29371zichunk_sizze_30440";
        values[25] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[26] = "human_generici32zisegmap_29336_dim1";
        values[26] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29296;
    }
    {
        names[27] = "human_generici32zisegmap_29336zisegmap_tblock_sizze_29329";
        values[27] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29296;
    }
    {
        names[28] = "human_generici32zisegred_large_30337_dim1";
        values[28] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266;
    }
    {
        names[29] = "human_generici32zisegred_large_30337ziseghist_tblock_sizze_29267";
        values[29] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266;
    }
    {
        names[30] = "human_generici32zisegred_large_30337zichunk_sizze_30338";
        values[30] = (int64_t) 1;
    }
    {
        names[31] = "human_generici32zisegred_small_30337_dim1";
        values[31] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266;
    }
    {
        names[32] = "human_generici32zisegred_small_30337ziseghist_tblock_sizze_29267";
        values[32] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266;
    }
    {
        names[33] = "human_generici32ziseghist_global_29274_dim1";
        values[33] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266;
    }
    {
        names[34] = "human_generici32ziseghist_global_29274ziseghist_tblock_sizze_29267";
        values[34] = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266;
    }
    {
        names[35] = "human_generici32ziseghist_local_29274_dim1";
        values[35] = ctx->max_thread_block_size;
    }
    {
        names[36] = "human_generici32ziseghist_local_29274zimax_tblock_sizze_30251";
        values[36] = ctx->max_thread_block_size;
    }
    {
        names[37] = "human_generici32zisegmap_29248_dim1";
        values[37] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29222;
    }
    {
        names[38] = "human_generici32zisegmap_29248zisegmap_tblock_sizze_29244";
        values[38] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29222;
    }
    {
        names[39] = "human_generici32zisegscan_29218_dim1";
        values[39] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29212;
    }
    {
        names[40] = "human_generici32zisegscan_29218zisegscan_tblock_sizze_29213";
        values[40] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29212;
    }
    {
        names[41] = "human_generici32zisegscan_29218zichunk_sizze_30131";
        values[41] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[42] = "human_generici32zisegscan_29210_dim1";
        values[42] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29204;
    }
    {
        names[43] = "human_generici32zisegscan_29210zisegscan_tblock_sizze_29205";
        values[43] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29204;
    }
    {
        names[44] = "human_generici32zisegscan_29210zichunk_sizze_29971";
        values[44] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[45] = "human_generici32zisegmap_29196_dim1";
        values[45] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29198;
    }
    {
        names[46] = "human_generici32zisegmap_29196zisegmap_tblock_sizze_29199";
        values[46] = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29198;
    }
    {
        names[47] = "human_generici32zisegscan_29194_dim1";
        values[47] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29188;
    }
    {
        names[48] = "human_generici32zisegscan_29194zisegscan_tblock_sizze_29189";
        values[48] = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29188;
    }
    {
        names[49] = "human_generici32zisegscan_29194zichunk_sizze_29794";
        values[49] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[50] = "human_genericf64zisegmap_29180_dim1";
        values[50] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29182;
    }
    {
        names[51] = "human_genericf64zisegmap_29180zisegmap_tblock_sizze_29183";
        values[51] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29182;
    }
    {
        names[52] = "human_genericf64zisegscan_29178_dim1";
        values[52] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_29172;
    }
    {
        names[53] = "human_genericf64zisegscan_29178zisegscan_tblock_sizze_29173";
        values[53] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_29172;
    }
    {
        names[54] = "human_genericf64zisegscan_29178zichunk_sizze_30878";
        values[54] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[55] = "human_genericf64zisegmap_29142_dim1";
        values[55] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29101;
    }
    {
        names[56] = "human_genericf64zisegmap_29142zisegmap_tblock_sizze_29135";
        values[56] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29101;
    }
    {
        names[57] = "human_genericf64zisegred_large_30775_dim1";
        values[57] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071;
    }
    {
        names[58] = "human_genericf64zisegred_large_30775ziseghist_tblock_sizze_29072";
        values[58] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071;
    }
    {
        names[59] = "human_genericf64zisegred_large_30775zichunk_sizze_30776";
        values[59] = (int64_t) 1;
    }
    {
        names[60] = "human_genericf64zisegred_small_30775_dim1";
        values[60] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071;
    }
    {
        names[61] = "human_genericf64zisegred_small_30775ziseghist_tblock_sizze_29072";
        values[61] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071;
    }
    {
        names[62] = "human_genericf64ziseghist_global_29079_dim1";
        values[62] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071;
    }
    {
        names[63] = "human_genericf64ziseghist_global_29079ziseghist_tblock_sizze_29072";
        values[63] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071;
    }
    {
        names[64] = "human_genericf64ziseghist_local_29079_dim1";
        values[64] = ctx->max_thread_block_size;
    }
    {
        names[65] = "human_genericf64ziseghist_local_29079zimax_tblock_sizze_30689";
        values[65] = ctx->max_thread_block_size;
    }
    {
        names[66] = "human_genericf64zisegmap_28992_dim1";
        values[66] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28905;
    }
    {
        names[67] = "human_genericf64zisegmap_28992zisegmap_tblock_sizze_28988";
        values[67] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28905;
    }
    {
        names[68] = "human_genericf64zisegscan_28901_dim1";
        values[68] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28895;
    }
    {
        names[69] = "human_genericf64zisegscan_28901zisegscan_tblock_sizze_28896";
        values[69] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28895;
    }
    {
        names[70] = "human_genericf64zisegscan_28901zichunk_sizze_30569";
        values[70] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[71] = "human_genericf64zisegmap_28887_dim1";
        values[71] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28889;
    }
    {
        names[72] = "human_genericf64zisegmap_28887zisegmap_tblock_sizze_28890";
        values[72] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28889;
    }
    {
        names[73] = "human_genericf64zisegscan_28885_dim1";
        values[73] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28879;
    }
    {
        names[74] = "human_genericf64zisegscan_28885zisegscan_tblock_sizze_28880";
        values[74] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28879;
    }
    {
        names[75] = "human_genericf64zisegscan_28885zichunk_sizze_30440";
        values[75] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[76] = "human_genericf64zisegmap_28850_dim1";
        values[76] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28810;
    }
    {
        names[77] = "human_genericf64zisegmap_28850zisegmap_tblock_sizze_28843";
        values[77] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28810;
    }
    {
        names[78] = "human_genericf64zisegred_large_30337_dim1";
        values[78] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780;
    }
    {
        names[79] = "human_genericf64zisegred_large_30337ziseghist_tblock_sizze_28781";
        values[79] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780;
    }
    {
        names[80] = "human_genericf64zisegred_large_30337zichunk_sizze_30338";
        values[80] = (int64_t) 1;
    }
    {
        names[81] = "human_genericf64zisegred_small_30337_dim1";
        values[81] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780;
    }
    {
        names[82] = "human_genericf64zisegred_small_30337ziseghist_tblock_sizze_28781";
        values[82] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780;
    }
    {
        names[83] = "human_genericf64ziseghist_global_28788_dim1";
        values[83] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780;
    }
    {
        names[84] = "human_genericf64ziseghist_global_28788ziseghist_tblock_sizze_28781";
        values[84] = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780;
    }
    {
        names[85] = "human_genericf64ziseghist_local_28788_dim1";
        values[85] = ctx->max_thread_block_size;
    }
    {
        names[86] = "human_genericf64ziseghist_local_28788zimax_tblock_sizze_30251";
        values[86] = ctx->max_thread_block_size;
    }
    {
        names[87] = "human_genericf64zisegmap_28762_dim1";
        values[87] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28736;
    }
    {
        names[88] = "human_genericf64zisegmap_28762zisegmap_tblock_sizze_28758";
        values[88] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28736;
    }
    {
        names[89] = "human_genericf64zisegscan_28732_dim1";
        values[89] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28726;
    }
    {
        names[90] = "human_genericf64zisegscan_28732zisegscan_tblock_sizze_28727";
        values[90] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28726;
    }
    {
        names[91] = "human_genericf64zisegscan_28732zichunk_sizze_30131";
        values[91] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[92] = "human_genericf64zisegscan_28724_dim1";
        values[92] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28718;
    }
    {
        names[93] = "human_genericf64zisegscan_28724zisegscan_tblock_sizze_28719";
        values[93] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28718;
    }
    {
        names[94] = "human_genericf64zisegscan_28724zichunk_sizze_29971";
        values[94] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[95] = "human_genericf64zisegmap_28710_dim1";
        values[95] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28712;
    }
    {
        names[96] = "human_genericf64zisegmap_28710zisegmap_tblock_sizze_28713";
        values[96] = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28712;
    }
    {
        names[97] = "human_genericf64zisegscan_28708_dim1";
        values[97] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28702;
    }
    {
        names[98] = "human_genericf64zisegscan_28708zisegscan_tblock_sizze_28703";
        values[98] = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28702;
    }
    {
        names[99] = "human_genericf64zisegscan_28708zichunk_sizze_29794";
        values[99] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[100] = "human_genericf32zisegmap_28694_dim1";
        values[100] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28696;
    }
    {
        names[101] = "human_genericf32zisegmap_28694zisegmap_tblock_sizze_28697";
        values[101] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28696;
    }
    {
        names[102] = "human_genericf32zisegscan_28692_dim1";
        values[102] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28686;
    }
    {
        names[103] = "human_genericf32zisegscan_28692zisegscan_tblock_sizze_28687";
        values[103] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28686;
    }
    {
        names[104] = "human_genericf32zisegscan_28692zichunk_sizze_30878";
        values[104] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[105] = "human_genericf32zisegmap_28656_dim1";
        values[105] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28615;
    }
    {
        names[106] = "human_genericf32zisegmap_28656zisegmap_tblock_sizze_28649";
        values[106] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28615;
    }
    {
        names[107] = "human_genericf32zisegred_large_30775_dim1";
        values[107] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585;
    }
    {
        names[108] = "human_genericf32zisegred_large_30775ziseghist_tblock_sizze_28586";
        values[108] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585;
    }
    {
        names[109] = "human_genericf32zisegred_large_30775zichunk_sizze_30776";
        values[109] = (int64_t) 1;
    }
    {
        names[110] = "human_genericf32zisegred_small_30775_dim1";
        values[110] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585;
    }
    {
        names[111] = "human_genericf32zisegred_small_30775ziseghist_tblock_sizze_28586";
        values[111] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585;
    }
    {
        names[112] = "human_genericf32ziseghist_global_28593_dim1";
        values[112] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585;
    }
    {
        names[113] = "human_genericf32ziseghist_global_28593ziseghist_tblock_sizze_28586";
        values[113] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585;
    }
    {
        names[114] = "human_genericf32ziseghist_local_28593_dim1";
        values[114] = ctx->max_thread_block_size;
    }
    {
        names[115] = "human_genericf32ziseghist_local_28593zimax_tblock_sizze_30689";
        values[115] = ctx->max_thread_block_size;
    }
    {
        names[116] = "human_genericf32zisegmap_28506_dim1";
        values[116] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28419;
    }
    {
        names[117] = "human_genericf32zisegmap_28506zisegmap_tblock_sizze_28502";
        values[117] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28419;
    }
    {
        names[118] = "human_genericf32zisegscan_28415_dim1";
        values[118] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28409;
    }
    {
        names[119] = "human_genericf32zisegscan_28415zisegscan_tblock_sizze_28410";
        values[119] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28409;
    }
    {
        names[120] = "human_genericf32zisegscan_28415zichunk_sizze_30569";
        values[120] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[121] = "human_genericf32zisegmap_28401_dim1";
        values[121] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28403;
    }
    {
        names[122] = "human_genericf32zisegmap_28401zisegmap_tblock_sizze_28404";
        values[122] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28403;
    }
    {
        names[123] = "human_genericf32zisegscan_28399_dim1";
        values[123] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28393;
    }
    {
        names[124] = "human_genericf32zisegscan_28399zisegscan_tblock_sizze_28394";
        values[124] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28393;
    }
    {
        names[125] = "human_genericf32zisegscan_28399zichunk_sizze_30440";
        values[125] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    {
        names[126] = "human_genericf32zisegmap_28364_dim1";
        values[126] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28324;
    }
    {
        names[127] = "human_genericf32zisegmap_28364zisegmap_tblock_sizze_28357";
        values[127] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28324;
    }
    {
        names[128] = "human_genericf32zisegred_large_30337_dim1";
        values[128] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294;
    }
    {
        names[129] = "human_genericf32zisegred_large_30337ziseghist_tblock_sizze_28295";
        values[129] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294;
    }
    {
        names[130] = "human_genericf32zisegred_large_30337zichunk_sizze_30338";
        values[130] = (int64_t) 1;
    }
    {
        names[131] = "human_genericf32zisegred_small_30337_dim1";
        values[131] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294;
    }
    {
        names[132] = "human_genericf32zisegred_small_30337ziseghist_tblock_sizze_28295";
        values[132] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294;
    }
    {
        names[133] = "human_genericf32ziseghist_global_28302_dim1";
        values[133] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294;
    }
    {
        names[134] = "human_genericf32ziseghist_global_28302ziseghist_tblock_sizze_28295";
        values[134] = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294;
    }
    {
        names[135] = "human_genericf32ziseghist_local_28302_dim1";
        values[135] = ctx->max_thread_block_size;
    }
    {
        names[136] = "human_genericf32ziseghist_local_28302zimax_tblock_sizze_30251";
        values[136] = ctx->max_thread_block_size;
    }
    {
        names[137] = "human_genericf32zisegmap_28278_dim1";
        values[137] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28254;
    }
    {
        names[138] = "human_genericf32zisegmap_28278zisegmap_tblock_sizze_28274";
        values[138] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28254;
    }
    {
        names[139] = "human_genericf32zisegscan_28250_dim1";
        values[139] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28244;
    }
    {
        names[140] = "human_genericf32zisegscan_28250zisegscan_tblock_sizze_28245";
        values[140] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28244;
    }
    {
        names[141] = "human_genericf32zisegscan_28250zichunk_sizze_30131";
        values[141] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[142] = "human_genericf32zisegscan_28242_dim1";
        values[142] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28236;
    }
    {
        names[143] = "human_genericf32zisegscan_28242zisegscan_tblock_sizze_28237";
        values[143] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28236;
    }
    {
        names[144] = "human_genericf32zisegscan_28242zichunk_sizze_29971";
        values[144] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 4), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
    }
    {
        names[145] = "human_genericf32zisegmap_28228_dim1";
        values[145] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28230;
    }
    {
        names[146] = "human_genericf32zisegmap_28228zisegmap_tblock_sizze_28231";
        values[146] = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28230;
    }
    {
        names[147] = "human_genericf32zisegscan_28226_dim1";
        values[147] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28220;
    }
    {
        names[148] = "human_genericf32zisegscan_28226zisegscan_tblock_sizze_28221";
        values[148] = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28220;
    }
    {
        names[149] = "human_genericf32zisegscan_28226zichunk_sizze_29794";
        values[149] = smax64((int64_t) 1, smin64(squot64(squot64(ctx->max_shared_memory, ctx->max_thread_block_size), (int64_t) 8), squot64(squot64(ctx->max_registers, ctx->max_thread_block_size) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
    }
    *names_out = names;
    *values_out = values;
    return num_macros;
}
static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:22:63-72\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:33:48-54\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:33:48-54\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:70:29-38\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:88:42-48\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:89:42-48\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:91:37-43\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:92:35-50\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:93:36-51\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:102:52-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 10:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:102:52-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 11:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:140:37-46\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  testing/test_generic.fut:11:1-77\n", args[0], args[1]);
            break;
        }
        
      case 12:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:22:63-72\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 13:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:33:48-54\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 14:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:33:48-54\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 15:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:70:29-38\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 16:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:88:42-48\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 17:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:89:42-48\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 18:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:91:37-43\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 19:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:92:35-50\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 20:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:93:36-51\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 21:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:102:52-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 22:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:102:52-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 23:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:140:37-46\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  testing/test_generic.fut:21:1-108\n", args[0], args[1]);
            break;
        }
        
      case 24:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:22:63-72\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 25:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:33:48-54\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 26:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:33:48-54\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 27:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:70:29-38\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 28:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:88:42-48\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 29:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:89:42-48\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 30:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:91:37-43\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 31:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:92:35-50\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 32:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:93:36-51\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 33:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:102:52-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 34:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:102:52-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
        
      case 35:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  human_generic.fut:140:37-46\n   #1  /prelude/soacs.fut:255:31-32\n   #2  /prelude/soacs.fut:255:48-50\n   #3  /prelude/functional.fut:9:44-45\n   #4  testing/test_generic.fut:31:1-108\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    int dummy;
    gpu_kernel builtinzhreplicate_boolzireplicate_29937;
    gpu_kernel builtinzhreplicate_i32zireplicate_29830;
    gpu_kernel builtinzhreplicate_i8zireplicate_29804;
    gpu_kernel human_genericf32ziseghist_global_28302;
    gpu_kernel human_genericf32ziseghist_global_28593;
    gpu_kernel human_genericf32ziseghist_local_28302;
    gpu_kernel human_genericf32ziseghist_local_28593;
    gpu_kernel human_genericf32zisegmap_28228;
    gpu_kernel human_genericf32zisegmap_28278;
    gpu_kernel human_genericf32zisegmap_28364;
    gpu_kernel human_genericf32zisegmap_28401;
    gpu_kernel human_genericf32zisegmap_28506;
    gpu_kernel human_genericf32zisegmap_28656;
    gpu_kernel human_genericf32zisegmap_28694;
    gpu_kernel human_genericf32zisegred_large_30337;
    gpu_kernel human_genericf32zisegred_large_30775;
    gpu_kernel human_genericf32zisegred_small_30337;
    gpu_kernel human_genericf32zisegred_small_30775;
    gpu_kernel human_genericf32zisegscan_28226;
    gpu_kernel human_genericf32zisegscan_28242;
    gpu_kernel human_genericf32zisegscan_28250;
    gpu_kernel human_genericf32zisegscan_28399;
    gpu_kernel human_genericf32zisegscan_28415;
    gpu_kernel human_genericf32zisegscan_28692;
    gpu_kernel human_genericf64ziseghist_global_28788;
    gpu_kernel human_genericf64ziseghist_global_29079;
    gpu_kernel human_genericf64ziseghist_local_28788;
    gpu_kernel human_genericf64ziseghist_local_29079;
    gpu_kernel human_genericf64zisegmap_28710;
    gpu_kernel human_genericf64zisegmap_28762;
    gpu_kernel human_genericf64zisegmap_28850;
    gpu_kernel human_genericf64zisegmap_28887;
    gpu_kernel human_genericf64zisegmap_28992;
    gpu_kernel human_genericf64zisegmap_29142;
    gpu_kernel human_genericf64zisegmap_29180;
    gpu_kernel human_genericf64zisegred_large_30337;
    gpu_kernel human_genericf64zisegred_large_30775;
    gpu_kernel human_genericf64zisegred_small_30337;
    gpu_kernel human_genericf64zisegred_small_30775;
    gpu_kernel human_genericf64zisegscan_28708;
    gpu_kernel human_genericf64zisegscan_28724;
    gpu_kernel human_genericf64zisegscan_28732;
    gpu_kernel human_genericf64zisegscan_28885;
    gpu_kernel human_genericf64zisegscan_28901;
    gpu_kernel human_genericf64zisegscan_29178;
    gpu_kernel human_generici32ziseghist_global_29274;
    gpu_kernel human_generici32ziseghist_global_29565;
    gpu_kernel human_generici32ziseghist_local_29274;
    gpu_kernel human_generici32ziseghist_local_29565;
    gpu_kernel human_generici32zisegmap_29196;
    gpu_kernel human_generici32zisegmap_29248;
    gpu_kernel human_generici32zisegmap_29336;
    gpu_kernel human_generici32zisegmap_29373;
    gpu_kernel human_generici32zisegmap_29478;
    gpu_kernel human_generici32zisegmap_29628;
    gpu_kernel human_generici32zisegmap_29666;
    gpu_kernel human_generici32zisegred_large_30337;
    gpu_kernel human_generici32zisegred_large_30775;
    gpu_kernel human_generici32zisegred_small_30337;
    gpu_kernel human_generici32zisegred_small_30775;
    gpu_kernel human_generici32zisegscan_29194;
    gpu_kernel human_generici32zisegscan_29210;
    gpu_kernel human_generici32zisegscan_29218;
    gpu_kernel human_generici32zisegscan_29371;
    gpu_kernel human_generici32zisegscan_29387;
    gpu_kernel human_generici32zisegscan_29664;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_boolzireplicate_29937, "builtinzhreplicate_boolzireplicate_29937");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_29830, "builtinzhreplicate_i32zireplicate_29830");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_29804, "builtinzhreplicate_i8zireplicate_29804");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32ziseghist_global_28302, "human_genericf32ziseghist_global_28302");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32ziseghist_global_28593, "human_genericf32ziseghist_global_28593");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32ziseghist_local_28302, "human_genericf32ziseghist_local_28302");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32ziseghist_local_28593, "human_genericf32ziseghist_local_28593");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegmap_28228, "human_genericf32zisegmap_28228");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegmap_28278, "human_genericf32zisegmap_28278");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegmap_28364, "human_genericf32zisegmap_28364");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegmap_28401, "human_genericf32zisegmap_28401");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegmap_28506, "human_genericf32zisegmap_28506");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegmap_28656, "human_genericf32zisegmap_28656");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegmap_28694, "human_genericf32zisegmap_28694");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegred_large_30337, "human_genericf32zisegred_large_30337");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegred_large_30775, "human_genericf32zisegred_large_30775");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegred_small_30337, "human_genericf32zisegred_small_30337");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegred_small_30775, "human_genericf32zisegred_small_30775");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegscan_28226, "human_genericf32zisegscan_28226");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegscan_28242, "human_genericf32zisegscan_28242");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegscan_28250, "human_genericf32zisegscan_28250");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegscan_28399, "human_genericf32zisegscan_28399");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegscan_28415, "human_genericf32zisegscan_28415");
    gpu_create_kernel(ctx, &ctx->program->human_genericf32zisegscan_28692, "human_genericf32zisegscan_28692");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64ziseghist_global_28788, "human_genericf64ziseghist_global_28788");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64ziseghist_global_29079, "human_genericf64ziseghist_global_29079");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64ziseghist_local_28788, "human_genericf64ziseghist_local_28788");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64ziseghist_local_29079, "human_genericf64ziseghist_local_29079");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegmap_28710, "human_genericf64zisegmap_28710");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegmap_28762, "human_genericf64zisegmap_28762");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegmap_28850, "human_genericf64zisegmap_28850");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegmap_28887, "human_genericf64zisegmap_28887");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegmap_28992, "human_genericf64zisegmap_28992");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegmap_29142, "human_genericf64zisegmap_29142");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegmap_29180, "human_genericf64zisegmap_29180");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegred_large_30337, "human_genericf64zisegred_large_30337");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegred_large_30775, "human_genericf64zisegred_large_30775");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegred_small_30337, "human_genericf64zisegred_small_30337");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegred_small_30775, "human_genericf64zisegred_small_30775");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegscan_28708, "human_genericf64zisegscan_28708");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegscan_28724, "human_genericf64zisegscan_28724");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegscan_28732, "human_genericf64zisegscan_28732");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegscan_28885, "human_genericf64zisegscan_28885");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegscan_28901, "human_genericf64zisegscan_28901");
    gpu_create_kernel(ctx, &ctx->program->human_genericf64zisegscan_29178, "human_genericf64zisegscan_29178");
    gpu_create_kernel(ctx, &ctx->program->human_generici32ziseghist_global_29274, "human_generici32ziseghist_global_29274");
    gpu_create_kernel(ctx, &ctx->program->human_generici32ziseghist_global_29565, "human_generici32ziseghist_global_29565");
    gpu_create_kernel(ctx, &ctx->program->human_generici32ziseghist_local_29274, "human_generici32ziseghist_local_29274");
    gpu_create_kernel(ctx, &ctx->program->human_generici32ziseghist_local_29565, "human_generici32ziseghist_local_29565");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegmap_29196, "human_generici32zisegmap_29196");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegmap_29248, "human_generici32zisegmap_29248");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegmap_29336, "human_generici32zisegmap_29336");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegmap_29373, "human_generici32zisegmap_29373");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegmap_29478, "human_generici32zisegmap_29478");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegmap_29628, "human_generici32zisegmap_29628");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegmap_29666, "human_generici32zisegmap_29666");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegred_large_30337, "human_generici32zisegred_large_30337");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegred_large_30775, "human_generici32zisegred_large_30775");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegred_small_30337, "human_generici32zisegred_small_30337");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegred_small_30775, "human_generici32zisegred_small_30775");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegscan_29194, "human_generici32zisegscan_29194");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegscan_29210, "human_generici32zisegscan_29210");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegscan_29218, "human_generici32zisegscan_29218");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegscan_29371, "human_generici32zisegscan_29371");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegscan_29387, "human_generici32zisegscan_29387");
    gpu_create_kernel(ctx, &ctx->program->human_generici32zisegscan_29664, "human_generici32zisegscan_29664");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_boolzireplicate_29937);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_29830);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_29804);
    gpu_free_kernel(ctx, ctx->program->human_genericf32ziseghist_global_28302);
    gpu_free_kernel(ctx, ctx->program->human_genericf32ziseghist_global_28593);
    gpu_free_kernel(ctx, ctx->program->human_genericf32ziseghist_local_28302);
    gpu_free_kernel(ctx, ctx->program->human_genericf32ziseghist_local_28593);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegmap_28228);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegmap_28278);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegmap_28364);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegmap_28401);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegmap_28506);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegmap_28656);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegmap_28694);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegred_large_30337);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegred_large_30775);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegred_small_30337);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegred_small_30775);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegscan_28226);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegscan_28242);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegscan_28250);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegscan_28399);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegscan_28415);
    gpu_free_kernel(ctx, ctx->program->human_genericf32zisegscan_28692);
    gpu_free_kernel(ctx, ctx->program->human_genericf64ziseghist_global_28788);
    gpu_free_kernel(ctx, ctx->program->human_genericf64ziseghist_global_29079);
    gpu_free_kernel(ctx, ctx->program->human_genericf64ziseghist_local_28788);
    gpu_free_kernel(ctx, ctx->program->human_genericf64ziseghist_local_29079);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegmap_28710);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegmap_28762);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegmap_28850);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegmap_28887);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegmap_28992);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegmap_29142);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegmap_29180);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegred_large_30337);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegred_large_30775);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegred_small_30337);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegred_small_30775);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegscan_28708);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegscan_28724);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegscan_28732);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegscan_28885);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegscan_28901);
    gpu_free_kernel(ctx, ctx->program->human_genericf64zisegscan_29178);
    gpu_free_kernel(ctx, ctx->program->human_generici32ziseghist_global_29274);
    gpu_free_kernel(ctx, ctx->program->human_generici32ziseghist_global_29565);
    gpu_free_kernel(ctx, ctx->program->human_generici32ziseghist_local_29274);
    gpu_free_kernel(ctx, ctx->program->human_generici32ziseghist_local_29565);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegmap_29196);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegmap_29248);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegmap_29336);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegmap_29373);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegmap_29478);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegmap_29628);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegmap_29666);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegred_large_30337);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegred_large_30775);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegred_small_30337);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegred_small_30775);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegscan_29194);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegscan_29210);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegscan_29218);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegscan_29371);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegscan_29387);
    gpu_free_kernel(ctx, ctx->program->human_generici32zisegscan_29664);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.builtinzhreplicate_boolzitblock_sizze_29941 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_29834 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_29808 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.human_genericf32zihist_L2_30312 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.human_genericf32zihist_L2_30750 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.human_genericf32zihist_L_30250 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.human_genericf32zihist_L_30688 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.human_genericf32ziseghist_num_tblocks_28296 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.human_genericf32ziseghist_num_tblocks_28587 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.human_genericf32zisegmap_num_tblocks_28232 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.human_genericf32zisegmap_num_tblocks_28405 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.human_genericf32zisegmap_num_tblocks_28698 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28230 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28254 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28324 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28403 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28419 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28615 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28696 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28222 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28238 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28246 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28395 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28411 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28688 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28220 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28236 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28244 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28393 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28409 = &ctx->cfg->tuning_params[31];
    ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28686 = &ctx->cfg->tuning_params[32];
    ctx->tuning_params.human_genericf64zihist_L2_30312 = &ctx->cfg->tuning_params[33];
    ctx->tuning_params.human_genericf64zihist_L2_30750 = &ctx->cfg->tuning_params[34];
    ctx->tuning_params.human_genericf64zihist_L_30250 = &ctx->cfg->tuning_params[35];
    ctx->tuning_params.human_genericf64zihist_L_30688 = &ctx->cfg->tuning_params[36];
    ctx->tuning_params.human_genericf64ziseghist_num_tblocks_28782 = &ctx->cfg->tuning_params[37];
    ctx->tuning_params.human_genericf64ziseghist_num_tblocks_29073 = &ctx->cfg->tuning_params[38];
    ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780 = &ctx->cfg->tuning_params[39];
    ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071 = &ctx->cfg->tuning_params[40];
    ctx->tuning_params.human_genericf64zisegmap_num_tblocks_28714 = &ctx->cfg->tuning_params[41];
    ctx->tuning_params.human_genericf64zisegmap_num_tblocks_28891 = &ctx->cfg->tuning_params[42];
    ctx->tuning_params.human_genericf64zisegmap_num_tblocks_29184 = &ctx->cfg->tuning_params[43];
    ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28712 = &ctx->cfg->tuning_params[44];
    ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28736 = &ctx->cfg->tuning_params[45];
    ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28810 = &ctx->cfg->tuning_params[46];
    ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28889 = &ctx->cfg->tuning_params[47];
    ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28905 = &ctx->cfg->tuning_params[48];
    ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29101 = &ctx->cfg->tuning_params[49];
    ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29182 = &ctx->cfg->tuning_params[50];
    ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28704 = &ctx->cfg->tuning_params[51];
    ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28720 = &ctx->cfg->tuning_params[52];
    ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28728 = &ctx->cfg->tuning_params[53];
    ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28881 = &ctx->cfg->tuning_params[54];
    ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28897 = &ctx->cfg->tuning_params[55];
    ctx->tuning_params.human_genericf64zisegscan_num_tblocks_29174 = &ctx->cfg->tuning_params[56];
    ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28702 = &ctx->cfg->tuning_params[57];
    ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28718 = &ctx->cfg->tuning_params[58];
    ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28726 = &ctx->cfg->tuning_params[59];
    ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28879 = &ctx->cfg->tuning_params[60];
    ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28895 = &ctx->cfg->tuning_params[61];
    ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_29172 = &ctx->cfg->tuning_params[62];
    ctx->tuning_params.human_generici32zihist_L2_30312 = &ctx->cfg->tuning_params[63];
    ctx->tuning_params.human_generici32zihist_L2_30750 = &ctx->cfg->tuning_params[64];
    ctx->tuning_params.human_generici32zihist_L_30250 = &ctx->cfg->tuning_params[65];
    ctx->tuning_params.human_generici32zihist_L_30688 = &ctx->cfg->tuning_params[66];
    ctx->tuning_params.human_generici32ziseghist_num_tblocks_29268 = &ctx->cfg->tuning_params[67];
    ctx->tuning_params.human_generici32ziseghist_num_tblocks_29559 = &ctx->cfg->tuning_params[68];
    ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266 = &ctx->cfg->tuning_params[69];
    ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557 = &ctx->cfg->tuning_params[70];
    ctx->tuning_params.human_generici32zisegmap_num_tblocks_29200 = &ctx->cfg->tuning_params[71];
    ctx->tuning_params.human_generici32zisegmap_num_tblocks_29377 = &ctx->cfg->tuning_params[72];
    ctx->tuning_params.human_generici32zisegmap_num_tblocks_29670 = &ctx->cfg->tuning_params[73];
    ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29198 = &ctx->cfg->tuning_params[74];
    ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29222 = &ctx->cfg->tuning_params[75];
    ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29296 = &ctx->cfg->tuning_params[76];
    ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29375 = &ctx->cfg->tuning_params[77];
    ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29391 = &ctx->cfg->tuning_params[78];
    ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29587 = &ctx->cfg->tuning_params[79];
    ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29668 = &ctx->cfg->tuning_params[80];
    ctx->tuning_params.human_generici32zisegscan_num_tblocks_29190 = &ctx->cfg->tuning_params[81];
    ctx->tuning_params.human_generici32zisegscan_num_tblocks_29206 = &ctx->cfg->tuning_params[82];
    ctx->tuning_params.human_generici32zisegscan_num_tblocks_29214 = &ctx->cfg->tuning_params[83];
    ctx->tuning_params.human_generici32zisegscan_num_tblocks_29367 = &ctx->cfg->tuning_params[84];
    ctx->tuning_params.human_generici32zisegscan_num_tblocks_29383 = &ctx->cfg->tuning_params[85];
    ctx->tuning_params.human_generici32zisegscan_num_tblocks_29660 = &ctx->cfg->tuning_params[86];
    ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29188 = &ctx->cfg->tuning_params[87];
    ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29204 = &ctx->cfg->tuning_params[88];
    ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29212 = &ctx->cfg->tuning_params[89];
    ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29365 = &ctx->cfg->tuning_params[90];
    ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29381 = &ctx->cfg->tuning_params[91];
    ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29658 = &ctx->cfg->tuning_params[92];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder_char(&builder, '{');
    str_builder_str(&builder, "\"memory\":{");
    str_builder(&builder, "\"space 'device'\": %lld", (long long) ctx->peak_mem_usage_device);
    str_builder_char(&builder, ',');
    str_builder(&builder, "\"default space\": %lld", (long long) ctx->peak_mem_usage_default);
    str_builder_str(&builder, "},\"events\":[");
    if (report_events_in_list(&ctx->event_list, &builder) != 0) {
        free(builder.str);
        return NULL;
    } else {
        str_builder_str(&builder, "]}");
        return builder.str;
    }
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

static void add_event(struct futhark_context* ctx,
                      const char* name,
                      char* description,
                      void* data,
                      event_report_fn f) {
  if (ctx->logging) {
    fprintf(ctx->log, "Event: %s\n%s\n", name, description);
  }
  add_event_to_list(&ctx->event_list, name, description, data, f);
}

char *futhark_context_get_error(struct futhark_context *ctx) {
  char *error = ctx->error;
  ctx->error = NULL;
  return error;
}

void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}

void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag) {
    cfg->profiling = flag;
}

void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag) {
    cfg->logging = flag;
}

void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f) {
  cfg->cache_fname = strdup(f);
}

int futhark_get_tuning_param_count(void) {
  return num_tuning_params;
}

const char *futhark_get_tuning_param_name(int i) {
  return tuning_param_names[i];
}

const char *futhark_get_tuning_param_class(int i) {
    return tuning_param_classes[i];
}

void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f){
  ctx->log = f;
}

void futhark_context_pause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 1;
}

void futhark_context_unpause_profiling(struct futhark_context *ctx) {
  ctx->profiling_paused = 0;
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->cache_fname);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  ctx->program_initialised = false;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  event_list_init(&ctx->event_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->detail_memory = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  set_tuning_params(ctx);
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    ctx->program_initialised = true;
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  if (ctx->program_initialised) {
    free_constants(ctx);
    teardown_program(ctx);
  }
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  event_list_free(&ctx->event_list);
  free(ctx->constants);
  free(ctx->error);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (r==map_r) {
    return false;
  }

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", (long int)dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", (long int)src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_29932, int64_t num_elems_29933, bool val_29934);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_29825, int64_t num_elems_29826, int32_t val_29827);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_29799, int64_t num_elems_29800, int8_t val_29801);
FUTHARK_FUN_ATTR int futrts_entry_human_genericf32(struct futhark_context *ctx, struct memblock_device *mem_out_p_30990, struct memblock_device ks_mem_29677, struct memblock_device shp_mem_29678, struct memblock_device II1_mem_29679, struct memblock_device A_mem_29680, int64_t mz2080U_18678, int64_t nz2081U_18679);
FUTHARK_FUN_ATTR int futrts_entry_human_genericf64(struct futhark_context *ctx, struct memblock_device *mem_out_p_30993, struct memblock_device ks_mem_29677, struct memblock_device shp_mem_29678, struct memblock_device II1_mem_29679, struct memblock_device A_mem_29680, int64_t mz2080U_21995, int64_t nz2081U_21996);
FUTHARK_FUN_ATTR int futrts_entry_human_generici32(struct futhark_context *ctx, struct memblock_device *mem_out_p_30996, struct memblock_device ks_mem_29677, struct memblock_device shp_mem_29678, struct memblock_device II1_mem_29679, struct memblock_device A_mem_29680, int64_t mz2080U_25210, int64_t nz2081U_25211);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_30383 (ctx->constants->counters_mem_30383)
    #define counters_mem_30821 (ctx->constants->counters_mem_30821)
    #define global_dynid_mem_29823 (ctx->constants->global_dynid_mem_29823)
    #define global_dynid_mem_29984 (ctx->constants->global_dynid_mem_29984)
    #define global_dynid_mem_30140 (ctx->constants->global_dynid_mem_30140)
    #define global_dynid_mem_30449 (ctx->constants->global_dynid_mem_30449)
    #define global_dynid_mem_30578 (ctx->constants->global_dynid_mem_30578)
    #define global_dynid_mem_30887 (ctx->constants->global_dynid_mem_30887)
    counters_mem_30383.references = NULL;
    counters_mem_30821.references = NULL;
    global_dynid_mem_29823.references = NULL;
    global_dynid_mem_29984.references = NULL;
    global_dynid_mem_30140.references = NULL;
    global_dynid_mem_30449.references = NULL;
    global_dynid_mem_30578.references = NULL;
    global_dynid_mem_30887.references = NULL;
    if (memblock_alloc_device(ctx, &global_dynid_mem_29823, (int64_t) 4, "global_dynid_mem_29823")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_29823, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_29984, (int64_t) 4, "global_dynid_mem_29984")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_29984, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30140, (int64_t) 4, "global_dynid_mem_30140")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30140, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_30383, (int64_t) 81920, "counters_mem_30383")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_30383, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30449, (int64_t) 4, "global_dynid_mem_30449")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30449, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30578, (int64_t) 4, "global_dynid_mem_30578")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30578, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_30821, (int64_t) 81920, "counters_mem_30821")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_30821, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30887, (int64_t) 4, "global_dynid_mem_30887")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30887, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_29823, (int64_t) 4, "global_dynid_mem_29823")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_29823, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_29984, (int64_t) 4, "global_dynid_mem_29984")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_29984, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30140, (int64_t) 4, "global_dynid_mem_30140")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30140, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_30383, (int64_t) 81920, "counters_mem_30383")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_30383, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30449, (int64_t) 4, "global_dynid_mem_30449")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30449, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30578, (int64_t) 4, "global_dynid_mem_30578")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30578, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_30821, (int64_t) 81920, "counters_mem_30821")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_30821, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30887, (int64_t) 4, "global_dynid_mem_30887")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30887, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_29823, (int64_t) 4, "global_dynid_mem_29823")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_29823, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_29984, (int64_t) 4, "global_dynid_mem_29984")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_29984, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30140, (int64_t) 4, "global_dynid_mem_30140")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30140, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_30383, (int64_t) 81920, "counters_mem_30383")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_30383, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30449, (int64_t) 4, "global_dynid_mem_30449")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30449, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30578, (int64_t) 4, "global_dynid_mem_30578")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30578, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_30821, (int64_t) 81920, "counters_mem_30821")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_30821, (int64_t) 20480, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &global_dynid_mem_30887, (int64_t) 4, "global_dynid_mem_30887")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, global_dynid_mem_30887, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_30383
    #undef counters_mem_30821
    #undef global_dynid_mem_29823
    #undef global_dynid_mem_29984
    #undef global_dynid_mem_30140
    #undef global_dynid_mem_30449
    #undef global_dynid_mem_30578
    #undef global_dynid_mem_30887
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_30383, "ctx->constants->counters_mem_30383") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_30821, "ctx->constants->counters_mem_30821") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_29823, "ctx->constants->global_dynid_mem_29823") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_29984, "ctx->constants->global_dynid_mem_29984") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_30140, "ctx->constants->global_dynid_mem_30140") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_30449, "ctx->constants->global_dynid_mem_30449") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_30578, "ctx->constants->global_dynid_mem_30578") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->global_dynid_mem_30887, "ctx->constants->global_dynid_mem_30887") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhreplicate_boolzireplicate_29937(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, bool arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_boolzireplicate_29937, "builtin#replicate_bool.replicate_29937", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_29830(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_29830, "builtin#replicate_i32.replicate_29830", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_29804(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_29804, "builtin#replicate_i8.replicate_29804", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegscan_28226(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegscan_28226, "human_genericf32.segscan_28226", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegmap_28228(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegmap_28228, "human_genericf32.segmap_28228", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegscan_28242(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegscan_28242, "human_genericf32.segscan_28242", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegscan_28250(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegscan_28250, "human_genericf32.segscan_28250", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegmap_28278(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegmap_28278, "human_genericf32.segmap_28278", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32ziseghist_local_28302(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32ziseghist_local_28302, "human_genericf32.seghist_local_28302", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32ziseghist_global_28302(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32ziseghist_global_28302, "human_genericf32.seghist_global_28302", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegred_small_30337(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegred_small_30337, "human_genericf32.segred_small_30337", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegred_large_30337(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegred_large_30337, "human_genericf32.segred_large_30337", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegmap_28364(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegmap_28364, "human_genericf32.segmap_28364", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegscan_28399(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegscan_28399, "human_genericf32.segscan_28399", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegmap_28401(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegmap_28401, "human_genericf32.segmap_28401", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegscan_28415(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegscan_28415, "human_genericf32.segscan_28415", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegmap_28506(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegmap_28506, "human_genericf32.segmap_28506", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32ziseghist_local_28593(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32ziseghist_local_28593, "human_genericf32.seghist_local_28593", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32ziseghist_global_28593(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32ziseghist_global_28593, "human_genericf32.seghist_global_28593", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegred_small_30775(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegred_small_30775, "human_genericf32.segred_small_30775", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegred_large_30775(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegred_large_30775, "human_genericf32.segred_large_30775", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegmap_28656(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegmap_28656, "human_genericf32.segmap_28656", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegscan_28692(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegscan_28692, "human_genericf32.segscan_28692", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf32zisegmap_28694(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf32zisegmap_28694, "human_genericf32.segmap_28694", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegscan_28708(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegscan_28708, "human_genericf64.segscan_28708", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegmap_28710(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegmap_28710, "human_genericf64.segmap_28710", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegscan_28724(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegscan_28724, "human_genericf64.segscan_28724", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegscan_28732(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegscan_28732, "human_genericf64.segscan_28732", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegmap_28762(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegmap_28762, "human_genericf64.segmap_28762", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64ziseghist_local_28788(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64ziseghist_local_28788, "human_genericf64.seghist_local_28788", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64ziseghist_global_28788(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64ziseghist_global_28788, "human_genericf64.seghist_global_28788", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegred_small_30337(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegred_small_30337, "human_genericf64.segred_small_30337", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegred_large_30337(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegred_large_30337, "human_genericf64.segred_large_30337", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegmap_28850(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegmap_28850, "human_genericf64.segmap_28850", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegscan_28885(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegscan_28885, "human_genericf64.segscan_28885", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegmap_28887(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegmap_28887, "human_genericf64.segmap_28887", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegscan_28901(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegscan_28901, "human_genericf64.segscan_28901", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegmap_28992(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegmap_28992, "human_genericf64.segmap_28992", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64ziseghist_local_29079(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64ziseghist_local_29079, "human_genericf64.seghist_local_29079", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64ziseghist_global_29079(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64ziseghist_global_29079, "human_genericf64.seghist_global_29079", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegred_small_30775(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegred_small_30775, "human_genericf64.segred_small_30775", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegred_large_30775(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegred_large_30775, "human_genericf64.segred_large_30775", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegmap_29142(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegmap_29142, "human_genericf64.segmap_29142", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegscan_29178(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegscan_29178, "human_genericf64.segscan_29178", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_genericf64zisegmap_29180(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_genericf64zisegmap_29180, "human_genericf64.segmap_29180", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegscan_29194(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegscan_29194, "human_generici32.segscan_29194", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegmap_29196(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegmap_29196, "human_generici32.segmap_29196", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegscan_29210(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegscan_29210, "human_generici32.segscan_29210", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegscan_29218(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegscan_29218, "human_generici32.segscan_29218", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegmap_29248(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegmap_29248, "human_generici32.segmap_29248", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32ziseghist_local_29274(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32ziseghist_local_29274, "human_generici32.seghist_local_29274", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32ziseghist_global_29274(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32ziseghist_global_29274, "human_generici32.seghist_global_29274", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegred_small_30337(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegred_small_30337, "human_generici32.segred_small_30337", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegred_large_30337(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegred_large_30337, "human_generici32.segred_large_30337", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegmap_29336(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegmap_29336, "human_generici32.segmap_29336", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegscan_29371(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegscan_29371, "human_generici32.segscan_29371", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegmap_29373(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegmap_29373, "human_generici32.segmap_29373", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegscan_29387(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegscan_29387, "human_generici32.segscan_29387", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegmap_29478(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegmap_29478, "human_generici32.segmap_29478", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32ziseghist_local_29565(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int32_t arg5, int64_t arg6, int64_t arg7, int64_t arg8, int32_t arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32ziseghist_local_29565, "human_generici32.seghist_local_29565", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32ziseghist_global_29565(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int32_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32ziseghist_global_29565, "human_generici32.seghist_global_29565", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegred_small_30775(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegred_small_30775, "human_generici32.segred_small_30775", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegred_large_30775(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, int64_t arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegred_large_30775, "human_generici32.segred_large_30775", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegmap_29628(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegmap_29628, "human_generici32.segmap_29628", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegscan_29664(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegscan_29664, "human_generici32.segscan_29664", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_human_generici32zisegmap_29666(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int32_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[11] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9};
        size_t args_sizes[11] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9)};
        
        return gpu_launch_kernel(ctx, ctx->program->human_generici32zisegmap_29666, "human_generici32.segmap_29666", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 11, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_i32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i32_1d *futhark_new_i32_1d(struct futhark_context *ctx, const int32_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i32_1d *futhark_new_raw_i32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_i32_1d *bad = NULL;
    struct futhark_i32_1d *arr = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr, int32_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_i32_1d(struct futhark_context *ctx, int32_t *out, struct futhark_i32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i32_1d(struct futhark_context *ctx, struct futhark_i32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f32_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_f32_1d *futhark_new_f32_1d(struct futhark_context *ctx, const float *data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 4, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f32_1d *futhark_new_raw_f32_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_f32_1d *bad = NULL;
    struct futhark_f32_1d *arr = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr, float *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 4);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f32_1d(struct futhark_context *ctx, float *out, struct futhark_f32_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 4 * (i0 * 1), 4);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f32_1d(struct futhark_context *ctx, struct futhark_f32_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_f64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_f64_1d *futhark_new_f64_1d(struct futhark_context *ctx, const double *data, int64_t dim0)
{
    int err = 0;
    struct futhark_f64_1d *bad = NULL;
    struct futhark_f64_1d *arr = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        err = 1;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_f64_1d *futhark_new_raw_f64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t dim0)
{
    int err = 0;
    struct futhark_f64_1d *bad = NULL;
    struct futhark_f64_1d *arr = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    arr->mem.mem = data;
    arr->shape[0] = dim0;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr, double *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
int futhark_index_f64_1d(struct futhark_context *ctx, double *out, struct futhark_f64_1d *arr, int64_t i0)
{
    int err = 0;
    
    if (i0 >= 0 && i0 < arr->shape[0]) {
        lock_lock(&ctx->lock);
        CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
        err = memcpy_gpu2host(ctx, false, (unsigned char *) out, 0, arr->mem.mem, 8 * (i0 * 1), 8);
        CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
        lock_unlock(&ctx->lock);
    } else {
        err = 1;
        set_error(ctx, strdup("Index out of bounds."));
    }
    return err;
}
CUdeviceptr futhark_values_raw_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_f64_1d(struct futhark_context *ctx, struct futhark_f64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_29932, int64_t num_elems_29933, bool val_29934)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
    struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
    struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
    struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
    struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
    struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
    struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
    struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
    int64_t replicate_n_29936 = num_elems_29933;
    int64_t tblock_sizze_29941;
    
    tblock_sizze_29941 = *ctx->tuning_params.builtinzhreplicate_boolzitblock_sizze_29941;
    
    int64_t virt_num_tblocks_29942 = sdiv_up64(replicate_n_29936, tblock_sizze_29941);
    int64_t num_tblocks_29943 = smin64(virt_num_tblocks_29942, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_boolzireplicate_29937(ctx, num_tblocks_29943, 1, 1, tblock_sizze_29941, 1, 1, (int64_t) 0, num_elems_29933, val_29934, replicate_n_29936, virt_num_tblocks_29942, num_tblocks_29943, mem_29932.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_29825, int64_t num_elems_29826, int32_t val_29827)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
    struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
    struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
    struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
    struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
    struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
    struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
    struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
    int64_t replicate_n_29829 = num_elems_29826;
    int64_t tblock_sizze_29834;
    
    tblock_sizze_29834 = *ctx->tuning_params.builtinzhreplicate_i32zitblock_sizze_29834;
    
    int64_t virt_num_tblocks_29835 = sdiv_up64(replicate_n_29829, tblock_sizze_29834);
    int64_t num_tblocks_29836 = smin64(virt_num_tblocks_29835, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_29830(ctx, num_tblocks_29836, 1, 1, tblock_sizze_29834, 1, 1, (int64_t) 0, num_elems_29826, val_29827, replicate_n_29829, virt_num_tblocks_29835, num_tblocks_29836, mem_29825.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_29799, int64_t num_elems_29800, int8_t val_29801)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
    struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
    struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
    struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
    struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
    struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
    struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
    struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
    int64_t replicate_n_29803 = num_elems_29800;
    int64_t tblock_sizze_29808;
    
    tblock_sizze_29808 = *ctx->tuning_params.builtinzhreplicate_i8zitblock_sizze_29808;
    
    int64_t virt_num_tblocks_29809 = sdiv_up64(replicate_n_29803, tblock_sizze_29808);
    int64_t num_tblocks_29810 = smin64(virt_num_tblocks_29809, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_29804(ctx, num_tblocks_29810, 1, 1, tblock_sizze_29808, 1, 1, (int64_t) 0, num_elems_29800, val_29801, replicate_n_29803, virt_num_tblocks_29809, num_tblocks_29810, mem_29799.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_human_genericf32(struct futhark_context *ctx, struct memblock_device *mem_out_p_30990, struct memblock_device ks_mem_29677, struct memblock_device shp_mem_29678, struct memblock_device II1_mem_29679, struct memblock_device A_mem_29680, int64_t mz2080U_18678, int64_t nz2081U_18679)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_param_tmp_30557;
    
    mem_param_tmp_30557.references = NULL;
    
    struct memblock_device mem_param_tmp_30556;
    
    mem_param_tmp_30556.references = NULL;
    
    struct memblock_device mem_param_tmp_30555;
    
    mem_param_tmp_30555.references = NULL;
    
    struct memblock_device mem_param_tmp_30554;
    
    mem_param_tmp_30554.references = NULL;
    
    struct memblock_device mem_param_tmp_30553;
    
    mem_param_tmp_30553.references = NULL;
    
    struct memblock_device mem_29763;
    
    mem_29763.references = NULL;
    
    struct memblock_device mem_29761;
    
    mem_29761.references = NULL;
    
    struct memblock_device incprefixes_mem_30885;
    
    incprefixes_mem_30885.references = NULL;
    
    struct memblock_device aggregates_mem_30883;
    
    aggregates_mem_30883.references = NULL;
    
    struct memblock_device status_flags_mem_30881;
    
    status_flags_mem_30881.references = NULL;
    
    struct memblock_device mem_29759;
    
    mem_29759.references = NULL;
    
    struct memblock_device mem_29757;
    
    mem_29757.references = NULL;
    
    struct memblock_device mem_29752;
    
    mem_29752.references = NULL;
    
    struct memblock_device mem_29750;
    
    mem_29750.references = NULL;
    
    struct memblock_device mem_29748;
    
    mem_29748.references = NULL;
    
    struct memblock_device segred_tmp_mem_30819;
    
    segred_tmp_mem_30819.references = NULL;
    
    struct memblock_device segred_tmp_mem_30817;
    
    segred_tmp_mem_30817.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30680;
    
    defunc_0_map_res_subhistos_mem_30680.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30678;
    
    defunc_0_map_res_subhistos_mem_30678.references = NULL;
    
    struct memblock_device incprefixes_mem_30576;
    
    incprefixes_mem_30576.references = NULL;
    
    struct memblock_device aggregates_mem_30574;
    
    aggregates_mem_30574.references = NULL;
    
    struct memblock_device status_flags_mem_30572;
    
    status_flags_mem_30572.references = NULL;
    
    struct memblock_device mem_param_29734;
    
    mem_param_29734.references = NULL;
    
    struct memblock_device mem_param_29731;
    
    mem_param_29731.references = NULL;
    
    struct memblock_device mem_param_29728;
    
    mem_param_29728.references = NULL;
    
    struct memblock_device mem_param_29725;
    
    mem_param_29725.references = NULL;
    
    struct memblock_device mem_param_29722;
    
    mem_param_29722.references = NULL;
    
    struct memblock_device ext_mem_29775;
    
    ext_mem_29775.references = NULL;
    
    struct memblock_device ext_mem_29776;
    
    ext_mem_29776.references = NULL;
    
    struct memblock_device ext_mem_29777;
    
    ext_mem_29777.references = NULL;
    
    struct memblock_device ext_mem_29778;
    
    ext_mem_29778.references = NULL;
    
    struct memblock_device ext_mem_29779;
    
    ext_mem_29779.references = NULL;
    
    struct memblock_device mem_29754;
    
    mem_29754.references = NULL;
    
    struct memblock_device mem_29744;
    
    mem_29744.references = NULL;
    
    struct memblock_device mem_29742;
    
    mem_29742.references = NULL;
    
    struct memblock_device mem_29740;
    
    mem_29740.references = NULL;
    
    struct memblock_device mem_29737;
    
    mem_29737.references = NULL;
    
    struct memblock_device mem_29718;
    
    mem_29718.references = NULL;
    
    struct memblock_device mem_29716;
    
    mem_29716.references = NULL;
    
    struct memblock_device incprefixes_mem_30447;
    
    incprefixes_mem_30447.references = NULL;
    
    struct memblock_device aggregates_mem_30445;
    
    aggregates_mem_30445.references = NULL;
    
    struct memblock_device status_flags_mem_30443;
    
    status_flags_mem_30443.references = NULL;
    
    struct memblock_device mem_29714;
    
    mem_29714.references = NULL;
    
    struct memblock_device mem_29712;
    
    mem_29712.references = NULL;
    
    struct memblock_device mem_29709;
    
    mem_29709.references = NULL;
    
    struct memblock_device mem_29707;
    
    mem_29707.references = NULL;
    
    struct memblock_device mem_29705;
    
    mem_29705.references = NULL;
    
    struct memblock_device mem_29703;
    
    mem_29703.references = NULL;
    
    struct memblock_device segred_tmp_mem_30381;
    
    segred_tmp_mem_30381.references = NULL;
    
    struct memblock_device segred_tmp_mem_30379;
    
    segred_tmp_mem_30379.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30242;
    
    defunc_0_map_res_subhistos_mem_30242.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30240;
    
    defunc_0_map_res_subhistos_mem_30240.references = NULL;
    
    struct memblock_device mem_29699;
    
    mem_29699.references = NULL;
    
    struct memblock_device mem_29697;
    
    mem_29697.references = NULL;
    
    struct memblock_device mem_29695;
    
    mem_29695.references = NULL;
    
    struct memblock_device incprefixes_mem_30138;
    
    incprefixes_mem_30138.references = NULL;
    
    struct memblock_device aggregates_mem_30136;
    
    aggregates_mem_30136.references = NULL;
    
    struct memblock_device status_flags_mem_30134;
    
    status_flags_mem_30134.references = NULL;
    
    struct memblock_device mem_29692;
    
    mem_29692.references = NULL;
    
    struct memblock_device incprefixes_mem_29982;
    
    incprefixes_mem_29982.references = NULL;
    
    struct memblock_device aggregates_mem_29980;
    
    aggregates_mem_29980.references = NULL;
    
    struct memblock_device incprefixes_mem_29978;
    
    incprefixes_mem_29978.references = NULL;
    
    struct memblock_device aggregates_mem_29976;
    
    aggregates_mem_29976.references = NULL;
    
    struct memblock_device status_flags_mem_29974;
    
    status_flags_mem_29974.references = NULL;
    
    struct memblock_device mem_29689;
    
    mem_29689.references = NULL;
    
    struct memblock_device mem_29687;
    
    mem_29687.references = NULL;
    
    struct memblock_device mem_29684;
    
    mem_29684.references = NULL;
    
    struct memblock_device incprefixes_mem_29821;
    
    incprefixes_mem_29821.references = NULL;
    
    struct memblock_device aggregates_mem_29819;
    
    aggregates_mem_29819.references = NULL;
    
    struct memblock_device status_flags_mem_29797;
    
    status_flags_mem_29797.references = NULL;
    
    struct memblock_device mem_29683;
    
    mem_29683.references = NULL;
    
    struct memblock_device mem_out_29788;
    
    mem_out_29788.references = NULL;
    
    struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
    struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
    struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
    struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
    struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
    struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
    struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
    struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
    int64_t segscan_tblock_sizze_28221;
    
    segscan_tblock_sizze_28221 = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28220;
    
    int64_t num_tblocks_28223;
    int64_t max_num_tblocks_29789;
    
    max_num_tblocks_29789 = *ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28222;
    num_tblocks_28223 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_18678, segscan_tblock_sizze_28221), max_num_tblocks_29789)));
    
    int64_t bytes_29682 = (int64_t) 8 * mz2080U_18678;
    
    if (memblock_alloc_device(ctx, &mem_29683, bytes_29682, "mem_29683")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_18678)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_29790;
        
        shared_memory_29790 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_29791;
        
        thread_block_sizze_29791 = ctx->max_thread_block_size;
        
        int64_t registers_29792;
        
        registers_29792 = ctx->max_registers;
        
        int64_t thread_block_sizze_29793;
        
        thread_block_sizze_29793 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_29794 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_29790, thread_block_sizze_29791), (int64_t) 8), squot64(squot64(registers_29792, thread_block_sizze_29793) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_29795 = sdiv_up64(mz2080U_18678, segscan_tblock_sizze_28221 * chunk_sizze_29794);
        int64_t num_virt_threads_29796 = num_virt_blocks_29795 * segscan_tblock_sizze_28221;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_29794, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_29797, num_virt_blocks_29795, "status_flags_mem_29797")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_29797, num_virt_blocks_29795, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29819, (int64_t) 8 * num_virt_blocks_29795, "aggregates_mem_29819")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29821, (int64_t) 8 * num_virt_blocks_29795, "incprefixes_mem_29821")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_genericf32zisegscan_28226(ctx, num_tblocks_28223, 1, 1, *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28220, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28221), chunk_sizze_29794 * segscan_tblock_sizze_28221 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28221), chunk_sizze_29794 * segscan_tblock_sizze_28221 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_18678, num_tblocks_28223, num_virt_blocks_29795, num_virt_threads_29796, shp_mem_29678.mem, mem_29683.mem, status_flags_mem_29797.mem, aggregates_mem_29819.mem, incprefixes_mem_29821.mem, global_dynid_mem_29823.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_alloc_device(ctx, &mem_29684, nz2081U_18679, "mem_29684")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_29684, nz2081U_18679, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_28231;
    
    segmap_tblock_sizze_28231 = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28230;
    
    int64_t num_tblocks_28233;
    int64_t max_num_tblocks_29952;
    
    max_num_tblocks_29952 = *ctx->tuning_params.human_genericf32zisegmap_num_tblocks_28232;
    num_tblocks_28233 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_18678, segmap_tblock_sizze_28231), max_num_tblocks_29952)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_29953 = sext_i64_i32(sdiv_up64(mz2080U_18678, segmap_tblock_sizze_28231));
    
    {
        err = gpu_kernel_human_genericf32zisegmap_28228(ctx, num_tblocks_28233, 1, 1, *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28230, 1, 1, (int64_t) 0, mz2080U_18678, nz2081U_18679, num_tblocks_28233, virt_num_tblocks_29953, mem_29683.mem, mem_29684.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29683, "mem_29683") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_28237;
    
    segscan_tblock_sizze_28237 = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28236;
    
    int64_t num_tblocks_28239;
    int64_t max_num_tblocks_29966;
    
    max_num_tblocks_29966 = *ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28238;
    num_tblocks_28239 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_18679, segscan_tblock_sizze_28237), max_num_tblocks_29966)));
    
    int64_t bytes_29688 = (int64_t) 4 * nz2081U_18679;
    
    if (memblock_alloc_device(ctx, &mem_29687, nz2081U_18679, "mem_29687")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29689, bytes_29688, "mem_29689")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_18679)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_29967;
        
        shared_memory_29967 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_29968;
        
        thread_block_sizze_29968 = ctx->max_thread_block_size;
        
        int64_t registers_29969;
        
        registers_29969 = ctx->max_registers;
        
        int64_t thread_block_sizze_29970;
        
        thread_block_sizze_29970 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_29971 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_29967, thread_block_sizze_29968), (int64_t) 4), squot64(squot64(registers_29969, thread_block_sizze_29970) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_29972 = sdiv_up64(nz2081U_18679, segscan_tblock_sizze_28237 * chunk_sizze_29971);
        int64_t num_virt_threads_29973 = num_virt_blocks_29972 * segscan_tblock_sizze_28237;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_29971, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_29974, num_virt_blocks_29972, "status_flags_mem_29974")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_29974, num_virt_blocks_29972, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29976, num_virt_blocks_29972, "aggregates_mem_29976")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29978, num_virt_blocks_29972, "incprefixes_mem_29978")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29980, (int64_t) 4 * num_virt_blocks_29972, "aggregates_mem_29980")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29982, (int64_t) 4 * num_virt_blocks_29972, "incprefixes_mem_29982")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_genericf32zisegscan_28242(ctx, num_tblocks_28239, 1, 1, *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28236, 1, 1, smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_28237, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_28237), smax64(chunk_sizze_29971 * segscan_tblock_sizze_28237, chunk_sizze_29971 * segscan_tblock_sizze_28237 * (int64_t) 4)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_28237, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_28237), smax64(chunk_sizze_29971 * segscan_tblock_sizze_28237, chunk_sizze_29971 * segscan_tblock_sizze_28237 * (int64_t) 4)), (int64_t) 8), (int64_t) 8), nz2081U_18679, num_tblocks_28239, num_virt_blocks_29972, num_virt_threads_29973, A_mem_29680.mem, mem_29684.mem, mem_29687.mem, mem_29689.mem, status_flags_mem_29974.mem, aggregates_mem_29976.mem, incprefixes_mem_29978.mem, aggregates_mem_29980.mem, incprefixes_mem_29982.mem, global_dynid_mem_29984.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_29684, "mem_29684") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29687, "mem_29687") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_28245;
    
    segscan_tblock_sizze_28245 = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28244;
    
    int64_t num_tblocks_28247;
    int64_t max_num_tblocks_30126;
    
    max_num_tblocks_30126 = *ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28246;
    num_tblocks_28247 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_18678, segscan_tblock_sizze_28245), max_num_tblocks_30126)));
    
    int64_t bytes_29691 = (int64_t) 4 * mz2080U_18678;
    
    if (memblock_alloc_device(ctx, &mem_29692, bytes_29691, "mem_29692")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_18678)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_30127;
        
        shared_memory_30127 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_30128;
        
        thread_block_sizze_30128 = ctx->max_thread_block_size;
        
        int64_t registers_30129;
        
        registers_30129 = ctx->max_registers;
        
        int64_t thread_block_sizze_30130;
        
        thread_block_sizze_30130 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_30131 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30127, thread_block_sizze_30128), (int64_t) 4), squot64(squot64(registers_30129, thread_block_sizze_30130) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_30132 = sdiv_up64(mz2080U_18678, segscan_tblock_sizze_28245 * chunk_sizze_30131);
        int64_t num_virt_threads_30133 = num_virt_blocks_30132 * segscan_tblock_sizze_28245;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30131, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_30134, num_virt_blocks_30132, "status_flags_mem_30134")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30134, num_virt_blocks_30132, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_30136, (int64_t) 4 * num_virt_blocks_30132, "aggregates_mem_30136")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_30138, (int64_t) 4 * num_virt_blocks_30132, "incprefixes_mem_30138")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_genericf32zisegscan_28250(ctx, num_tblocks_28247, 1, 1, *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28244, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28245), chunk_sizze_30131 * segscan_tblock_sizze_28245 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28245), chunk_sizze_30131 * segscan_tblock_sizze_28245 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_18678, num_tblocks_28247, num_virt_blocks_30132, num_virt_threads_30133, shp_mem_29678.mem, mem_29692.mem, status_flags_mem_30134.mem, aggregates_mem_30136.mem, incprefixes_mem_30138.mem, global_dynid_mem_30140.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_28274;
    
    segmap_tblock_sizze_28274 = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28254;
    
    int64_t segmap_usable_groups_28275 = sdiv_up64(mz2080U_18678, segmap_tblock_sizze_28274);
    
    if (memblock_alloc_device(ctx, &mem_29695, bytes_29691, "mem_29695")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30229 = sext_i64_i32(sdiv_up64(mz2080U_18678, segmap_tblock_sizze_28274));
    
    {
        err = gpu_kernel_human_genericf32zisegmap_28278(ctx, segmap_usable_groups_28275, 1, 1, *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28254, 1, 1, (int64_t) 0, mz2080U_18678, nz2081U_18679, shp_mem_29678.mem, mem_29689.mem, mem_29692.mem, mem_29695.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29689, "mem_29689") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29692, "mem_29692") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_29697, bytes_29691, "mem_29697")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_29697, mz2080U_18678, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29699, bytes_29691, "mem_29699")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_29699, mz2080U_18678, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t seghist_tblock_sizze_28295;
    
    seghist_tblock_sizze_28295 = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294;
    
    int64_t num_tblocks_28297;
    int64_t max_num_tblocks_30238;
    
    max_num_tblocks_30238 = *ctx->tuning_params.human_genericf32ziseghist_num_tblocks_28296;
    num_tblocks_28297 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_18679, seghist_tblock_sizze_28295), max_num_tblocks_30238)));
    
    int64_t num_subhistos_30239;
    int64_t h_30244 = (int64_t) 4 * mz2080U_18678 + (int64_t) 4 * mz2080U_18678;
    int64_t seg_h_30245 = (int64_t) 4 * mz2080U_18678 + (int64_t) 4 * mz2080U_18678;
    
    if (!(seg_h_30245 == (int64_t) 0)) {
        int64_t hist_H_30246 = mz2080U_18678;
        int64_t hist_el_sizze_30247 = sdiv_up64(h_30244, hist_H_30246);
        int64_t hist_N_30248 = nz2081U_18679;
        int32_t hist_RF_30249 = 1;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegHist");
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_28297 * seghist_tblock_sizze_28295), '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_28295, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30246, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_30248, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_30247, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_30249, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_30244, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_30245, '\n');
        
        int64_t hist_L_30250;
        
        hist_L_30250 = *ctx->tuning_params.human_genericf32zihist_L_30250;
        
        int64_t max_tblock_sizze_30251;
        
        max_tblock_sizze_30251 = ctx->max_thread_block_size;
        
        int64_t num_tblocks_30252 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_28297 * seghist_tblock_sizze_28295)), max_tblock_sizze_30251);
        double hist_m_prime_30253 = sitofp_i64_f64(smin64(squot64(hist_L_30250, hist_el_sizze_30247), sdiv_up64(hist_N_30248, num_tblocks_30252))) / sitofp_i64_f64(hist_H_30246);
        int64_t hist_M0_30254 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_30253), max_tblock_sizze_30251));
        int64_t hist_Nout_30255 = (int64_t) 1;
        int64_t hist_Nin_30256 = nz2081U_18679;
        int64_t work_asymp_M_max_30257 = squot64(hist_Nout_30255 * hist_N_30248, (int64_t) 2 * num_tblocks_30252 * hist_H_30246);
        int32_t hist_M_30258 = sext_i64_i32(smin64(hist_M0_30254, work_asymp_M_max_30257));
        int64_t hist_C_30259 = sdiv_up64(max_tblock_sizze_30251, sext_i32_i64(smax32(1, hist_M_30258)));
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_30254, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_30257, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_30259, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_30251, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_30258, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_30246 * hist_el_sizze_30247 * sext_i32_i64(hist_M_30258)), '\n');
        
        int64_t local_mem_needed_30260 = hist_el_sizze_30247 * sext_i32_i64(hist_M_30258);
        int32_t hist_S_30261 = sext_i64_i32(sdiv_up64(hist_H_30246 * local_mem_needed_30260 + (int64_t) 1, hist_L_30250));
        
        if (sle64(hist_H_30246, hist_Nin_30256) && (sle64(local_mem_needed_30260, hist_L_30250) && (sle32(hist_S_30261, 3) && (sle64(hist_C_30259, max_tblock_sizze_30251) && slt32(0, hist_M_30258))))) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using shared memory");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30246, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30258, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_30259, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30261, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_30258, '\n');
            num_subhistos_30239 = num_tblocks_30252;
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_30239, '\n');
            if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_18678 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30240")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_18678, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30240.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29699.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_18678})) != 0)
                    goto cleanup;
            }
            if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_18678 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30242")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_18678, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30242.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29697.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_18678})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_30262 = 0; chk_i_30262 < hist_S_30261; chk_i_30262++) {
                int64_t num_segments_30263 = (int64_t) 1;
                int64_t hist_H_chk_30264 = sdiv_up64(mz2080U_18678, sext_i32_i64(hist_S_30261));
                int64_t histo_sizze_30265 = hist_H_chk_30264;
                int32_t init_per_thread_30266 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_30258) * histo_sizze_30265, max_tblock_sizze_30251));
                
                {
                    err = gpu_kernel_human_genericf32ziseghist_local_28302(ctx, num_tblocks_30252, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8)), mz2080U_18678, nz2081U_18679, num_subhistos_30239, num_tblocks_30252, hist_M_30258, chk_i_30262, num_segments_30263, hist_H_chk_30264, histo_sizze_30265, init_per_thread_30266, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
            }
        } else {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using global memory");
            
            int64_t hist_H_30307 = mz2080U_18678;
            double hist_RF_30308 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
            int32_t hist_el_sizze_30309 = 4;
            double hist_C_max_30310 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28297 * seghist_tblock_sizze_28295)), sitofp_i32_f64(hist_H_30307) / 2.0);
            int32_t hist_M_min_30311 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28297 * seghist_tblock_sizze_28295)) / hist_C_max_30310)));
            int64_t hist_L2_30312;
            
            hist_L2_30312 = *ctx->tuning_params.human_genericf32zihist_L2_30312;
            
            double hist_RACE_exp_30313 = fmax64(1.0, 0.75 * hist_RF_30308 / (64.0 / sitofp_i32_f64(hist_el_sizze_30309)));
            int32_t hist_S_30314;
            
            if (slt64(nz2081U_18679, hist_H_30307)) {
                hist_S_30314 = 1;
            } else {
                hist_S_30314 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_30311) * hist_H_30307 * sext_i32_i64(hist_el_sizze_30309), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_30312) * hist_RACE_exp_30313)));
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_30313, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30314, '\n');
            
            int64_t hist_H_chk_30315 = sdiv_up64(mz2080U_18678, sext_i32_i64(hist_S_30314));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_30315, '\n');
            
            double hist_k_max_30316 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_30312) / sitofp_i32_f64(8)) * hist_RACE_exp_30313, sitofp_i32_f64(nz2081U_18679)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_28297 * seghist_tblock_sizze_28295));
            int64_t hist_u_30317 = (int64_t) 2;
            double hist_C_30318 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28297 * seghist_tblock_sizze_28295)), sitofp_i32_f64(hist_u_30317 * hist_H_chk_30315) / hist_k_max_30316);
            int32_t hist_M_30319 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_30316, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30319, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_30318, '\n');
            num_subhistos_30239 = sext_i32_i64(hist_M_30319);
            if (hist_M_30319 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_18678 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30240")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_18678, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30240.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29699.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_18678})) != 0)
                    goto cleanup;
            }
            if (hist_M_30319 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_18678 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30242")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_18678, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30242.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29697.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_18678})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_30320 = 0; chk_i_30320 < hist_S_30314; chk_i_30320++) {
                int64_t hist_H_chk_30321 = sdiv_up64(mz2080U_18678, sext_i32_i64(hist_S_30314));
                
                {
                    err = gpu_kernel_human_genericf32ziseghist_global_28302(ctx, num_tblocks_28297, 1, 1, *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294, 1, 1, (int64_t) 0, mz2080U_18678, nz2081U_18679, num_tblocks_28297, num_subhistos_30239, chk_i_30320, hist_H_chk_30321, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
            }
        }
        if (num_subhistos_30239 == (int64_t) 1) {
            if (memblock_set_device(ctx, &mem_29699, &defunc_0_map_res_subhistos_mem_30240, "defunc_0_map_res_subhistos_mem_30240") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_29697, &defunc_0_map_res_subhistos_mem_30242, "defunc_0_map_res_subhistos_mem_30242") != 0)
                return 1;
        } else {
            int64_t chunk_sizze_30338 = (int64_t) 1;
            
            if (slt64(num_subhistos_30239 * (int64_t) 2, seghist_tblock_sizze_28295 * chunk_sizze_30338)) {
                int64_t segment_sizze_nonzzero_30339 = smax64((int64_t) 1, num_subhistos_30239);
                int64_t num_threads_30340 = seghist_tblock_sizze_28295 * seghist_tblock_sizze_28295;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-small");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_18678, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30239, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339), '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_18678, squot64(seghist_tblock_sizze_28295, segment_sizze_nonzzero_30339))), '\n');
                {
                    err = gpu_kernel_human_genericf32zisegred_small_30337(ctx, num_tblocks_28297, 1, 1, *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294, 1, 1, (int64_t) 4 * seghist_tblock_sizze_28295 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28295, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_28295 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28295, (int64_t) 8), (int64_t) 8)), mz2080U_18678, num_tblocks_28297, num_subhistos_30239, segment_sizze_nonzzero_30339, mem_29697.mem, mem_29699.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            } else {
                int64_t blocks_per_segment_30375 = sdiv_up64(num_tblocks_28297, smax64((int64_t) 1, mz2080U_18678));
                int64_t q_30376 = sdiv_up64(num_subhistos_30239, seghist_tblock_sizze_28295 * blocks_per_segment_30375 * chunk_sizze_30338);
                int64_t num_virtblocks_30377 = blocks_per_segment_30375 * mz2080U_18678;
                int64_t threads_per_segment_30378 = blocks_per_segment_30375 * seghist_tblock_sizze_28295;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-large");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_18678, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30239, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_30377, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_28297, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_28295, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_30376, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_30375, '\n');
                if (memblock_alloc_device(ctx, &segred_tmp_mem_30379, (int64_t) 4 * num_virtblocks_30377, "segred_tmp_mem_30379")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &segred_tmp_mem_30381, (int64_t) 4 * num_virtblocks_30377, "segred_tmp_mem_30381")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_human_genericf32zisegred_large_30337(ctx, num_tblocks_28297, 1, 1, *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28294, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_28295 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28295, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_28295 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28295, (int64_t) 8), (int64_t) 8)), mz2080U_18678, num_tblocks_28297, num_subhistos_30239, blocks_per_segment_30375, q_30376, num_virtblocks_30377, threads_per_segment_30378, mem_29697.mem, mem_29699.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem, segred_tmp_mem_30379.mem, segred_tmp_mem_30381.mem, counters_mem_30383.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segmap_tblock_sizze_28357;
    
    segmap_tblock_sizze_28357 = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28324;
    
    int64_t segmap_usable_groups_28358 = sdiv_up64(mz2080U_18678, segmap_tblock_sizze_28357);
    
    if (memblock_alloc_device(ctx, &mem_29703, bytes_29691, "mem_29703")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29705, bytes_29691, "mem_29705")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29707, bytes_29691, "mem_29707")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29709, bytes_29691, "mem_29709")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30426 = sext_i64_i32(sdiv_up64(mz2080U_18678, segmap_tblock_sizze_28357));
    
    {
        err = gpu_kernel_human_genericf32zisegmap_28364(ctx, segmap_usable_groups_28358, 1, 1, *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28324, 1, 1, (int64_t) 0, mz2080U_18678, ks_mem_29677.mem, shp_mem_29678.mem, mem_29695.mem, mem_29697.mem, mem_29699.mem, mem_29703.mem, mem_29705.mem, mem_29707.mem, mem_29709.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29697, "mem_29697") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29699, "mem_29699") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_28394;
    
    segscan_tblock_sizze_28394 = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28393;
    
    int64_t num_tblocks_28396;
    int64_t max_num_tblocks_30435;
    
    max_num_tblocks_30435 = *ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28395;
    num_tblocks_28396 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_18679, segscan_tblock_sizze_28394), max_num_tblocks_30435)));
    
    int64_t bytes_29711 = (int64_t) 8 * nz2081U_18679;
    
    if (memblock_alloc_device(ctx, &mem_29712, bytes_29711, "mem_29712")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29714, bytes_29711, "mem_29714")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_18679)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_30436;
        
        shared_memory_30436 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_30437;
        
        thread_block_sizze_30437 = ctx->max_thread_block_size;
        
        int64_t registers_30438;
        
        registers_30438 = ctx->max_registers;
        
        int64_t thread_block_sizze_30439;
        
        thread_block_sizze_30439 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_30440 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30436, thread_block_sizze_30437), (int64_t) 8), squot64(squot64(registers_30438, thread_block_sizze_30439) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_30441 = sdiv_up64(nz2081U_18679, segscan_tblock_sizze_28394 * chunk_sizze_30440);
        int64_t num_virt_threads_30442 = num_virt_blocks_30441 * segscan_tblock_sizze_28394;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30440, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_30443, num_virt_blocks_30441, "status_flags_mem_30443")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30443, num_virt_blocks_30441, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_30445, (int64_t) 8 * num_virt_blocks_30441, "aggregates_mem_30445")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_30447, (int64_t) 8 * num_virt_blocks_30441, "incprefixes_mem_30447")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_genericf32zisegscan_28399(ctx, num_tblocks_28396, 1, 1, *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28393, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28394), chunk_sizze_30440 * segscan_tblock_sizze_28394 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28394), chunk_sizze_30440 * segscan_tblock_sizze_28394 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_18678, nz2081U_18679, num_tblocks_28396, num_virt_blocks_30441, num_virt_threads_30442, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, mem_29709.mem, mem_29712.mem, mem_29714.mem, status_flags_mem_30443.mem, aggregates_mem_30445.mem, incprefixes_mem_30447.mem, global_dynid_mem_30449.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_29695, "mem_29695") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29709, "mem_29709") != 0)
        return 1;
    
    bool cond_27077 = nz2081U_18679 == (int64_t) 0;
    bool x_27078 = !cond_27077;
    int64_t tmp_27079 = sub64(nz2081U_18679, (int64_t) 1);
    bool x_27080 = sle64((int64_t) 0, tmp_27079);
    bool y_27081 = slt64(tmp_27079, nz2081U_18679);
    bool bounds_check_27082 = x_27080 && y_27081;
    bool protect_assert_disj_27083 = cond_27077 || bounds_check_27082;
    bool index_certs_27084;
    
    if (!protect_assert_disj_27083) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_27079, "] out of bounds for array of shape [", (long long) nz2081U_18679, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:11:1-77\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_27085;
    
    if (x_27078) {
        int64_t read_res_30991;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_30991, mem_29712.mem, tmp_27079 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_28151 = read_res_30991;
        
        m_f_res_27085 = x_28151;
    } else {
        m_f_res_27085 = (int64_t) 0;
    }
    
    int64_t m_27087;
    
    if (cond_27077) {
        m_27087 = (int64_t) 0;
    } else {
        m_27087 = m_f_res_27085;
    }
    
    int64_t m_27097 = sub64(m_27087, (int64_t) 1);
    bool i_p_m_t_s_leq_w_27099 = slt64(m_27097, nz2081U_18679);
    bool zzero_leq_i_p_m_t_s_27098 = sle64((int64_t) 0, m_27097);
    bool y_27101 = zzero_leq_i_p_m_t_s_27098 && i_p_m_t_s_leq_w_27099;
    bool i_lte_j_27100 = sle64((int64_t) 0, m_27087);
    bool forwards_ok_27102 = i_lte_j_27100 && y_27101;
    bool eq_x_zz_27094 = (int64_t) 0 == m_f_res_27085;
    bool p_and_eq_x_y_27095 = x_27078 && eq_x_zz_27094;
    bool empty_slice_27096 = cond_27077 || p_and_eq_x_y_27095;
    bool ok_or_empty_27103 = empty_slice_27096 || forwards_ok_27102;
    bool index_certs_27104;
    
    if (!ok_or_empty_27103) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_27087, "] out of bounds for array of shape [", (long long) nz2081U_18679, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:11:1-77\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_29715 = (int64_t) 4 * m_27087;
    
    if (memblock_alloc_device(ctx, &mem_29716, bytes_29715, "mem_29716")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29716.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, II1_mem_29679.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27087})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_29718, bytes_29715, "mem_29718")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29718.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, A_mem_29680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27087})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_28404;
    
    segmap_tblock_sizze_28404 = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28403;
    
    int64_t num_tblocks_28406;
    int64_t max_num_tblocks_30538;
    
    max_num_tblocks_30538 = *ctx->tuning_params.human_genericf32zisegmap_num_tblocks_28405;
    num_tblocks_28406 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_18679, segmap_tblock_sizze_28404), max_num_tblocks_30538)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30539 = sext_i64_i32(sdiv_up64(nz2081U_18679, segmap_tblock_sizze_28404));
    
    {
        err = gpu_kernel_human_genericf32zisegmap_28401(ctx, num_tblocks_28406, 1, 1, *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28403, 1, 1, (int64_t) 0, nz2081U_18679, m_27087, num_tblocks_28406, virt_num_tblocks_30539, II1_mem_29679.mem, A_mem_29680.mem, mem_29712.mem, mem_29714.mem, mem_29716.mem, mem_29718.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29712, "mem_29712") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29714, "mem_29714") != 0)
        return 1;
    
    bool loop_cond_27114 = slt64((int64_t) 0, m_27087);
    int64_t segscan_tblock_sizze_28410;
    
    segscan_tblock_sizze_28410 = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28409;
    
    int64_t num_tblocks_28412;
    int64_t max_num_tblocks_30552;
    
    max_num_tblocks_30552 = *ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28411;
    num_tblocks_28412 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_18678, segscan_tblock_sizze_28410), max_num_tblocks_30552)));
    
    int64_t segmap_tblock_sizze_28502;
    
    segmap_tblock_sizze_28502 = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28419;
    
    int64_t segmap_usable_groups_28503 = sdiv_up_safe64(mz2080U_18678, segmap_tblock_sizze_28502);
    int64_t seghist_tblock_sizze_28586;
    
    seghist_tblock_sizze_28586 = *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585;
    
    int64_t segmap_tblock_sizze_28649;
    
    segmap_tblock_sizze_28649 = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28615;
    
    int64_t segmap_usable_groups_28650 = sdiv_up_safe64(mz2080U_18678, segmap_tblock_sizze_28649);
    int64_t segscan_tblock_sizze_28687;
    
    segscan_tblock_sizze_28687 = *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28686;
    
    int64_t segmap_tblock_sizze_28697;
    
    segmap_tblock_sizze_28697 = *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28696;
    if (memblock_alloc_device(ctx, &mem_29737, bytes_29691, "mem_29737")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29740, bytes_29691, "mem_29740")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29742, bytes_29691, "mem_29742")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29744, bytes_29691, "mem_29744")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29754, bytes_29691, "mem_29754")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t result_27116;
    bool result_27117;
    int64_t loop_dz2081Uz2088Uz2087U_27123;
    bool loop_while_27124;
    
    if (memblock_set_device(ctx, &mem_param_29722, &mem_29705, "mem_29705") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29725, &mem_29703, "mem_29703") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29728, &mem_29716, "mem_29716") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29731, &mem_29718, "mem_29718") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29734, &mem_29707, "mem_29707") != 0)
        return 1;
    loop_dz2081Uz2088Uz2087U_27123 = m_27087;
    loop_while_27124 = loop_cond_27114;
    while (loop_while_27124) {
        if (slt64((int64_t) 0, mz2080U_18678)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_30565;
            
            shared_memory_30565 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_30566;
            
            thread_block_sizze_30566 = ctx->max_thread_block_size;
            
            int64_t registers_30567;
            
            registers_30567 = ctx->max_registers;
            
            int64_t thread_block_sizze_30568;
            
            thread_block_sizze_30568 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_30569 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30565, thread_block_sizze_30566), (int64_t) 4), squot64(squot64(registers_30567, thread_block_sizze_30568) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
            int64_t num_virt_blocks_30570 = sdiv_up64(mz2080U_18678, segscan_tblock_sizze_28410 * chunk_sizze_30569);
            int64_t num_virt_threads_30571 = num_virt_blocks_30570 * segscan_tblock_sizze_28410;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30569, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_30572, num_virt_blocks_30570, "status_flags_mem_30572")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30572, num_virt_blocks_30570, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_30574, (int64_t) 4 * num_virt_blocks_30570, "aggregates_mem_30574")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_30576, (int64_t) 4 * num_virt_blocks_30570, "incprefixes_mem_30576")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_human_genericf32zisegscan_28415(ctx, num_tblocks_28412, 1, 1, *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28409, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28410), chunk_sizze_30569 * segscan_tblock_sizze_28410 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28410), chunk_sizze_30569 * segscan_tblock_sizze_28410 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_18678, num_tblocks_28412, num_virt_blocks_30570, num_virt_threads_30571, mem_param_29725.mem, mem_29737.mem, status_flags_mem_30572.mem, aggregates_mem_30574.mem, incprefixes_mem_30576.mem, global_dynid_mem_30578.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30667 = sext_i64_i32(sdiv_up64(mz2080U_18678, segmap_tblock_sizze_28502));
        
        {
            err = gpu_kernel_human_genericf32zisegmap_28506(ctx, segmap_usable_groups_28503, 1, 1, *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28419, 1, 1, (int64_t) 0, mz2080U_18678, loop_dz2081Uz2088Uz2087U_27123, mem_param_29725.mem, mem_param_29731.mem, mem_29737.mem, mem_29740.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (futrts_builtinzhreplicate_i32(ctx, mem_29742, mz2080U_18678, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i32(ctx, mem_29744, mz2080U_18678, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_tblocks_28588;
        int64_t max_num_tblocks_30676;
        
        max_num_tblocks_30676 = *ctx->tuning_params.human_genericf32ziseghist_num_tblocks_28587;
        num_tblocks_28588 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27123, seghist_tblock_sizze_28586), max_num_tblocks_30676)));
        
        int64_t num_subhistos_30677;
        int64_t h_30682 = (int64_t) 4 * mz2080U_18678 + (int64_t) 4 * mz2080U_18678;
        int64_t seg_h_30683 = (int64_t) 4 * mz2080U_18678 + (int64_t) 4 * mz2080U_18678;
        
        if (!(seg_h_30683 == (int64_t) 0)) {
            int64_t hist_H_30684 = mz2080U_18678;
            int64_t hist_el_sizze_30685 = sdiv_up64(h_30682, hist_H_30684);
            int64_t hist_N_30686 = loop_dz2081Uz2088Uz2087U_27123;
            int32_t hist_RF_30687 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegHist");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_28588 * seghist_tblock_sizze_28586), '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_28586, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30684, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_30686, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_30685, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_30687, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_30682, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_30683, '\n');
            
            int64_t hist_L_30688;
            
            hist_L_30688 = *ctx->tuning_params.human_genericf32zihist_L_30688;
            
            int64_t max_tblock_sizze_30689;
            
            max_tblock_sizze_30689 = ctx->max_thread_block_size;
            
            int64_t num_tblocks_30690 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_28588 * seghist_tblock_sizze_28586)), max_tblock_sizze_30689);
            double hist_m_prime_30691 = sitofp_i64_f64(smin64(squot64(hist_L_30688, hist_el_sizze_30685), sdiv_up64(hist_N_30686, num_tblocks_30690))) / sitofp_i64_f64(hist_H_30684);
            int64_t hist_M0_30692 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_30691), max_tblock_sizze_30689));
            int64_t hist_Nout_30693 = (int64_t) 1;
            int64_t hist_Nin_30694 = loop_dz2081Uz2088Uz2087U_27123;
            int64_t work_asymp_M_max_30695 = squot64(hist_Nout_30693 * hist_N_30686, (int64_t) 2 * num_tblocks_30690 * hist_H_30684);
            int32_t hist_M_30696 = sext_i64_i32(smin64(hist_M0_30692, work_asymp_M_max_30695));
            int64_t hist_C_30697 = sdiv_up64(max_tblock_sizze_30689, sext_i32_i64(smax32(1, hist_M_30696)));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_30692, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_30695, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_30697, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_30689, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_30696, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_30684 * hist_el_sizze_30685 * sext_i32_i64(hist_M_30696)), '\n');
            
            int64_t local_mem_needed_30698 = hist_el_sizze_30685 * sext_i32_i64(hist_M_30696);
            int32_t hist_S_30699 = sext_i64_i32(sdiv_up64(hist_H_30684 * local_mem_needed_30698 + (int64_t) 1, hist_L_30688));
            
            if (sle64(hist_H_30684, hist_Nin_30694) && (sle64(local_mem_needed_30698, hist_L_30688) && (sle32(hist_S_30699, 3) && (sle64(hist_C_30697, max_tblock_sizze_30689) && slt32(0, hist_M_30696))))) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using shared memory");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30684, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30696, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_30697, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30699, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_30696, '\n');
                num_subhistos_30677 = num_tblocks_30690;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_30677, '\n');
                if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_18678 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30678")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_18678, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30678.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29744.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_18678})) != 0)
                        goto cleanup;
                }
                if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_18678 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30680")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_18678, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29742.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_18678})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_30700 = 0; chk_i_30700 < hist_S_30699; chk_i_30700++) {
                    int64_t num_segments_30701 = (int64_t) 1;
                    int64_t hist_H_chk_30702 = sdiv_up64(mz2080U_18678, sext_i32_i64(hist_S_30699));
                    int64_t histo_sizze_30703 = hist_H_chk_30702;
                    int32_t init_per_thread_30704 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_30696) * histo_sizze_30703, max_tblock_sizze_30689));
                    
                    {
                        err = gpu_kernel_human_genericf32ziseghist_local_28593(ctx, num_tblocks_30690, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8)), mz2080U_18678, loop_dz2081Uz2088Uz2087U_27123, num_subhistos_30677, num_tblocks_30690, hist_M_30696, chk_i_30700, num_segments_30701, hist_H_chk_30702, histo_sizze_30703, init_per_thread_30704, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                }
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using global memory");
                
                int64_t hist_H_30745 = mz2080U_18678;
                double hist_RF_30746 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
                int32_t hist_el_sizze_30747 = 4;
                double hist_C_max_30748 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28588 * seghist_tblock_sizze_28586)), sitofp_i32_f64(hist_H_30745) / 2.0);
                int32_t hist_M_min_30749 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28588 * seghist_tblock_sizze_28586)) / hist_C_max_30748)));
                int64_t hist_L2_30750;
                
                hist_L2_30750 = *ctx->tuning_params.human_genericf32zihist_L2_30750;
                
                double hist_RACE_exp_30751 = fmax64(1.0, 0.75 * hist_RF_30746 / (64.0 / sitofp_i32_f64(hist_el_sizze_30747)));
                int32_t hist_S_30752;
                
                if (slt64(loop_dz2081Uz2088Uz2087U_27123, hist_H_30745)) {
                    hist_S_30752 = 1;
                } else {
                    hist_S_30752 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_30749) * hist_H_30745 * sext_i32_i64(hist_el_sizze_30747), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_30750) * hist_RACE_exp_30751)));
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_30751, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30752, '\n');
                
                int64_t hist_H_chk_30753 = sdiv_up64(mz2080U_18678, sext_i32_i64(hist_S_30752));
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_30753, '\n');
                
                double hist_k_max_30754 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_30750) / sitofp_i32_f64(8)) * hist_RACE_exp_30751, sitofp_i32_f64(loop_dz2081Uz2088Uz2087U_27123)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_28588 * seghist_tblock_sizze_28586));
                int64_t hist_u_30755 = (int64_t) 2;
                double hist_C_30756 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28588 * seghist_tblock_sizze_28586)), sitofp_i32_f64(hist_u_30755 * hist_H_chk_30753) / hist_k_max_30754);
                int32_t hist_M_30757 = 1;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_30754, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30757, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_30756, '\n');
                num_subhistos_30677 = sext_i32_i64(hist_M_30757);
                if (hist_M_30757 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_18678 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30678")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_18678, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30678.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29744.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_18678})) != 0)
                        goto cleanup;
                }
                if (hist_M_30757 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_18678 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30680")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_18678, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29742.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_18678})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_30758 = 0; chk_i_30758 < hist_S_30752; chk_i_30758++) {
                    int64_t hist_H_chk_30759 = sdiv_up64(mz2080U_18678, sext_i32_i64(hist_S_30752));
                    
                    {
                        err = gpu_kernel_human_genericf32ziseghist_global_28593(ctx, num_tblocks_28588, 1, 1, *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585, 1, 1, (int64_t) 0, mz2080U_18678, loop_dz2081Uz2088Uz2087U_27123, num_tblocks_28588, num_subhistos_30677, chk_i_30758, hist_H_chk_30759, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                }
            }
            if (num_subhistos_30677 == (int64_t) 1) {
                if (memblock_set_device(ctx, &mem_29744, &defunc_0_map_res_subhistos_mem_30678, "defunc_0_map_res_subhistos_mem_30678") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_29742, &defunc_0_map_res_subhistos_mem_30680, "defunc_0_map_res_subhistos_mem_30680") != 0)
                    return 1;
            } else {
                int64_t chunk_sizze_30776 = (int64_t) 1;
                
                if (slt64(num_subhistos_30677 * (int64_t) 2, seghist_tblock_sizze_28586 * chunk_sizze_30776)) {
                    int64_t segment_sizze_nonzzero_30777 = smax64((int64_t) 1, num_subhistos_30677);
                    int64_t num_threads_30778 = seghist_tblock_sizze_28586 * seghist_tblock_sizze_28586;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_18678, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30677, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_18678, squot64(seghist_tblock_sizze_28586, segment_sizze_nonzzero_30777))), '\n');
                    {
                        err = gpu_kernel_human_genericf32zisegred_small_30775(ctx, num_tblocks_28588, 1, 1, *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585, 1, 1, (int64_t) 4 * seghist_tblock_sizze_28586 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28586, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_28586 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28586, (int64_t) 8), (int64_t) 8)), mz2080U_18678, num_tblocks_28588, num_subhistos_30677, segment_sizze_nonzzero_30777, mem_29742.mem, mem_29744.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_30813 = sdiv_up64(num_tblocks_28588, smax64((int64_t) 1, mz2080U_18678));
                    int64_t q_30814 = sdiv_up64(num_subhistos_30677, seghist_tblock_sizze_28586 * blocks_per_segment_30813 * chunk_sizze_30776);
                    int64_t num_virtblocks_30815 = blocks_per_segment_30813 * mz2080U_18678;
                    int64_t threads_per_segment_30816 = blocks_per_segment_30813 * seghist_tblock_sizze_28586;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_18678, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30677, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_30815, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_28588, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_28586, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_30814, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_30813, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_30817, (int64_t) 4 * num_virtblocks_30815, "segred_tmp_mem_30817")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_30819, (int64_t) 4 * num_virtblocks_30815, "segred_tmp_mem_30819")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_human_genericf32zisegred_large_30775(ctx, num_tblocks_28588, 1, 1, *ctx->tuning_params.human_genericf32ziseghist_tblock_sizze_28585, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_28586 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28586, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_28586 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28586, (int64_t) 8), (int64_t) 8)), mz2080U_18678, num_tblocks_28588, num_subhistos_30677, blocks_per_segment_30813, q_30814, num_virtblocks_30815, threads_per_segment_30816, mem_29742.mem, mem_29744.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem, segred_tmp_mem_30817.mem, segred_tmp_mem_30819.mem, counters_mem_30821.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_alloc_device(ctx, &mem_29748, bytes_29691, "mem_29748")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29750, bytes_29691, "mem_29750")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29752, bytes_29691, "mem_29752")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30864 = sext_i64_i32(sdiv_up64(mz2080U_18678, segmap_tblock_sizze_28649));
        
        {
            err = gpu_kernel_human_genericf32zisegmap_28656(ctx, segmap_usable_groups_28650, 1, 1, *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28615, 1, 1, (int64_t) 0, mz2080U_18678, mem_param_29722.mem, mem_param_29725.mem, mem_param_29734.mem, mem_29740.mem, mem_29742.mem, mem_29744.mem, mem_29748.mem, mem_29750.mem, mem_29752.mem, mem_29754.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t num_tblocks_28689;
        int64_t max_num_tblocks_30873;
        
        max_num_tblocks_30873 = *ctx->tuning_params.human_genericf32zisegscan_num_tblocks_28688;
        num_tblocks_28689 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27123, segscan_tblock_sizze_28687), max_num_tblocks_30873)));
        
        int64_t bytes_29756 = (int64_t) 8 * loop_dz2081Uz2088Uz2087U_27123;
        
        if (memblock_alloc_device(ctx, &mem_29757, bytes_29756, "mem_29757")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29759, bytes_29756, "mem_29759")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, loop_dz2081Uz2088Uz2087U_27123)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_30874;
            
            shared_memory_30874 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_30875;
            
            thread_block_sizze_30875 = ctx->max_thread_block_size;
            
            int64_t registers_30876;
            
            registers_30876 = ctx->max_registers;
            
            int64_t thread_block_sizze_30877;
            
            thread_block_sizze_30877 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_30878 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30874, thread_block_sizze_30875), (int64_t) 8), squot64(squot64(registers_30876, thread_block_sizze_30877) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_30879 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27123, segscan_tblock_sizze_28687 * chunk_sizze_30878);
            int64_t num_virt_threads_30880 = num_virt_blocks_30879 * segscan_tblock_sizze_28687;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30878, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_30881, num_virt_blocks_30879, "status_flags_mem_30881")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30881, num_virt_blocks_30879, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_30883, (int64_t) 8 * num_virt_blocks_30879, "aggregates_mem_30883")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_30885, (int64_t) 8 * num_virt_blocks_30879, "incprefixes_mem_30885")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_human_genericf32zisegscan_28692(ctx, num_tblocks_28689, 1, 1, *ctx->tuning_params.human_genericf32zisegscan_tblock_sizze_28686, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28687), chunk_sizze_30878 * segscan_tblock_sizze_28687 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28687), chunk_sizze_30878 * segscan_tblock_sizze_28687 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_18678, loop_dz2081Uz2088Uz2087U_27123, num_tblocks_28689, num_virt_blocks_30879, num_virt_threads_30880, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, mem_29754.mem, mem_29757.mem, mem_29759.mem, status_flags_mem_30881.mem, aggregates_mem_30883.mem, incprefixes_mem_30885.mem, global_dynid_mem_30887.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        bool cond_27333 = loop_dz2081Uz2088Uz2087U_27123 == (int64_t) 0;
        bool x_27334 = !cond_27333;
        int64_t tmp_27335 = sub64(loop_dz2081Uz2088Uz2087U_27123, (int64_t) 1);
        bool x_27336 = sle64((int64_t) 0, tmp_27335);
        bool y_27337 = slt64(tmp_27335, loop_dz2081Uz2088Uz2087U_27123);
        bool bounds_check_27338 = x_27336 && y_27337;
        bool protect_assert_disj_27339 = cond_27333 || bounds_check_27338;
        bool index_certs_27340;
        
        if (!protect_assert_disj_27339) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_27335, "] out of bounds for array of shape [", (long long) loop_dz2081Uz2088Uz2087U_27123, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:11:1-77\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t m_f_res_27341;
        
        if (x_27334) {
            int64_t read_res_30992;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_30992, mem_29757.mem, tmp_27335 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_28179 = read_res_30992;
            
            m_f_res_27341 = x_28179;
        } else {
            m_f_res_27341 = (int64_t) 0;
        }
        
        int64_t m_27343;
        
        if (cond_27333) {
            m_27343 = (int64_t) 0;
        } else {
            m_27343 = m_f_res_27341;
        }
        
        int64_t m_27353 = sub64(m_27343, (int64_t) 1);
        bool i_p_m_t_s_leq_w_27355 = slt64(m_27353, loop_dz2081Uz2088Uz2087U_27123);
        bool zzero_leq_i_p_m_t_s_27354 = sle64((int64_t) 0, m_27353);
        bool y_27357 = zzero_leq_i_p_m_t_s_27354 && i_p_m_t_s_leq_w_27355;
        bool i_lte_j_27356 = sle64((int64_t) 0, m_27343);
        bool forwards_ok_27358 = i_lte_j_27356 && y_27357;
        bool eq_x_zz_27350 = (int64_t) 0 == m_f_res_27341;
        bool p_and_eq_x_y_27351 = x_27334 && eq_x_zz_27350;
        bool empty_slice_27352 = cond_27333 || p_and_eq_x_y_27351;
        bool ok_or_empty_27359 = empty_slice_27352 || forwards_ok_27358;
        bool index_certs_27360;
        
        if (!ok_or_empty_27359) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_27343, "] out of bounds for array of shape [", (long long) loop_dz2081Uz2088Uz2087U_27123, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:11:1-77\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_29760 = (int64_t) 4 * m_27343;
        
        if (memblock_alloc_device(ctx, &mem_29761, bytes_29760, "mem_29761")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29761.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_29728.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27343})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_29763, bytes_29760, "mem_29763")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29763.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_29731.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27343})) != 0)
            goto cleanup;
        
        int64_t num_tblocks_28699;
        int64_t max_num_tblocks_30976;
        
        max_num_tblocks_30976 = *ctx->tuning_params.human_genericf32zisegmap_num_tblocks_28698;
        num_tblocks_28699 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27123, segmap_tblock_sizze_28697), max_num_tblocks_30976)));
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30977 = sext_i64_i32(sdiv_up64(loop_dz2081Uz2088Uz2087U_27123, segmap_tblock_sizze_28697));
        
        {
            err = gpu_kernel_human_genericf32zisegmap_28694(ctx, num_tblocks_28699, 1, 1, *ctx->tuning_params.human_genericf32zisegmap_tblock_sizze_28696, 1, 1, (int64_t) 0, loop_dz2081Uz2088Uz2087U_27123, m_27343, num_tblocks_28699, virt_num_tblocks_30977, mem_param_29728.mem, mem_param_29731.mem, mem_29757.mem, mem_29759.mem, mem_29761.mem, mem_29763.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_29757, "mem_29757") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29759, "mem_29759") != 0)
            return 1;
        
        bool loop_cond_27370 = slt64((int64_t) 0, m_27343);
        
        if (memblock_set_device(ctx, &mem_param_tmp_30553, &mem_29750, "mem_29750") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30554, &mem_29748, "mem_29748") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30555, &mem_29761, "mem_29761") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30556, &mem_29763, "mem_29763") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30557, &mem_29752, "mem_29752") != 0)
            return 1;
        
        int64_t loop_dz2081Uz2088Uz2087U_tmp_30558 = m_27343;
        bool loop_while_tmp_30559 = loop_cond_27370;
        
        if (memblock_set_device(ctx, &mem_param_29722, &mem_param_tmp_30553, "mem_param_tmp_30553") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29725, &mem_param_tmp_30554, "mem_param_tmp_30554") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29728, &mem_param_tmp_30555, "mem_param_tmp_30555") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29731, &mem_param_tmp_30556, "mem_param_tmp_30556") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29734, &mem_param_tmp_30557, "mem_param_tmp_30557") != 0)
            return 1;
        loop_dz2081Uz2088Uz2087U_27123 = loop_dz2081Uz2088Uz2087U_tmp_30558;
        loop_while_27124 = loop_while_tmp_30559;
    }
    if (memblock_set_device(ctx, &ext_mem_29779, &mem_param_29722, "mem_param_29722") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29778, &mem_param_29725, "mem_param_29725") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29777, &mem_param_29728, "mem_param_29728") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29776, &mem_param_29731, "mem_param_29731") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29775, &mem_param_29734, "mem_param_29734") != 0)
        return 1;
    result_27116 = loop_dz2081Uz2088Uz2087U_27123;
    result_27117 = loop_while_27124;
    if (memblock_unref_device(ctx, &mem_29703, "mem_29703") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29705, "mem_29705") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29707, "mem_29707") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29716, "mem_29716") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29718, "mem_29718") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29737, "mem_29737") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29740, "mem_29740") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29742, "mem_29742") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29744, "mem_29744") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29754, "mem_29754") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_29788, &ext_mem_29775, "ext_mem_29775") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_30990, &mem_out_29788, "mem_out_29788") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_param_tmp_30557, "mem_param_tmp_30557") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30556, "mem_param_tmp_30556") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30555, "mem_param_tmp_30555") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30554, "mem_param_tmp_30554") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30553, "mem_param_tmp_30553") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29763, "mem_29763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29761, "mem_29761") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30885, "incprefixes_mem_30885") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30883, "aggregates_mem_30883") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30881, "status_flags_mem_30881") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29759, "mem_29759") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29757, "mem_29757") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29752, "mem_29752") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29750, "mem_29750") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29748, "mem_29748") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30819, "segred_tmp_mem_30819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30817, "segred_tmp_mem_30817") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30680, "defunc_0_map_res_subhistos_mem_30680") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30678, "defunc_0_map_res_subhistos_mem_30678") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30576, "incprefixes_mem_30576") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30574, "aggregates_mem_30574") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30572, "status_flags_mem_30572") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29734, "mem_param_29734") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29731, "mem_param_29731") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29728, "mem_param_29728") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29725, "mem_param_29725") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29722, "mem_param_29722") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29775, "ext_mem_29775") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29776, "ext_mem_29776") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29777, "ext_mem_29777") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29778, "ext_mem_29778") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29779, "ext_mem_29779") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29754, "mem_29754") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29744, "mem_29744") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29742, "mem_29742") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29740, "mem_29740") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29737, "mem_29737") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29718, "mem_29718") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29716, "mem_29716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30447, "incprefixes_mem_30447") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30445, "aggregates_mem_30445") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30443, "status_flags_mem_30443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29714, "mem_29714") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29712, "mem_29712") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29709, "mem_29709") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29707, "mem_29707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29705, "mem_29705") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29703, "mem_29703") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30381, "segred_tmp_mem_30381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30379, "segred_tmp_mem_30379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30242, "defunc_0_map_res_subhistos_mem_30242") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30240, "defunc_0_map_res_subhistos_mem_30240") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29699, "mem_29699") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29697, "mem_29697") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29695, "mem_29695") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30138, "incprefixes_mem_30138") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30136, "aggregates_mem_30136") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30134, "status_flags_mem_30134") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29692, "mem_29692") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29982, "incprefixes_mem_29982") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29980, "aggregates_mem_29980") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29978, "incprefixes_mem_29978") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29976, "aggregates_mem_29976") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_29974, "status_flags_mem_29974") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29689, "mem_29689") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29687, "mem_29687") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29684, "mem_29684") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29821, "incprefixes_mem_29821") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29819, "aggregates_mem_29819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_29797, "status_flags_mem_29797") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29683, "mem_29683") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_29788, "mem_out_29788") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_human_genericf64(struct futhark_context *ctx, struct memblock_device *mem_out_p_30993, struct memblock_device ks_mem_29677, struct memblock_device shp_mem_29678, struct memblock_device II1_mem_29679, struct memblock_device A_mem_29680, int64_t mz2080U_21995, int64_t nz2081U_21996)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_param_tmp_30557;
    
    mem_param_tmp_30557.references = NULL;
    
    struct memblock_device mem_param_tmp_30556;
    
    mem_param_tmp_30556.references = NULL;
    
    struct memblock_device mem_param_tmp_30555;
    
    mem_param_tmp_30555.references = NULL;
    
    struct memblock_device mem_param_tmp_30554;
    
    mem_param_tmp_30554.references = NULL;
    
    struct memblock_device mem_param_tmp_30553;
    
    mem_param_tmp_30553.references = NULL;
    
    struct memblock_device mem_29763;
    
    mem_29763.references = NULL;
    
    struct memblock_device mem_29761;
    
    mem_29761.references = NULL;
    
    struct memblock_device incprefixes_mem_30885;
    
    incprefixes_mem_30885.references = NULL;
    
    struct memblock_device aggregates_mem_30883;
    
    aggregates_mem_30883.references = NULL;
    
    struct memblock_device status_flags_mem_30881;
    
    status_flags_mem_30881.references = NULL;
    
    struct memblock_device mem_29759;
    
    mem_29759.references = NULL;
    
    struct memblock_device mem_29757;
    
    mem_29757.references = NULL;
    
    struct memblock_device mem_29752;
    
    mem_29752.references = NULL;
    
    struct memblock_device mem_29750;
    
    mem_29750.references = NULL;
    
    struct memblock_device mem_29748;
    
    mem_29748.references = NULL;
    
    struct memblock_device segred_tmp_mem_30819;
    
    segred_tmp_mem_30819.references = NULL;
    
    struct memblock_device segred_tmp_mem_30817;
    
    segred_tmp_mem_30817.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30680;
    
    defunc_0_map_res_subhistos_mem_30680.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30678;
    
    defunc_0_map_res_subhistos_mem_30678.references = NULL;
    
    struct memblock_device incprefixes_mem_30576;
    
    incprefixes_mem_30576.references = NULL;
    
    struct memblock_device aggregates_mem_30574;
    
    aggregates_mem_30574.references = NULL;
    
    struct memblock_device status_flags_mem_30572;
    
    status_flags_mem_30572.references = NULL;
    
    struct memblock_device mem_param_29734;
    
    mem_param_29734.references = NULL;
    
    struct memblock_device mem_param_29731;
    
    mem_param_29731.references = NULL;
    
    struct memblock_device mem_param_29728;
    
    mem_param_29728.references = NULL;
    
    struct memblock_device mem_param_29725;
    
    mem_param_29725.references = NULL;
    
    struct memblock_device mem_param_29722;
    
    mem_param_29722.references = NULL;
    
    struct memblock_device ext_mem_29775;
    
    ext_mem_29775.references = NULL;
    
    struct memblock_device ext_mem_29776;
    
    ext_mem_29776.references = NULL;
    
    struct memblock_device ext_mem_29777;
    
    ext_mem_29777.references = NULL;
    
    struct memblock_device ext_mem_29778;
    
    ext_mem_29778.references = NULL;
    
    struct memblock_device ext_mem_29779;
    
    ext_mem_29779.references = NULL;
    
    struct memblock_device mem_29754;
    
    mem_29754.references = NULL;
    
    struct memblock_device mem_29744;
    
    mem_29744.references = NULL;
    
    struct memblock_device mem_29742;
    
    mem_29742.references = NULL;
    
    struct memblock_device mem_29740;
    
    mem_29740.references = NULL;
    
    struct memblock_device mem_29737;
    
    mem_29737.references = NULL;
    
    struct memblock_device mem_29718;
    
    mem_29718.references = NULL;
    
    struct memblock_device mem_29716;
    
    mem_29716.references = NULL;
    
    struct memblock_device incprefixes_mem_30447;
    
    incprefixes_mem_30447.references = NULL;
    
    struct memblock_device aggregates_mem_30445;
    
    aggregates_mem_30445.references = NULL;
    
    struct memblock_device status_flags_mem_30443;
    
    status_flags_mem_30443.references = NULL;
    
    struct memblock_device mem_29714;
    
    mem_29714.references = NULL;
    
    struct memblock_device mem_29712;
    
    mem_29712.references = NULL;
    
    struct memblock_device mem_29709;
    
    mem_29709.references = NULL;
    
    struct memblock_device mem_29707;
    
    mem_29707.references = NULL;
    
    struct memblock_device mem_29705;
    
    mem_29705.references = NULL;
    
    struct memblock_device mem_29703;
    
    mem_29703.references = NULL;
    
    struct memblock_device segred_tmp_mem_30381;
    
    segred_tmp_mem_30381.references = NULL;
    
    struct memblock_device segred_tmp_mem_30379;
    
    segred_tmp_mem_30379.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30242;
    
    defunc_0_map_res_subhistos_mem_30242.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30240;
    
    defunc_0_map_res_subhistos_mem_30240.references = NULL;
    
    struct memblock_device mem_29699;
    
    mem_29699.references = NULL;
    
    struct memblock_device mem_29697;
    
    mem_29697.references = NULL;
    
    struct memblock_device mem_29695;
    
    mem_29695.references = NULL;
    
    struct memblock_device incprefixes_mem_30138;
    
    incprefixes_mem_30138.references = NULL;
    
    struct memblock_device aggregates_mem_30136;
    
    aggregates_mem_30136.references = NULL;
    
    struct memblock_device status_flags_mem_30134;
    
    status_flags_mem_30134.references = NULL;
    
    struct memblock_device mem_29692;
    
    mem_29692.references = NULL;
    
    struct memblock_device incprefixes_mem_29982;
    
    incprefixes_mem_29982.references = NULL;
    
    struct memblock_device aggregates_mem_29980;
    
    aggregates_mem_29980.references = NULL;
    
    struct memblock_device incprefixes_mem_29978;
    
    incprefixes_mem_29978.references = NULL;
    
    struct memblock_device aggregates_mem_29976;
    
    aggregates_mem_29976.references = NULL;
    
    struct memblock_device status_flags_mem_29974;
    
    status_flags_mem_29974.references = NULL;
    
    struct memblock_device mem_29689;
    
    mem_29689.references = NULL;
    
    struct memblock_device mem_29687;
    
    mem_29687.references = NULL;
    
    struct memblock_device mem_29684;
    
    mem_29684.references = NULL;
    
    struct memblock_device incprefixes_mem_29821;
    
    incprefixes_mem_29821.references = NULL;
    
    struct memblock_device aggregates_mem_29819;
    
    aggregates_mem_29819.references = NULL;
    
    struct memblock_device status_flags_mem_29797;
    
    status_flags_mem_29797.references = NULL;
    
    struct memblock_device mem_29683;
    
    mem_29683.references = NULL;
    
    struct memblock_device mem_out_29788;
    
    mem_out_29788.references = NULL;
    
    struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
    struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
    struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
    struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
    struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
    struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
    struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
    struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
    int64_t segscan_tblock_sizze_28703;
    
    segscan_tblock_sizze_28703 = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28702;
    
    int64_t num_tblocks_28705;
    int64_t max_num_tblocks_29789;
    
    max_num_tblocks_29789 = *ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28704;
    num_tblocks_28705 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_21995, segscan_tblock_sizze_28703), max_num_tblocks_29789)));
    
    int64_t bytes_29682 = (int64_t) 8 * mz2080U_21995;
    
    if (memblock_alloc_device(ctx, &mem_29683, bytes_29682, "mem_29683")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_21995)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_29790;
        
        shared_memory_29790 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_29791;
        
        thread_block_sizze_29791 = ctx->max_thread_block_size;
        
        int64_t registers_29792;
        
        registers_29792 = ctx->max_registers;
        
        int64_t thread_block_sizze_29793;
        
        thread_block_sizze_29793 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_29794 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_29790, thread_block_sizze_29791), (int64_t) 8), squot64(squot64(registers_29792, thread_block_sizze_29793) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_29795 = sdiv_up64(mz2080U_21995, segscan_tblock_sizze_28703 * chunk_sizze_29794);
        int64_t num_virt_threads_29796 = num_virt_blocks_29795 * segscan_tblock_sizze_28703;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_29794, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_29797, num_virt_blocks_29795, "status_flags_mem_29797")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_29797, num_virt_blocks_29795, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29819, (int64_t) 8 * num_virt_blocks_29795, "aggregates_mem_29819")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29821, (int64_t) 8 * num_virt_blocks_29795, "incprefixes_mem_29821")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_genericf64zisegscan_28708(ctx, num_tblocks_28705, 1, 1, *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28702, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28703), chunk_sizze_29794 * segscan_tblock_sizze_28703 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28703), chunk_sizze_29794 * segscan_tblock_sizze_28703 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_21995, num_tblocks_28705, num_virt_blocks_29795, num_virt_threads_29796, shp_mem_29678.mem, mem_29683.mem, status_flags_mem_29797.mem, aggregates_mem_29819.mem, incprefixes_mem_29821.mem, global_dynid_mem_29823.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_alloc_device(ctx, &mem_29684, nz2081U_21996, "mem_29684")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_29684, nz2081U_21996, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_28713;
    
    segmap_tblock_sizze_28713 = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28712;
    
    int64_t num_tblocks_28715;
    int64_t max_num_tblocks_29952;
    
    max_num_tblocks_29952 = *ctx->tuning_params.human_genericf64zisegmap_num_tblocks_28714;
    num_tblocks_28715 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_21995, segmap_tblock_sizze_28713), max_num_tblocks_29952)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_29953 = sext_i64_i32(sdiv_up64(mz2080U_21995, segmap_tblock_sizze_28713));
    
    {
        err = gpu_kernel_human_genericf64zisegmap_28710(ctx, num_tblocks_28715, 1, 1, *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28712, 1, 1, (int64_t) 0, mz2080U_21995, nz2081U_21996, num_tblocks_28715, virt_num_tblocks_29953, mem_29683.mem, mem_29684.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29683, "mem_29683") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_28719;
    
    segscan_tblock_sizze_28719 = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28718;
    
    int64_t num_tblocks_28721;
    int64_t max_num_tblocks_29966;
    
    max_num_tblocks_29966 = *ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28720;
    num_tblocks_28721 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_21996, segscan_tblock_sizze_28719), max_num_tblocks_29966)));
    
    int64_t bytes_29688 = (int64_t) 8 * nz2081U_21996;
    
    if (memblock_alloc_device(ctx, &mem_29687, nz2081U_21996, "mem_29687")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29689, bytes_29688, "mem_29689")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_21996)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_29967;
        
        shared_memory_29967 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_29968;
        
        thread_block_sizze_29968 = ctx->max_thread_block_size;
        
        int64_t registers_29969;
        
        registers_29969 = ctx->max_registers;
        
        int64_t thread_block_sizze_29970;
        
        thread_block_sizze_29970 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_29971 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_29967, thread_block_sizze_29968), (int64_t) 8), squot64(squot64(registers_29969, thread_block_sizze_29970) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_29972 = sdiv_up64(nz2081U_21996, segscan_tblock_sizze_28719 * chunk_sizze_29971);
        int64_t num_virt_threads_29973 = num_virt_blocks_29972 * segscan_tblock_sizze_28719;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_29971, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_29974, num_virt_blocks_29972, "status_flags_mem_29974")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_29974, num_virt_blocks_29972, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29976, num_virt_blocks_29972, "aggregates_mem_29976")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29978, num_virt_blocks_29972, "incprefixes_mem_29978")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29980, (int64_t) 8 * num_virt_blocks_29972, "aggregates_mem_29980")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29982, (int64_t) 8 * num_virt_blocks_29972, "incprefixes_mem_29982")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_genericf64zisegscan_28724(ctx, num_tblocks_28721, 1, 1, *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28718, 1, 1, smax64(smax64((int64_t) 320, sdiv_up64(segscan_tblock_sizze_28719, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_28719), smax64(chunk_sizze_29971 * segscan_tblock_sizze_28719, chunk_sizze_29971 * segscan_tblock_sizze_28719 * (int64_t) 8)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 320, sdiv_up64(segscan_tblock_sizze_28719, (int64_t) 8) * (int64_t) 8 + (int64_t) 8 * segscan_tblock_sizze_28719), smax64(chunk_sizze_29971 * segscan_tblock_sizze_28719, chunk_sizze_29971 * segscan_tblock_sizze_28719 * (int64_t) 8)), (int64_t) 8), (int64_t) 8), nz2081U_21996, num_tblocks_28721, num_virt_blocks_29972, num_virt_threads_29973, A_mem_29680.mem, mem_29684.mem, mem_29687.mem, mem_29689.mem, status_flags_mem_29974.mem, aggregates_mem_29976.mem, incprefixes_mem_29978.mem, aggregates_mem_29980.mem, incprefixes_mem_29982.mem, global_dynid_mem_29984.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_29684, "mem_29684") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29687, "mem_29687") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_28727;
    
    segscan_tblock_sizze_28727 = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28726;
    
    int64_t num_tblocks_28729;
    int64_t max_num_tblocks_30126;
    
    max_num_tblocks_30126 = *ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28728;
    num_tblocks_28729 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_21995, segscan_tblock_sizze_28727), max_num_tblocks_30126)));
    
    int64_t bytes_29691 = (int64_t) 4 * mz2080U_21995;
    
    if (memblock_alloc_device(ctx, &mem_29692, bytes_29691, "mem_29692")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_21995)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_30127;
        
        shared_memory_30127 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_30128;
        
        thread_block_sizze_30128 = ctx->max_thread_block_size;
        
        int64_t registers_30129;
        
        registers_30129 = ctx->max_registers;
        
        int64_t thread_block_sizze_30130;
        
        thread_block_sizze_30130 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_30131 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30127, thread_block_sizze_30128), (int64_t) 4), squot64(squot64(registers_30129, thread_block_sizze_30130) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_30132 = sdiv_up64(mz2080U_21995, segscan_tblock_sizze_28727 * chunk_sizze_30131);
        int64_t num_virt_threads_30133 = num_virt_blocks_30132 * segscan_tblock_sizze_28727;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30131, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_30134, num_virt_blocks_30132, "status_flags_mem_30134")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30134, num_virt_blocks_30132, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_30136, (int64_t) 4 * num_virt_blocks_30132, "aggregates_mem_30136")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_30138, (int64_t) 4 * num_virt_blocks_30132, "incprefixes_mem_30138")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_genericf64zisegscan_28732(ctx, num_tblocks_28729, 1, 1, *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28726, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28727), chunk_sizze_30131 * segscan_tblock_sizze_28727 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28727), chunk_sizze_30131 * segscan_tblock_sizze_28727 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_21995, num_tblocks_28729, num_virt_blocks_30132, num_virt_threads_30133, shp_mem_29678.mem, mem_29692.mem, status_flags_mem_30134.mem, aggregates_mem_30136.mem, incprefixes_mem_30138.mem, global_dynid_mem_30140.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_28758;
    
    segmap_tblock_sizze_28758 = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28736;
    
    int64_t segmap_usable_groups_28759 = sdiv_up64(mz2080U_21995, segmap_tblock_sizze_28758);
    
    if (memblock_alloc_device(ctx, &mem_29695, bytes_29682, "mem_29695")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30229 = sext_i64_i32(sdiv_up64(mz2080U_21995, segmap_tblock_sizze_28758));
    
    {
        err = gpu_kernel_human_genericf64zisegmap_28762(ctx, segmap_usable_groups_28759, 1, 1, *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28736, 1, 1, (int64_t) 0, mz2080U_21995, nz2081U_21996, shp_mem_29678.mem, mem_29689.mem, mem_29692.mem, mem_29695.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29689, "mem_29689") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29692, "mem_29692") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_29697, bytes_29691, "mem_29697")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_29697, mz2080U_21995, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29699, bytes_29691, "mem_29699")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_29699, mz2080U_21995, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t seghist_tblock_sizze_28781;
    
    seghist_tblock_sizze_28781 = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780;
    
    int64_t num_tblocks_28783;
    int64_t max_num_tblocks_30238;
    
    max_num_tblocks_30238 = *ctx->tuning_params.human_genericf64ziseghist_num_tblocks_28782;
    num_tblocks_28783 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_21996, seghist_tblock_sizze_28781), max_num_tblocks_30238)));
    
    int64_t num_subhistos_30239;
    int64_t h_30244 = (int64_t) 4 * mz2080U_21995 + (int64_t) 4 * mz2080U_21995;
    int64_t seg_h_30245 = (int64_t) 4 * mz2080U_21995 + (int64_t) 4 * mz2080U_21995;
    
    if (!(seg_h_30245 == (int64_t) 0)) {
        int64_t hist_H_30246 = mz2080U_21995;
        int64_t hist_el_sizze_30247 = sdiv_up64(h_30244, hist_H_30246);
        int64_t hist_N_30248 = nz2081U_21996;
        int32_t hist_RF_30249 = 1;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegHist");
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_28783 * seghist_tblock_sizze_28781), '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_28781, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30246, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_30248, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_30247, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_30249, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_30244, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_30245, '\n');
        
        int64_t hist_L_30250;
        
        hist_L_30250 = *ctx->tuning_params.human_genericf64zihist_L_30250;
        
        int64_t max_tblock_sizze_30251;
        
        max_tblock_sizze_30251 = ctx->max_thread_block_size;
        
        int64_t num_tblocks_30252 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_28783 * seghist_tblock_sizze_28781)), max_tblock_sizze_30251);
        double hist_m_prime_30253 = sitofp_i64_f64(smin64(squot64(hist_L_30250, hist_el_sizze_30247), sdiv_up64(hist_N_30248, num_tblocks_30252))) / sitofp_i64_f64(hist_H_30246);
        int64_t hist_M0_30254 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_30253), max_tblock_sizze_30251));
        int64_t hist_Nout_30255 = (int64_t) 1;
        int64_t hist_Nin_30256 = nz2081U_21996;
        int64_t work_asymp_M_max_30257 = squot64(hist_Nout_30255 * hist_N_30248, (int64_t) 2 * num_tblocks_30252 * hist_H_30246);
        int32_t hist_M_30258 = sext_i64_i32(smin64(hist_M0_30254, work_asymp_M_max_30257));
        int64_t hist_C_30259 = sdiv_up64(max_tblock_sizze_30251, sext_i32_i64(smax32(1, hist_M_30258)));
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_30254, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_30257, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_30259, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_30251, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_30258, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_30246 * hist_el_sizze_30247 * sext_i32_i64(hist_M_30258)), '\n');
        
        int64_t local_mem_needed_30260 = hist_el_sizze_30247 * sext_i32_i64(hist_M_30258);
        int32_t hist_S_30261 = sext_i64_i32(sdiv_up64(hist_H_30246 * local_mem_needed_30260 + (int64_t) 1, hist_L_30250));
        
        if (sle64(hist_H_30246, hist_Nin_30256) && (sle64(local_mem_needed_30260, hist_L_30250) && (sle32(hist_S_30261, 3) && (sle64(hist_C_30259, max_tblock_sizze_30251) && slt32(0, hist_M_30258))))) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using shared memory");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30246, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30258, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_30259, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30261, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_30258, '\n');
            num_subhistos_30239 = num_tblocks_30252;
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_30239, '\n');
            if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_21995 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30240")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_21995, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30240.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29699.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_21995})) != 0)
                    goto cleanup;
            }
            if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_21995 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30242")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_21995, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30242.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29697.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_21995})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_30262 = 0; chk_i_30262 < hist_S_30261; chk_i_30262++) {
                int64_t num_segments_30263 = (int64_t) 1;
                int64_t hist_H_chk_30264 = sdiv_up64(mz2080U_21995, sext_i32_i64(hist_S_30261));
                int64_t histo_sizze_30265 = hist_H_chk_30264;
                int32_t init_per_thread_30266 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_30258) * histo_sizze_30265, max_tblock_sizze_30251));
                
                {
                    err = gpu_kernel_human_genericf64ziseghist_local_28788(ctx, num_tblocks_30252, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8)), mz2080U_21995, nz2081U_21996, num_subhistos_30239, num_tblocks_30252, hist_M_30258, chk_i_30262, num_segments_30263, hist_H_chk_30264, histo_sizze_30265, init_per_thread_30266, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
            }
        } else {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using global memory");
            
            int64_t hist_H_30307 = mz2080U_21995;
            double hist_RF_30308 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
            int32_t hist_el_sizze_30309 = 4;
            double hist_C_max_30310 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28783 * seghist_tblock_sizze_28781)), sitofp_i32_f64(hist_H_30307) / 2.0);
            int32_t hist_M_min_30311 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28783 * seghist_tblock_sizze_28781)) / hist_C_max_30310)));
            int64_t hist_L2_30312;
            
            hist_L2_30312 = *ctx->tuning_params.human_genericf64zihist_L2_30312;
            
            double hist_RACE_exp_30313 = fmax64(1.0, 0.75 * hist_RF_30308 / (64.0 / sitofp_i32_f64(hist_el_sizze_30309)));
            int32_t hist_S_30314;
            
            if (slt64(nz2081U_21996, hist_H_30307)) {
                hist_S_30314 = 1;
            } else {
                hist_S_30314 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_30311) * hist_H_30307 * sext_i32_i64(hist_el_sizze_30309), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_30312) * hist_RACE_exp_30313)));
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_30313, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30314, '\n');
            
            int64_t hist_H_chk_30315 = sdiv_up64(mz2080U_21995, sext_i32_i64(hist_S_30314));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_30315, '\n');
            
            double hist_k_max_30316 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_30312) / sitofp_i32_f64(8)) * hist_RACE_exp_30313, sitofp_i32_f64(nz2081U_21996)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_28783 * seghist_tblock_sizze_28781));
            int64_t hist_u_30317 = (int64_t) 2;
            double hist_C_30318 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_28783 * seghist_tblock_sizze_28781)), sitofp_i32_f64(hist_u_30317 * hist_H_chk_30315) / hist_k_max_30316);
            int32_t hist_M_30319 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_30316, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30319, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_30318, '\n');
            num_subhistos_30239 = sext_i32_i64(hist_M_30319);
            if (hist_M_30319 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_21995 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30240")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_21995, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30240.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29699.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_21995})) != 0)
                    goto cleanup;
            }
            if (hist_M_30319 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_21995 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30242")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_21995, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30242.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29697.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_21995})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_30320 = 0; chk_i_30320 < hist_S_30314; chk_i_30320++) {
                int64_t hist_H_chk_30321 = sdiv_up64(mz2080U_21995, sext_i32_i64(hist_S_30314));
                
                {
                    err = gpu_kernel_human_genericf64ziseghist_global_28788(ctx, num_tblocks_28783, 1, 1, *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780, 1, 1, (int64_t) 0, mz2080U_21995, nz2081U_21996, num_tblocks_28783, num_subhistos_30239, chk_i_30320, hist_H_chk_30321, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
            }
        }
        if (num_subhistos_30239 == (int64_t) 1) {
            if (memblock_set_device(ctx, &mem_29699, &defunc_0_map_res_subhistos_mem_30240, "defunc_0_map_res_subhistos_mem_30240") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_29697, &defunc_0_map_res_subhistos_mem_30242, "defunc_0_map_res_subhistos_mem_30242") != 0)
                return 1;
        } else {
            int64_t chunk_sizze_30338 = (int64_t) 1;
            
            if (slt64(num_subhistos_30239 * (int64_t) 2, seghist_tblock_sizze_28781 * chunk_sizze_30338)) {
                int64_t segment_sizze_nonzzero_30339 = smax64((int64_t) 1, num_subhistos_30239);
                int64_t num_threads_30340 = seghist_tblock_sizze_28781 * seghist_tblock_sizze_28781;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-small");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_21995, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30239, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339), '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_21995, squot64(seghist_tblock_sizze_28781, segment_sizze_nonzzero_30339))), '\n');
                {
                    err = gpu_kernel_human_genericf64zisegred_small_30337(ctx, num_tblocks_28783, 1, 1, *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780, 1, 1, (int64_t) 4 * seghist_tblock_sizze_28781 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28781, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_28781 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28781, (int64_t) 8), (int64_t) 8)), mz2080U_21995, num_tblocks_28783, num_subhistos_30239, segment_sizze_nonzzero_30339, mem_29697.mem, mem_29699.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            } else {
                int64_t blocks_per_segment_30375 = sdiv_up64(num_tblocks_28783, smax64((int64_t) 1, mz2080U_21995));
                int64_t q_30376 = sdiv_up64(num_subhistos_30239, seghist_tblock_sizze_28781 * blocks_per_segment_30375 * chunk_sizze_30338);
                int64_t num_virtblocks_30377 = blocks_per_segment_30375 * mz2080U_21995;
                int64_t threads_per_segment_30378 = blocks_per_segment_30375 * seghist_tblock_sizze_28781;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-large");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_21995, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30239, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_30377, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_28783, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_28781, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_30376, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_30375, '\n');
                if (memblock_alloc_device(ctx, &segred_tmp_mem_30379, (int64_t) 4 * num_virtblocks_30377, "segred_tmp_mem_30379")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &segred_tmp_mem_30381, (int64_t) 4 * num_virtblocks_30377, "segred_tmp_mem_30381")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_human_genericf64zisegred_large_30337(ctx, num_tblocks_28783, 1, 1, *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_28780, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_28781 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28781, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_28781 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_28781, (int64_t) 8), (int64_t) 8)), mz2080U_21995, num_tblocks_28783, num_subhistos_30239, blocks_per_segment_30375, q_30376, num_virtblocks_30377, threads_per_segment_30378, mem_29697.mem, mem_29699.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem, segred_tmp_mem_30379.mem, segred_tmp_mem_30381.mem, counters_mem_30383.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segmap_tblock_sizze_28843;
    
    segmap_tblock_sizze_28843 = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28810;
    
    int64_t segmap_usable_groups_28844 = sdiv_up64(mz2080U_21995, segmap_tblock_sizze_28843);
    
    if (memblock_alloc_device(ctx, &mem_29703, bytes_29691, "mem_29703")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29705, bytes_29691, "mem_29705")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29707, bytes_29682, "mem_29707")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29709, bytes_29691, "mem_29709")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30426 = sext_i64_i32(sdiv_up64(mz2080U_21995, segmap_tblock_sizze_28843));
    
    {
        err = gpu_kernel_human_genericf64zisegmap_28850(ctx, segmap_usable_groups_28844, 1, 1, *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28810, 1, 1, (int64_t) 0, mz2080U_21995, ks_mem_29677.mem, shp_mem_29678.mem, mem_29695.mem, mem_29697.mem, mem_29699.mem, mem_29703.mem, mem_29705.mem, mem_29707.mem, mem_29709.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29697, "mem_29697") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29699, "mem_29699") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_28880;
    
    segscan_tblock_sizze_28880 = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28879;
    
    int64_t num_tblocks_28882;
    int64_t max_num_tblocks_30435;
    
    max_num_tblocks_30435 = *ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28881;
    num_tblocks_28882 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_21996, segscan_tblock_sizze_28880), max_num_tblocks_30435)));
    if (memblock_alloc_device(ctx, &mem_29712, bytes_29688, "mem_29712")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29714, bytes_29688, "mem_29714")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_21996)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_30436;
        
        shared_memory_30436 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_30437;
        
        thread_block_sizze_30437 = ctx->max_thread_block_size;
        
        int64_t registers_30438;
        
        registers_30438 = ctx->max_registers;
        
        int64_t thread_block_sizze_30439;
        
        thread_block_sizze_30439 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_30440 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30436, thread_block_sizze_30437), (int64_t) 8), squot64(squot64(registers_30438, thread_block_sizze_30439) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_30441 = sdiv_up64(nz2081U_21996, segscan_tblock_sizze_28880 * chunk_sizze_30440);
        int64_t num_virt_threads_30442 = num_virt_blocks_30441 * segscan_tblock_sizze_28880;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30440, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_30443, num_virt_blocks_30441, "status_flags_mem_30443")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30443, num_virt_blocks_30441, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_30445, (int64_t) 8 * num_virt_blocks_30441, "aggregates_mem_30445")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_30447, (int64_t) 8 * num_virt_blocks_30441, "incprefixes_mem_30447")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_genericf64zisegscan_28885(ctx, num_tblocks_28882, 1, 1, *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28879, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28880), chunk_sizze_30440 * segscan_tblock_sizze_28880 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_28880), chunk_sizze_30440 * segscan_tblock_sizze_28880 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_21995, nz2081U_21996, num_tblocks_28882, num_virt_blocks_30441, num_virt_threads_30442, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, mem_29709.mem, mem_29712.mem, mem_29714.mem, status_flags_mem_30443.mem, aggregates_mem_30445.mem, incprefixes_mem_30447.mem, global_dynid_mem_30449.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_29695, "mem_29695") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29709, "mem_29709") != 0)
        return 1;
    
    bool cond_27079 = nz2081U_21996 == (int64_t) 0;
    bool x_27080 = !cond_27079;
    int64_t tmp_27081 = sub64(nz2081U_21996, (int64_t) 1);
    bool x_27082 = sle64((int64_t) 0, tmp_27081);
    bool y_27083 = slt64(tmp_27081, nz2081U_21996);
    bool bounds_check_27084 = x_27082 && y_27083;
    bool protect_assert_disj_27085 = cond_27079 || bounds_check_27084;
    bool index_certs_27086;
    
    if (!protect_assert_disj_27085) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_27081, "] out of bounds for array of shape [", (long long) nz2081U_21996, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:21:1-108\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_27087;
    
    if (x_27080) {
        int64_t read_res_30994;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_30994, mem_29712.mem, tmp_27081 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_28161 = read_res_30994;
        
        m_f_res_27087 = x_28161;
    } else {
        m_f_res_27087 = (int64_t) 0;
    }
    
    int64_t m_27089;
    
    if (cond_27079) {
        m_27089 = (int64_t) 0;
    } else {
        m_27089 = m_f_res_27087;
    }
    
    int64_t m_27099 = sub64(m_27089, (int64_t) 1);
    bool i_p_m_t_s_leq_w_27101 = slt64(m_27099, nz2081U_21996);
    bool zzero_leq_i_p_m_t_s_27100 = sle64((int64_t) 0, m_27099);
    bool y_27103 = zzero_leq_i_p_m_t_s_27100 && i_p_m_t_s_leq_w_27101;
    bool i_lte_j_27102 = sle64((int64_t) 0, m_27089);
    bool forwards_ok_27104 = i_lte_j_27102 && y_27103;
    bool eq_x_zz_27096 = (int64_t) 0 == m_f_res_27087;
    bool p_and_eq_x_y_27097 = x_27080 && eq_x_zz_27096;
    bool empty_slice_27098 = cond_27079 || p_and_eq_x_y_27097;
    bool ok_or_empty_27105 = empty_slice_27098 || forwards_ok_27104;
    bool index_certs_27106;
    
    if (!ok_or_empty_27105) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_27089, "] out of bounds for array of shape [", (long long) nz2081U_21996, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:21:1-108\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_29715 = (int64_t) 4 * m_27089;
    int64_t bytes_29717 = (int64_t) 8 * m_27089;
    
    if (memblock_alloc_device(ctx, &mem_29716, bytes_29715, "mem_29716")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29716.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, II1_mem_29679.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27089})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_29718, bytes_29717, "mem_29718")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_29718.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, A_mem_29680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27089})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_28890;
    
    segmap_tblock_sizze_28890 = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28889;
    
    int64_t num_tblocks_28892;
    int64_t max_num_tblocks_30538;
    
    max_num_tblocks_30538 = *ctx->tuning_params.human_genericf64zisegmap_num_tblocks_28891;
    num_tblocks_28892 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_21996, segmap_tblock_sizze_28890), max_num_tblocks_30538)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30539 = sext_i64_i32(sdiv_up64(nz2081U_21996, segmap_tblock_sizze_28890));
    
    {
        err = gpu_kernel_human_genericf64zisegmap_28887(ctx, num_tblocks_28892, 1, 1, *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28889, 1, 1, (int64_t) 0, nz2081U_21996, m_27089, num_tblocks_28892, virt_num_tblocks_30539, II1_mem_29679.mem, A_mem_29680.mem, mem_29712.mem, mem_29714.mem, mem_29716.mem, mem_29718.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29712, "mem_29712") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29714, "mem_29714") != 0)
        return 1;
    
    bool loop_cond_27116 = slt64((int64_t) 0, m_27089);
    int64_t segscan_tblock_sizze_28896;
    
    segscan_tblock_sizze_28896 = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28895;
    
    int64_t num_tblocks_28898;
    int64_t max_num_tblocks_30552;
    
    max_num_tblocks_30552 = *ctx->tuning_params.human_genericf64zisegscan_num_tblocks_28897;
    num_tblocks_28898 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_21995, segscan_tblock_sizze_28896), max_num_tblocks_30552)));
    
    int64_t segmap_tblock_sizze_28988;
    
    segmap_tblock_sizze_28988 = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28905;
    
    int64_t segmap_usable_groups_28989 = sdiv_up_safe64(mz2080U_21995, segmap_tblock_sizze_28988);
    int64_t seghist_tblock_sizze_29072;
    
    seghist_tblock_sizze_29072 = *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071;
    
    int64_t segmap_tblock_sizze_29135;
    
    segmap_tblock_sizze_29135 = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29101;
    
    int64_t segmap_usable_groups_29136 = sdiv_up_safe64(mz2080U_21995, segmap_tblock_sizze_29135);
    int64_t segscan_tblock_sizze_29173;
    
    segscan_tblock_sizze_29173 = *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_29172;
    
    int64_t segmap_tblock_sizze_29183;
    
    segmap_tblock_sizze_29183 = *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29182;
    if (memblock_alloc_device(ctx, &mem_29737, bytes_29691, "mem_29737")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29740, bytes_29682, "mem_29740")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29742, bytes_29691, "mem_29742")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29744, bytes_29691, "mem_29744")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29754, bytes_29691, "mem_29754")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t result_27118;
    bool result_27119;
    int64_t loop_dz2081Uz2088Uz2087U_27125;
    bool loop_while_27126;
    
    if (memblock_set_device(ctx, &mem_param_29722, &mem_29705, "mem_29705") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29725, &mem_29703, "mem_29703") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29728, &mem_29716, "mem_29716") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29731, &mem_29718, "mem_29718") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29734, &mem_29707, "mem_29707") != 0)
        return 1;
    loop_dz2081Uz2088Uz2087U_27125 = m_27089;
    loop_while_27126 = loop_cond_27116;
    while (loop_while_27126) {
        if (slt64((int64_t) 0, mz2080U_21995)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_30565;
            
            shared_memory_30565 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_30566;
            
            thread_block_sizze_30566 = ctx->max_thread_block_size;
            
            int64_t registers_30567;
            
            registers_30567 = ctx->max_registers;
            
            int64_t thread_block_sizze_30568;
            
            thread_block_sizze_30568 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_30569 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30565, thread_block_sizze_30566), (int64_t) 4), squot64(squot64(registers_30567, thread_block_sizze_30568) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
            int64_t num_virt_blocks_30570 = sdiv_up64(mz2080U_21995, segscan_tblock_sizze_28896 * chunk_sizze_30569);
            int64_t num_virt_threads_30571 = num_virt_blocks_30570 * segscan_tblock_sizze_28896;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30569, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_30572, num_virt_blocks_30570, "status_flags_mem_30572")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30572, num_virt_blocks_30570, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_30574, (int64_t) 4 * num_virt_blocks_30570, "aggregates_mem_30574")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_30576, (int64_t) 4 * num_virt_blocks_30570, "incprefixes_mem_30576")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_human_genericf64zisegscan_28901(ctx, num_tblocks_28898, 1, 1, *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_28895, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28896), chunk_sizze_30569 * segscan_tblock_sizze_28896 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_28896), chunk_sizze_30569 * segscan_tblock_sizze_28896 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_21995, num_tblocks_28898, num_virt_blocks_30570, num_virt_threads_30571, mem_param_29725.mem, mem_29737.mem, status_flags_mem_30572.mem, aggregates_mem_30574.mem, incprefixes_mem_30576.mem, global_dynid_mem_30578.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30667 = sext_i64_i32(sdiv_up64(mz2080U_21995, segmap_tblock_sizze_28988));
        
        {
            err = gpu_kernel_human_genericf64zisegmap_28992(ctx, segmap_usable_groups_28989, 1, 1, *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_28905, 1, 1, (int64_t) 0, mz2080U_21995, loop_dz2081Uz2088Uz2087U_27125, mem_param_29725.mem, mem_param_29731.mem, mem_29737.mem, mem_29740.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (futrts_builtinzhreplicate_i32(ctx, mem_29742, mz2080U_21995, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i32(ctx, mem_29744, mz2080U_21995, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_tblocks_29074;
        int64_t max_num_tblocks_30676;
        
        max_num_tblocks_30676 = *ctx->tuning_params.human_genericf64ziseghist_num_tblocks_29073;
        num_tblocks_29074 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, seghist_tblock_sizze_29072), max_num_tblocks_30676)));
        
        int64_t num_subhistos_30677;
        int64_t h_30682 = (int64_t) 4 * mz2080U_21995 + (int64_t) 4 * mz2080U_21995;
        int64_t seg_h_30683 = (int64_t) 4 * mz2080U_21995 + (int64_t) 4 * mz2080U_21995;
        
        if (!(seg_h_30683 == (int64_t) 0)) {
            int64_t hist_H_30684 = mz2080U_21995;
            int64_t hist_el_sizze_30685 = sdiv_up64(h_30682, hist_H_30684);
            int64_t hist_N_30686 = loop_dz2081Uz2088Uz2087U_27125;
            int32_t hist_RF_30687 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegHist");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_29074 * seghist_tblock_sizze_29072), '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_29072, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30684, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_30686, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_30685, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_30687, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_30682, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_30683, '\n');
            
            int64_t hist_L_30688;
            
            hist_L_30688 = *ctx->tuning_params.human_genericf64zihist_L_30688;
            
            int64_t max_tblock_sizze_30689;
            
            max_tblock_sizze_30689 = ctx->max_thread_block_size;
            
            int64_t num_tblocks_30690 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_29074 * seghist_tblock_sizze_29072)), max_tblock_sizze_30689);
            double hist_m_prime_30691 = sitofp_i64_f64(smin64(squot64(hist_L_30688, hist_el_sizze_30685), sdiv_up64(hist_N_30686, num_tblocks_30690))) / sitofp_i64_f64(hist_H_30684);
            int64_t hist_M0_30692 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_30691), max_tblock_sizze_30689));
            int64_t hist_Nout_30693 = (int64_t) 1;
            int64_t hist_Nin_30694 = loop_dz2081Uz2088Uz2087U_27125;
            int64_t work_asymp_M_max_30695 = squot64(hist_Nout_30693 * hist_N_30686, (int64_t) 2 * num_tblocks_30690 * hist_H_30684);
            int32_t hist_M_30696 = sext_i64_i32(smin64(hist_M0_30692, work_asymp_M_max_30695));
            int64_t hist_C_30697 = sdiv_up64(max_tblock_sizze_30689, sext_i32_i64(smax32(1, hist_M_30696)));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_30692, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_30695, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_30697, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_30689, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_30696, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_30684 * hist_el_sizze_30685 * sext_i32_i64(hist_M_30696)), '\n');
            
            int64_t local_mem_needed_30698 = hist_el_sizze_30685 * sext_i32_i64(hist_M_30696);
            int32_t hist_S_30699 = sext_i64_i32(sdiv_up64(hist_H_30684 * local_mem_needed_30698 + (int64_t) 1, hist_L_30688));
            
            if (sle64(hist_H_30684, hist_Nin_30694) && (sle64(local_mem_needed_30698, hist_L_30688) && (sle32(hist_S_30699, 3) && (sle64(hist_C_30697, max_tblock_sizze_30689) && slt32(0, hist_M_30696))))) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using shared memory");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30684, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30696, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_30697, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30699, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_30696, '\n');
                num_subhistos_30677 = num_tblocks_30690;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_30677, '\n');
                if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_21995 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30678")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_21995, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30678.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29744.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_21995})) != 0)
                        goto cleanup;
                }
                if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_21995 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30680")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_21995, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29742.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_21995})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_30700 = 0; chk_i_30700 < hist_S_30699; chk_i_30700++) {
                    int64_t num_segments_30701 = (int64_t) 1;
                    int64_t hist_H_chk_30702 = sdiv_up64(mz2080U_21995, sext_i32_i64(hist_S_30699));
                    int64_t histo_sizze_30703 = hist_H_chk_30702;
                    int32_t init_per_thread_30704 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_30696) * histo_sizze_30703, max_tblock_sizze_30689));
                    
                    {
                        err = gpu_kernel_human_genericf64ziseghist_local_29079(ctx, num_tblocks_30690, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8)), mz2080U_21995, loop_dz2081Uz2088Uz2087U_27125, num_subhistos_30677, num_tblocks_30690, hist_M_30696, chk_i_30700, num_segments_30701, hist_H_chk_30702, histo_sizze_30703, init_per_thread_30704, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                }
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using global memory");
                
                int64_t hist_H_30745 = mz2080U_21995;
                double hist_RF_30746 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
                int32_t hist_el_sizze_30747 = 4;
                double hist_C_max_30748 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29074 * seghist_tblock_sizze_29072)), sitofp_i32_f64(hist_H_30745) / 2.0);
                int32_t hist_M_min_30749 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29074 * seghist_tblock_sizze_29072)) / hist_C_max_30748)));
                int64_t hist_L2_30750;
                
                hist_L2_30750 = *ctx->tuning_params.human_genericf64zihist_L2_30750;
                
                double hist_RACE_exp_30751 = fmax64(1.0, 0.75 * hist_RF_30746 / (64.0 / sitofp_i32_f64(hist_el_sizze_30747)));
                int32_t hist_S_30752;
                
                if (slt64(loop_dz2081Uz2088Uz2087U_27125, hist_H_30745)) {
                    hist_S_30752 = 1;
                } else {
                    hist_S_30752 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_30749) * hist_H_30745 * sext_i32_i64(hist_el_sizze_30747), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_30750) * hist_RACE_exp_30751)));
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_30751, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30752, '\n');
                
                int64_t hist_H_chk_30753 = sdiv_up64(mz2080U_21995, sext_i32_i64(hist_S_30752));
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_30753, '\n');
                
                double hist_k_max_30754 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_30750) / sitofp_i32_f64(8)) * hist_RACE_exp_30751, sitofp_i32_f64(loop_dz2081Uz2088Uz2087U_27125)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_29074 * seghist_tblock_sizze_29072));
                int64_t hist_u_30755 = (int64_t) 2;
                double hist_C_30756 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29074 * seghist_tblock_sizze_29072)), sitofp_i32_f64(hist_u_30755 * hist_H_chk_30753) / hist_k_max_30754);
                int32_t hist_M_30757 = 1;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_30754, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30757, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_30756, '\n');
                num_subhistos_30677 = sext_i32_i64(hist_M_30757);
                if (hist_M_30757 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_21995 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30678")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_21995, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30678.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29744.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_21995})) != 0)
                        goto cleanup;
                }
                if (hist_M_30757 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_21995 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30680")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_21995, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29742.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_21995})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_30758 = 0; chk_i_30758 < hist_S_30752; chk_i_30758++) {
                    int64_t hist_H_chk_30759 = sdiv_up64(mz2080U_21995, sext_i32_i64(hist_S_30752));
                    
                    {
                        err = gpu_kernel_human_genericf64ziseghist_global_29079(ctx, num_tblocks_29074, 1, 1, *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071, 1, 1, (int64_t) 0, mz2080U_21995, loop_dz2081Uz2088Uz2087U_27125, num_tblocks_29074, num_subhistos_30677, chk_i_30758, hist_H_chk_30759, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                }
            }
            if (num_subhistos_30677 == (int64_t) 1) {
                if (memblock_set_device(ctx, &mem_29744, &defunc_0_map_res_subhistos_mem_30678, "defunc_0_map_res_subhistos_mem_30678") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_29742, &defunc_0_map_res_subhistos_mem_30680, "defunc_0_map_res_subhistos_mem_30680") != 0)
                    return 1;
            } else {
                int64_t chunk_sizze_30776 = (int64_t) 1;
                
                if (slt64(num_subhistos_30677 * (int64_t) 2, seghist_tblock_sizze_29072 * chunk_sizze_30776)) {
                    int64_t segment_sizze_nonzzero_30777 = smax64((int64_t) 1, num_subhistos_30677);
                    int64_t num_threads_30778 = seghist_tblock_sizze_29072 * seghist_tblock_sizze_29072;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_21995, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30677, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_21995, squot64(seghist_tblock_sizze_29072, segment_sizze_nonzzero_30777))), '\n');
                    {
                        err = gpu_kernel_human_genericf64zisegred_small_30775(ctx, num_tblocks_29074, 1, 1, *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071, 1, 1, (int64_t) 4 * seghist_tblock_sizze_29072 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29072, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_29072 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29072, (int64_t) 8), (int64_t) 8)), mz2080U_21995, num_tblocks_29074, num_subhistos_30677, segment_sizze_nonzzero_30777, mem_29742.mem, mem_29744.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_30813 = sdiv_up64(num_tblocks_29074, smax64((int64_t) 1, mz2080U_21995));
                    int64_t q_30814 = sdiv_up64(num_subhistos_30677, seghist_tblock_sizze_29072 * blocks_per_segment_30813 * chunk_sizze_30776);
                    int64_t num_virtblocks_30815 = blocks_per_segment_30813 * mz2080U_21995;
                    int64_t threads_per_segment_30816 = blocks_per_segment_30813 * seghist_tblock_sizze_29072;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_21995, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30677, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_30815, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_29074, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_29072, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_30814, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_30813, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_30817, (int64_t) 4 * num_virtblocks_30815, "segred_tmp_mem_30817")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_30819, (int64_t) 4 * num_virtblocks_30815, "segred_tmp_mem_30819")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_human_genericf64zisegred_large_30775(ctx, num_tblocks_29074, 1, 1, *ctx->tuning_params.human_genericf64ziseghist_tblock_sizze_29071, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_29072 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29072, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_29072 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29072, (int64_t) 8), (int64_t) 8)), mz2080U_21995, num_tblocks_29074, num_subhistos_30677, blocks_per_segment_30813, q_30814, num_virtblocks_30815, threads_per_segment_30816, mem_29742.mem, mem_29744.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem, segred_tmp_mem_30817.mem, segred_tmp_mem_30819.mem, counters_mem_30821.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_alloc_device(ctx, &mem_29748, bytes_29691, "mem_29748")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29750, bytes_29691, "mem_29750")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29752, bytes_29682, "mem_29752")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30864 = sext_i64_i32(sdiv_up64(mz2080U_21995, segmap_tblock_sizze_29135));
        
        {
            err = gpu_kernel_human_genericf64zisegmap_29142(ctx, segmap_usable_groups_29136, 1, 1, *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29101, 1, 1, (int64_t) 0, mz2080U_21995, mem_param_29722.mem, mem_param_29725.mem, mem_param_29734.mem, mem_29740.mem, mem_29742.mem, mem_29744.mem, mem_29748.mem, mem_29750.mem, mem_29752.mem, mem_29754.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t num_tblocks_29175;
        int64_t max_num_tblocks_30873;
        
        max_num_tblocks_30873 = *ctx->tuning_params.human_genericf64zisegscan_num_tblocks_29174;
        num_tblocks_29175 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, segscan_tblock_sizze_29173), max_num_tblocks_30873)));
        
        int64_t bytes_29756 = (int64_t) 8 * loop_dz2081Uz2088Uz2087U_27125;
        
        if (memblock_alloc_device(ctx, &mem_29757, bytes_29756, "mem_29757")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29759, bytes_29756, "mem_29759")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, loop_dz2081Uz2088Uz2087U_27125)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_30874;
            
            shared_memory_30874 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_30875;
            
            thread_block_sizze_30875 = ctx->max_thread_block_size;
            
            int64_t registers_30876;
            
            registers_30876 = ctx->max_registers;
            
            int64_t thread_block_sizze_30877;
            
            thread_block_sizze_30877 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_30878 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30874, thread_block_sizze_30875), (int64_t) 8), squot64(squot64(registers_30876, thread_block_sizze_30877) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_30879 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, segscan_tblock_sizze_29173 * chunk_sizze_30878);
            int64_t num_virt_threads_30880 = num_virt_blocks_30879 * segscan_tblock_sizze_29173;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30878, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_30881, num_virt_blocks_30879, "status_flags_mem_30881")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30881, num_virt_blocks_30879, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_30883, (int64_t) 8 * num_virt_blocks_30879, "aggregates_mem_30883")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_30885, (int64_t) 8 * num_virt_blocks_30879, "incprefixes_mem_30885")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_human_genericf64zisegscan_29178(ctx, num_tblocks_29175, 1, 1, *ctx->tuning_params.human_genericf64zisegscan_tblock_sizze_29172, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29173), chunk_sizze_30878 * segscan_tblock_sizze_29173 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29173), chunk_sizze_30878 * segscan_tblock_sizze_29173 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_21995, loop_dz2081Uz2088Uz2087U_27125, num_tblocks_29175, num_virt_blocks_30879, num_virt_threads_30880, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, mem_29754.mem, mem_29757.mem, mem_29759.mem, status_flags_mem_30881.mem, aggregates_mem_30883.mem, incprefixes_mem_30885.mem, global_dynid_mem_30887.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        bool cond_27335 = loop_dz2081Uz2088Uz2087U_27125 == (int64_t) 0;
        bool x_27336 = !cond_27335;
        int64_t tmp_27337 = sub64(loop_dz2081Uz2088Uz2087U_27125, (int64_t) 1);
        bool x_27338 = sle64((int64_t) 0, tmp_27337);
        bool y_27339 = slt64(tmp_27337, loop_dz2081Uz2088Uz2087U_27125);
        bool bounds_check_27340 = x_27338 && y_27339;
        bool protect_assert_disj_27341 = cond_27335 || bounds_check_27340;
        bool index_certs_27342;
        
        if (!protect_assert_disj_27341) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_27337, "] out of bounds for array of shape [", (long long) loop_dz2081Uz2088Uz2087U_27125, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:21:1-108\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t m_f_res_27343;
        
        if (x_27336) {
            int64_t read_res_30995;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_30995, mem_29757.mem, tmp_27337 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_28189 = read_res_30995;
            
            m_f_res_27343 = x_28189;
        } else {
            m_f_res_27343 = (int64_t) 0;
        }
        
        int64_t m_27345;
        
        if (cond_27335) {
            m_27345 = (int64_t) 0;
        } else {
            m_27345 = m_f_res_27343;
        }
        
        int64_t m_27355 = sub64(m_27345, (int64_t) 1);
        bool i_p_m_t_s_leq_w_27357 = slt64(m_27355, loop_dz2081Uz2088Uz2087U_27125);
        bool zzero_leq_i_p_m_t_s_27356 = sle64((int64_t) 0, m_27355);
        bool y_27359 = zzero_leq_i_p_m_t_s_27356 && i_p_m_t_s_leq_w_27357;
        bool i_lte_j_27358 = sle64((int64_t) 0, m_27345);
        bool forwards_ok_27360 = i_lte_j_27358 && y_27359;
        bool eq_x_zz_27352 = (int64_t) 0 == m_f_res_27343;
        bool p_and_eq_x_y_27353 = x_27336 && eq_x_zz_27352;
        bool empty_slice_27354 = cond_27335 || p_and_eq_x_y_27353;
        bool ok_or_empty_27361 = empty_slice_27354 || forwards_ok_27360;
        bool index_certs_27362;
        
        if (!ok_or_empty_27361) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_27345, "] out of bounds for array of shape [", (long long) loop_dz2081Uz2088Uz2087U_27125, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:21:1-108\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_29760 = (int64_t) 4 * m_27345;
        int64_t bytes_29762 = (int64_t) 8 * m_27345;
        
        if (memblock_alloc_device(ctx, &mem_29761, bytes_29760, "mem_29761")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29761.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_29728.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27345})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_29763, bytes_29762, "mem_29763")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_29763.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_29731.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27345})) != 0)
            goto cleanup;
        
        int64_t num_tblocks_29185;
        int64_t max_num_tblocks_30976;
        
        max_num_tblocks_30976 = *ctx->tuning_params.human_genericf64zisegmap_num_tblocks_29184;
        num_tblocks_29185 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, segmap_tblock_sizze_29183), max_num_tblocks_30976)));
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30977 = sext_i64_i32(sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, segmap_tblock_sizze_29183));
        
        {
            err = gpu_kernel_human_genericf64zisegmap_29180(ctx, num_tblocks_29185, 1, 1, *ctx->tuning_params.human_genericf64zisegmap_tblock_sizze_29182, 1, 1, (int64_t) 0, loop_dz2081Uz2088Uz2087U_27125, m_27345, num_tblocks_29185, virt_num_tblocks_30977, mem_param_29728.mem, mem_param_29731.mem, mem_29757.mem, mem_29759.mem, mem_29761.mem, mem_29763.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_29757, "mem_29757") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29759, "mem_29759") != 0)
            return 1;
        
        bool loop_cond_27372 = slt64((int64_t) 0, m_27345);
        
        if (memblock_set_device(ctx, &mem_param_tmp_30553, &mem_29750, "mem_29750") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30554, &mem_29748, "mem_29748") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30555, &mem_29761, "mem_29761") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30556, &mem_29763, "mem_29763") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30557, &mem_29752, "mem_29752") != 0)
            return 1;
        
        int64_t loop_dz2081Uz2088Uz2087U_tmp_30558 = m_27345;
        bool loop_while_tmp_30559 = loop_cond_27372;
        
        if (memblock_set_device(ctx, &mem_param_29722, &mem_param_tmp_30553, "mem_param_tmp_30553") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29725, &mem_param_tmp_30554, "mem_param_tmp_30554") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29728, &mem_param_tmp_30555, "mem_param_tmp_30555") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29731, &mem_param_tmp_30556, "mem_param_tmp_30556") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29734, &mem_param_tmp_30557, "mem_param_tmp_30557") != 0)
            return 1;
        loop_dz2081Uz2088Uz2087U_27125 = loop_dz2081Uz2088Uz2087U_tmp_30558;
        loop_while_27126 = loop_while_tmp_30559;
    }
    if (memblock_set_device(ctx, &ext_mem_29779, &mem_param_29722, "mem_param_29722") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29778, &mem_param_29725, "mem_param_29725") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29777, &mem_param_29728, "mem_param_29728") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29776, &mem_param_29731, "mem_param_29731") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29775, &mem_param_29734, "mem_param_29734") != 0)
        return 1;
    result_27118 = loop_dz2081Uz2088Uz2087U_27125;
    result_27119 = loop_while_27126;
    if (memblock_unref_device(ctx, &mem_29703, "mem_29703") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29705, "mem_29705") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29707, "mem_29707") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29716, "mem_29716") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29718, "mem_29718") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29737, "mem_29737") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29740, "mem_29740") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29742, "mem_29742") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29744, "mem_29744") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29754, "mem_29754") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_29788, &ext_mem_29775, "ext_mem_29775") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_30993, &mem_out_29788, "mem_out_29788") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_param_tmp_30557, "mem_param_tmp_30557") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30556, "mem_param_tmp_30556") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30555, "mem_param_tmp_30555") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30554, "mem_param_tmp_30554") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30553, "mem_param_tmp_30553") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29763, "mem_29763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29761, "mem_29761") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30885, "incprefixes_mem_30885") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30883, "aggregates_mem_30883") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30881, "status_flags_mem_30881") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29759, "mem_29759") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29757, "mem_29757") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29752, "mem_29752") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29750, "mem_29750") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29748, "mem_29748") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30819, "segred_tmp_mem_30819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30817, "segred_tmp_mem_30817") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30680, "defunc_0_map_res_subhistos_mem_30680") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30678, "defunc_0_map_res_subhistos_mem_30678") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30576, "incprefixes_mem_30576") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30574, "aggregates_mem_30574") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30572, "status_flags_mem_30572") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29734, "mem_param_29734") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29731, "mem_param_29731") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29728, "mem_param_29728") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29725, "mem_param_29725") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29722, "mem_param_29722") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29775, "ext_mem_29775") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29776, "ext_mem_29776") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29777, "ext_mem_29777") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29778, "ext_mem_29778") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29779, "ext_mem_29779") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29754, "mem_29754") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29744, "mem_29744") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29742, "mem_29742") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29740, "mem_29740") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29737, "mem_29737") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29718, "mem_29718") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29716, "mem_29716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30447, "incprefixes_mem_30447") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30445, "aggregates_mem_30445") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30443, "status_flags_mem_30443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29714, "mem_29714") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29712, "mem_29712") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29709, "mem_29709") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29707, "mem_29707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29705, "mem_29705") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29703, "mem_29703") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30381, "segred_tmp_mem_30381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30379, "segred_tmp_mem_30379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30242, "defunc_0_map_res_subhistos_mem_30242") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30240, "defunc_0_map_res_subhistos_mem_30240") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29699, "mem_29699") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29697, "mem_29697") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29695, "mem_29695") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30138, "incprefixes_mem_30138") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30136, "aggregates_mem_30136") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30134, "status_flags_mem_30134") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29692, "mem_29692") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29982, "incprefixes_mem_29982") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29980, "aggregates_mem_29980") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29978, "incprefixes_mem_29978") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29976, "aggregates_mem_29976") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_29974, "status_flags_mem_29974") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29689, "mem_29689") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29687, "mem_29687") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29684, "mem_29684") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29821, "incprefixes_mem_29821") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29819, "aggregates_mem_29819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_29797, "status_flags_mem_29797") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29683, "mem_29683") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_29788, "mem_out_29788") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_human_generici32(struct futhark_context *ctx, struct memblock_device *mem_out_p_30996, struct memblock_device ks_mem_29677, struct memblock_device shp_mem_29678, struct memblock_device II1_mem_29679, struct memblock_device A_mem_29680, int64_t mz2080U_25210, int64_t nz2081U_25211)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_param_tmp_30557;
    
    mem_param_tmp_30557.references = NULL;
    
    struct memblock_device mem_param_tmp_30556;
    
    mem_param_tmp_30556.references = NULL;
    
    struct memblock_device mem_param_tmp_30555;
    
    mem_param_tmp_30555.references = NULL;
    
    struct memblock_device mem_param_tmp_30554;
    
    mem_param_tmp_30554.references = NULL;
    
    struct memblock_device mem_param_tmp_30553;
    
    mem_param_tmp_30553.references = NULL;
    
    struct memblock_device mem_29763;
    
    mem_29763.references = NULL;
    
    struct memblock_device mem_29761;
    
    mem_29761.references = NULL;
    
    struct memblock_device incprefixes_mem_30885;
    
    incprefixes_mem_30885.references = NULL;
    
    struct memblock_device aggregates_mem_30883;
    
    aggregates_mem_30883.references = NULL;
    
    struct memblock_device status_flags_mem_30881;
    
    status_flags_mem_30881.references = NULL;
    
    struct memblock_device mem_29759;
    
    mem_29759.references = NULL;
    
    struct memblock_device mem_29757;
    
    mem_29757.references = NULL;
    
    struct memblock_device mem_29752;
    
    mem_29752.references = NULL;
    
    struct memblock_device mem_29750;
    
    mem_29750.references = NULL;
    
    struct memblock_device mem_29748;
    
    mem_29748.references = NULL;
    
    struct memblock_device segred_tmp_mem_30819;
    
    segred_tmp_mem_30819.references = NULL;
    
    struct memblock_device segred_tmp_mem_30817;
    
    segred_tmp_mem_30817.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30680;
    
    defunc_0_map_res_subhistos_mem_30680.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30678;
    
    defunc_0_map_res_subhistos_mem_30678.references = NULL;
    
    struct memblock_device incprefixes_mem_30576;
    
    incprefixes_mem_30576.references = NULL;
    
    struct memblock_device aggregates_mem_30574;
    
    aggregates_mem_30574.references = NULL;
    
    struct memblock_device status_flags_mem_30572;
    
    status_flags_mem_30572.references = NULL;
    
    struct memblock_device mem_param_29734;
    
    mem_param_29734.references = NULL;
    
    struct memblock_device mem_param_29731;
    
    mem_param_29731.references = NULL;
    
    struct memblock_device mem_param_29728;
    
    mem_param_29728.references = NULL;
    
    struct memblock_device mem_param_29725;
    
    mem_param_29725.references = NULL;
    
    struct memblock_device mem_param_29722;
    
    mem_param_29722.references = NULL;
    
    struct memblock_device ext_mem_29775;
    
    ext_mem_29775.references = NULL;
    
    struct memblock_device ext_mem_29776;
    
    ext_mem_29776.references = NULL;
    
    struct memblock_device ext_mem_29777;
    
    ext_mem_29777.references = NULL;
    
    struct memblock_device ext_mem_29778;
    
    ext_mem_29778.references = NULL;
    
    struct memblock_device ext_mem_29779;
    
    ext_mem_29779.references = NULL;
    
    struct memblock_device mem_29754;
    
    mem_29754.references = NULL;
    
    struct memblock_device mem_29744;
    
    mem_29744.references = NULL;
    
    struct memblock_device mem_29742;
    
    mem_29742.references = NULL;
    
    struct memblock_device mem_29740;
    
    mem_29740.references = NULL;
    
    struct memblock_device mem_29737;
    
    mem_29737.references = NULL;
    
    struct memblock_device mem_29718;
    
    mem_29718.references = NULL;
    
    struct memblock_device mem_29716;
    
    mem_29716.references = NULL;
    
    struct memblock_device incprefixes_mem_30447;
    
    incprefixes_mem_30447.references = NULL;
    
    struct memblock_device aggregates_mem_30445;
    
    aggregates_mem_30445.references = NULL;
    
    struct memblock_device status_flags_mem_30443;
    
    status_flags_mem_30443.references = NULL;
    
    struct memblock_device mem_29714;
    
    mem_29714.references = NULL;
    
    struct memblock_device mem_29712;
    
    mem_29712.references = NULL;
    
    struct memblock_device mem_29709;
    
    mem_29709.references = NULL;
    
    struct memblock_device mem_29707;
    
    mem_29707.references = NULL;
    
    struct memblock_device mem_29705;
    
    mem_29705.references = NULL;
    
    struct memblock_device mem_29703;
    
    mem_29703.references = NULL;
    
    struct memblock_device segred_tmp_mem_30381;
    
    segred_tmp_mem_30381.references = NULL;
    
    struct memblock_device segred_tmp_mem_30379;
    
    segred_tmp_mem_30379.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30242;
    
    defunc_0_map_res_subhistos_mem_30242.references = NULL;
    
    struct memblock_device defunc_0_map_res_subhistos_mem_30240;
    
    defunc_0_map_res_subhistos_mem_30240.references = NULL;
    
    struct memblock_device mem_29699;
    
    mem_29699.references = NULL;
    
    struct memblock_device mem_29697;
    
    mem_29697.references = NULL;
    
    struct memblock_device mem_29695;
    
    mem_29695.references = NULL;
    
    struct memblock_device incprefixes_mem_30138;
    
    incprefixes_mem_30138.references = NULL;
    
    struct memblock_device aggregates_mem_30136;
    
    aggregates_mem_30136.references = NULL;
    
    struct memblock_device status_flags_mem_30134;
    
    status_flags_mem_30134.references = NULL;
    
    struct memblock_device mem_29692;
    
    mem_29692.references = NULL;
    
    struct memblock_device incprefixes_mem_29982;
    
    incprefixes_mem_29982.references = NULL;
    
    struct memblock_device aggregates_mem_29980;
    
    aggregates_mem_29980.references = NULL;
    
    struct memblock_device incprefixes_mem_29978;
    
    incprefixes_mem_29978.references = NULL;
    
    struct memblock_device aggregates_mem_29976;
    
    aggregates_mem_29976.references = NULL;
    
    struct memblock_device status_flags_mem_29974;
    
    status_flags_mem_29974.references = NULL;
    
    struct memblock_device mem_29689;
    
    mem_29689.references = NULL;
    
    struct memblock_device mem_29687;
    
    mem_29687.references = NULL;
    
    struct memblock_device mem_29684;
    
    mem_29684.references = NULL;
    
    struct memblock_device incprefixes_mem_29821;
    
    incprefixes_mem_29821.references = NULL;
    
    struct memblock_device aggregates_mem_29819;
    
    aggregates_mem_29819.references = NULL;
    
    struct memblock_device status_flags_mem_29797;
    
    status_flags_mem_29797.references = NULL;
    
    struct memblock_device mem_29683;
    
    mem_29683.references = NULL;
    
    struct memblock_device mem_out_29788;
    
    mem_out_29788.references = NULL;
    
    struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
    struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
    struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
    struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
    struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
    struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
    struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
    struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
    int64_t segscan_tblock_sizze_29189;
    
    segscan_tblock_sizze_29189 = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29188;
    
    int64_t num_tblocks_29191;
    int64_t max_num_tblocks_29789;
    
    max_num_tblocks_29789 = *ctx->tuning_params.human_generici32zisegscan_num_tblocks_29190;
    num_tblocks_29191 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_25210, segscan_tblock_sizze_29189), max_num_tblocks_29789)));
    
    int64_t bytes_29682 = (int64_t) 8 * mz2080U_25210;
    
    if (memblock_alloc_device(ctx, &mem_29683, bytes_29682, "mem_29683")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_25210)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_29790;
        
        shared_memory_29790 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_29791;
        
        thread_block_sizze_29791 = ctx->max_thread_block_size;
        
        int64_t registers_29792;
        
        registers_29792 = ctx->max_registers;
        
        int64_t thread_block_sizze_29793;
        
        thread_block_sizze_29793 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_29794 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_29790, thread_block_sizze_29791), (int64_t) 8), squot64(squot64(registers_29792, thread_block_sizze_29793) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_29795 = sdiv_up64(mz2080U_25210, segscan_tblock_sizze_29189 * chunk_sizze_29794);
        int64_t num_virt_threads_29796 = num_virt_blocks_29795 * segscan_tblock_sizze_29189;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_29794, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_29797, num_virt_blocks_29795, "status_flags_mem_29797")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_29797, num_virt_blocks_29795, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29819, (int64_t) 8 * num_virt_blocks_29795, "aggregates_mem_29819")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29821, (int64_t) 8 * num_virt_blocks_29795, "incprefixes_mem_29821")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_generici32zisegscan_29194(ctx, num_tblocks_29191, 1, 1, *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29188, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29189), chunk_sizze_29794 * segscan_tblock_sizze_29189 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29189), chunk_sizze_29794 * segscan_tblock_sizze_29189 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_25210, num_tblocks_29191, num_virt_blocks_29795, num_virt_threads_29796, shp_mem_29678.mem, mem_29683.mem, status_flags_mem_29797.mem, aggregates_mem_29819.mem, incprefixes_mem_29821.mem, global_dynid_mem_29823.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_alloc_device(ctx, &mem_29684, nz2081U_25211, "mem_29684")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_29684, nz2081U_25211, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_tblock_sizze_29199;
    
    segmap_tblock_sizze_29199 = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29198;
    
    int64_t num_tblocks_29201;
    int64_t max_num_tblocks_29952;
    
    max_num_tblocks_29952 = *ctx->tuning_params.human_generici32zisegmap_num_tblocks_29200;
    num_tblocks_29201 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_25210, segmap_tblock_sizze_29199), max_num_tblocks_29952)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_29953 = sext_i64_i32(sdiv_up64(mz2080U_25210, segmap_tblock_sizze_29199));
    
    {
        err = gpu_kernel_human_generici32zisegmap_29196(ctx, num_tblocks_29201, 1, 1, *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29198, 1, 1, (int64_t) 0, mz2080U_25210, nz2081U_25211, num_tblocks_29201, virt_num_tblocks_29953, mem_29683.mem, mem_29684.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29683, "mem_29683") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_29205;
    
    segscan_tblock_sizze_29205 = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29204;
    
    int64_t num_tblocks_29207;
    int64_t max_num_tblocks_29966;
    
    max_num_tblocks_29966 = *ctx->tuning_params.human_generici32zisegscan_num_tblocks_29206;
    num_tblocks_29207 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_25211, segscan_tblock_sizze_29205), max_num_tblocks_29966)));
    
    int64_t bytes_29688 = (int64_t) 4 * nz2081U_25211;
    
    if (memblock_alloc_device(ctx, &mem_29687, nz2081U_25211, "mem_29687")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29689, bytes_29688, "mem_29689")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_25211)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_29967;
        
        shared_memory_29967 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_29968;
        
        thread_block_sizze_29968 = ctx->max_thread_block_size;
        
        int64_t registers_29969;
        
        registers_29969 = ctx->max_registers;
        
        int64_t thread_block_sizze_29970;
        
        thread_block_sizze_29970 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_29971 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_29967, thread_block_sizze_29968), (int64_t) 4), squot64(squot64(registers_29969, thread_block_sizze_29970) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 1) + smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_29972 = sdiv_up64(nz2081U_25211, segscan_tblock_sizze_29205 * chunk_sizze_29971);
        int64_t num_virt_threads_29973 = num_virt_blocks_29972 * segscan_tblock_sizze_29205;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_29971, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_29974, num_virt_blocks_29972, "status_flags_mem_29974")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_29974, num_virt_blocks_29972, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29976, num_virt_blocks_29972, "aggregates_mem_29976")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29978, num_virt_blocks_29972, "incprefixes_mem_29978")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_29980, (int64_t) 4 * num_virt_blocks_29972, "aggregates_mem_29980")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_29982, (int64_t) 4 * num_virt_blocks_29972, "incprefixes_mem_29982")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_generici32zisegscan_29210(ctx, num_tblocks_29207, 1, 1, *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29204, 1, 1, smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_29205, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_29205), smax64(chunk_sizze_29971 * segscan_tblock_sizze_29205, chunk_sizze_29971 * segscan_tblock_sizze_29205 * (int64_t) 4)) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 192, sdiv_up64(segscan_tblock_sizze_29205, (int64_t) 4) * (int64_t) 4 + (int64_t) 4 * segscan_tblock_sizze_29205), smax64(chunk_sizze_29971 * segscan_tblock_sizze_29205, chunk_sizze_29971 * segscan_tblock_sizze_29205 * (int64_t) 4)), (int64_t) 8), (int64_t) 8), nz2081U_25211, num_tblocks_29207, num_virt_blocks_29972, num_virt_threads_29973, A_mem_29680.mem, mem_29684.mem, mem_29687.mem, mem_29689.mem, status_flags_mem_29974.mem, aggregates_mem_29976.mem, incprefixes_mem_29978.mem, aggregates_mem_29980.mem, incprefixes_mem_29982.mem, global_dynid_mem_29984.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_29684, "mem_29684") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29687, "mem_29687") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_29213;
    
    segscan_tblock_sizze_29213 = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29212;
    
    int64_t num_tblocks_29215;
    int64_t max_num_tblocks_30126;
    
    max_num_tblocks_30126 = *ctx->tuning_params.human_generici32zisegscan_num_tblocks_29214;
    num_tblocks_29215 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_25210, segscan_tblock_sizze_29213), max_num_tblocks_30126)));
    
    int64_t bytes_29691 = (int64_t) 4 * mz2080U_25210;
    
    if (memblock_alloc_device(ctx, &mem_29692, bytes_29691, "mem_29692")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, mz2080U_25210)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_30127;
        
        shared_memory_30127 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_30128;
        
        thread_block_sizze_30128 = ctx->max_thread_block_size;
        
        int64_t registers_30129;
        
        registers_30129 = ctx->max_registers;
        
        int64_t thread_block_sizze_30130;
        
        thread_block_sizze_30130 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_30131 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30127, thread_block_sizze_30128), (int64_t) 4), squot64(squot64(registers_30129, thread_block_sizze_30130) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
        int64_t num_virt_blocks_30132 = sdiv_up64(mz2080U_25210, segscan_tblock_sizze_29213 * chunk_sizze_30131);
        int64_t num_virt_threads_30133 = num_virt_blocks_30132 * segscan_tblock_sizze_29213;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30131, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_30134, num_virt_blocks_30132, "status_flags_mem_30134")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30134, num_virt_blocks_30132, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_30136, (int64_t) 4 * num_virt_blocks_30132, "aggregates_mem_30136")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_30138, (int64_t) 4 * num_virt_blocks_30132, "incprefixes_mem_30138")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_generici32zisegscan_29218(ctx, num_tblocks_29215, 1, 1, *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29212, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_29213), chunk_sizze_30131 * segscan_tblock_sizze_29213 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_29213), chunk_sizze_30131 * segscan_tblock_sizze_29213 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_25210, num_tblocks_29215, num_virt_blocks_30132, num_virt_threads_30133, shp_mem_29678.mem, mem_29692.mem, status_flags_mem_30134.mem, aggregates_mem_30136.mem, incprefixes_mem_30138.mem, global_dynid_mem_30140.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t segmap_tblock_sizze_29244;
    
    segmap_tblock_sizze_29244 = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29222;
    
    int64_t segmap_usable_groups_29245 = sdiv_up64(mz2080U_25210, segmap_tblock_sizze_29244);
    
    if (memblock_alloc_device(ctx, &mem_29695, bytes_29691, "mem_29695")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30229 = sext_i64_i32(sdiv_up64(mz2080U_25210, segmap_tblock_sizze_29244));
    
    {
        err = gpu_kernel_human_generici32zisegmap_29248(ctx, segmap_usable_groups_29245, 1, 1, *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29222, 1, 1, (int64_t) 0, mz2080U_25210, nz2081U_25211, shp_mem_29678.mem, mem_29689.mem, mem_29692.mem, mem_29695.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29689, "mem_29689") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29692, "mem_29692") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_29697, bytes_29691, "mem_29697")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_29697, mz2080U_25210, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29699, bytes_29691, "mem_29699")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, mem_29699, mz2080U_25210, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t seghist_tblock_sizze_29267;
    
    seghist_tblock_sizze_29267 = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266;
    
    int64_t num_tblocks_29269;
    int64_t max_num_tblocks_30238;
    
    max_num_tblocks_30238 = *ctx->tuning_params.human_generici32ziseghist_num_tblocks_29268;
    num_tblocks_29269 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_25211, seghist_tblock_sizze_29267), max_num_tblocks_30238)));
    
    int64_t num_subhistos_30239;
    int64_t h_30244 = (int64_t) 4 * mz2080U_25210 + (int64_t) 4 * mz2080U_25210;
    int64_t seg_h_30245 = (int64_t) 4 * mz2080U_25210 + (int64_t) 4 * mz2080U_25210;
    
    if (!(seg_h_30245 == (int64_t) 0)) {
        int64_t hist_H_30246 = mz2080U_25210;
        int64_t hist_el_sizze_30247 = sdiv_up64(h_30244, hist_H_30246);
        int64_t hist_N_30248 = nz2081U_25211;
        int32_t hist_RF_30249 = 1;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegHist");
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_29269 * seghist_tblock_sizze_29267), '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_29267, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30246, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_30248, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_30247, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_30249, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_30244, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_30245, '\n');
        
        int64_t hist_L_30250;
        
        hist_L_30250 = *ctx->tuning_params.human_generici32zihist_L_30250;
        
        int64_t max_tblock_sizze_30251;
        
        max_tblock_sizze_30251 = ctx->max_thread_block_size;
        
        int64_t num_tblocks_30252 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_29269 * seghist_tblock_sizze_29267)), max_tblock_sizze_30251);
        double hist_m_prime_30253 = sitofp_i64_f64(smin64(squot64(hist_L_30250, hist_el_sizze_30247), sdiv_up64(hist_N_30248, num_tblocks_30252))) / sitofp_i64_f64(hist_H_30246);
        int64_t hist_M0_30254 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_30253), max_tblock_sizze_30251));
        int64_t hist_Nout_30255 = (int64_t) 1;
        int64_t hist_Nin_30256 = nz2081U_25211;
        int64_t work_asymp_M_max_30257 = squot64(hist_Nout_30255 * hist_N_30248, (int64_t) 2 * num_tblocks_30252 * hist_H_30246);
        int32_t hist_M_30258 = sext_i64_i32(smin64(hist_M0_30254, work_asymp_M_max_30257));
        int64_t hist_C_30259 = sdiv_up64(max_tblock_sizze_30251, sext_i32_i64(smax32(1, hist_M_30258)));
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_30254, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_30257, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_30259, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_30251, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_30258, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_30246 * hist_el_sizze_30247 * sext_i32_i64(hist_M_30258)), '\n');
        
        int64_t local_mem_needed_30260 = hist_el_sizze_30247 * sext_i32_i64(hist_M_30258);
        int32_t hist_S_30261 = sext_i64_i32(sdiv_up64(hist_H_30246 * local_mem_needed_30260 + (int64_t) 1, hist_L_30250));
        
        if (sle64(hist_H_30246, hist_Nin_30256) && (sle64(local_mem_needed_30260, hist_L_30250) && (sle32(hist_S_30261, 3) && (sle64(hist_C_30259, max_tblock_sizze_30251) && slt32(0, hist_M_30258))))) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using shared memory");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30246, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30258, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_30259, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30261, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_30258, '\n');
            num_subhistos_30239 = num_tblocks_30252;
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_30239, '\n');
            if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_25210 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30240")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_25210, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30240.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29699.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_25210})) != 0)
                    goto cleanup;
            }
            if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_25210 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30242")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_25210, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30242.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29697.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_25210})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_30262 = 0; chk_i_30262 < hist_S_30261; chk_i_30262++) {
                int64_t num_segments_30263 = (int64_t) 1;
                int64_t hist_H_chk_30264 = sdiv_up64(mz2080U_25210, sext_i32_i64(hist_S_30261));
                int64_t histo_sizze_30265 = hist_H_chk_30264;
                int32_t init_per_thread_30266 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_30258) * histo_sizze_30265, max_tblock_sizze_30251));
                
                {
                    err = gpu_kernel_human_generici32ziseghist_local_29274(ctx, num_tblocks_30252, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30258 * hist_H_chk_30264), (int64_t) 8), (int64_t) 8)), mz2080U_25210, nz2081U_25211, num_subhistos_30239, num_tblocks_30252, hist_M_30258, chk_i_30262, num_segments_30263, hist_H_chk_30264, histo_sizze_30265, init_per_thread_30266, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
            }
        } else {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "## Using global memory");
            
            int64_t hist_H_30307 = mz2080U_25210;
            double hist_RF_30308 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
            int32_t hist_el_sizze_30309 = 4;
            double hist_C_max_30310 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29269 * seghist_tblock_sizze_29267)), sitofp_i32_f64(hist_H_30307) / 2.0);
            int32_t hist_M_min_30311 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29269 * seghist_tblock_sizze_29267)) / hist_C_max_30310)));
            int64_t hist_L2_30312;
            
            hist_L2_30312 = *ctx->tuning_params.human_generici32zihist_L2_30312;
            
            double hist_RACE_exp_30313 = fmax64(1.0, 0.75 * hist_RF_30308 / (64.0 / sitofp_i32_f64(hist_el_sizze_30309)));
            int32_t hist_S_30314;
            
            if (slt64(nz2081U_25211, hist_H_30307)) {
                hist_S_30314 = 1;
            } else {
                hist_S_30314 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_30311) * hist_H_30307 * sext_i32_i64(hist_el_sizze_30309), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_30312) * hist_RACE_exp_30313)));
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_30313, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30314, '\n');
            
            int64_t hist_H_chk_30315 = sdiv_up64(mz2080U_25210, sext_i32_i64(hist_S_30314));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_30315, '\n');
            
            double hist_k_max_30316 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_30312) / sitofp_i32_f64(8)) * hist_RACE_exp_30313, sitofp_i32_f64(nz2081U_25211)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_29269 * seghist_tblock_sizze_29267));
            int64_t hist_u_30317 = (int64_t) 2;
            double hist_C_30318 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29269 * seghist_tblock_sizze_29267)), sitofp_i32_f64(hist_u_30317 * hist_H_chk_30315) / hist_k_max_30316);
            int32_t hist_M_30319 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_30316, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30319, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_30318, '\n');
            num_subhistos_30239 = sext_i32_i64(hist_M_30319);
            if (hist_M_30319 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30240, &mem_29699, "mem_29699") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_25210 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30240")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30240, num_subhistos_30239 * mz2080U_25210, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30240.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29699.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_25210})) != 0)
                    goto cleanup;
            }
            if (hist_M_30319 == 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else if (num_subhistos_30239 == (int64_t) 1) {
                if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30242, &mem_29697, "mem_29697") != 0)
                    return 1;
            } else {
                if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_25210 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30242")) {
                    err = 1;
                    goto cleanup;
                }
                if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30242, num_subhistos_30239 * mz2080U_25210, 0) != 0) {
                    err = 1;
                    goto cleanup;
                }
                if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30242.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29697.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_25210})) != 0)
                    goto cleanup;
            }
            for (int32_t chk_i_30320 = 0; chk_i_30320 < hist_S_30314; chk_i_30320++) {
                int64_t hist_H_chk_30321 = sdiv_up64(mz2080U_25210, sext_i32_i64(hist_S_30314));
                
                {
                    err = gpu_kernel_human_generici32ziseghist_global_29274(ctx, num_tblocks_29269, 1, 1, *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266, 1, 1, (int64_t) 0, mz2080U_25210, nz2081U_25211, num_tblocks_29269, num_subhistos_30239, chk_i_30320, hist_H_chk_30321, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
                ctx->failure_is_an_option = 1;
            }
        }
        if (num_subhistos_30239 == (int64_t) 1) {
            if (memblock_set_device(ctx, &mem_29699, &defunc_0_map_res_subhistos_mem_30240, "defunc_0_map_res_subhistos_mem_30240") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_29697, &defunc_0_map_res_subhistos_mem_30242, "defunc_0_map_res_subhistos_mem_30242") != 0)
                return 1;
        } else {
            int64_t chunk_sizze_30338 = (int64_t) 1;
            
            if (slt64(num_subhistos_30239 * (int64_t) 2, seghist_tblock_sizze_29267 * chunk_sizze_30338)) {
                int64_t segment_sizze_nonzzero_30339 = smax64((int64_t) 1, num_subhistos_30239);
                int64_t num_threads_30340 = seghist_tblock_sizze_29267 * seghist_tblock_sizze_29267;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-small");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_25210, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30239, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339), '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_25210, squot64(seghist_tblock_sizze_29267, segment_sizze_nonzzero_30339))), '\n');
                {
                    err = gpu_kernel_human_generici32zisegred_small_30337(ctx, num_tblocks_29269, 1, 1, *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266, 1, 1, (int64_t) 4 * seghist_tblock_sizze_29267 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29267, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_29267 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29267, (int64_t) 8), (int64_t) 8)), mz2080U_25210, num_tblocks_29269, num_subhistos_30239, segment_sizze_nonzzero_30339, mem_29697.mem, mem_29699.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            } else {
                int64_t blocks_per_segment_30375 = sdiv_up64(num_tblocks_29269, smax64((int64_t) 1, mz2080U_25210));
                int64_t q_30376 = sdiv_up64(num_subhistos_30239, seghist_tblock_sizze_29267 * blocks_per_segment_30375 * chunk_sizze_30338);
                int64_t num_virtblocks_30377 = blocks_per_segment_30375 * mz2080U_25210;
                int64_t threads_per_segment_30378 = blocks_per_segment_30375 * seghist_tblock_sizze_29267;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "# SegRed-large");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_25210, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30239, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_30377, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_29269, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_29267, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_30376, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_30375, '\n');
                if (memblock_alloc_device(ctx, &segred_tmp_mem_30379, (int64_t) 4 * num_virtblocks_30377, "segred_tmp_mem_30379")) {
                    err = 1;
                    goto cleanup;
                }
                if (memblock_alloc_device(ctx, &segred_tmp_mem_30381, (int64_t) 4 * num_virtblocks_30377, "segred_tmp_mem_30381")) {
                    err = 1;
                    goto cleanup;
                }
                {
                    err = gpu_kernel_human_generici32zisegred_large_30337(ctx, num_tblocks_29269, 1, 1, *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29266, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_29267 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29267, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_29267 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29267, (int64_t) 8), (int64_t) 8)), mz2080U_25210, num_tblocks_29269, num_subhistos_30239, blocks_per_segment_30375, q_30376, num_virtblocks_30377, threads_per_segment_30378, mem_29697.mem, mem_29699.mem, defunc_0_map_res_subhistos_mem_30240.mem, defunc_0_map_res_subhistos_mem_30242.mem, segred_tmp_mem_30379.mem, segred_tmp_mem_30381.mem, counters_mem_30383.mem);
                    if (err != FUTHARK_SUCCESS)
                        goto cleanup;
                }
            }
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segmap_tblock_sizze_29329;
    
    segmap_tblock_sizze_29329 = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29296;
    
    int64_t segmap_usable_groups_29330 = sdiv_up64(mz2080U_25210, segmap_tblock_sizze_29329);
    
    if (memblock_alloc_device(ctx, &mem_29703, bytes_29691, "mem_29703")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29705, bytes_29691, "mem_29705")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29707, bytes_29691, "mem_29707")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29709, bytes_29691, "mem_29709")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30426 = sext_i64_i32(sdiv_up64(mz2080U_25210, segmap_tblock_sizze_29329));
    
    {
        err = gpu_kernel_human_generici32zisegmap_29336(ctx, segmap_usable_groups_29330, 1, 1, *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29296, 1, 1, (int64_t) 0, mz2080U_25210, ks_mem_29677.mem, shp_mem_29678.mem, mem_29695.mem, mem_29697.mem, mem_29699.mem, mem_29703.mem, mem_29705.mem, mem_29707.mem, mem_29709.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29697, "mem_29697") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29699, "mem_29699") != 0)
        return 1;
    
    int64_t segscan_tblock_sizze_29366;
    
    segscan_tblock_sizze_29366 = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29365;
    
    int64_t num_tblocks_29368;
    int64_t max_num_tblocks_30435;
    
    max_num_tblocks_30435 = *ctx->tuning_params.human_generici32zisegscan_num_tblocks_29367;
    num_tblocks_29368 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_25211, segscan_tblock_sizze_29366), max_num_tblocks_30435)));
    
    int64_t bytes_29711 = (int64_t) 8 * nz2081U_25211;
    
    if (memblock_alloc_device(ctx, &mem_29712, bytes_29711, "mem_29712")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29714, bytes_29711, "mem_29714")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, nz2081U_25211)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t shared_memory_30436;
        
        shared_memory_30436 = ctx->max_shared_memory;
        
        int64_t thread_block_sizze_30437;
        
        thread_block_sizze_30437 = ctx->max_thread_block_size;
        
        int64_t registers_30438;
        
        registers_30438 = ctx->max_registers;
        
        int64_t thread_block_sizze_30439;
        
        thread_block_sizze_30439 = ctx->max_thread_block_size;
        
        int64_t chunk_sizze_30440 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30436, thread_block_sizze_30437), (int64_t) 8), squot64(squot64(registers_30438, thread_block_sizze_30439) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
        int64_t num_virt_blocks_30441 = sdiv_up64(nz2081U_25211, segscan_tblock_sizze_29366 * chunk_sizze_30440);
        int64_t num_virt_threads_30442 = num_virt_blocks_30441 * segscan_tblock_sizze_29366;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30440, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_30443, num_virt_blocks_30441, "status_flags_mem_30443")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30443, num_virt_blocks_30441, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_30445, (int64_t) 8 * num_virt_blocks_30441, "aggregates_mem_30445")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_30447, (int64_t) 8 * num_virt_blocks_30441, "incprefixes_mem_30447")) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_human_generici32zisegscan_29371(ctx, num_tblocks_29368, 1, 1, *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29365, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29366), chunk_sizze_30440 * segscan_tblock_sizze_29366 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29366), chunk_sizze_30440 * segscan_tblock_sizze_29366 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_25210, nz2081U_25211, num_tblocks_29368, num_virt_blocks_30441, num_virt_threads_30442, II1_mem_29679.mem, A_mem_29680.mem, mem_29695.mem, mem_29709.mem, mem_29712.mem, mem_29714.mem, status_flags_mem_30443.mem, aggregates_mem_30445.mem, incprefixes_mem_30447.mem, global_dynid_mem_30449.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_29695, "mem_29695") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29709, "mem_29709") != 0)
        return 1;
    
    bool cond_27079 = nz2081U_25211 == (int64_t) 0;
    bool x_27080 = !cond_27079;
    int64_t tmp_27081 = sub64(nz2081U_25211, (int64_t) 1);
    bool x_27082 = sle64((int64_t) 0, tmp_27081);
    bool y_27083 = slt64(tmp_27081, nz2081U_25211);
    bool bounds_check_27084 = x_27082 && y_27083;
    bool protect_assert_disj_27085 = cond_27079 || bounds_check_27084;
    bool index_certs_27086;
    
    if (!protect_assert_disj_27085) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_27081, "] out of bounds for array of shape [", (long long) nz2081U_25211, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:31:1-108\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t m_f_res_27087;
    
    if (x_27080) {
        int64_t read_res_30997;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_30997, mem_29712.mem, tmp_27081 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_28161 = read_res_30997;
        
        m_f_res_27087 = x_28161;
    } else {
        m_f_res_27087 = (int64_t) 0;
    }
    
    int64_t m_27089;
    
    if (cond_27079) {
        m_27089 = (int64_t) 0;
    } else {
        m_27089 = m_f_res_27087;
    }
    
    int64_t m_27099 = sub64(m_27089, (int64_t) 1);
    bool i_p_m_t_s_leq_w_27101 = slt64(m_27099, nz2081U_25211);
    bool zzero_leq_i_p_m_t_s_27100 = sle64((int64_t) 0, m_27099);
    bool y_27103 = zzero_leq_i_p_m_t_s_27100 && i_p_m_t_s_leq_w_27101;
    bool i_lte_j_27102 = sle64((int64_t) 0, m_27089);
    bool forwards_ok_27104 = i_lte_j_27102 && y_27103;
    bool eq_x_zz_27096 = (int64_t) 0 == m_f_res_27087;
    bool p_and_eq_x_y_27097 = x_27080 && eq_x_zz_27096;
    bool empty_slice_27098 = cond_27079 || p_and_eq_x_y_27097;
    bool ok_or_empty_27105 = empty_slice_27098 || forwards_ok_27104;
    bool index_certs_27106;
    
    if (!ok_or_empty_27105) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_27089, "] out of bounds for array of shape [", (long long) nz2081U_25211, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:31:1-108\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t bytes_29715 = (int64_t) 4 * m_27089;
    
    if (memblock_alloc_device(ctx, &mem_29716, bytes_29715, "mem_29716")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29716.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, II1_mem_29679.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27089})) != 0)
        goto cleanup;
    if (memblock_alloc_device(ctx, &mem_29718, bytes_29715, "mem_29718")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29718.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, A_mem_29680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27089})) != 0)
        goto cleanup;
    
    int64_t segmap_tblock_sizze_29376;
    
    segmap_tblock_sizze_29376 = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29375;
    
    int64_t num_tblocks_29378;
    int64_t max_num_tblocks_30538;
    
    max_num_tblocks_30538 = *ctx->tuning_params.human_generici32zisegmap_num_tblocks_29377;
    num_tblocks_29378 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(nz2081U_25211, segmap_tblock_sizze_29376), max_num_tblocks_30538)));
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_tblocks_30539 = sext_i64_i32(sdiv_up64(nz2081U_25211, segmap_tblock_sizze_29376));
    
    {
        err = gpu_kernel_human_generici32zisegmap_29373(ctx, num_tblocks_29378, 1, 1, *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29375, 1, 1, (int64_t) 0, nz2081U_25211, m_27089, num_tblocks_29378, virt_num_tblocks_30539, II1_mem_29679.mem, A_mem_29680.mem, mem_29712.mem, mem_29714.mem, mem_29716.mem, mem_29718.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_29712, "mem_29712") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29714, "mem_29714") != 0)
        return 1;
    
    bool loop_cond_27116 = slt64((int64_t) 0, m_27089);
    int64_t segscan_tblock_sizze_29382;
    
    segscan_tblock_sizze_29382 = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29381;
    
    int64_t num_tblocks_29384;
    int64_t max_num_tblocks_30552;
    
    max_num_tblocks_30552 = *ctx->tuning_params.human_generici32zisegscan_num_tblocks_29383;
    num_tblocks_29384 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(mz2080U_25210, segscan_tblock_sizze_29382), max_num_tblocks_30552)));
    
    int64_t segmap_tblock_sizze_29474;
    
    segmap_tblock_sizze_29474 = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29391;
    
    int64_t segmap_usable_groups_29475 = sdiv_up_safe64(mz2080U_25210, segmap_tblock_sizze_29474);
    int64_t seghist_tblock_sizze_29558;
    
    seghist_tblock_sizze_29558 = *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557;
    
    int64_t segmap_tblock_sizze_29621;
    
    segmap_tblock_sizze_29621 = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29587;
    
    int64_t segmap_usable_groups_29622 = sdiv_up_safe64(mz2080U_25210, segmap_tblock_sizze_29621);
    int64_t segscan_tblock_sizze_29659;
    
    segscan_tblock_sizze_29659 = *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29658;
    
    int64_t segmap_tblock_sizze_29669;
    
    segmap_tblock_sizze_29669 = *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29668;
    if (memblock_alloc_device(ctx, &mem_29737, bytes_29691, "mem_29737")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29740, bytes_29691, "mem_29740")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29742, bytes_29691, "mem_29742")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29744, bytes_29691, "mem_29744")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_29754, bytes_29691, "mem_29754")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t result_27118;
    bool result_27119;
    int64_t loop_dz2081Uz2088Uz2087U_27125;
    bool loop_while_27126;
    
    if (memblock_set_device(ctx, &mem_param_29722, &mem_29705, "mem_29705") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29725, &mem_29703, "mem_29703") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29728, &mem_29716, "mem_29716") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29731, &mem_29718, "mem_29718") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_29734, &mem_29707, "mem_29707") != 0)
        return 1;
    loop_dz2081Uz2088Uz2087U_27125 = m_27089;
    loop_while_27126 = loop_cond_27116;
    while (loop_while_27126) {
        if (slt64((int64_t) 0, mz2080U_25210)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_30565;
            
            shared_memory_30565 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_30566;
            
            thread_block_sizze_30566 = ctx->max_thread_block_size;
            
            int64_t registers_30567;
            
            registers_30567 = ctx->max_registers;
            
            int64_t thread_block_sizze_30568;
            
            thread_block_sizze_30568 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_30569 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30565, thread_block_sizze_30566), (int64_t) 4), squot64(squot64(registers_30567, thread_block_sizze_30568) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 4), (int64_t) 4))));
            int64_t num_virt_blocks_30570 = sdiv_up64(mz2080U_25210, segscan_tblock_sizze_29382 * chunk_sizze_30569);
            int64_t num_virt_threads_30571 = num_virt_blocks_30570 * segscan_tblock_sizze_29382;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30569, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_30572, num_virt_blocks_30570, "status_flags_mem_30572")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30572, num_virt_blocks_30570, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_30574, (int64_t) 4 * num_virt_blocks_30570, "aggregates_mem_30574")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_30576, (int64_t) 4 * num_virt_blocks_30570, "incprefixes_mem_30576")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_human_generici32zisegscan_29387(ctx, num_tblocks_29384, 1, 1, *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29381, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_29382), chunk_sizze_30569 * segscan_tblock_sizze_29382 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_tblock_sizze_29382), chunk_sizze_30569 * segscan_tblock_sizze_29382 * (int64_t) 4), (int64_t) 8), (int64_t) 8), mz2080U_25210, num_tblocks_29384, num_virt_blocks_30570, num_virt_threads_30571, mem_param_29725.mem, mem_29737.mem, status_flags_mem_30572.mem, aggregates_mem_30574.mem, incprefixes_mem_30576.mem, global_dynid_mem_30578.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30667 = sext_i64_i32(sdiv_up64(mz2080U_25210, segmap_tblock_sizze_29474));
        
        {
            err = gpu_kernel_human_generici32zisegmap_29478(ctx, segmap_usable_groups_29475, 1, 1, *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29391, 1, 1, (int64_t) 0, mz2080U_25210, loop_dz2081Uz2088Uz2087U_27125, mem_param_29725.mem, mem_param_29731.mem, mem_29737.mem, mem_29740.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (futrts_builtinzhreplicate_i32(ctx, mem_29742, mz2080U_25210, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i32(ctx, mem_29744, mz2080U_25210, 0) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t num_tblocks_29560;
        int64_t max_num_tblocks_30676;
        
        max_num_tblocks_30676 = *ctx->tuning_params.human_generici32ziseghist_num_tblocks_29559;
        num_tblocks_29560 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, seghist_tblock_sizze_29558), max_num_tblocks_30676)));
        
        int64_t num_subhistos_30677;
        int64_t h_30682 = (int64_t) 4 * mz2080U_25210 + (int64_t) 4 * mz2080U_25210;
        int64_t seg_h_30683 = (int64_t) 4 * mz2080U_25210 + (int64_t) 4 * mz2080U_25210;
        
        if (!(seg_h_30683 == (int64_t) 0)) {
            int64_t hist_H_30684 = mz2080U_25210;
            int64_t hist_el_sizze_30685 = sdiv_up64(h_30682, hist_H_30684);
            int64_t hist_N_30686 = loop_dz2081Uz2088Uz2087U_27125;
            int32_t hist_RF_30687 = 1;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegHist");
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of threads (T)", (long long) sext_i64_i32(num_tblocks_29560 * seghist_tblock_sizze_29558), '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Desired block size (B)", (long long) seghist_tblock_sizze_29558, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30684, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Input elements per histogram (N)", (long long) hist_N_30686, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Number of segments", (long long) (int64_t) 1, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Histogram element size (el_size)", (long long) hist_el_sizze_30685, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Race factor (RF)", (long long) hist_RF_30687, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms per segment", (long long) h_30682, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Memory per set of subhistograms times segments", (long long) seg_h_30683, '\n');
            
            int64_t hist_L_30688;
            
            hist_L_30688 = *ctx->tuning_params.human_generici32zihist_L_30688;
            
            int64_t max_tblock_sizze_30689;
            
            max_tblock_sizze_30689 = ctx->max_thread_block_size;
            
            int64_t num_tblocks_30690 = sdiv_up64(sext_i32_i64(sext_i64_i32(num_tblocks_29560 * seghist_tblock_sizze_29558)), max_tblock_sizze_30689);
            double hist_m_prime_30691 = sitofp_i64_f64(smin64(squot64(hist_L_30688, hist_el_sizze_30685), sdiv_up64(hist_N_30686, num_tblocks_30690))) / sitofp_i64_f64(hist_H_30684);
            int64_t hist_M0_30692 = smax64((int64_t) 1, smin64(fptosi_f64_i64(hist_m_prime_30691), max_tblock_sizze_30689));
            int64_t hist_Nout_30693 = (int64_t) 1;
            int64_t hist_Nin_30694 = loop_dz2081Uz2088Uz2087U_27125;
            int64_t work_asymp_M_max_30695 = squot64(hist_Nout_30693 * hist_N_30686, (int64_t) 2 * num_tblocks_30690 * hist_H_30684);
            int32_t hist_M_30696 = sext_i64_i32(smin64(hist_M0_30692, work_asymp_M_max_30695));
            int64_t hist_C_30697 = sdiv_up64(max_tblock_sizze_30689, sext_i32_i64(smax32(1, hist_M_30696)));
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local hist_M0", (long long) hist_M0_30692, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local work asymp M max", (long long) work_asymp_M_max_30695, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local C", (long long) hist_C_30697, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local B", (long long) max_tblock_sizze_30689, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "local M", (long long) hist_M_30696, '\n');
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "shared memory needed", (long long) (hist_H_30684 * hist_el_sizze_30685 * sext_i32_i64(hist_M_30696)), '\n');
            
            int64_t local_mem_needed_30698 = hist_el_sizze_30685 * sext_i32_i64(hist_M_30696);
            int32_t hist_S_30699 = sext_i64_i32(sdiv_up64(hist_H_30684 * local_mem_needed_30698 + (int64_t) 1, hist_L_30688));
            
            if (sle64(hist_H_30684, hist_Nin_30694) && (sle64(local_mem_needed_30698, hist_L_30688) && (sle32(hist_S_30699, 3) && (sle64(hist_C_30697, max_tblock_sizze_30689) && slt32(0, hist_M_30696))))) {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using shared memory");
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Histogram size (H)", (long long) hist_H_30684, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30696, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Cooperation level (C)", (long long) hist_C_30697, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30699, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of local subhistograms per block", (long long) hist_M_30696, '\n');
                num_subhistos_30677 = num_tblocks_30690;
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of subhistograms in global memory per segment", (long long) num_subhistos_30677, '\n');
                if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_25210 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30678")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_25210, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30678.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29744.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_25210})) != 0)
                        goto cleanup;
                }
                if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_25210 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30680")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_25210, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29742.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_25210})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_30700 = 0; chk_i_30700 < hist_S_30699; chk_i_30700++) {
                    int64_t num_segments_30701 = (int64_t) 1;
                    int64_t hist_H_chk_30702 = sdiv_up64(mz2080U_25210, sext_i32_i64(hist_S_30699));
                    int64_t histo_sizze_30703 = hist_H_chk_30702;
                    int32_t init_per_thread_30704 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_30696) * histo_sizze_30703, max_tblock_sizze_30689));
                    
                    {
                        err = gpu_kernel_human_generici32ziseghist_local_29565(ctx, num_tblocks_30690, 1, 1, ctx->max_thread_block_size, 1, 1, (int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702) + srem64((int64_t) 8 - srem64((int64_t) 4 * (hist_M_30696 * hist_H_chk_30702), (int64_t) 8), (int64_t) 8)), mz2080U_25210, loop_dz2081Uz2088Uz2087U_27125, num_subhistos_30677, num_tblocks_30690, hist_M_30696, chk_i_30700, num_segments_30701, hist_H_chk_30702, histo_sizze_30703, init_per_thread_30704, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                }
            } else {
                if (ctx->debugging)
                    fprintf(ctx->log, "%s\n", "## Using global memory");
                
                int64_t hist_H_30745 = mz2080U_25210;
                double hist_RF_30746 = (0.0 + sitofp_i32_f64((int64_t) 1)) / 1.0;
                int32_t hist_el_sizze_30747 = 4;
                double hist_C_max_30748 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29560 * seghist_tblock_sizze_29558)), sitofp_i32_f64(hist_H_30745) / 2.0);
                int32_t hist_M_min_30749 = smax32(1, sext_i64_i32(fptosi_f64_i64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29560 * seghist_tblock_sizze_29558)) / hist_C_max_30748)));
                int64_t hist_L2_30750;
                
                hist_L2_30750 = *ctx->tuning_params.human_generici32zihist_L2_30750;
                
                double hist_RACE_exp_30751 = fmax64(1.0, 0.75 * hist_RF_30746 / (64.0 / sitofp_i32_f64(hist_el_sizze_30747)));
                int32_t hist_S_30752;
                
                if (slt64(loop_dz2081Uz2088Uz2087U_27125, hist_H_30745)) {
                    hist_S_30752 = 1;
                } else {
                    hist_S_30752 = sext_i64_i32(sdiv_up64(sext_i32_i64(hist_M_min_30749) * hist_H_30745 * sext_i32_i64(hist_el_sizze_30747), fptosi_f64_i64(0.4 * sitofp_i32_f64(hist_L2_30750) * hist_RACE_exp_30751)));
                }
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Race expansion factor (RACE^exp)", (double) hist_RACE_exp_30751, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Number of chunks (S)", (long long) hist_S_30752, '\n');
                
                int64_t hist_H_chk_30753 = sdiv_up64(mz2080U_25210, sext_i32_i64(hist_S_30752));
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Chunk size (H_chk)", (long long) hist_H_chk_30753, '\n');
                
                double hist_k_max_30754 = fmin64(0.4 * (sitofp_i32_f64(hist_L2_30750) / sitofp_i32_f64(8)) * hist_RACE_exp_30751, sitofp_i32_f64(loop_dz2081Uz2088Uz2087U_27125)) / sitofp_i32_f64(sext_i64_i32(num_tblocks_29560 * seghist_tblock_sizze_29558));
                int64_t hist_u_30755 = (int64_t) 2;
                double hist_C_30756 = fmin64(sitofp_i32_f64(sext_i64_i32(num_tblocks_29560 * seghist_tblock_sizze_29558)), sitofp_i32_f64(hist_u_30755 * hist_H_chk_30753) / hist_k_max_30754);
                int32_t hist_M_30757 = 1;
                
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Elements/thread in L2 cache (k_max)", (double) hist_k_max_30754, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %llu%c", "Multiplication degree (M)", (long long) hist_M_30757, '\n');
                if (ctx->debugging)
                    fprintf(ctx->log, "%s: %f%c", "Cooperation level (C)", (double) hist_C_30756, '\n');
                num_subhistos_30677 = sext_i32_i64(hist_M_30757);
                if (hist_M_30757 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30678, &mem_29744, "mem_29744") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_25210 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30678")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30678, num_subhistos_30677 * mz2080U_25210, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30678.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29744.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_25210})) != 0)
                        goto cleanup;
                }
                if (hist_M_30757 == 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else if (num_subhistos_30677 == (int64_t) 1) {
                    if (memblock_set_device(ctx, &defunc_0_map_res_subhistos_mem_30680, &mem_29742, "mem_29742") != 0)
                        return 1;
                } else {
                    if (memblock_alloc_device(ctx, &defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_25210 * (int64_t) 4, "defunc_0_map_res_subhistos_mem_30680")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (futrts_builtinzhreplicate_i32(ctx, defunc_0_map_res_subhistos_mem_30680, num_subhistos_30677 * mz2080U_25210, 0) != 0) {
                        err = 1;
                        goto cleanup;
                    }
                    if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, defunc_0_map_res_subhistos_mem_30680.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_29742.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {mz2080U_25210})) != 0)
                        goto cleanup;
                }
                for (int32_t chk_i_30758 = 0; chk_i_30758 < hist_S_30752; chk_i_30758++) {
                    int64_t hist_H_chk_30759 = sdiv_up64(mz2080U_25210, sext_i32_i64(hist_S_30752));
                    
                    {
                        err = gpu_kernel_human_generici32ziseghist_global_29565(ctx, num_tblocks_29560, 1, 1, *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557, 1, 1, (int64_t) 0, mz2080U_25210, loop_dz2081Uz2088Uz2087U_27125, num_tblocks_29560, num_subhistos_30677, chk_i_30758, hist_H_chk_30759, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                    ctx->failure_is_an_option = 1;
                }
            }
            if (num_subhistos_30677 == (int64_t) 1) {
                if (memblock_set_device(ctx, &mem_29744, &defunc_0_map_res_subhistos_mem_30678, "defunc_0_map_res_subhistos_mem_30678") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_29742, &defunc_0_map_res_subhistos_mem_30680, "defunc_0_map_res_subhistos_mem_30680") != 0)
                    return 1;
            } else {
                int64_t chunk_sizze_30776 = (int64_t) 1;
                
                if (slt64(num_subhistos_30677 * (int64_t) 2, seghist_tblock_sizze_29558 * chunk_sizze_30776)) {
                    int64_t segment_sizze_nonzzero_30777 = smax64((int64_t) 1, num_subhistos_30677);
                    int64_t num_threads_30778 = seghist_tblock_sizze_29558 * seghist_tblock_sizze_29558;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-small");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_25210, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30677, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segments_per_block", (long long) squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777), '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "required_blocks", (long long) sext_i64_i32(sdiv_up64(mz2080U_25210, squot64(seghist_tblock_sizze_29558, segment_sizze_nonzzero_30777))), '\n');
                    {
                        err = gpu_kernel_human_generici32zisegred_small_30775(ctx, num_tblocks_29560, 1, 1, *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557, 1, 1, (int64_t) 4 * seghist_tblock_sizze_29558 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29558, (int64_t) 8), (int64_t) 8) + ((int64_t) 4 * seghist_tblock_sizze_29558 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29558, (int64_t) 8), (int64_t) 8)), mz2080U_25210, num_tblocks_29560, num_subhistos_30677, segment_sizze_nonzzero_30777, mem_29742.mem, mem_29744.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                } else {
                    int64_t blocks_per_segment_30813 = sdiv_up64(num_tblocks_29560, smax64((int64_t) 1, mz2080U_25210));
                    int64_t q_30814 = sdiv_up64(num_subhistos_30677, seghist_tblock_sizze_29558 * blocks_per_segment_30813 * chunk_sizze_30776);
                    int64_t num_virtblocks_30815 = blocks_per_segment_30813 * mz2080U_25210;
                    int64_t threads_per_segment_30816 = blocks_per_segment_30813 * seghist_tblock_sizze_29558;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "# SegRed-large");
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) mz2080U_25210, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) num_subhistos_30677, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_virtblocks", (long long) num_virtblocks_30815, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "num_tblocks", (long long) num_tblocks_29560, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "tblock_size", (long long) seghist_tblock_sizze_29558, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "q", (long long) q_30814, '\n');
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s: %llu%c", "blocks_per_segment", (long long) blocks_per_segment_30813, '\n');
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_30817, (int64_t) 4 * num_virtblocks_30815, "segred_tmp_mem_30817")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_30819, (int64_t) 4 * num_virtblocks_30815, "segred_tmp_mem_30819")) {
                        err = 1;
                        goto cleanup;
                    }
                    {
                        err = gpu_kernel_human_generici32zisegred_large_30775(ctx, num_tblocks_29560, 1, 1, *ctx->tuning_params.human_generici32ziseghist_tblock_sizze_29557, 1, 1, 8 + ((int64_t) 4 * seghist_tblock_sizze_29558 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29558, (int64_t) 8), (int64_t) 8)) + ((int64_t) 4 * seghist_tblock_sizze_29558 + srem64((int64_t) 8 - srem64((int64_t) 4 * seghist_tblock_sizze_29558, (int64_t) 8), (int64_t) 8)), mz2080U_25210, num_tblocks_29560, num_subhistos_30677, blocks_per_segment_30813, q_30814, num_virtblocks_30815, threads_per_segment_30816, mem_29742.mem, mem_29744.mem, defunc_0_map_res_subhistos_mem_30678.mem, defunc_0_map_res_subhistos_mem_30680.mem, segred_tmp_mem_30817.mem, segred_tmp_mem_30819.mem, counters_mem_30821.mem);
                        if (err != FUTHARK_SUCCESS)
                            goto cleanup;
                    }
                }
            }
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_alloc_device(ctx, &mem_29748, bytes_29691, "mem_29748")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29750, bytes_29691, "mem_29750")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29752, bytes_29691, "mem_29752")) {
            err = 1;
            goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30864 = sext_i64_i32(sdiv_up64(mz2080U_25210, segmap_tblock_sizze_29621));
        
        {
            err = gpu_kernel_human_generici32zisegmap_29628(ctx, segmap_usable_groups_29622, 1, 1, *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29587, 1, 1, (int64_t) 0, mz2080U_25210, mem_param_29722.mem, mem_param_29725.mem, mem_param_29734.mem, mem_29740.mem, mem_29742.mem, mem_29744.mem, mem_29748.mem, mem_29750.mem, mem_29752.mem, mem_29754.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        
        int64_t num_tblocks_29661;
        int64_t max_num_tblocks_30873;
        
        max_num_tblocks_30873 = *ctx->tuning_params.human_generici32zisegscan_num_tblocks_29660;
        num_tblocks_29661 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, segscan_tblock_sizze_29659), max_num_tblocks_30873)));
        
        int64_t bytes_29756 = (int64_t) 8 * loop_dz2081Uz2088Uz2087U_27125;
        
        if (memblock_alloc_device(ctx, &mem_29757, bytes_29756, "mem_29757")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &mem_29759, bytes_29756, "mem_29759")) {
            err = 1;
            goto cleanup;
        }
        if (slt64((int64_t) 0, loop_dz2081Uz2088Uz2087U_27125)) {
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "\n# SegScan");
            
            int64_t shared_memory_30874;
            
            shared_memory_30874 = ctx->max_shared_memory;
            
            int64_t thread_block_sizze_30875;
            
            thread_block_sizze_30875 = ctx->max_thread_block_size;
            
            int64_t registers_30876;
            
            registers_30876 = ctx->max_registers;
            
            int64_t thread_block_sizze_30877;
            
            thread_block_sizze_30877 = ctx->max_thread_block_size;
            
            int64_t chunk_sizze_30878 = smax64((int64_t) 1, smin64(squot64(squot64(shared_memory_30874, thread_block_sizze_30875), (int64_t) 8), squot64(squot64(registers_30876, thread_block_sizze_30877) - (int64_t) 1 - squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4), (int64_t) 2 * squot64(smax64((int64_t) 4, (int64_t) 8), (int64_t) 4))));
            int64_t num_virt_blocks_30879 = sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, segscan_tblock_sizze_29659 * chunk_sizze_30878);
            int64_t num_virt_threads_30880 = num_virt_blocks_30879 * segscan_tblock_sizze_29659;
            
            if (ctx->debugging)
                fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (chunk)", (long long) chunk_sizze_30878, '\n');
            if (memblock_alloc_device(ctx, &status_flags_mem_30881, num_virt_blocks_30879, "status_flags_mem_30881")) {
                err = 1;
                goto cleanup;
            }
            if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_30881, num_virt_blocks_30879, (int8_t) 0) != 0) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &aggregates_mem_30883, (int64_t) 8 * num_virt_blocks_30879, "aggregates_mem_30883")) {
                err = 1;
                goto cleanup;
            }
            if (memblock_alloc_device(ctx, &incprefixes_mem_30885, (int64_t) 8 * num_virt_blocks_30879, "incprefixes_mem_30885")) {
                err = 1;
                goto cleanup;
            }
            {
                err = gpu_kernel_human_generici32zisegscan_29664(ctx, num_tblocks_29661, 1, 1, *ctx->tuning_params.human_generici32zisegscan_tblock_sizze_29658, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29659), chunk_sizze_30878 * segscan_tblock_sizze_29659 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_tblock_sizze_29659), chunk_sizze_30878 * segscan_tblock_sizze_29659 * (int64_t) 8), (int64_t) 8), (int64_t) 8), mz2080U_25210, loop_dz2081Uz2088Uz2087U_27125, num_tblocks_29661, num_virt_blocks_30879, num_virt_threads_30880, mem_param_29728.mem, mem_param_29731.mem, mem_29740.mem, mem_29754.mem, mem_29757.mem, mem_29759.mem, status_flags_mem_30881.mem, aggregates_mem_30883.mem, incprefixes_mem_30885.mem, global_dynid_mem_30887.mem);
                if (err != FUTHARK_SUCCESS)
                    goto cleanup;
            }
            ctx->failure_is_an_option = 1;
            if (ctx->debugging)
                fprintf(ctx->log, "%s\n", "");
        }
        
        bool cond_27335 = loop_dz2081Uz2088Uz2087U_27125 == (int64_t) 0;
        bool x_27336 = !cond_27335;
        int64_t tmp_27337 = sub64(loop_dz2081Uz2088Uz2087U_27125, (int64_t) 1);
        bool x_27338 = sle64((int64_t) 0, tmp_27337);
        bool y_27339 = slt64(tmp_27337, loop_dz2081Uz2088Uz2087U_27125);
        bool bounds_check_27340 = x_27338 && y_27339;
        bool protect_assert_disj_27341 = cond_27335 || bounds_check_27340;
        bool index_certs_27342;
        
        if (!protect_assert_disj_27341) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) tmp_27337, "] out of bounds for array of shape [", (long long) loop_dz2081Uz2088Uz2087U_27125, "].", "-> #0  /prelude/soacs.fut:257:33-47\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:31:1-108\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t m_f_res_27343;
        
        if (x_27336) {
            int64_t read_res_30998;
            
            if ((err = gpu_scalar_from_device(ctx, &read_res_30998, mem_29757.mem, tmp_27337 * sizeof(int64_t), sizeof(int64_t))) != 0)
                goto cleanup;
            if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
                err = 1;
                goto cleanup;
            }
            
            int64_t x_28189 = read_res_30998;
            
            m_f_res_27343 = x_28189;
        } else {
            m_f_res_27343 = (int64_t) 0;
        }
        
        int64_t m_27345;
        
        if (cond_27335) {
            m_27345 = (int64_t) 0;
        } else {
            m_27345 = m_f_res_27343;
        }
        
        int64_t m_27355 = sub64(m_27345, (int64_t) 1);
        bool i_p_m_t_s_leq_w_27357 = slt64(m_27355, loop_dz2081Uz2088Uz2087U_27125);
        bool zzero_leq_i_p_m_t_s_27356 = sle64((int64_t) 0, m_27355);
        bool y_27359 = zzero_leq_i_p_m_t_s_27356 && i_p_m_t_s_leq_w_27357;
        bool i_lte_j_27358 = sle64((int64_t) 0, m_27345);
        bool forwards_ok_27360 = i_lte_j_27358 && y_27359;
        bool eq_x_zz_27352 = (int64_t) 0 == m_f_res_27343;
        bool p_and_eq_x_y_27353 = x_27336 && eq_x_zz_27352;
        bool empty_slice_27354 = cond_27335 || p_and_eq_x_y_27353;
        bool ok_or_empty_27361 = empty_slice_27354 || forwards_ok_27360;
        bool index_certs_27362;
        
        if (!ok_or_empty_27361) {
            set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) m_27345, "] out of bounds for array of shape [", (long long) loop_dz2081Uz2088Uz2087U_27125, "].", "-> #0  /prelude/soacs.fut:258:29-35\n   #1  /prelude/functional.fut:9:44-45\n   #2  testing/test_generic.fut:31:1-108\n"));
            err = FUTHARK_PROGRAM_ERROR;
            goto cleanup;
        }
        
        int64_t bytes_29760 = (int64_t) 4 * m_27345;
        
        if (memblock_alloc_device(ctx, &mem_29761, bytes_29760, "mem_29761")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29761.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_29728.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27345})) != 0)
            goto cleanup;
        if (memblock_alloc_device(ctx, &mem_29763, bytes_29760, "mem_29763")) {
            err = 1;
            goto cleanup;
        }
        if ((err = lmad_copy_gpu2gpu_4b(ctx, 1, mem_29763.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_param_29731.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {m_27345})) != 0)
            goto cleanup;
        
        int64_t num_tblocks_29671;
        int64_t max_num_tblocks_30976;
        
        max_num_tblocks_30976 = *ctx->tuning_params.human_generici32zisegmap_num_tblocks_29670;
        num_tblocks_29671 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, segmap_tblock_sizze_29669), max_num_tblocks_30976)));
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegMap");
        
        int32_t virt_num_tblocks_30977 = sext_i64_i32(sdiv_up64(loop_dz2081Uz2088Uz2087U_27125, segmap_tblock_sizze_29669));
        
        {
            err = gpu_kernel_human_generici32zisegmap_29666(ctx, num_tblocks_29671, 1, 1, *ctx->tuning_params.human_generici32zisegmap_tblock_sizze_29668, 1, 1, (int64_t) 0, loop_dz2081Uz2088Uz2087U_27125, m_27345, num_tblocks_29671, virt_num_tblocks_30977, mem_param_29728.mem, mem_param_29731.mem, mem_29757.mem, mem_29759.mem, mem_29761.mem, mem_29763.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
        if (memblock_unref_device(ctx, &mem_29757, "mem_29757") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29759, "mem_29759") != 0)
            return 1;
        
        bool loop_cond_27372 = slt64((int64_t) 0, m_27345);
        
        if (memblock_set_device(ctx, &mem_param_tmp_30553, &mem_29750, "mem_29750") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30554, &mem_29748, "mem_29748") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30555, &mem_29761, "mem_29761") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30556, &mem_29763, "mem_29763") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_30557, &mem_29752, "mem_29752") != 0)
            return 1;
        
        int64_t loop_dz2081Uz2088Uz2087U_tmp_30558 = m_27345;
        bool loop_while_tmp_30559 = loop_cond_27372;
        
        if (memblock_set_device(ctx, &mem_param_29722, &mem_param_tmp_30553, "mem_param_tmp_30553") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29725, &mem_param_tmp_30554, "mem_param_tmp_30554") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29728, &mem_param_tmp_30555, "mem_param_tmp_30555") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29731, &mem_param_tmp_30556, "mem_param_tmp_30556") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_29734, &mem_param_tmp_30557, "mem_param_tmp_30557") != 0)
            return 1;
        loop_dz2081Uz2088Uz2087U_27125 = loop_dz2081Uz2088Uz2087U_tmp_30558;
        loop_while_27126 = loop_while_tmp_30559;
    }
    if (memblock_set_device(ctx, &ext_mem_29779, &mem_param_29722, "mem_param_29722") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29778, &mem_param_29725, "mem_param_29725") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29777, &mem_param_29728, "mem_param_29728") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29776, &mem_param_29731, "mem_param_29731") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_29775, &mem_param_29734, "mem_param_29734") != 0)
        return 1;
    result_27118 = loop_dz2081Uz2088Uz2087U_27125;
    result_27119 = loop_while_27126;
    if (memblock_unref_device(ctx, &mem_29703, "mem_29703") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29705, "mem_29705") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29707, "mem_29707") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29716, "mem_29716") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29718, "mem_29718") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29737, "mem_29737") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29740, "mem_29740") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29742, "mem_29742") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29744, "mem_29744") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_29754, "mem_29754") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_29788, &ext_mem_29775, "ext_mem_29775") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_30996, &mem_out_29788, "mem_out_29788") != 0)
        return 1;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_param_tmp_30557, "mem_param_tmp_30557") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30556, "mem_param_tmp_30556") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30555, "mem_param_tmp_30555") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30554, "mem_param_tmp_30554") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_tmp_30553, "mem_param_tmp_30553") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29763, "mem_29763") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29761, "mem_29761") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30885, "incprefixes_mem_30885") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30883, "aggregates_mem_30883") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30881, "status_flags_mem_30881") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29759, "mem_29759") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29757, "mem_29757") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29752, "mem_29752") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29750, "mem_29750") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29748, "mem_29748") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30819, "segred_tmp_mem_30819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30817, "segred_tmp_mem_30817") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30680, "defunc_0_map_res_subhistos_mem_30680") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30678, "defunc_0_map_res_subhistos_mem_30678") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30576, "incprefixes_mem_30576") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30574, "aggregates_mem_30574") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30572, "status_flags_mem_30572") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29734, "mem_param_29734") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29731, "mem_param_29731") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29728, "mem_param_29728") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29725, "mem_param_29725") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_param_29722, "mem_param_29722") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29775, "ext_mem_29775") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29776, "ext_mem_29776") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29777, "ext_mem_29777") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29778, "ext_mem_29778") != 0)
            return 1;
        if (memblock_unref_device(ctx, &ext_mem_29779, "ext_mem_29779") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29754, "mem_29754") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29744, "mem_29744") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29742, "mem_29742") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29740, "mem_29740") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29737, "mem_29737") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29718, "mem_29718") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29716, "mem_29716") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30447, "incprefixes_mem_30447") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30445, "aggregates_mem_30445") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30443, "status_flags_mem_30443") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29714, "mem_29714") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29712, "mem_29712") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29709, "mem_29709") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29707, "mem_29707") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29705, "mem_29705") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29703, "mem_29703") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30381, "segred_tmp_mem_30381") != 0)
            return 1;
        if (memblock_unref_device(ctx, &segred_tmp_mem_30379, "segred_tmp_mem_30379") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30242, "defunc_0_map_res_subhistos_mem_30242") != 0)
            return 1;
        if (memblock_unref_device(ctx, &defunc_0_map_res_subhistos_mem_30240, "defunc_0_map_res_subhistos_mem_30240") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29699, "mem_29699") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29697, "mem_29697") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29695, "mem_29695") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_30138, "incprefixes_mem_30138") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_30136, "aggregates_mem_30136") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_30134, "status_flags_mem_30134") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29692, "mem_29692") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29982, "incprefixes_mem_29982") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29980, "aggregates_mem_29980") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29978, "incprefixes_mem_29978") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29976, "aggregates_mem_29976") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_29974, "status_flags_mem_29974") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29689, "mem_29689") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29687, "mem_29687") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29684, "mem_29684") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_29821, "incprefixes_mem_29821") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_29819, "aggregates_mem_29819") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_29797, "status_flags_mem_29797") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_29683, "mem_29683") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_29788, "mem_out_29788") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_human_genericf32(struct futhark_context *ctx, struct futhark_f32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_f32_1d *in3)
{
    int64_t mz2080U_18678 = (int64_t) 0;
    int64_t nz2081U_18679 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_29788;
    
    mem_out_29788.references = NULL;
    
    struct memblock_device A_mem_29680;
    
    A_mem_29680.references = NULL;
    
    struct memblock_device II1_mem_29679;
    
    II1_mem_29679.references = NULL;
    
    struct memblock_device shp_mem_29678;
    
    shp_mem_29678.references = NULL;
    
    struct memblock_device ks_mem_29677;
    
    ks_mem_29677.references = NULL;
    ks_mem_29677 = in0->mem;
    mz2080U_18678 = in0->shape[0];
    shp_mem_29678 = in1->mem;
    mz2080U_18678 = in1->shape[0];
    II1_mem_29679 = in2->mem;
    nz2081U_18679 = in2->shape[0];
    A_mem_29680 = in3->mem;
    nz2081U_18679 = in3->shape[0];
    if (!(mz2080U_18678 == in0->shape[0] && (mz2080U_18678 == in1->shape[0] && (nz2081U_18679 == in2->shape[0] && nz2081U_18679 == in3->shape[0])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_human_genericf32(ctx, &mem_out_29788, ks_mem_29677, shp_mem_29678, II1_mem_29679, A_mem_29680, mz2080U_18678, nz2081U_18679);
        if (ret == 0) {
            struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
            struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
            struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
            struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
            struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
            struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
            struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
            struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
            
            assert((*out0 = (struct futhark_f32_1d *) malloc(sizeof(struct futhark_f32_1d))) != NULL);
            (*out0)->mem = mem_out_29788;
            (*out0)->shape[0] = mz2080U_18678;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_human_genericf64(struct futhark_context *ctx, struct futhark_f64_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_f64_1d *in3)
{
    int64_t mz2080U_21995 = (int64_t) 0;
    int64_t nz2081U_21996 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_29788;
    
    mem_out_29788.references = NULL;
    
    struct memblock_device A_mem_29680;
    
    A_mem_29680.references = NULL;
    
    struct memblock_device II1_mem_29679;
    
    II1_mem_29679.references = NULL;
    
    struct memblock_device shp_mem_29678;
    
    shp_mem_29678.references = NULL;
    
    struct memblock_device ks_mem_29677;
    
    ks_mem_29677.references = NULL;
    ks_mem_29677 = in0->mem;
    mz2080U_21995 = in0->shape[0];
    shp_mem_29678 = in1->mem;
    mz2080U_21995 = in1->shape[0];
    II1_mem_29679 = in2->mem;
    nz2081U_21996 = in2->shape[0];
    A_mem_29680 = in3->mem;
    nz2081U_21996 = in3->shape[0];
    if (!(mz2080U_21995 == in0->shape[0] && (mz2080U_21995 == in1->shape[0] && (nz2081U_21996 == in2->shape[0] && nz2081U_21996 == in3->shape[0])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_human_genericf64(ctx, &mem_out_29788, ks_mem_29677, shp_mem_29678, II1_mem_29679, A_mem_29680, mz2080U_21995, nz2081U_21996);
        if (ret == 0) {
            struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
            struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
            struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
            struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
            struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
            struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
            struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
            struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
            
            assert((*out0 = (struct futhark_f64_1d *) malloc(sizeof(struct futhark_f64_1d))) != NULL);
            (*out0)->mem = mem_out_29788;
            (*out0)->shape[0] = mz2080U_21995;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_human_generici32(struct futhark_context *ctx, struct futhark_i32_1d **out0, const struct futhark_i32_1d *in0, const struct futhark_i32_1d *in1, const struct futhark_i32_1d *in2, const struct futhark_i32_1d *in3)
{
    int64_t mz2080U_25210 = (int64_t) 0;
    int64_t nz2081U_25211 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_29788;
    
    mem_out_29788.references = NULL;
    
    struct memblock_device A_mem_29680;
    
    A_mem_29680.references = NULL;
    
    struct memblock_device II1_mem_29679;
    
    II1_mem_29679.references = NULL;
    
    struct memblock_device shp_mem_29678;
    
    shp_mem_29678.references = NULL;
    
    struct memblock_device ks_mem_29677;
    
    ks_mem_29677.references = NULL;
    ks_mem_29677 = in0->mem;
    mz2080U_25210 = in0->shape[0];
    shp_mem_29678 = in1->mem;
    mz2080U_25210 = in1->shape[0];
    II1_mem_29679 = in2->mem;
    nz2081U_25211 = in2->shape[0];
    A_mem_29680 = in3->mem;
    nz2081U_25211 = in3->shape[0];
    if (!(mz2080U_25210 == in0->shape[0] && (mz2080U_25210 == in1->shape[0] && (nz2081U_25211 == in2->shape[0] && nz2081U_25211 == in3->shape[0])))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_human_generici32(ctx, &mem_out_29788, ks_mem_29677, shp_mem_29678, II1_mem_29679, A_mem_29680, mz2080U_25210, nz2081U_25211);
        if (ret == 0) {
            struct memblock_device counters_mem_30383 = ctx->constants->counters_mem_30383;
            struct memblock_device counters_mem_30821 = ctx->constants->counters_mem_30821;
            struct memblock_device global_dynid_mem_29823 = ctx->constants->global_dynid_mem_29823;
            struct memblock_device global_dynid_mem_29984 = ctx->constants->global_dynid_mem_29984;
            struct memblock_device global_dynid_mem_30140 = ctx->constants->global_dynid_mem_30140;
            struct memblock_device global_dynid_mem_30449 = ctx->constants->global_dynid_mem_30449;
            struct memblock_device global_dynid_mem_30578 = ctx->constants->global_dynid_mem_30578;
            struct memblock_device global_dynid_mem_30887 = ctx->constants->global_dynid_mem_30887;
            
            assert((*out0 = (struct futhark_i32_1d *) malloc(sizeof(struct futhark_i32_1d))) != NULL);
            (*out0)->mem = mem_out_29788;
            (*out0)->shape[0] = mz2080U_25210;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
